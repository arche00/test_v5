"""
Suffix ìœˆë„ìš° í¬ê¸°ë³„ ì‹ ë¢°ë„ ì¡°íšŒ ì•±
ngram_chunk í…Œì´ë¸”ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ suffixì˜ ìœˆë„ìš° í¬ê¸°ë³„ ì‹ ë¢°ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í‘œì‹œ
"""

import streamlit as st
import pandas as pd
import os
import sys

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from svg_parser_module import get_change_point_db_connection

# íŽ˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Suffix ì‹ ë¢°ë„ ì¡°íšŒ",
    page_icon="ðŸ“Š",
    layout="wide"
)

def calculate_suffix_confidence(df):
    """
    ngram_chunk ë°ì´í„°ì—ì„œ suffixë³„ ì‹ ë¢°ë„ ê³„ì‚°
    
    Args:
        df: ngram_chunk í…Œì´ë¸”ì˜ DataFrame (window_size, prefix, suffix, count í¬í•¨)
           ì´ë¯¸ ì§‘ê³„ëœ ë°ì´í„°ì´ë¯€ë¡œ count ì»¬ëŸ¼ì„ ì§ì ‘ ì‚¬ìš©
    
    Returns:
        DataFrame: suffixë³„ ì‹ ë¢°ë„ ì •ë³´
    """
    if df.empty:
        return pd.DataFrame()
    
    # ì´ë¯¸ ì§‘ê³„ëœ ë°ì´í„°ì´ë¯€ë¡œ count ì»¬ëŸ¼ì„ ì§ì ‘ ì‚¬ìš©
    # ê° prefixë³„ë¡œ suffix ë¶„í¬ ê³„ì‚°
    prefix_totals = df.groupby(['window_size', 'prefix'])['count'].sum().reset_index(name='total_count')
    
    # ë³‘í•©í•˜ì—¬ ë¹„ìœ¨ ê³„ì‚°
    merged = df.merge(prefix_totals, on=['window_size', 'prefix'])
    merged['ratio'] = merged['count'] / merged['total_count']
    
    # ê° prefixë³„ë¡œ bì™€ p suffixì˜ ë¹„ìœ¨ ê³„ì‚°
    suffix_stats = []
    for (window_size, prefix), group in merged.groupby(['window_size', 'prefix']):
        # suffixë³„ count í•©ê³„ ê³„ì‚°
        b_count = group[group['suffix'] == 'b']['count'].sum()
        p_count = group[group['suffix'] == 'p']['count'].sum()
        t_count = group[group['suffix'] == 't']['count'].sum()
        total = b_count + p_count + t_count
        
        if total > 0:
            b_ratio = b_count / total
            p_ratio = p_count / total
            t_ratio = t_count / total
            
            # ì‹ ë¢°ë„ ê³„ì‚°: bì™€ pì˜ ë¹„ìœ¨ ì°¨ì´ (ì ˆëŒ€ê°’)
            confidence = abs(b_ratio - p_ratio)
            
            # ê°€ìž¥ ë¹ˆë„ê°€ ë†’ì€ suffix
            most_common_idx = group['count'].idxmax()
            most_common_suffix = group.loc[most_common_idx, 'suffix']
            most_common_count = group.loc[most_common_idx, 'count']
            most_common_ratio = group.loc[most_common_idx, 'ratio']
            
            suffix_stats.append({
                'window_size': window_size,
                'prefix': prefix,
                'b_count': b_count,
                'p_count': p_count,
                't_count': t_count,
                'total_count': total,
                'b_ratio': b_ratio,
                'p_ratio': p_ratio,
                't_ratio': t_ratio,
                'confidence': confidence,
                'most_common_suffix': most_common_suffix,
                'most_common_count': most_common_count,
                'most_common_ratio': most_common_ratio
            })
    
    return pd.DataFrame(suffix_stats)


def load_ngram_chunks():
    """
    ngram_chunk í…Œì´ë¸”ì—ì„œ ë°ì´í„° ë¡œë“œ
    """
    try:
        conn = get_change_point_db_connection()
        if conn is None:
            return pd.DataFrame()
        
        # í…Œì´ë¸” ì´ë¦„ í™•ì¸ (ngram_chunk ë˜ëŠ” ngram_chunks_change_point)
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE '%ngram%'")
        tables = [row[0] for row in cursor.fetchall()]
        
        table_name = None
        if 'ngram_chunk' in tables:
            table_name = 'ngram_chunk'
        elif 'ngram_chunks_change_point' in tables:
            table_name = 'ngram_chunks_change_point'
        else:
            st.error("ngram_chunk ë˜ëŠ” ngram_chunks_change_point í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            conn.close()
            return pd.DataFrame()
        
        query = f"""
            SELECT window_size, prefix, suffix, COUNT(*) as count
            FROM {table_name}
            GROUP BY window_size, prefix, suffix
            ORDER BY window_size, prefix, suffix
        """
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        return df
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()


def get_summary_statistics(confidence_df):
    """
    ì‹ ë¢°ë„ ë°ì´í„°ì˜ ìš”ì•½ í†µê³„ ê³„ì‚°
    
    Args:
        confidence_df: calculate_suffix_confidenceë¡œ ê³„ì‚°ëœ DataFrame
    
    Returns:
        dict: ìš”ì•½ í†µê³„
    """
    if confidence_df.empty:
        return {}
    
    summary = {}
    
    for window_size in sorted(confidence_df['window_size'].unique()):
        window_data = confidence_df[confidence_df['window_size'] == window_size]
        
        summary[window_size] = {
            'total_prefixes': len(window_data),
            'avg_confidence': window_data['confidence'].mean(),
            'max_confidence': window_data['confidence'].max(),
            'min_confidence': window_data['confidence'].min(),
            'high_confidence_count': len(window_data[window_data['confidence'] >= 0.5]),
            'medium_confidence_count': len(window_data[(window_data['confidence'] >= 0.3) & (window_data['confidence'] < 0.5)]),
            'low_confidence_count': len(window_data[window_data['confidence'] < 0.3]),
            'total_ngrams': window_data['total_count'].sum(),
            'avg_total_count': window_data['total_count'].mean(),
        }
    
    return summary


def main():
    st.title("ðŸ“Š Suffix ìœˆë„ìš° í¬ê¸°ë³„ ì‹ ë¢°ë„ ì¡°íšŒ")
    st.markdown("ngram_chunk í…Œì´ë¸”ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ suffixì˜ ìœˆë„ìš° í¬ê¸°ë³„ ì‹ ë¢°ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤.")
    st.markdown("---")
    
    # ë°ì´í„° ë¡œë“œ
    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        ngram_df = load_ngram_chunks()
    
    if ngram_df.empty:
        st.warning("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ngram_chunk í…Œì´ë¸”ì— ë°ì´í„°ê°€ ìžˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    st.success(f"âœ… {len(ngram_df)}ê°œì˜ ngram ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    
    # ì‹ ë¢°ë„ ê³„ì‚°
    with st.spinner("ì‹ ë¢°ë„ ê³„ì‚° ì¤‘..."):
        confidence_df = calculate_suffix_confidence(ngram_df)
    
    if confidence_df.empty:
        st.warning("âš ï¸ ì‹ ë¢°ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìš”ì•½ í†µê³„
    st.header("ðŸ“ˆ ìš”ì•½ í†µê³„")
    summary = get_summary_statistics(confidence_df)
    
    # ìœˆë„ìš° í¬ê¸°ë³„ ìš”ì•½ í‘œì‹œ
    summary_rows = []
    for window_size in sorted(summary.keys()):
        stats = summary[window_size]
        summary_rows.append({
            'ìœˆë„ìš° í¬ê¸°': window_size,
            'ì´ Prefix ìˆ˜': stats['total_prefixes'],
            'í‰ê·  ì‹ ë¢°ë„': f"{stats['avg_confidence']:.4f}",
            'ìµœëŒ€ ì‹ ë¢°ë„': f"{stats['max_confidence']:.4f}",
            'ìµœì†Œ ì‹ ë¢°ë„': f"{stats['min_confidence']:.4f}",
            'ê³ ì‹ ë¢°ë„ (â‰¥0.5)': stats['high_confidence_count'],
            'ì¤‘ì‹ ë¢°ë„ (0.3~0.5)': stats['medium_confidence_count'],
            'ì €ì‹ ë¢°ë„ (<0.3)': stats['low_confidence_count'],
            'ì´ N-gram ìˆ˜': stats['total_ngrams'],
            'í‰ê·  N-gram ìˆ˜': f"{stats['avg_total_count']:.1f}",
        })
    
    summary_df = pd.DataFrame(summary_rows)
    st.dataframe(summary_df, use_container_width=True, hide_index=True)
    
    st.markdown("---")
    
    # ìœˆë„ìš° í¬ê¸°ë³„ ìƒì„¸ ì‹ ë¢°ë„ í…Œì´ë¸”
    st.header("ðŸ“‹ ìœˆë„ìš° í¬ê¸°ë³„ ìƒì„¸ ì‹ ë¢°ë„")
    
    window_sizes = sorted(confidence_df['window_size'].unique())
    selected_window = st.selectbox(
        "ìœˆë„ìš° í¬ê¸° ì„ íƒ",
        options=window_sizes,
        index=0 if window_sizes else None
    )
    
    if selected_window:
        window_data = confidence_df[confidence_df['window_size'] == selected_window].copy()
        
        # ì •ë ¬ ì˜µì…˜
        col_sort1, col_sort2 = st.columns(2)
        with col_sort1:
            sort_by = st.selectbox(
                "ì •ë ¬ ê¸°ì¤€",
                options=['confidence', 'total_count', 'prefix'],
                format_func=lambda x: {'confidence': 'ì‹ ë¢°ë„', 'total_count': 'ì´ ê°œìˆ˜', 'prefix': 'Prefix'}[x],
                index=0
            )
        with col_sort2:
            sort_ascending = st.checkbox("ì˜¤ë¦„ì°¨ìˆœ", value=False)
        
        # ì •ë ¬
        window_data = window_data.sort_values(by=sort_by, ascending=sort_ascending)
        
        # ìˆœì„œ ë²ˆí˜¸ ì¶”ê°€ (1ë¶€í„° ì‹œìž‘)
        window_data = window_data.reset_index(drop=True)
        window_data.insert(0, 'ìˆœì„œ', range(1, len(window_data) + 1))
        
        # ì»¬ëŸ¼ëª… í•œê¸€í™”
        display_data = window_data.copy()
        display_data = display_data.rename(columns={
            'window_size': 'ìœˆë„ìš° í¬ê¸°',
            'prefix': 'Prefix',
            'b_count': 'B ê°œìˆ˜',
            'p_count': 'P ê°œìˆ˜',
            't_count': 'T ê°œìˆ˜',
            'total_count': 'ì´ ê°œìˆ˜',
            'b_ratio': 'B ë¹„ìœ¨',
            'p_ratio': 'P ë¹„ìœ¨',
            't_ratio': 'T ë¹„ìœ¨',
            'confidence': 'ì‹ ë¢°ë„',
            'most_common_suffix': 'ê°€ìž¥ ë¹ˆë„ ë†’ì€ Suffix',
            'most_common_count': 'ê°€ìž¥ ë¹ˆë„ ë†’ì€ ê°œìˆ˜',
            'most_common_ratio': 'ê°€ìž¥ ë¹ˆë„ ë†’ì€ ë¹„ìœ¨'
        })
        
        # ìˆ«ìž í¬ë§·íŒ…
        display_data['B ë¹„ìœ¨'] = display_data['B ë¹„ìœ¨'].apply(lambda x: f"{x:.4f}")
        display_data['P ë¹„ìœ¨'] = display_data['P ë¹„ìœ¨'].apply(lambda x: f"{x:.4f}")
        display_data['T ë¹„ìœ¨'] = display_data['T ë¹„ìœ¨'].apply(lambda x: f"{x:.4f}")
        display_data['ì‹ ë¢°ë„'] = display_data['ì‹ ë¢°ë„'].apply(lambda x: f"{x:.4f}")
        display_data['ê°€ìž¥ ë¹ˆë„ ë†’ì€ ë¹„ìœ¨'] = display_data['ê°€ìž¥ ë¹ˆë„ ë†’ì€ ë¹„ìœ¨'].apply(lambda x: f"{x:.4f}")
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì • (ìˆœì„œê°€ ê°€ìž¥ ì™¼ìª½ì— ì˜¤ë„ë¡)
        column_order = ['ìˆœì„œ'] + [col for col in display_data.columns if col != 'ìˆœì„œ']
        display_data = display_data[column_order]
        
        st.dataframe(
            display_data,
            use_container_width=True,
            hide_index=True
        )
        
        st.info(f"ì´ {len(window_data)}ê°œì˜ prefixì— ëŒ€í•œ ì‹ ë¢°ë„ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    st.header("ðŸ’¾ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
    
    col_dl1, col_dl2 = st.columns(2)
    
    with col_dl1:
        # ì‹ ë¢°ë„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        csv_confidence = confidence_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ðŸ“¥ ì‹ ë¢°ë„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
            data=csv_confidence,
            file_name=f"suffix_confidence_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with col_dl2:
        # ìš”ì•½ í†µê³„ ë‹¤ìš´ë¡œë“œ
        csv_summary = summary_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ðŸ“¥ ìš”ì•½ í†µê³„ ë‹¤ìš´ë¡œë“œ (CSV)",
            data=csv_summary,
            file_name=f"suffix_confidence_summary_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )


if __name__ == "__main__":
    main()
