"""
Walk-forward Analysis ê¸°ë°˜ ì‹ ë¢°ë„ íŒ¨í„´ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜

- 5íšŒ ì—°ì† ì‹¤íŒ¨ ë°©ì§€ ëª©í‘œ
- ìœˆë„ìš° í¬ê¸° 8-12, ì„ê³„ê°’ 50-65% ë²”ìœ„ íƒìƒ‰
- ìµœì†Œ í‘œë³¸ ìˆ˜ í•„í„° ì ìš©
"""

import sys
from pathlib import Path

# ìƒìœ„ í´ë”ì˜ ëª¨ë“ˆì„ importí•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

import pandas as pd
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

from svg_parser_module import get_change_point_db_connection
from change_point_prediction_module import (
    save_or_update_predictions_for_change_point_data,
    batch_validate_multi_window_scenario_cp,
)


def count_five_consecutive_losses(history):
    """
    íˆìŠ¤í† ë¦¬ì—ì„œ 5íšŒ ì´ìƒ ì—°ì† ì‹¤íŒ¨ êµ¬ê°„ì˜ ê°œìˆ˜ë¥¼ ì¹´ìš´íŠ¸
    
    Args:
        history: ê²€ì¦ ê²°ê³¼ì˜ history ë¦¬ìŠ¤íŠ¸
    
    Returns:
        int: 5íšŒ ì´ìƒ ì—°ì† ì‹¤íŒ¨ê°€ ë°œìƒí•œ êµ¬ê°„ì˜ ê°œìˆ˜
    """
    if not history:
        return 0
    
    failure_score = 0
    consecutive_failures = 0
    in_failure_sequence = False
    
    for entry in history:
        is_correct = entry.get("is_correct")
        # ì˜ˆì¸¡ì´ ìˆ˜í–‰ëœ ê²½ìš°ë§Œ ì¹´ìš´íŠ¸
        if is_correct is not None:
            if not is_correct:
                consecutive_failures += 1
                if consecutive_failures >= 5 and not in_failure_sequence:
                    # 5íšŒ ì—°ì† ì‹¤íŒ¨ ì‹œì‘
                    in_failure_sequence = True
                    failure_score += 1
            else:
                # ì¼ì¹˜í•˜ë©´ ì—°ì† ì‹¤íŒ¨ ë¦¬ì…‹
                consecutive_failures = 0
                in_failure_sequence = False
    
    return failure_score


def measure_performance(validation_results):
    """
    ê²€ì¦ ê²°ê³¼ì—ì„œ ì„±ê³¼ ì§€í‘œ ê³„ì‚°
    
    Args:
        validation_results: batch_validate_multi_window_scenario_cp() ë°˜í™˜ê°’
    
    Returns:
        dict: {
            "mcl": Max Consecutive Losses,
            "total_bets": Total Bets,
            "win_rate": Win Rate (%),
            "failure_score": 5ì—°íŒ¨ ë°œìƒ íšŸìˆ˜
        }
    """
    if not validation_results or not validation_results.get("results"):
        return {
            "mcl": 0,
            "total_bets": 0,
            "win_rate": 0.0,
            "failure_score": 0,
        }
    
    # ì „ì²´ ê²°ê³¼ ì§‘ê³„
    all_history = []
    total_predictions = 0
    max_consecutive_failures = 0
    
    for result in validation_results["results"]:
        history = result.get("history", [])
        all_history.extend(history)
        total_predictions += result.get("total_predictions", 0)
        max_consecutive_failures = max(
            max_consecutive_failures,
            result.get("max_consecutive_failures", 0)
        )
    
    # Failure Score ê³„ì‚° (ì „ì²´ íˆìŠ¤í† ë¦¬ì—ì„œ 5ì—°íŒ¨ êµ¬ê°„ ì¹´ìš´íŠ¸)
    failure_score = count_five_consecutive_losses(all_history)
    
    # Win Rate ê³„ì‚°
    total_correct = sum(
        1 for entry in all_history
        if entry.get("is_correct") is True
    )
    win_rate = (total_correct / total_predictions * 100) if total_predictions > 0 else 0.0
    
    return {
        "mcl": max_consecutive_failures,
        "total_bets": total_predictions,
        "win_rate": win_rate,
        "failure_score": failure_score,
    }


def _run_single_combination(
    all_ids,
    initial_train_count,
    validation_count,
    window_size,
    threshold,
    method,
    min_sample_count,
    total_count,
):
    """
    ë‹¨ì¼ ì¡°í•©ì— ëŒ€í•œ Walk-forward Analysis ì‹¤í–‰
    
    Args:
        all_ids: ì „ì²´ ë°ì´í„° ID ë¦¬ìŠ¤íŠ¸
        initial_train_count: ì´ˆê¸° í•™ìŠµ ë°ì´í„° ê°œìˆ˜
        validation_count: ê²€ì¦ ë°ì´í„° ê°œìˆ˜
        window_size: ìœˆë„ìš° í¬ê¸°
        threshold: ì„ê³„ê°’
        method: ì˜ˆì¸¡ ë°©ë²•
        min_sample_count: ìµœì†Œ í‘œë³¸ ìˆ˜
        total_count: ì „ì²´ ë°ì´í„° ê°œìˆ˜
    
    Returns:
        dict: result_entry ë˜ëŠ” None
    """
    try:
        # Walk-forward Analysis ì‹¤í–‰
        train_ids = all_ids[:initial_train_count].copy()
        validation_start_idx = initial_train_count
        
        # ì „ì²´ ê²€ì¦ ê²°ê³¼ë¥¼ ëˆ„ì í•  ë¦¬ìŠ¤íŠ¸
        all_validation_results = []
        
        # ê²€ì¦ êµ¬ê°„ì„ ìˆœíšŒ
        while validation_start_idx < total_count:
            validation_end_idx = min(
                validation_start_idx + validation_count,
                total_count
            )
            validation_ids = all_ids[validation_start_idx:validation_end_idx]
            
            if not validation_ids:
                break
            
            # í•™ìŠµ ë°ì´í„°ë¡œ ì˜ˆì¸¡ê°’ ìƒì„± (ìµœì†Œ í‘œë³¸ ìˆ˜ í•„í„° ì ìš©)
            cutoff_id = train_ids[-1] if train_ids else None
            try:
                save_or_update_predictions_for_change_point_data(
                    cutoff_grid_string_id=cutoff_id,
                    window_sizes=(window_size,),
                    methods=(method,),
                    thresholds=(threshold,),
                    min_sample_count=min_sample_count,
                )
            except Exception as e:
                # ì˜ˆì¸¡ê°’ ìƒì„± ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ
                return None
            
            # ê²€ì¦ ìˆ˜í–‰
            validation_cutoff_id = train_ids[-1] if train_ids else 0
            validation_result = batch_validate_multi_window_scenario_cp(
                cutoff_grid_string_id=validation_cutoff_id,
                window_sizes=(window_size,),
                method=method,
                threshold=threshold,
            )
            
            if validation_result and validation_result.get("results"):
                all_validation_results.append(validation_result)
            
            # ê²€ì¦ ì™„ë£Œ í›„ í•™ìŠµ ë°ì´í„°ì— ê²€ì¦ ë°ì´í„° ì¶”ê°€ (Rolling ì—…ë°ì´íŠ¸)
            train_ids.extend(validation_ids)
            validation_start_idx = validation_end_idx
        
        # ëª¨ë“  ê²€ì¦ êµ¬ê°„ì˜ ê²°ê³¼ë¥¼ ì§‘ê³„
        if not all_validation_results:
            return None
        
        # ê²°ê³¼ ë³‘í•©
        merged_results = {
            "results": [],
            "summary": {
                "total_grid_strings": 0,
                "avg_accuracy": 0.0,
                "max_consecutive_failures": 0,
                "avg_max_consecutive_failures": 0.0,
                "total_steps": 0,
                "total_failures": 0,
                "total_predictions": 0,
                "total_skipped": 0,
            },
            "grid_string_ids": [],
        }
        
        for vr in all_validation_results:
            merged_results["results"].extend(vr.get("results", []))
            merged_results["grid_string_ids"].extend(vr.get("grid_string_ids", []))
        
        # ìš”ì•½ í†µê³„ ì¬ê³„ì‚°
        if merged_results["results"]:
            n = len(merged_results["results"])
            merged_results["summary"] = {
                "total_grid_strings": n,
                "avg_accuracy": sum(x["accuracy"] for x in merged_results["results"]) / n,
                "max_consecutive_failures": max(x["max_consecutive_failures"] for x in merged_results["results"]),
                "avg_max_consecutive_failures": sum(x["max_consecutive_failures"] for x in merged_results["results"]) / n,
                "total_steps": sum(x["total_steps"] for x in merged_results["results"]),
                "total_failures": sum(x["total_failures"] for x in merged_results["results"]),
                "total_predictions": sum(x["total_predictions"] for x in merged_results["results"]),
                "total_skipped": sum(x.get("total_skipped", 0) for x in merged_results["results"]),
            }
        
        # ì„±ê³¼ ì¸¡ì •
        performance = measure_performance(merged_results)
        
        result_entry = {
            "window_size": window_size,
            "threshold": threshold,
            "mcl": performance["mcl"],
            "total_bets": performance["total_bets"],
            "win_rate": performance["win_rate"],
            "failure_score": performance["failure_score"],
            "is_passed": performance["failure_score"] == 0,
        }
        return result_entry
        
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ None ë°˜í™˜
        import traceback
        print(f"Error in _run_single_combination: {e}")
        print(traceback.format_exc())
        return None


def walk_forward_simulation_cp(
    window_sizes=(8, 9, 10, 11, 12),
    threshold_range=(50, 65, 1),  # (min, max, step)
    method="ë¹ˆë„ ê¸°ë°˜",
    initial_train_ratio=0.4,
    validation_ratio=0.1,
    min_sample_count=15,  # S_min
    progress_callback=None,
    max_workers=10,  # ThreadPoolExecutor ì‘ì—…ì ìˆ˜
):
    """
    Walk-forward Analysis ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜
    
    Args:
        window_sizes: ìœˆë„ìš° í¬ê¸° ëª©ë¡
        threshold_range: ì„ê³„ê°’ ë²”ìœ„ (min, max, step)
        method: ì˜ˆì¸¡ ë°©ë²•
        initial_train_ratio: ì´ˆê¸° í•™ìŠµ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ 0.4 = 40%)
        validation_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ 0.1 = 10%)
        min_sample_count: ìµœì†Œ í‘œë³¸ ìˆ˜ (ê¸°ë³¸ 15)
        progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜ (pct, message)
    
    Returns:
        dict: {
            "results": [
                {
                    "window_size": W,
                    "threshold": T,
                    "mcl": Max Consecutive Losses,
                    "total_bets": Total Bets,
                    "win_rate": Win Rate,
                    "failure_score": 5ì—°íŒ¨ ë°œìƒ íšŸìˆ˜,
                    "is_passed": failure_score == 0
                }
            ],
            "optimal_combinations": [
                {"window_size": W, "threshold": T, ...}  # MCL < 5 ë§Œì¡±í•˜ëŠ” ì¡°í•©
            ]
        }
    """
    conn = get_change_point_db_connection()
    try:
        # ì§„í–‰ ìƒí™© ì½œë°± í˜¸ì¶œ (ë°ì´í„° ë¡œë“œ ì‹œì‘)
        if progress_callback:
            progress_callback(0.01, "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì™„ë£Œ. ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ì „ì²´ ë°ì´í„°ë¥¼ ì‹œê°„ ìˆœì„œë¡œ ë¡œë“œ
        df_all = pd.read_sql_query(
            "SELECT id FROM preprocessed_grid_strings ORDER BY id",
            conn,
        )
        
        if len(df_all) == 0:
            if progress_callback:
                progress_callback(1.0, "âš ï¸ ê²½ê³ : ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {
                "results": [],
                "optimal_combinations": [],
            }
        
        total_count = len(df_all)
        all_ids = df_all["id"].tolist()
        
        if progress_callback:
            progress_callback(0.02, f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {total_count:,}ê°œ ë ˆì½”ë“œ")
        
        # ë°ì´í„° ë¶„í•  ê³„ì‚°
        initial_train_count = int(total_count * initial_train_ratio)
        validation_count = int(total_count * validation_ratio)
        
        if progress_callback:
            progress_callback(0.03, f"ë°ì´í„° ë¶„í• : í•™ìŠµ {initial_train_count:,}ê°œ, ê²€ì¦ {validation_count:,}ê°œ")
        
        # ì„ê³„ê°’ ëª©ë¡ ìƒì„±
        threshold_min, threshold_max, threshold_step = threshold_range
        thresholds = []
        t = threshold_min
        while t <= threshold_max:
            thresholds.append(round(t, 1))
            t += threshold_step
        
        # ê²°ê³¼ ì €ì¥
        all_results = []
        total_combinations = len(window_sizes) * len(thresholds)
        
        if progress_callback:
            progress_callback(0.04, f"ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • ì™„ë£Œ: {len(window_sizes)}ê°œ ìœˆë„ìš° Ã— {len(thresholds)}ê°œ ì„ê³„ê°’ = ì´ {total_combinations}ê°œ ì¡°í•©")
        
        if progress_callback:
            progress_callback(
                0.05,
                f"ğŸš€ Walk-forward Analysis ì‹œì‘ | "
                f"ì´ {total_combinations}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸ ì˜ˆì • | "
                f"ìµœì í™” ëª¨ë“œ: ì˜ˆì¸¡ê°’ ìºì‹± + ThreadPoolExecutor ({max_workers}ê°œ ì‘ì—…ì)"
            )
        
        completed_count = 0
        start_time = time.time()
        
        # ë‹¨ê³„ 1: ìœˆë„ìš°ë³„ë¡œ ì˜ˆì¸¡ê°’ ìƒì„± (ìºì‹±)
        if progress_callback:
            progress_callback(0.06, f"ğŸ“¦ ì˜ˆì¸¡ê°’ ìƒì„± ì¤‘... (ìœˆë„ìš°ë³„ ìºì‹±)")
        
        # ìœˆë„ìš°ë³„ë¡œ ì˜ˆì¸¡ê°’ì„ ë¯¸ë¦¬ ìƒì„±í•˜ì—¬ ì¬ì‚¬ìš©
        # ê° ìœˆë„ìš°ì— ëŒ€í•´ ëª¨ë“  ì„ê³„ê°’ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ì„ í•œ ë²ˆì— ìƒì„±
        for window_idx, window_size in enumerate(window_sizes):
            if progress_callback:
                window_progress = 0.06 + (window_idx / len(window_sizes)) * 0.10
                progress_callback(
                    window_progress,
                    f"ğŸ“¦ ìœˆë„ìš° {window_size} ì˜ˆì¸¡ê°’ ìƒì„± ì¤‘... ({window_idx + 1}/{len(window_sizes)})"
                )
            
            # í•´ë‹¹ ìœˆë„ìš°ì— ëŒ€í•œ ëª¨ë“  ì„ê³„ê°’ì˜ ì˜ˆì¸¡ê°’ì„ í•œ ë²ˆì— ìƒì„±
            try:
                save_or_update_predictions_for_change_point_data(
                    cutoff_grid_string_id=None,  # ì „ì²´ ë°ì´í„° ì‚¬ìš©
                    window_sizes=(window_size,),
                    methods=(method,),
                    thresholds=thresholds,  # ëª¨ë“  ì„ê³„ê°’ í•œ ë²ˆì— ìƒì„±
                    min_sample_count=min_sample_count,
                )
            except Exception as e:
                if progress_callback:
                    progress_callback(
                        window_progress,
                        f"âš ï¸ ìœˆë„ìš° {window_size} ì˜ˆì¸¡ê°’ ìƒì„± ì‹¤íŒ¨: {str(e)}"
                    )
        
        if progress_callback:
            progress_callback(0.16, f"âœ… ì˜ˆì¸¡ê°’ ìƒì„± ì™„ë£Œ. ê²€ì¦ ì‹œì‘...")
        
        # ë‹¨ê³„ 2: ThreadPoolExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ê²€ì¦
        # ì¡°í•© ëª©ë¡ ìƒì„±
        combinations = []
        for window_size in window_sizes:
            for threshold in thresholds:
                combinations.append((window_size, threshold))
        
        def validate_single_combination(args):
            """ë‹¨ì¼ ì¡°í•© ê²€ì¦ í•¨ìˆ˜ (ThreadPoolExecutorìš©)"""
            (window_size, threshold, all_ids_local, initial_train_count_local, 
             validation_count_local, total_count_local, method_local) = args
            try:
                # ì˜ˆì¸¡ê°’ì€ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê²€ì¦ë§Œ ìˆ˜í–‰
                # Walk-forward Analysisë¥¼ ìœ„í•´ ê° ê²€ì¦ êµ¬ê°„ë³„ë¡œ ì‹¤í–‰
                train_ids = all_ids_local[:initial_train_count_local].copy()
                validation_start_idx = initial_train_count_local
                all_validation_results = []
                
                # ê²€ì¦ êµ¬ê°„ì„ ìˆœíšŒ
                while validation_start_idx < total_count_local:
                    validation_end_idx = min(
                        validation_start_idx + validation_count_local,
                        total_count_local
                    )
                    validation_ids = all_ids_local[validation_start_idx:validation_end_idx]
                    
                    if not validation_ids:
                        break
                    
                    # ê²€ì¦ ìˆ˜í–‰ (ì˜ˆì¸¡ê°’ì€ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŒ)
                    validation_cutoff_id = train_ids[-1] if train_ids else 0
                    validation_result = batch_validate_multi_window_scenario_cp(
                        cutoff_grid_string_id=validation_cutoff_id,
                        window_sizes=(window_size,),
                        method=method_local,
                        threshold=threshold,
                    )
                    
                    if validation_result and validation_result.get("results"):
                        all_validation_results.append(validation_result)
                    
                    # ê²€ì¦ ì™„ë£Œ í›„ í•™ìŠµ ë°ì´í„°ì— ê²€ì¦ ë°ì´í„° ì¶”ê°€ (Rolling ì—…ë°ì´íŠ¸)
                    train_ids.extend(validation_ids)
                    validation_start_idx = validation_end_idx
                
                # ê²°ê³¼ ì§‘ê³„
                if not all_validation_results:
                    return None
                
                # ê²°ê³¼ ë³‘í•©
                merged_results = {
                    "results": [],
                    "summary": {
                        "total_grid_strings": 0,
                        "avg_accuracy": 0.0,
                        "max_consecutive_failures": 0,
                        "avg_max_consecutive_failures": 0.0,
                        "total_steps": 0,
                        "total_failures": 0,
                        "total_predictions": 0,
                        "total_skipped": 0,
                    },
                    "grid_string_ids": [],
                }
                
                for vr in all_validation_results:
                    merged_results["results"].extend(vr.get("results", []))
                    merged_results["grid_string_ids"].extend(vr.get("grid_string_ids", []))
                
                # ìš”ì•½ í†µê³„ ì¬ê³„ì‚°
                if merged_results["results"]:
                    n = len(merged_results["results"])
                    merged_results["summary"] = {
                        "total_grid_strings": n,
                        "avg_accuracy": sum(x["accuracy"] for x in merged_results["results"]) / n,
                        "max_consecutive_failures": max(x["max_consecutive_failures"] for x in merged_results["results"]),
                        "avg_max_consecutive_failures": sum(x["max_consecutive_failures"] for x in merged_results["results"]) / n,
                        "total_steps": sum(x["total_steps"] for x in merged_results["results"]),
                        "total_failures": sum(x["total_failures"] for x in merged_results["results"]),
                        "total_predictions": sum(x["total_predictions"] for x in merged_results["results"]),
                        "total_skipped": sum(x.get("total_skipped", 0) for x in merged_results["results"]),
                    }
                
                # ì„±ê³¼ ì¸¡ì •
                performance = measure_performance(merged_results)
                
                return {
                    "window_size": window_size,
                    "threshold": threshold,
                    "mcl": performance["mcl"],
                    "total_bets": performance["total_bets"],
                    "win_rate": performance["win_rate"],
                    "failure_score": performance["failure_score"],
                    "is_passed": performance["failure_score"] == 0,
                }
            except Exception as e:
                import traceback
                print(f"Error in validate_single_combination (ìœˆë„ìš°={window_size}, ì„ê³„ê°’={threshold}): {e}")
                print(traceback.format_exc())
                return None
        
        # ThreadPoolExecutorë¡œ ë³‘ë ¬ ê²€ì¦ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ëª¨ë“  ì‘ì—… ì œì¶œ (í•„ìš”í•œ ì¸ì ëª¨ë‘ ì „ë‹¬)
            future_to_combo = {
                executor.submit(
                    validate_single_combination,
                    (window_size, threshold, all_ids, initial_train_count, 
                     validation_count, total_count, method)
                ): (window_size, threshold)
                for window_size, threshold in combinations
            }
            
            # ì™„ë£Œëœ ì‘ì—…ë¶€í„° ì²˜ë¦¬
            last_callback_time = time.time()
            callback_interval = 0.5  # 0.5ì´ˆë§ˆë‹¤ ì½œë°± í˜¸ì¶œ
            
            for future in as_completed(future_to_combo):
                combo = future_to_combo[future]
                window_size, threshold = combo
                completed_count += 1
                
                try:
                    result_entry = future.result()
                    
                    if result_entry is not None:
                        all_results.append(result_entry)
                    
                    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                    current_time = time.time()
                    if progress_callback and (current_time - last_callback_time >= callback_interval or completed_count == total_combinations):
                        last_callback_time = current_time
                        
                        # ì§„í–‰ë¥  ê³„ì‚° (ì˜ˆì¸¡ê°’ ìƒì„± 16%, ê²€ì¦ 84%)
                        progress = 0.16 + (completed_count / total_combinations) * 0.84
                        elapsed = time.time() - start_time
                        
                        if completed_count > 0:
                            avg_time_per_combo = elapsed / completed_count
                            remaining = (total_combinations - completed_count) * avg_time_per_combo
                            
                            # ê²½ê³¼ ì‹œê°„ í¬ë§·íŒ…
                            elapsed_hours = int(elapsed // 3600)
                            elapsed_min = int((elapsed % 3600) // 60)
                            elapsed_sec = int(elapsed % 60)
                            
                            if elapsed_hours > 0:
                                elapsed_str = f"{elapsed_hours}ì‹œê°„ {elapsed_min}ë¶„ {elapsed_sec}ì´ˆ"
                            elif elapsed_min > 0:
                                elapsed_str = f"{elapsed_min}ë¶„ {elapsed_sec}ì´ˆ"
                            else:
                                elapsed_str = f"{elapsed_sec}ì´ˆ"
                            
                            # ë‚¨ì€ ì‹œê°„ í¬ë§·íŒ…
                            remaining_hours = int(remaining // 3600)
                            remaining_min = int((remaining % 3600) // 60)
                            remaining_sec = int(remaining % 60)
                            
                            if remaining_hours > 0:
                                remaining_str = f"{remaining_hours}ì‹œê°„ {remaining_min}ë¶„ {remaining_sec}ì´ˆ"
                            elif remaining_min > 0:
                                remaining_str = f"{remaining_min}ë¶„ {remaining_sec}ì´ˆ"
                            else:
                                remaining_str = f"{remaining_sec}ì´ˆ"
                            
                            # ì§„í–‰ë¥  í¼ì„¼íŠ¸
                            progress_pct = progress * 100
                            
                            # í˜„ì¬ ìµœê³  ê²°ê³¼ ì¶”ì 
                            best_result = None
                            if all_results:
                                passed_results = [r for r in all_results if r.get("is_passed", False)]
                                if passed_results:
                                    best_result = min(passed_results, key=lambda x: (x["threshold"], x["window_size"]))
                            
                            # ìƒíƒœ ë©”ì‹œì§€ êµ¬ì„±
                            status_parts = [
                                f"ì§„í–‰ë¥ : {progress_pct:.1f}% ({completed_count}/{total_combinations})",
                                f"ê²½ê³¼ ì‹œê°„: {elapsed_str}",
                                f"ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining_str}",
                            ]
                            
                            if best_result:
                                status_parts.append(
                                    f"í˜„ì¬ ìµœê³ : ìœˆë„ìš°={best_result['window_size']}, "
                                    f"ì„ê³„ê°’={best_result['threshold']}% (MCL={best_result['mcl']}, "
                                    f"Failure Score={best_result['failure_score']})"
                                )
                            else:
                                status_parts.append(f"ì²˜ë¦¬ ì¤‘: ìœˆë„ìš°={window_size}, ì„ê³„ê°’={threshold}%")
                            
                            status_parts.append(f"ë³‘ë ¬ ì‘ì—…ì: {max_workers}ê°œ")
                            
                            progress_callback(progress, " | ".join(status_parts))
                
                except Exception as e:
                    # ì—ëŸ¬ ë°œìƒ ì‹œ ê³„ì† ì§„í–‰
                    if progress_callback:
                        error_msg = str(e)
                        progress_callback(
                            progress,
                            f"âŒ ì¡°í•© (ìœˆë„ìš°={window_size}, ì„ê³„ê°’={threshold}%) ì˜¤ë¥˜: {error_msg} (ê³„ì† ì§„í–‰)"
                        )
                    pass
        
        # ìµœì  ì¡°í•© ì°¾ê¸° (MCL < 5 ë§Œì¡±í•˜ëŠ” ì¡°í•© ì¤‘ ê°€ì¥ ë‚®ì€ T)
        optimal_combinations = []
        for result in all_results:
            if result["mcl"] < 5:  # MCL < 5 ë§Œì¡±
                optimal_combinations.append(result)
        
        # ì„ê³„ê°’ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚®ì€ ìˆœ)
        optimal_combinations.sort(key=lambda x: (x["threshold"], x["window_size"]))
        
        if progress_callback:
            total_elapsed = time.time() - start_time
            elapsed_hours = int(total_elapsed // 3600)
            elapsed_min = int((total_elapsed % 3600) // 60)
            elapsed_sec = int(total_elapsed % 60)
            
            if elapsed_hours > 0:
                elapsed_str = f"{elapsed_hours}ì‹œê°„ {elapsed_min}ë¶„ {elapsed_sec}ì´ˆ"
            elif elapsed_min > 0:
                elapsed_str = f"{elapsed_min}ë¶„ {elapsed_sec}ì´ˆ"
            else:
                elapsed_str = f"{elapsed_sec}ì´ˆ"
            
            optimal_count = len(optimal_combinations)
            status_msg = (
                f"âœ… ì™„ë£Œ! | "
                f"ì´ ì†Œìš” ì‹œê°„: {elapsed_str} | "
                f"í…ŒìŠ¤íŠ¸ ì¡°í•©: {len(all_results)}ê°œ | "
                f"MCL < 5 ë§Œì¡± ì¡°í•©: {optimal_count}ê°œ"
            )
            
            if optimal_count > 0:
                best = optimal_combinations[0]
                status_msg += (
                    f" | ìµœì  ì¡°í•©: ìœˆë„ìš°={best['window_size']}, "
                    f"ì„ê³„ê°’={best['threshold']}% (MCL={best['mcl']}, "
                    f"Failure Score={best['failure_score']})"
                )
            
            progress_callback(1.0, status_msg)
        
        return {
            "results": all_results,
            "optimal_combinations": optimal_combinations,
        }
    finally:
        conn.close()
