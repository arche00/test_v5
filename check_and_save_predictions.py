"""
stored_predictions í…Œì´ë¸” ìƒíƒœ í™•ì¸ ë° ì˜ˆì¸¡ê°’ ì €ì¥ ìŠ¤í¬ë¦½íŠ¸
"""
import sqlite3
import os
import sys

# hypothesis_validation_app.pyì˜ í•¨ìˆ˜ë“¤ì„ importí•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Streamlit ì—†ì´ ì‹¤í–‰í•˜ê¸° ìœ„í•´ mock ì„¤ì •
class MockStreamlit:
    def error(self, msg):
        print(f"[ERROR] {msg}")
    def warning(self, msg):
        print(f"[WARNING] {msg}")
    def info(self, msg):
        print(f"[INFO] {msg}")

# streamlit ëª¨ë“ˆì„ mockìœ¼ë¡œ êµì²´
sys.modules['streamlit'] = type(sys)('streamlit')
sys.modules['streamlit'].st = MockStreamlit()

# ì´ì œ hypothesis_validation_appì„ import
from hypothesis_validation_app import (
    get_db_connection,
    save_or_update_predictions_for_historical_data,
    load_ngram_chunks
)

def check_db_status():
    """DB ìƒíƒœ í™•ì¸"""
    print("=" * 60)
    print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸")
    print("=" * 60)
    
    conn = get_db_connection()
    if conn is None:
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        return
    
    try:
        cursor = conn.cursor()
        
        # preprocessed_grid_strings í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM preprocessed_grid_strings")
        grid_count = cursor.fetchone()[0]
        print(f"âœ… preprocessed_grid_strings: {grid_count:,}ê°œ")
        
        # ngram_chunks í™•ì¸
        cursor.execute("SELECT window_size, COUNT(*) FROM ngram_chunks GROUP BY window_size")
        ngram_results = cursor.fetchall()
        total_ngrams = 0
        for window_size, count in ngram_results:
            print(f"âœ… ngram_chunks (window_size={window_size}): {count:,}ê°œ")
            total_ngrams += count
        print(f"   ì´ ngram_chunks: {total_ngrams:,}ê°œ")
        
        # stored_predictions í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM stored_predictions")
        pred_count = cursor.fetchone()[0]
        print(f"{'âœ…' if pred_count > 0 else 'âŒ'} stored_predictions: {pred_count:,}ê°œ")
        
        if pred_count > 0:
            # ì €ì¥ëœ ì˜ˆì¸¡ê°’ ìƒ˜í”Œ í™•ì¸
            cursor.execute("""
                SELECT window_size, method, threshold, COUNT(*) as count
                FROM stored_predictions
                GROUP BY window_size, method, threshold
                ORDER BY window_size, method, threshold
            """)
            print("\nğŸ“‹ ì €ì¥ëœ ì˜ˆì¸¡ê°’ ë¶„í¬:")
            for row in cursor.fetchall():
                print(f"   window_size={row[0]}, method={row[1]}, threshold={row[2]}: {row[3]:,}ê°œ")
        
        # grid_string_id ë²”ìœ„ í™•ì¸
        cursor.execute("SELECT MIN(id), MAX(id) FROM preprocessed_grid_strings")
        min_id, max_id = cursor.fetchone()
        print(f"\nğŸ“Œ grid_string_id ë²”ìœ„: {min_id} ~ {max_id}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        conn.close()

def save_predictions(cutoff_id=None, window_sizes=[5, 6, 7, 8, 9], 
                     methods=["ë¹ˆë„ ê¸°ë°˜"], thresholds=[0, 50, 60, 70, 80, 90, 100]):
    """ì˜ˆì¸¡ê°’ ì €ì¥"""
    print("\n" + "=" * 60)
    print("ğŸ’¾ ì˜ˆì¸¡ê°’ ì €ì¥ ì‹œì‘")
    print("=" * 60)
    
    if cutoff_id is None:
        print("ğŸ“Œ cutoff_idê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        print(f"ğŸ“Œ cutoff_id: {cutoff_id} (ì´ ID ì´í•˜ê°€ í•™ìŠµ ë°ì´í„°)")
    
    print(f"ğŸ“Œ window_sizes: {window_sizes}")
    print(f"ğŸ“Œ methods: {methods}")
    print(f"ğŸ“Œ thresholds: {thresholds}")
    print()
    
    try:
        result = save_or_update_predictions_for_historical_data(
            cutoff_grid_string_id=cutoff_id,
            window_sizes=window_sizes,
            methods=methods,
            thresholds=thresholds,
            batch_size=1000
        )
        
        if result:
            print("\nâœ… ì˜ˆì¸¡ê°’ ì €ì¥ ì™„ë£Œ!")
            print(f"   ì´ ì €ì¥/ì—…ë°ì´íŠ¸: {result['total_saved']:,}ê°œ")
            print(f"   ìƒˆ ë ˆì½”ë“œ: {result['new_records']:,}ê°œ")
            print(f"   ì—…ë°ì´íŠ¸: {result['updated_records']:,}ê°œ")
            print(f"   ê³ ìœ  Prefix ìˆ˜: {result['unique_prefixes']:,}ê°œ")
        else:
            print("\nâŒ ì˜ˆì¸¡ê°’ ì €ì¥ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # 1. DB ìƒíƒœ í™•ì¸
    check_db_status()
    
    # 2. ì˜ˆì¸¡ê°’ ì €ì¥ ì—¬ë¶€ í™•ì¸
    conn = get_db_connection()
    if conn:
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM stored_predictions")
        pred_count = cursor.fetchone()[0]
        conn.close()
        
        if pred_count == 0:
            print("\n" + "=" * 60)
            print("âš ï¸  stored_predictions í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            print("=" * 60)
            
            # ìë™ìœ¼ë¡œ ì˜ˆì¸¡ê°’ ì €ì¥ ì‹¤í–‰ (ì „ì²´ ë°ì´í„° ì‚¬ìš©)
            print("\nìë™ìœ¼ë¡œ ì˜ˆì¸¡ê°’ì„ ì €ì¥í•©ë‹ˆë‹¤...")
            cutoff_id = None  # ì „ì²´ ë°ì´í„° ì‚¬ìš©
            
            # ì˜ˆì¸¡ê°’ ì €ì¥ ì‹¤í–‰
            save_predictions(cutoff_id=cutoff_id)
            
            # ì €ì¥ í›„ ë‹¤ì‹œ í™•ì¸
            print("\n" + "=" * 60)
            print("ğŸ“Š ì €ì¥ í›„ ìƒíƒœ í™•ì¸")
            print("=" * 60)
            check_db_status()
        else:
            print(f"\nâœ… stored_predictions í…Œì´ë¸”ì— {pred_count:,}ê°œì˜ ì˜ˆì¸¡ê°’ì´ ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")

