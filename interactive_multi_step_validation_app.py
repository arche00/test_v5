"""
Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Îã§Îã®Í≥Ñ ÏòàÏ∏° ÏãúÎÇòÎ¶¨Ïò§ Í≤ÄÏ¶ù Ïï±
Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Îã§Îã®Í≥Ñ ÏòàÏ∏° ÏãúÎÇòÎ¶¨Ïò§Î•º ÏûêÎèôÏúºÎ°ú Í≤ÄÏ¶ùÌïòÎäî ÏãúÏä§ÌÖú
"""

import streamlit as st

# ÌéòÏù¥ÏßÄ ÏÑ§Ï†ï (Î™®Îì† import Ï†ÑÏóê Ïã§ÌñâÎêòÏñ¥Ïïº Ìï®)
st.set_page_config(
    page_title="Interactive Multi-Step Validation",
    page_icon="üå≥",
    layout="wide"
)

import pandas as pd
import sqlite3
import uuid
from collections import defaultdict
from datetime import datetime

# Í∏∞Ï°¥ Ïï±Ïùò Ìï®ÏàòÎì§ import
# Ï£ºÏùò: hypothesis_validation_app.pyÎèÑ set_page_config()Î•º Ìò∏Ï∂úÌïòÏßÄÎßå,
# Ïù¥ÎØ∏ ÏúÑÏóêÏÑú Ìò∏Ï∂úÌñàÏúºÎØÄÎ°ú Î¨¥ÏãúÎê©ÎãàÎã§.
from hypothesis_validation_app import (
    get_db_connection,
    load_preprocessed_data,
    load_ngram_chunks,
    build_frequency_model,
    build_weighted_model,
    predict_for_prefix,
    predict_with_fallback_interval,
    get_next_prefix
)

# DB Í≤ΩÎ°ú
DB_PATH = 'hypothesis_validation.db'

def get_prediction_from_stored_table(prefix, window_size, method, threshold=0):
    """
    stored_predictions ÌÖåÏù¥Î∏îÏóêÏÑú ÏòàÏ∏°Í∞í Ï°∞Ìöå
    
    Args:
        prefix: ÏòàÏ∏°Ìï† prefix Î¨∏ÏûêÏó¥
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞
        method: ÏòàÏ∏° Î∞©Î≤ï ("ÎπàÎèÑ Í∏∞Î∞ò" ÎòêÎäî "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò")
        threshold: ÏûÑÍ≥ÑÍ∞í (Í∏∞Î≥∏Í∞í: 0)
    
    Returns:
        dict: {
            'predicted': ÏòàÏ∏°Í∞í ('b' ÎòêÎäî 'p' ÎòêÎäî None),
            'confidence': Ïã†Î¢∞ÎèÑ,
            'ratios': {'b': b_ratio, 'p': p_ratio},
            'is_forced': False (ÌÖåÏù¥Î∏îÏóêÏÑú Í∞ÄÏ†∏Ïò® ÏòàÏ∏°ÏùÄ Í∞ïÏ†ú ÏòàÏ∏°Ïù¥ ÏïÑÎãò)
        }
    """
    conn = get_db_connection()
    if conn is None:
        return {
            'predicted': None,
            'confidence': 0.0,
            'ratios': {},
            'is_forced': False
        }
    
    try:
        query = """
            SELECT predicted_value, confidence, b_ratio, p_ratio
            FROM stored_predictions
            WHERE window_size = ?
              AND prefix = ?
              AND method = ?
              AND threshold = ?
            LIMIT 1
        """
        
        df = pd.read_sql_query(
            query,
            conn,
            params=[window_size, prefix, method, threshold]
        )
        
        if len(df) > 0:
            row = df.iloc[0]
            return {
                'predicted': row['predicted_value'],
                'confidence': row['confidence'],
                'ratios': {'b': row['b_ratio'], 'p': row['p_ratio']},
                'is_forced': False
            }
        else:
            return {
                'predicted': None,
                'confidence': 0.0,
                'ratios': {},
                'is_forced': False
            }
            
    except Exception as e:
        return {
            'predicted': None,
            'confidence': 0.0,
            'ratios': {},
            'is_forced': False
        }
    finally:
        conn.close()

def predict_with_fallback_interval_stored(
    prefix,
    window_size,
    method,
    threshold=60,
    max_interval=6,
    current_interval=0,
    stored_threshold=0
):
    """
    stored_predictions ÌÖåÏù¥Î∏î Í∏∞Î∞ò ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏòàÏ∏° (Í∞ïÏ†ú ÏòàÏ∏° Ìè¨Ìï®)
    
    Args:
        prefix: ÏòàÏ∏°Ìï† prefix Î¨∏ÏûêÏó¥
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞
        method: ÏòàÏ∏° Î∞©Î≤ï
        threshold: ÏûÑÍ≥ÑÍ∞í (%)
        max_interval: ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤©
        current_interval: ÌòÑÏû¨ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤©
        stored_threshold: stored_predictionsÏóêÏÑú Ï°∞ÌöåÌï† ÏûÑÍ≥ÑÍ∞í
    
    Returns:
        dict: {
            'predicted': ÏòàÏ∏°Í∞í,
            'confidence': Ïã†Î¢∞ÎèÑ,
            'ratios': ÎπÑÏú® ÎîïÏÖîÎÑàÎ¶¨,
            'is_forced': Í∞ïÏ†ú ÏòàÏ∏° Ïó¨Î∂Ä
        }
    """
    # stored_predictionsÏóêÏÑú ÏòàÏ∏°Í∞í Ï°∞Ìöå
    result = get_prediction_from_stored_table(prefix, window_size, method, stored_threshold)
    
    predicted = result.get('predicted')
    confidence = result.get('confidence', 0.0)
    ratios = result.get('ratios', {})
    
    if predicted is None:
        # prefixÍ∞Ä ÌÖåÏù¥Î∏îÏóê ÏóÜÎäî Í≤ΩÏö∞
        return {
            'predicted': None,
            'confidence': 0.0,
            'ratios': {},
            'is_forced': False
        }
    
    # ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ Ï†ÅÏö©
    if confidence >= threshold:
        # Ïã†Î¢∞ÎèÑÍ∞Ä ÏûÑÍ≥ÑÍ∞í Ïù¥ÏÉÅÏù¥Î©¥ ÏòàÏ∏°
        return {
            'predicted': predicted,
            'confidence': confidence,
            'ratios': ratios,
            'is_forced': False
        }
    elif current_interval >= max_interval:
        # Í∞ÑÍ≤©Ïù¥ ÏµúÎåÄÏπòÎ•º ÎÑòÏúºÎ©¥ Í∞ïÏ†ú ÏòàÏ∏°
        return {
            'predicted': predicted,
            'confidence': confidence,
            'ratios': ratios,
            'is_forced': True
        }
    else:
        # ÏòàÏ∏° Ïïà Ìï®
        return {
            'predicted': None,
            'confidence': confidence,
            'ratios': ratios,
            'is_forced': False
        }

def create_validation_tables():
    """Í≤ÄÏ¶ù Í≤∞Í≥º Ï†ÄÏû•ÏùÑ ÏúÑÌïú ÌÖåÏù¥Î∏î ÏÉùÏÑ±"""
    conn = get_db_connection()
    if conn is None:
        return False
    
    cursor = conn.cursor()
    
    try:
        # 1. Í≤ÄÏ¶ù ÏÑ∏ÏÖò Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌÖåÏù¥Î∏î
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS interactive_validation_sessions (
                session_id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL UNIQUE,
                cutoff_grid_string_id INTEGER NOT NULL,
                window_size INTEGER NOT NULL,
                method TEXT NOT NULL,
                use_threshold BOOLEAN NOT NULL,
                threshold REAL,
                max_interval INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
            )
        ''')
        
        # 2. Ï†ÑÎûµÎ≥Ñ ÏöîÏïΩ ÌÜµÍ≥Ñ ÌÖåÏù¥Î∏î
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS interactive_validation_summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                strategy_type TEXT NOT NULL,
                total_grid_strings INTEGER NOT NULL,
                avg_accuracy REAL NOT NULL,
                max_consecutive_failures INTEGER NOT NULL,
                avg_max_consecutive_failures REAL NOT NULL,
                prediction_rate REAL NOT NULL,
                forced_prediction_rate REAL NOT NULL,
                forced_success_rate REAL NOT NULL,
                total_steps INTEGER NOT NULL,
                total_failures INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                total_forced_predictions INTEGER NOT NULL,
                total_forced_successes INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES interactive_validation_sessions(validation_id),
                UNIQUE(validation_id, strategy_type)
            )
        ''')
        
        # 3. Grid StringÎ≥Ñ ÏÉÅÏÑ∏ Í≤∞Í≥º ÌÖåÏù¥Î∏î
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS interactive_validation_grid_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                strategy_type TEXT NOT NULL,
                grid_string_id INTEGER NOT NULL,
                max_consecutive_failures INTEGER NOT NULL,
                total_steps INTEGER NOT NULL,
                total_failures INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                accuracy REAL NOT NULL,
                forced_prediction_rate REAL NOT NULL,
                forced_success_rate REAL NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES interactive_validation_sessions(validation_id),
                FOREIGN KEY (grid_string_id) REFERENCES preprocessed_grid_strings(id),
                UNIQUE(validation_id, strategy_type, grid_string_id)
            )
        ''')
        
        # Ïù∏Îç±Ïä§ ÏÉùÏÑ±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_sessions_created_at 
            ON interactive_validation_sessions(created_at)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_sessions_cutoff 
            ON interactive_validation_sessions(cutoff_grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_sessions_settings 
            ON interactive_validation_sessions(window_size, method, use_threshold)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_summaries_validation_id 
            ON interactive_validation_summaries(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_summaries_strategy 
            ON interactive_validation_summaries(strategy_type)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_summaries_max_failures 
            ON interactive_validation_summaries(max_consecutive_failures)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_summaries_accuracy 
            ON interactive_validation_summaries(avg_accuracy)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_validation_id 
            ON interactive_validation_grid_results(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_strategy 
            ON interactive_validation_grid_results(strategy_type)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_grid_string_id 
            ON interactive_validation_grid_results(grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_max_failures 
            ON interactive_validation_grid_results(max_consecutive_failures)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_accuracy 
            ON interactive_validation_grid_results(accuracy)
        ''')
        
        # 4. Ïã†Î¢∞ÎèÑ Íµ¨Í∞ÑÎ≥Ñ ÌÜµÍ≥Ñ ÌÖåÏù¥Î∏î
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS confidence_statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT,
                strategy_type TEXT,
                confidence_range TEXT NOT NULL,
                total_predictions INTEGER NOT NULL,
                matches INTEGER NOT NULL,
                mismatches INTEGER NOT NULL,
                match_rate REAL NOT NULL,
                avg_confidence REAL NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                UNIQUE(validation_id, strategy_type, confidence_range)
            )
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_statistics_validation_id 
            ON confidence_statistics(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_statistics_strategy 
            ON confidence_statistics(strategy_type)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_statistics_range 
            ON confidence_statistics(confidence_range)
        ''')
        
        # 5. Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù ÏÑ∏ÏÖò ÌÖåÏù¥Î∏î (2Í∞ú ÏûÑÍ≥ÑÍ∞í ÎπÑÍµêÏö©)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS confidence_skip_validation_sessions (
                session_id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL UNIQUE,
                cutoff_grid_string_id INTEGER NOT NULL,
                window_size INTEGER NOT NULL,
                method TEXT NOT NULL,
                use_threshold BOOLEAN NOT NULL,
                threshold REAL,
                max_interval INTEGER NOT NULL,
                confidence_skip_threshold_1 REAL NOT NULL,
                confidence_skip_threshold_2 REAL NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
            )
        ''')
        
        # 6. Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ ÏöîÏïΩ ÌÜµÍ≥Ñ ÌÖåÏù¥Î∏î (ÏûÑÍ≥ÑÍ∞íÎ≥Ñ)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS confidence_skip_validation_summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                confidence_skip_threshold REAL NOT NULL,
                total_grid_strings INTEGER NOT NULL,
                avg_accuracy REAL NOT NULL,
                max_consecutive_failures INTEGER NOT NULL,
                avg_max_consecutive_failures REAL NOT NULL,
                prediction_rate REAL NOT NULL,
                forced_prediction_rate REAL NOT NULL,
                forced_success_rate REAL NOT NULL,
                total_steps INTEGER NOT NULL,
                total_failures INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                total_forced_predictions INTEGER NOT NULL,
                total_forced_successes INTEGER NOT NULL,
                total_skipped_predictions INTEGER NOT NULL,
                avg_first_success_step REAL,
                min_first_success_step INTEGER,
                max_first_success_step INTEGER,
                total_with_success INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES confidence_skip_validation_sessions(validation_id),
                UNIQUE(validation_id, confidence_skip_threshold)
            )
        ''')
        
        # 7. Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Grid StringÎ≥Ñ ÏÉÅÏÑ∏ Í≤∞Í≥º ÌÖåÏù¥Î∏î
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS confidence_skip_validation_grid_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                confidence_skip_threshold REAL NOT NULL,
                grid_string_id INTEGER NOT NULL,
                max_consecutive_failures INTEGER NOT NULL,
                total_steps INTEGER NOT NULL,
                total_failures INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                total_skipped_predictions INTEGER NOT NULL,
                accuracy REAL NOT NULL,
                forced_prediction_rate REAL NOT NULL,
                forced_success_rate REAL NOT NULL,
                first_success_step INTEGER,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES confidence_skip_validation_sessions(validation_id),
                FOREIGN KEY (grid_string_id) REFERENCES preprocessed_grid_strings(id),
                UNIQUE(validation_id, confidence_skip_threshold, grid_string_id)
            )
        ''')
        
        # 8. Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Ïä§ÌÖùÎ≥Ñ ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨ ÌÖåÏù¥Î∏î
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS confidence_skip_validation_steps (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                confidence_skip_threshold REAL NOT NULL,
                grid_string_id INTEGER NOT NULL,
                step INTEGER NOT NULL,
                prefix TEXT,
                predicted TEXT,
                actual TEXT,
                is_correct INTEGER,
                confidence REAL,
                is_forced INTEGER NOT NULL,
                current_interval INTEGER NOT NULL,
                has_prediction INTEGER NOT NULL,
                validated INTEGER NOT NULL,
                skipped INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES confidence_skip_validation_sessions(validation_id),
                FOREIGN KEY (grid_string_id) REFERENCES preprocessed_grid_strings(id)
            )
        ''')
        
        # Ïù∏Îç±Ïä§ ÏÉùÏÑ±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_sessions_created_at 
            ON confidence_skip_validation_sessions(created_at)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_sessions_cutoff 
            ON confidence_skip_validation_sessions(cutoff_grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_summaries_validation_id 
            ON confidence_skip_validation_summaries(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_summaries_threshold 
            ON confidence_skip_validation_summaries(confidence_skip_threshold)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_grid_results_validation_id 
            ON confidence_skip_validation_grid_results(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_grid_results_threshold 
            ON confidence_skip_validation_grid_results(confidence_skip_threshold)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_grid_results_grid_string_id 
            ON confidence_skip_validation_grid_results(grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_grid_results_first_success 
            ON confidence_skip_validation_grid_results(first_success_step)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_steps_validation_id 
            ON confidence_skip_validation_steps(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_steps_threshold 
            ON confidence_skip_validation_steps(confidence_skip_threshold)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_steps_grid_string_id 
            ON confidence_skip_validation_steps(grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_steps_step 
            ON confidence_skip_validation_steps(step)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_steps_validation_grid_step 
            ON confidence_skip_validation_steps(validation_id, grid_string_id, step)
        ''')
        
        # 9. ÏÑ∏ÏÖòÎ≥Ñ ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î Ïä§ÎÉÖÏÉ∑ ÌÖåÏù¥Î∏î
        # interactive_validation_sessionsÏôÄ confidence_skip_validation_sessions Î™®Îëê ÏßÄÏõê
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS validation_session_prediction_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                window_size INTEGER NOT NULL,
                prefix TEXT NOT NULL,
                predicted_value TEXT,
                confidence REAL,
                b_ratio REAL,
                p_ratio REAL,
                method TEXT NOT NULL,
                threshold REAL NOT NULL,
                snapshot_created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                UNIQUE(validation_id, window_size, prefix, method, threshold)
            )
        ''')
        
        # 10. ÏÑ∏ÏÖòÎ≥Ñ Í≤ÄÏ¶ùÌïú Grid String ID Î¶¨Ïä§Ìä∏ ÌÖåÏù¥Î∏î
        # interactive_validation_sessionsÏôÄ confidence_skip_validation_sessions Î™®Îëê ÏßÄÏõê
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS validation_session_grid_strings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                grid_string_id INTEGER NOT NULL,
                sequence_order INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (grid_string_id) REFERENCES preprocessed_grid_strings(id),
                UNIQUE(validation_id, grid_string_id)
            )
        ''')
        
        # Ïù∏Îç±Ïä§ ÏÉùÏÑ±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_prediction_snapshots_validation_id 
            ON validation_session_prediction_snapshots(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_prediction_snapshots_window_method_threshold 
            ON validation_session_prediction_snapshots(window_size, method, threshold)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_session_grid_strings_validation_id 
            ON validation_session_grid_strings(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_session_grid_strings_grid_string_id 
            ON validation_session_grid_strings(grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_session_grid_strings_sequence 
            ON validation_session_grid_strings(validation_id, sequence_order)
        ''')
        
        conn.commit()
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"ÌÖåÏù¥Î∏î ÏÉùÏÑ± Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        return False
    finally:
        conn.close()

def collect_confidence_statistics(history, validation_id=None, strategy_type=None):
    """
    ÌûàÏä§ÌÜ†Î¶¨ÏóêÏÑú Ïã†Î¢∞ÎèÑ Íµ¨Í∞ÑÎ≥Ñ ÌÜµÍ≥Ñ ÏàòÏßë (50-60% Íµ¨Í∞Ñ, 1% Í∞ÑÍ≤©)
    
    Args:
        history: Í≤ÄÏ¶ù ÌûàÏä§ÌÜ†Î¶¨ Î¶¨Ïä§Ìä∏
        validation_id: Í≤ÄÏ¶ù ID (ÏÑ†ÌÉùÏ†Å)
        strategy_type: Ï†ÑÎûµ ÌÉÄÏûÖ (ÏÑ†ÌÉùÏ†Å)
    
    Returns:
        dict: Ïã†Î¢∞ÎèÑ Íµ¨Í∞ÑÎ≥Ñ ÌÜµÍ≥Ñ
    """
    # Ïã†Î¢∞ÎèÑ Íµ¨Í∞ÑÎ≥Ñ ÌÜµÍ≥Ñ Ï¥àÍ∏∞Ìôî (50-60%, 1% Í∞ÑÍ≤©)
    confidence_ranges = {}
    for i in range(50, 61):  # 50, 51, 52, ..., 60
        range_key = f"{i}-{i+1}" if i < 60 else "60+"
        confidence_ranges[range_key] = {
            'total_predictions': 0,
            'matches': 0,
            'mismatches': 0,
            'confidence_sum': 0.0
        }
    
    # ÌûàÏä§ÌÜ†Î¶¨ÏóêÏÑú ÌÜµÍ≥Ñ ÏàòÏßë
    for entry in history:
        has_prediction = entry.get('has_prediction', False)
        is_correct = entry.get('is_correct')
        confidence = entry.get('confidence', 0.0)
        validated = entry.get('validated', False)
        
        # ÏòàÏ∏°Í∞íÏù¥ ÏûàÍ≥† Í≤ÄÏ¶ùÎêú Í≤ΩÏö∞Îßå ÌÜµÍ≥ÑÏóê Ìè¨Ìï®
        if has_prediction and validated and is_correct is not None:
            # Ïã†Î¢∞ÎèÑ Íµ¨Í∞Ñ Í≤∞Ï†ï
            conf_int = int(confidence)
            if conf_int < 50:
                continue  # 50% ÎØ∏ÎßåÏùÄ Ï†úÏô∏
            elif conf_int >= 60:
                range_key = "60+"
            else:
                range_key = f"{conf_int}-{conf_int+1}"
            
            if range_key in confidence_ranges:
                confidence_ranges[range_key]['total_predictions'] += 1
                confidence_ranges[range_key]['confidence_sum'] += confidence
                
                if is_correct:
                    confidence_ranges[range_key]['matches'] += 1
                else:
                    confidence_ranges[range_key]['mismatches'] += 1
    
    # ÌÜµÍ≥Ñ Í≥ÑÏÇ∞ Î∞è Ï†ïÎ¶¨
    statistics = []
    for range_key, stats in confidence_ranges.items():
        if stats['total_predictions'] > 0:
            match_rate = (stats['matches'] / stats['total_predictions']) * 100
            avg_confidence = stats['confidence_sum'] / stats['total_predictions']
            
            statistics.append({
                'confidence_range': range_key,
                'total_predictions': stats['total_predictions'],
                'matches': stats['matches'],
                'mismatches': stats['mismatches'],
                'match_rate': match_rate,
                'avg_confidence': avg_confidence
            })
    
    return statistics

def save_confidence_statistics(statistics, validation_id=None, strategy_type=None):
    """
    Ïã†Î¢∞ÎèÑ ÌÜµÍ≥ÑÎ•º DBÏóê Ï†ÄÏû•
    
    Args:
        statistics: collect_confidence_statistics()Ïùò Î∞òÌôòÍ∞í
        validation_id: Í≤ÄÏ¶ù ID (ÏÑ†ÌÉùÏ†Å)
        strategy_type: Ï†ÑÎûµ ÌÉÄÏûÖ (ÏÑ†ÌÉùÏ†Å)
    """
    conn = get_db_connection()
    if conn is None:
        return False
    
    cursor = conn.cursor()
    
    try:
        for stat in statistics:
            cursor.execute('''
                INSERT OR REPLACE INTO confidence_statistics (
                    validation_id, strategy_type, confidence_range,
                    total_predictions, matches, mismatches,
                    match_rate, avg_confidence, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                strategy_type,
                stat['confidence_range'],
                stat['total_predictions'],
                stat['matches'],
                stat['mismatches'],
                stat['match_rate'],
                stat['avg_confidence']
            ))
        
        conn.commit()
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ Ï†ÄÏû• Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        return False
    finally:
        conn.close()

def save_confidence_skip_validation_results(
    cutoff_grid_string_id,
    window_size,
    method,
    use_threshold,
    threshold,
    max_interval,
    confidence_skip_threshold_1,
    confidence_skip_threshold_2,
    batch_results_1,
    batch_results_2,
    grid_string_ids=None
):
    """
    Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù Í≤∞Í≥ºÎ•º DBÏóê Ï†ÄÏû• (2Í∞ú ÏûÑÍ≥ÑÍ∞í ÎπÑÍµê)
    
    Args:
        cutoff_grid_string_id: Í∏∞Ï§Ä grid_string ID
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞
        method: ÏòàÏ∏° Î∞©Î≤ï
        use_threshold: ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö© Ïó¨Î∂Ä
        threshold: ÏûÑÍ≥ÑÍ∞í
        max_interval: ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤©
        confidence_skip_threshold_1: Ï≤´ Î≤àÏß∏ Ïä§ÌÇµ Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í
        confidence_skip_threshold_2: Îëê Î≤àÏß∏ Ïä§ÌÇµ Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í
        batch_results_1: Ï≤´ Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í Í≤ÄÏ¶ù Í≤∞Í≥º
        batch_results_2: Îëê Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í Í≤ÄÏ¶ù Í≤∞Í≥º
        grid_string_ids: Í≤ÄÏ¶ùÌïú grid_string_id Î¶¨Ïä§Ìä∏ (ÏÑ†ÌÉùÏ†Å)
    
    Returns:
        str: validation_id (Ï†ÄÏû• ÏÑ±Í≥µ Ïãú), None (Ïã§Ìå® Ïãú)
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    cursor = conn.cursor()
    
    try:
        # validation_id ÏÉùÏÑ± (UUID)
        validation_id = str(uuid.uuid4())
        
        # 1. Í≤ÄÏ¶ù ÏÑ∏ÏÖò Ï†ÄÏû•
        cursor.execute('''
            INSERT INTO confidence_skip_validation_sessions (
                validation_id, cutoff_grid_string_id, window_size, method,
                use_threshold, threshold, max_interval,
                confidence_skip_threshold_1, confidence_skip_threshold_2,
                created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
        ''', (
            validation_id,
            cutoff_grid_string_id,
            window_size,
            method,
            use_threshold,
            threshold if use_threshold else None,
            max_interval,
            confidence_skip_threshold_1,
            confidence_skip_threshold_2
        ))
        
        # 2. Ï≤´ Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í ÏöîÏïΩ ÌÜµÍ≥Ñ Ï†ÄÏû•
        if batch_results_1 and 'summary' in batch_results_1:
            summary_1 = batch_results_1['summary']
            cursor.execute('''
                INSERT INTO confidence_skip_validation_summaries (
                    validation_id, confidence_skip_threshold,
                    total_grid_strings, avg_accuracy, max_consecutive_failures,
                    avg_max_consecutive_failures, prediction_rate,
                    forced_prediction_rate, forced_success_rate,
                    total_steps, total_failures, total_predictions,
                    total_forced_predictions, total_forced_successes,
                    total_skipped_predictions,
                    avg_first_success_step, min_first_success_step, max_first_success_step,
                    total_with_success, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                confidence_skip_threshold_1,
                summary_1.get('total_grid_strings', 0),
                summary_1.get('avg_accuracy', 0.0),
                summary_1.get('max_consecutive_failures', 0),
                summary_1.get('avg_max_consecutive_failures', 0.0),
                summary_1.get('prediction_rate', 0.0),
                summary_1.get('forced_prediction_rate', 0.0),
                summary_1.get('forced_success_rate', 0.0),
                summary_1.get('total_steps', 0),
                summary_1.get('total_failures', 0),
                summary_1.get('total_predictions', 0),
                summary_1.get('total_forced_predictions', 0),
                summary_1.get('total_forced_successes', 0),
                summary_1.get('total_skipped_predictions', 0),
                summary_1.get('avg_first_success_step'),
                summary_1.get('min_first_success_step'),
                summary_1.get('max_first_success_step'),
                summary_1.get('total_with_success', 0)
            ))
            
            # Grid StringÎ≥Ñ Í≤∞Í≥º Ï†ÄÏû• (Ï≤´ Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í)
            if 'results' in batch_results_1:
                for result in batch_results_1['results']:
                    cursor.execute('''
                        INSERT OR REPLACE INTO confidence_skip_validation_grid_results (
                            validation_id, confidence_skip_threshold, grid_string_id,
                            max_consecutive_failures, total_steps, total_failures,
                            total_predictions, total_skipped_predictions,
                            accuracy, forced_prediction_rate, forced_success_rate,
                            first_success_step, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                    ''', (
                        validation_id,
                        confidence_skip_threshold_1,
                        result.get('grid_string_id'),
                        result.get('max_consecutive_failures', 0),
                        result.get('total_steps', 0),
                        result.get('total_failures', 0),
                        result.get('total_predictions', 0),
                        result.get('total_skipped_predictions', 0),
                        result.get('accuracy', 0.0),
                        result.get('forced_prediction_rate', 0.0),
                        result.get('forced_success_rate', 0.0),
                        result.get('first_success_step')
                    ))
                    
                    # ÌûàÏä§ÌÜ†Î¶¨ Ï†ÄÏû• (Ï≤´ Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í)
                    if 'history' in result and result['history']:
                        for entry in result['history']:
                            cursor.execute('''
                                INSERT INTO confidence_skip_validation_steps (
                                    validation_id, confidence_skip_threshold, grid_string_id,
                                    step, prefix, predicted, actual, is_correct,
                                    confidence, is_forced, current_interval,
                                    has_prediction, validated, skipped, created_at
                                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                            ''', (
                                validation_id,
                                confidence_skip_threshold_1,
                                result.get('grid_string_id'),
                                entry.get('step', 0),
                                entry.get('prefix'),
                                entry.get('predicted'),
                                entry.get('actual'),
                                1 if entry.get('is_correct') is True else (0 if entry.get('is_correct') is False else None),
                                entry.get('confidence', 0.0),
                                1 if entry.get('is_forced', False) else 0,
                                entry.get('current_interval', 0),
                                1 if entry.get('has_prediction', False) else 0,
                                1 if entry.get('validated', False) else 0,
                                1 if entry.get('skipped', False) else 0
                            ))
        
        # 3. Îëê Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í ÏöîÏïΩ ÌÜµÍ≥Ñ Ï†ÄÏû•
        if batch_results_2 and 'summary' in batch_results_2:
            summary_2 = batch_results_2['summary']
            cursor.execute('''
                INSERT INTO confidence_skip_validation_summaries (
                    validation_id, confidence_skip_threshold,
                    total_grid_strings, avg_accuracy, max_consecutive_failures,
                    avg_max_consecutive_failures, prediction_rate,
                    forced_prediction_rate, forced_success_rate,
                    total_steps, total_failures, total_predictions,
                    total_forced_predictions, total_forced_successes,
                    total_skipped_predictions,
                    avg_first_success_step, min_first_success_step, max_first_success_step,
                    total_with_success, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                confidence_skip_threshold_2,
                summary_2.get('total_grid_strings', 0),
                summary_2.get('avg_accuracy', 0.0),
                summary_2.get('max_consecutive_failures', 0),
                summary_2.get('avg_max_consecutive_failures', 0.0),
                summary_2.get('prediction_rate', 0.0),
                summary_2.get('forced_prediction_rate', 0.0),
                summary_2.get('forced_success_rate', 0.0),
                summary_2.get('total_steps', 0),
                summary_2.get('total_failures', 0),
                summary_2.get('total_predictions', 0),
                summary_2.get('total_forced_predictions', 0),
                summary_2.get('total_forced_successes', 0),
                summary_2.get('total_skipped_predictions', 0),
                summary_2.get('avg_first_success_step'),
                summary_2.get('min_first_success_step'),
                summary_2.get('max_first_success_step'),
                summary_2.get('total_with_success', 0)
            ))
            
            # Grid StringÎ≥Ñ Í≤∞Í≥º Ï†ÄÏû• (Îëê Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í)
            if 'results' in batch_results_2:
                for result in batch_results_2['results']:
                    cursor.execute('''
                        INSERT OR REPLACE INTO confidence_skip_validation_grid_results (
                            validation_id, confidence_skip_threshold, grid_string_id,
                            max_consecutive_failures, total_steps, total_failures,
                            total_predictions, total_skipped_predictions,
                            accuracy, forced_prediction_rate, forced_success_rate,
                            first_success_step, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                    ''', (
                        validation_id,
                        confidence_skip_threshold_2,
                        result.get('grid_string_id'),
                        result.get('max_consecutive_failures', 0),
                        result.get('total_steps', 0),
                        result.get('total_failures', 0),
                        result.get('total_predictions', 0),
                        result.get('total_skipped_predictions', 0),
                        result.get('accuracy', 0.0),
                        result.get('forced_prediction_rate', 0.0),
                        result.get('forced_success_rate', 0.0),
                        result.get('first_success_step')
                    ))
                    
                    # ÌûàÏä§ÌÜ†Î¶¨ Ï†ÄÏû• (Îëê Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í)
                    if 'history' in result and result['history']:
                        for entry in result['history']:
                            cursor.execute('''
                                INSERT INTO confidence_skip_validation_steps (
                                    validation_id, confidence_skip_threshold, grid_string_id,
                                    step, prefix, predicted, actual, is_correct,
                                    confidence, is_forced, current_interval,
                                    has_prediction, validated, skipped, created_at
                                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                            ''', (
                                validation_id,
                                confidence_skip_threshold_2,
                                result.get('grid_string_id'),
                                entry.get('step', 0),
                                entry.get('prefix'),
                                entry.get('predicted'),
                                entry.get('actual'),
                                1 if entry.get('is_correct') is True else (0 if entry.get('is_correct') is False else None),
                                entry.get('confidence', 0.0),
                                1 if entry.get('is_forced', False) else 0,
                                entry.get('current_interval', 0),
                                1 if entry.get('has_prediction', False) else 0,
                                1 if entry.get('validated', False) else 0,
                                1 if entry.get('skipped', False) else 0
                            ))
        
        # 4. ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î Ïä§ÎÉÖÏÉ∑ Ï†ÄÏû• (Í≤ÄÏ¶ù ÏãúÏ†êÏóê Ïã§ÏãúÍ∞Ñ Í≥ÑÏÇ∞)
        # cutoff_grid_string_id Í∏∞Ï§ÄÏúºÎ°ú ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï∂ïÌïòÏó¨ Î™®Îç∏ ÏÉùÏÑ±
        # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎÇòÏò¨ Ïàò ÏûàÎäî Î™®Îì† prefixÏóê ÎåÄÌïú ÏòàÏ∏°Í∞í Í≥ÑÏÇ∞ Î∞è Ï†ÄÏû•
        snapshot_threshold = threshold if use_threshold else 0.0
        
        try:
            # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï∂ï
            train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
            train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[cutoff_grid_string_id])
            train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
            
            if len(train_ids) > 0:
                # N-gram Î°úÎìú
                train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
                
                if len(train_ngrams) > 0:
                    # Î™®Îç∏ Íµ¨Ï∂ï
                    if method == "ÎπàÎèÑ Í∏∞Î∞ò":
                        model = build_frequency_model(train_ngrams)
                    elif method == "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò":
                        model = build_weighted_model(train_ngrams)
                    else:
                        model = build_frequency_model(train_ngrams)
                    
                    # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎÇòÏò¨ Ïàò ÏûàÎäî Î™®Îì† prefix Ï∂îÏ∂ú
                    prefixes = set()
                    for ngram in train_ngrams:
                        if len(ngram) >= window_size:
                            prefix = ngram[:window_size-1]
                            prefixes.add(prefix)
                    
                    # Í∞Å prefixÏóê ÎåÄÌï¥ ÏòàÏ∏°Í∞í Í≥ÑÏÇ∞ Î∞è Ï†ÄÏû•
                    snapshot_count = 0
                    for prefix in prefixes:
                        prediction_result = predict_for_prefix(model, prefix, method)
                        predicted_value = prediction_result.get('predicted')
                        confidence = prediction_result.get('confidence', 0.0)
                        ratios = prediction_result.get('ratios', {})
                        b_ratio = ratios.get('b', 0.0) if ratios else 0.0
                        p_ratio = ratios.get('p', 0.0) if ratios else 0.0
                        
                        cursor.execute('''
                            INSERT INTO validation_session_prediction_snapshots (
                                validation_id, window_size, prefix, predicted_value,
                                confidence, b_ratio, p_ratio, method, threshold,
                                snapshot_created_at
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                        ''', (
                            validation_id, window_size, prefix, predicted_value,
                            confidence, b_ratio, p_ratio, method, snapshot_threshold
                        ))
                        snapshot_count += 1
                    
                    if snapshot_count > 0:
                        st.info(f"ÏòàÏ∏°Í∞í Ïä§ÎÉÖÏÉ∑ {snapshot_count}Í∞ú Ï†ÄÏû• ÏôÑÎ£å")
        except Exception as e:
            # ÏòàÏ∏°Í∞í Ïä§ÎÉÖÏÉ∑ Ï†ÄÏû• Ïã§Ìå®Ìï¥ÎèÑ ÏÑ∏ÏÖò Ï†ÄÏû•ÏùÄ Í≥ÑÏÜç ÏßÑÌñâ
            st.warning(f"ÏòàÏ∏°Í∞í Ïä§ÎÉÖÏÉ∑ Ï†ÄÏû• Ï§ë Ïò§Î•ò Î∞úÏÉù (ÏÑ∏ÏÖòÏùÄ Ï†ÄÏû•Îê®): {str(e)}")
        
        # 5. Grid String ID Î¶¨Ïä§Ìä∏ Ï†ÄÏû•
        if grid_string_ids and len(grid_string_ids) > 0:
            for order, grid_string_id in enumerate(grid_string_ids, start=1):
                cursor.execute('''
                    INSERT OR REPLACE INTO validation_session_grid_strings (
                        validation_id, grid_string_id, sequence_order, created_at
                    ) VALUES (?, ?, ?, datetime('now', '+9 hours'))
                ''', (validation_id, grid_string_id, order))
        
        conn.commit()
        return validation_id
        
    except Exception as e:
        conn.rollback()
        st.error(f"Í≤ÄÏ¶ù Í≤∞Í≥º Ï†ÄÏû• Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        import traceback
        st.error(f"ÏÉÅÏÑ∏ Ïò§Î•ò: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def save_validation_results(
    cutoff_grid_string_id,
    window_size,
    method,
    use_threshold,
    threshold,
    max_interval,
    batch_results_default,
    batch_results_reverse,
    grid_string_ids=None
):
    """
    Í≤ÄÏ¶ù Í≤∞Í≥ºÎ•º DBÏóê Ï†ÄÏû•
    
    Args:
        cutoff_grid_string_id: Í∏∞Ï§Ä grid_string ID
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞
        method: ÏòàÏ∏° Î∞©Î≤ï
        use_threshold: ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö© Ïó¨Î∂Ä
        threshold: ÏûÑÍ≥ÑÍ∞í
        max_interval: ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤©
        batch_results_default: Í∏∞Î≥∏ Ï†ÑÎûµ Î∞∞Ïπò Í≤∞Í≥º
        batch_results_reverse: Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ Î∞∞Ïπò Í≤∞Í≥º
        grid_string_ids: Í≤ÄÏ¶ùÌïú grid_string_id Î¶¨Ïä§Ìä∏ (ÏÑ†ÌÉùÏ†Å)
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    cursor = conn.cursor()
    
    try:
        # validation_id ÏÉùÏÑ± (UUID)
        validation_id = str(uuid.uuid4())
        
        # 1. Í≤ÄÏ¶ù ÏÑ∏ÏÖò Ï†ÄÏû•
        cursor.execute('''
            INSERT INTO interactive_validation_sessions (
                validation_id, cutoff_grid_string_id, window_size, method,
                use_threshold, threshold, max_interval, created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
        ''', (
            validation_id,
            cutoff_grid_string_id,
            window_size,
            method,
            use_threshold,
            threshold if use_threshold else None,
            max_interval
        ))
        
        # 2. ÏöîÏïΩ ÌÜµÍ≥Ñ Ï†ÄÏû• (Í∏∞Î≥∏ Ï†ÑÎûµ)
        if batch_results_default and 'summary' in batch_results_default:
            summary_default = batch_results_default['summary']
            cursor.execute('''
                INSERT INTO interactive_validation_summaries (
                    validation_id, strategy_type, total_grid_strings,
                    avg_accuracy, max_consecutive_failures, avg_max_consecutive_failures,
                    prediction_rate, forced_prediction_rate, forced_success_rate,
                    total_steps, total_failures, total_predictions,
                    total_forced_predictions, total_forced_successes, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                'default',
                summary_default.get('total_grid_strings', 0),
                summary_default.get('avg_accuracy', 0.0),
                summary_default.get('max_consecutive_failures', 0),
                summary_default.get('avg_max_consecutive_failures', 0.0),
                summary_default.get('prediction_rate', 0.0),
                summary_default.get('forced_prediction_rate', 0.0),
                summary_default.get('forced_success_rate', 0.0),
                summary_default.get('total_steps', 0),
                summary_default.get('total_failures', 0),
                summary_default.get('total_predictions', 0),
                summary_default.get('total_forced_predictions', 0),
                summary_default.get('total_forced_successes', 0)
            ))
            
            # Grid StringÎ≥Ñ Í≤∞Í≥º Ï†ÄÏû• (Í∏∞Î≥∏ Ï†ÑÎûµ)
            if 'results' in batch_results_default:
                for result in batch_results_default['results']:
                    cursor.execute('''
                        INSERT OR REPLACE INTO interactive_validation_grid_results (
                            validation_id, strategy_type, grid_string_id,
                            max_consecutive_failures, total_steps, total_failures,
                            total_predictions, accuracy, forced_prediction_rate,
                            forced_success_rate, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                    ''', (
                        validation_id,
                        'default',
                        result.get('grid_string_id'),
                        result.get('max_consecutive_failures', 0),
                        result.get('total_steps', 0),
                        result.get('total_failures', 0),
                        result.get('total_predictions', 0),
                        result.get('accuracy', 0.0),
                        result.get('forced_prediction_rate', 0.0),
                        result.get('forced_success_rate', 0.0)
                    ))
        
        # 3. ÏöîÏïΩ ÌÜµÍ≥Ñ Ï†ÄÏû• (Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ)
        if batch_results_reverse and 'summary' in batch_results_reverse:
            summary_reverse = batch_results_reverse['summary']
            cursor.execute('''
                INSERT INTO interactive_validation_summaries (
                    validation_id, strategy_type, total_grid_strings,
                    avg_accuracy, max_consecutive_failures, avg_max_consecutive_failures,
                    prediction_rate, forced_prediction_rate, forced_success_rate,
                    total_steps, total_failures, total_predictions,
                    total_forced_predictions, total_forced_successes, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                'reverse',
                summary_reverse.get('total_grid_strings', 0),
                summary_reverse.get('avg_accuracy', 0.0),
                summary_reverse.get('max_consecutive_failures', 0),
                summary_reverse.get('avg_max_consecutive_failures', 0.0),
                summary_reverse.get('prediction_rate', 0.0),
                summary_reverse.get('forced_prediction_rate', 0.0),
                summary_reverse.get('forced_success_rate', 0.0),
                summary_reverse.get('total_steps', 0),
                summary_reverse.get('total_failures', 0),
                summary_reverse.get('total_predictions', 0),
                summary_reverse.get('total_forced_predictions', 0),
                summary_reverse.get('total_forced_successes', 0)
            ))
            
            # Grid StringÎ≥Ñ Í≤∞Í≥º Ï†ÄÏû• (Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ)
            if 'results' in batch_results_reverse:
                for result in batch_results_reverse['results']:
                    cursor.execute('''
                        INSERT OR REPLACE INTO interactive_validation_grid_results (
                            validation_id, strategy_type, grid_string_id,
                            max_consecutive_failures, total_steps, total_failures,
                            total_predictions, accuracy, forced_prediction_rate,
                            forced_success_rate, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                    ''', (
                        validation_id,
                        'reverse',
                        result.get('grid_string_id'),
                        result.get('max_consecutive_failures', 0),
                        result.get('total_steps', 0),
                        result.get('total_failures', 0),
                        result.get('total_predictions', 0),
                        result.get('accuracy', 0.0),
                        result.get('forced_prediction_rate', 0.0),
                        result.get('forced_success_rate', 0.0)
                    ))
        
        # 4. ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î Ïä§ÎÉÖÏÉ∑ Ï†ÄÏû• (Í≤ÄÏ¶ù ÏãúÏ†êÏóê Ïã§ÏãúÍ∞Ñ Í≥ÑÏÇ∞)
        # cutoff_grid_string_id Í∏∞Ï§ÄÏúºÎ°ú ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï∂ïÌïòÏó¨ Î™®Îç∏ ÏÉùÏÑ±
        # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎÇòÏò¨ Ïàò ÏûàÎäî Î™®Îì† prefixÏóê ÎåÄÌïú ÏòàÏ∏°Í∞í Í≥ÑÏÇ∞ Î∞è Ï†ÄÏû•
        snapshot_threshold = threshold if use_threshold else 0.0
        
        try:
            # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï∂ï
            train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
            train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[cutoff_grid_string_id])
            train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
            
            if len(train_ids) > 0:
                # N-gram Î°úÎìú
                train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
                
                if len(train_ngrams) > 0:
                    # Î™®Îç∏ Íµ¨Ï∂ï
                    if method == "ÎπàÎèÑ Í∏∞Î∞ò":
                        model = build_frequency_model(train_ngrams)
                    elif method == "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò":
                        model = build_weighted_model(train_ngrams)
                    else:
                        model = build_frequency_model(train_ngrams)
                    
                    # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÎÇòÏò¨ Ïàò ÏûàÎäî Î™®Îì† prefix Ï∂îÏ∂ú
                    prefixes = set()
                    for ngram in train_ngrams:
                        if len(ngram) >= window_size:
                            prefix = ngram[:window_size-1]
                            prefixes.add(prefix)
                    
                    # Í∞Å prefixÏóê ÎåÄÌï¥ ÏòàÏ∏°Í∞í Í≥ÑÏÇ∞ Î∞è Ï†ÄÏû•
                    snapshot_count = 0
                    for prefix in prefixes:
                        prediction_result = predict_for_prefix(model, prefix, method)
                        predicted_value = prediction_result.get('predicted')
                        confidence = prediction_result.get('confidence', 0.0)
                        ratios = prediction_result.get('ratios', {})
                        b_ratio = ratios.get('b', 0.0) if ratios else 0.0
                        p_ratio = ratios.get('p', 0.0) if ratios else 0.0
                        
                        cursor.execute('''
                            INSERT INTO validation_session_prediction_snapshots (
                                validation_id, window_size, prefix, predicted_value,
                                confidence, b_ratio, p_ratio, method, threshold,
                                snapshot_created_at
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                        ''', (
                            validation_id, window_size, prefix, predicted_value,
                            confidence, b_ratio, p_ratio, method, snapshot_threshold
                        ))
                        snapshot_count += 1
                    
                    if snapshot_count > 0:
                        st.info(f"ÏòàÏ∏°Í∞í Ïä§ÎÉÖÏÉ∑ {snapshot_count}Í∞ú Ï†ÄÏû• ÏôÑÎ£å")
        except Exception as e:
            # ÏòàÏ∏°Í∞í Ïä§ÎÉÖÏÉ∑ Ï†ÄÏû• Ïã§Ìå®Ìï¥ÎèÑ ÏÑ∏ÏÖò Ï†ÄÏû•ÏùÄ Í≥ÑÏÜç ÏßÑÌñâ
            st.warning(f"ÏòàÏ∏°Í∞í Ïä§ÎÉÖÏÉ∑ Ï†ÄÏû• Ï§ë Ïò§Î•ò Î∞úÏÉù (ÏÑ∏ÏÖòÏùÄ Ï†ÄÏû•Îê®): {str(e)}")
        
        # 5. Grid String ID Î¶¨Ïä§Ìä∏ Ï†ÄÏû•
        if grid_string_ids and len(grid_string_ids) > 0:
            for order, grid_string_id in enumerate(grid_string_ids, start=1):
                cursor.execute('''
                    INSERT OR REPLACE INTO validation_session_grid_strings (
                        validation_id, grid_string_id, sequence_order, created_at
                    ) VALUES (?, ?, ?, datetime('now', '+9 hours'))
                ''', (validation_id, grid_string_id, order))
        
        conn.commit()
        return validation_id
        
    except Exception as e:
        conn.rollback()
        st.error(f"Í≤ÄÏ¶ù Í≤∞Í≥º Ï†ÄÏû• Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        import traceback
        st.error(f"ÏÉÅÏÑ∏ Ïò§Î•ò: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def validate_interactive_multi_step_scenario_with_confidence_skip(
    grid_string_id,
    cutoff_grid_string_id,
    window_size=7,
    method="ÎπàÎèÑ Í∏∞Î∞ò",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False,
    confidence_skip_threshold=51,
    use_stored_predictions=False,
    stored_threshold=0
):
    """
    Ïã†Î¢∞ÎèÑ Í∏∞Î∞ò Ïä§ÌÇµ Í∑úÏπôÏù¥ ÏûàÎäî Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Îã§Îã®Í≥Ñ ÏòàÏ∏° ÏãúÎÇòÎ¶¨Ïò§ Í≤ÄÏ¶ù
    
    Í∑úÏπô:
    1. Í∏∞Î≥∏ Í∑úÏπôÏùÄ Í∏∞Ï°¥Í≥º ÎèôÏùº
    2. Í∞ïÏ†ú ÏòàÏ∏° Ïã†Î¢∞ÎèÑÍ∞Ä 51% ÎØ∏ÎßåÏù∏ Í≤ΩÏö∞ Ìï¥Îãπ Ïä§ÌÖùÏùÄ Ïä§ÌÇµ (Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ)
    3. Ïä§ÌÇµ ÏÉÅÌÉúÏóêÏÑú Í∞ÑÍ≤© Í≥ÑÏÇ∞ÏùÄ Î©àÏ∂§ (Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÏùå)
    4. Îã§Ïùå Ïä§ÌÖùÏóêÏÑú ÏûÑÍ≥ÑÍ∞í ÎßåÏ°± ÏòàÏ∏° ÎòêÎäî Ïã†Î¢∞ÎèÑ 51% Ïù¥ÏÉÅ Í∞ïÏ†ú ÏòàÏ∏°Ïù¥ ÎÇòÏò¨ ÎïåÍπåÏßÄ ÎåÄÍ∏∞
    
    Args:
        grid_string_id: Í≤ÄÏ¶ùÌï† grid_stringÏùò ID
        cutoff_grid_string_id: ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Í∏∞Ï§Ä ID
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞
        method: ÏòàÏ∏° Î∞©Î≤ï
        use_threshold: ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö© Ïó¨Î∂Ä
        threshold: ÏûÑÍ≥ÑÍ∞í
        max_interval: ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤©
        reverse_forced_prediction: Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ ÏÇ¨Ïö© Ïó¨Î∂Ä
        confidence_skip_threshold: Ïä§ÌÇµÌï† Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í (Í∏∞Î≥∏Í∞í: 51)
        use_stored_predictions: ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î(stored_predictions) ÏÇ¨Ïö© Ïó¨Î∂Ä (Í∏∞Î≥∏Í∞í: False)
        stored_threshold: stored_predictions Ï°∞Ìöå Ïãú ÏÇ¨Ïö©Ìï† ÏûÑÍ≥ÑÍ∞í (Í∏∞Î≥∏Í∞í: 0)
    
    Returns:
        dict: Í≤ÄÏ¶ù Í≤∞Í≥º
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string Î°úÎìú
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        
        if len(grid_string) < window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_skipped_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'first_success_step': None,
                'history': []
            }
        
        # ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î ÏÇ¨Ïö© Ïó¨Î∂ÄÏóê Îî∞Îùº Î™®Îç∏ Íµ¨Ï∂ï ÎòêÎäî Ïä§ÌÇµ
        model = None
        if not use_stored_predictions:
            # Ïã§ÏãúÍ∞Ñ Î™®Îç∏ ÏÇ¨Ïö©: ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï∂ï (Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Ï†úÏô∏)
            # grid_string_idÍ∞Ä cutoff_grid_string_id Ïù¥ÌïòÏù∏ Í≤ΩÏö∞ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï†úÏô∏
            train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? AND id < ? ORDER BY id"
            train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[cutoff_grid_string_id, grid_string_id])
            train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
            
            # N-gram Î°úÎìú
            train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
            
            if len(train_ngrams) == 0:
                return {
                    'grid_string_id': grid_string_id,
                    'max_consecutive_failures': 0,
                    'max_consecutive_matches': 0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0,
                    'total_forced_predictions': 0,
                    'total_skipped_predictions': 0,
                    'forced_prediction_rate': 0.0,
                    'accuracy': 0.0,
                    'first_success_step': None,
                    'history': []
                }
            
            # Î™®Îç∏ Íµ¨Ï∂ï
            if method == "ÎπàÎèÑ Í∏∞Î∞ò":
                model = build_frequency_model(train_ngrams)
            elif method == "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò":
                model = build_weighted_model(train_ngrams)
            else:
                model = build_frequency_model(train_ngrams)
        
        # ÏãúÎÇòÎ¶¨Ïò§ Î∞©ÏãùÏúºÎ°ú ÌÖåÏä§Ìä∏
        prefix_length = window_size - 1
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        consecutive_matches = 0
        max_consecutive_matches = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        total_forced_predictions = 0
        total_skipped_predictions = 0
        total_forced_successes = 0
        current_interval = 0
        first_success_step = None  # Ï≤´ Î≤àÏß∏ ÏÑ±Í≥µ Ïä§ÌÖù Ï∂îÏ†Å
        
        # Ï¥àÍ∏∞ prefix ÏÉùÏÑ±
        if len(grid_string) < prefix_length:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_skipped_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'first_success_step': None,
                'history': []
            }
        
        current_prefix = grid_string[:prefix_length]
        
        # Í∞Å Ïä§ÌÖùÎßàÎã§ ÏòàÏ∏°
        i = prefix_length
        while i < len(grid_string):
            total_steps += 1
            actual_value = grid_string[i]
            
            # ÏòàÏ∏° ÏàòÌñâ (Í∏∞Î≥∏ Í∑úÏπô: Î™®Îì† Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏° ÏãúÎèÑ)
            if use_stored_predictions:
                # ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î ÏÇ¨Ïö©
                if use_threshold:
                    # ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö©: ÏûÑÍ≥ÑÍ∞í Ïù¥ÏÉÅÏùº ÎïåÎßå ÏòàÏ∏°, ÏïÑÎãàÎ©¥ Í∞ïÏ†ú ÏòàÏ∏°
                    prediction_result = predict_with_fallback_interval_stored(
                        current_prefix,
                        window_size,
                        method,
                        threshold=threshold,
                        max_interval=max_interval,
                        current_interval=current_interval,
                        stored_threshold=stored_threshold
                    )
                else:
                    # ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÎØ∏ÏÇ¨Ïö©: Î™®Îì† Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏°
                    prediction_result = get_prediction_from_stored_table(
                        current_prefix,
                        window_size,
                        method,
                        stored_threshold
                    )
                    if 'is_forced' not in prediction_result:
                        prediction_result['is_forced'] = False
            else:
                # Ïã§ÏãúÍ∞Ñ Î™®Îç∏ ÏÇ¨Ïö©
                if use_threshold:
                    # ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö©: ÏûÑÍ≥ÑÍ∞í Ïù¥ÏÉÅÏùº ÎïåÎßå ÏòàÏ∏°, ÏïÑÎãàÎ©¥ Í∞ïÏ†ú ÏòàÏ∏°
                    prediction_result = predict_with_fallback_interval(
                        model,
                        current_prefix,
                        method=method,
                        threshold=threshold,
                        max_interval=max_interval,
                        current_interval=current_interval
                    )
                else:
                    # ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÎØ∏ÏÇ¨Ïö©: Î™®Îì† Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏° (Í∏∞Î≥∏ Í∑úÏπô)
                    prediction_result = predict_for_prefix(model, current_prefix, method)
                    # predict_for_prefixÎäî Ìï≠ÏÉÅ ÏòàÏ∏°Í∞íÏùÑ Î∞òÌôòÌïòÍ±∞ÎÇò NoneÏùÑ Î∞òÌôò
                    # NoneÏù∏ Í≤ΩÏö∞ÎèÑ ÏûàÏúºÎØÄÎ°ú is_forcedÎäî FalseÎ°ú ÏÑ§Ï†ï
                    if 'is_forced' not in prediction_result:
                        prediction_result['is_forced'] = False
            
            predicted_value = prediction_result.get('predicted')
            confidence = prediction_result.get('confidence', 0.0)
            is_forced = prediction_result.get('is_forced', False)
            
            # Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ: Í∞ïÏ†ú ÏòàÏ∏° Ïãú Î∞òÎåÄ Í∞í ÏÑ†ÌÉù
            if is_forced and reverse_forced_prediction and predicted_value is not None:
                predicted_value = 'p' if predicted_value == 'b' else 'b'
            
            has_prediction = predicted_value is not None
            
            # Ïã†Î¢∞ÎèÑ Í∏∞Î∞ò Ïä§ÌÇµ Í∑úÏπô Ï≤¥ÌÅ¨
            should_skip = False
            # Í∏∞Î≥∏ Í∑úÏπô: use_threshold=FalseÏùº ÎïåÎäî Î™®Îì† ÏòàÏ∏°Í∞íÏóê ÎåÄÌï¥ Í≤ÄÏ¶ù ÏàòÌñâ
            # Ïä§ÌÇµ Í∑úÏπôÏùÄ use_threshold=TrueÏù¥Í≥† Í∞ïÏ†ú ÏòàÏ∏°Ïùº ÎïåÎßå Ï†ÅÏö©
            if use_threshold and has_prediction and is_forced and confidence < confidence_skip_threshold:
                # ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö© Ï§ëÏù¥Í≥†, Í∞ïÏ†ú ÏòàÏ∏°Ïù¥Í≥† Ïã†Î¢∞ÎèÑÍ∞Ä ÏûÑÍ≥ÑÍ∞í ÎØ∏ÎßåÏù¥Î©¥ Ïä§ÌÇµ
                should_skip = True
                total_skipped_predictions += 1
            
            # Í≤ÄÏ¶ù ÏàòÌñâ Ïó¨Î∂Ä Í≤∞Ï†ï (Í∏∞Î≥∏ Í∑úÏπô: ÏòàÏ∏°Í∞íÏù¥ ÏûàÏúºÎ©¥ Ìï≠ÏÉÅ Í≤ÄÏ¶ù)
            is_correct = None
            should_validate = False
            
            if has_prediction and not should_skip:
                # Í∏∞Î≥∏ Í∑úÏπô: ÏòàÏ∏°Í∞íÏù¥ ÏûàÍ≥† Ïä§ÌÇµÌïòÏßÄ ÏïäÏúºÎ©¥ Ìï≠ÏÉÅ Í≤ÄÏ¶ù ÏàòÌñâ
                should_validate = True
                is_correct = predicted_value == actual_value
                
                if not is_correct:
                    consecutive_failures += 1
                    consecutive_matches = 0
                    total_failures += 1
                    if consecutive_failures > max_consecutive_failures:
                        max_consecutive_failures = consecutive_failures
                else:
                    consecutive_failures = 0
                    consecutive_matches += 1
                    if consecutive_matches > max_consecutive_matches:
                        max_consecutive_matches = consecutive_matches
                    # Ï≤´ Î≤àÏß∏ ÏÑ±Í≥µ Ïä§ÌÖù Í∏∞Î°ù
                    if first_success_step is None:
                        first_success_step = total_steps
                
                total_predictions += 1
                if is_forced:
                    total_forced_predictions += 1
                    if is_correct:
                        total_forced_successes += 1
                
                # Í≤ÄÏ¶ù ÌõÑ Í∞ÑÍ≤© Î¶¨ÏÖã
                current_interval = 0
                
                # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù
                history.append({
                    'step': total_steps,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': has_prediction,
                    'validated': True,
                    'skipped': False
                })
                
                # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ
                i += 1
                current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
            elif has_prediction and should_skip:
                # Ïä§ÌÇµ: Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâÌïòÎêò Í∞ÑÍ≤©ÏùÄ Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÏùå (Î©àÏ∂§)
                # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù
                history.append({
                    'step': total_steps,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': has_prediction,
                    'validated': False,
                    'skipped': True
                })
                
                # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ (Í∞ÑÍ≤©ÏùÄ Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÏùå - Î©àÏ∂§ ÏÉÅÌÉú)
                i += 1
                current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
                # current_intervalÏùÄ Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÏùå (Î©àÏ∂§)
            else:
                # ÏòàÏ∏°Í∞íÏù¥ ÏóÜÏùå: Í∞ÑÍ≤© Ï¶ùÍ∞Ä
                history.append({
                    'step': total_steps,
                    'prefix': current_prefix,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': False,
                    'current_interval': current_interval,
                    'has_prediction': False,
                    'validated': False,
                    'skipped': False
                })
                
                current_interval += 1
                # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ
                i += 1
                current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
        
        # Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # Í∞ïÏ†ú ÏòàÏ∏° ÎπÑÏú® Í≥ÑÏÇ∞
        forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # Í∞ïÏ†ú ÏòàÏ∏° ÏÑ±Í≥µ ÎπÑÏú® Í≥ÑÏÇ∞
        forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'max_consecutive_matches': max_consecutive_matches,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'total_forced_predictions': total_forced_predictions,
            'total_skipped_predictions': total_skipped_predictions,
            'forced_prediction_rate': forced_prediction_rate,
            'forced_success_rate': forced_success_rate,
            'accuracy': accuracy,
            'first_success_step': first_success_step,  # Ï≤´ Î≤àÏß∏ ÏÑ±Í≥µ Ïä§ÌÖù
            'history': history
        }
        
    except Exception as e:
        st.error(f"Í≤ÄÏ¶ù Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        return None
    finally:
        conn.close()

def validate_interactive_multi_step_scenario(
    grid_string_id,
    cutoff_grid_string_id,
    window_size=7,
    method="ÎπàÎèÑ Í∏∞Î∞ò",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False
):
    """
    Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Îã§Îã®Í≥Ñ ÏòàÏ∏° ÏãúÎÇòÎ¶¨Ïò§ Î∞©ÏãùÏúºÎ°ú Îã®Ïùº grid_string Í≤ÄÏ¶ù
    
    Args:
        grid_string_id: Í≤ÄÏ¶ùÌï† grid_stringÏùò ID
        cutoff_grid_string_id: ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Í∏∞Ï§Ä ID (Ïù¥ ID Ïù¥ÌïòÎ•º ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Î°ú ÏÇ¨Ïö©)
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞ (Í∏∞Î≥∏Í∞í: 7)
        method: ÏòàÏ∏° Î∞©Î≤ï ("ÎπàÎèÑ Í∏∞Î∞ò", "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò", "ÏïàÏ†Ñ Ïö∞ÏÑ†", Í∏∞Î≥∏Í∞í: "ÎπàÎèÑ Í∏∞Î∞ò")
        use_threshold: ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö© Ïó¨Î∂Ä (Í∏∞Î≥∏Í∞í: True)
        threshold: ÏûÑÍ≥ÑÍ∞í (Í∏∞Î≥∏Í∞í: 60)
        max_interval: ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤© (Í∏∞Î≥∏Í∞í: 6)
    
    Returns:
        dict: {
            'grid_string_id': int,
            'max_consecutive_failures': int,
            'total_steps': int,
            'total_failures': int,
            'total_predictions': int,
            'accuracy': float,
            'history': list
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string Î°úÎìú
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        
        if len(grid_string) < window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'history': []
            }
        
        # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï∂ï (cutoff_grid_string_id Ïù¥Ìïò, Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Ï†úÏô∏)
        # grid_string_idÍ∞Ä cutoff_grid_string_id Ïù¥ÌïòÏù∏ Í≤ΩÏö∞ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï†úÏô∏
        train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? AND id < ? ORDER BY id"
        train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[cutoff_grid_string_id, grid_string_id])
        train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
        
        # N-gram Î°úÎìú
        train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
        
        if len(train_ngrams) == 0:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'history': []
            }
        
        # Î™®Îç∏ Íµ¨Ï∂ï
        if method == "ÎπàÎèÑ Í∏∞Î∞ò":
            model = build_frequency_model(train_ngrams)
        elif method == "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò":
            model = build_weighted_model(train_ngrams)
        else:
            # ÏïàÏ†Ñ Ïö∞ÏÑ†ÏùÄ Î≥ÑÎèÑ Ï≤òÎ¶¨ ÌïÑÏöî (ÏùºÎã® ÎπàÎèÑ Í∏∞Î∞òÏúºÎ°ú ÎåÄÏ≤¥)
            model = build_frequency_model(train_ngrams)
        
        # ÏãúÎÇòÎ¶¨Ïò§ Î∞©ÏãùÏúºÎ°ú ÌÖåÏä§Ìä∏
        prefix_length = window_size - 1
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        consecutive_matches = 0
        max_consecutive_matches = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        total_forced_predictions = 0
        total_forced_successes = 0
        current_interval = 0
        
        # Ï¥àÍ∏∞ prefix ÏÉùÏÑ±
        if len(grid_string) < prefix_length:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'history': []
            }
        
        current_prefix = grid_string[:prefix_length]
        
        # ÏòàÏ∏°Í∞íÏù¥ ÏûàÎäî Î™®Îì† Ïä§ÌÖùÏóêÏÑú Í≤ÄÏ¶ù ÏàòÌñâ
        # Í∞ÑÍ≤© Ï°∞Í±¥ÏùÄ ÏòàÏ∏°Ïù¥ ÏóÜÎäî Ïä§ÌÖùÏùÑ Ï∂îÏ†ÅÌïòÎäî Ïö©ÎèÑÎ°úÎßå ÏÇ¨Ïö© (current_interval)
        
        # Í∞Å Ïä§ÌÖùÎßàÎã§ ÏòàÏ∏° (Î™®Îì† Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏°Í∞í ÏÉùÏÑ±)
        for i in range(prefix_length, len(grid_string)):
            total_steps += 1
            actual_value = grid_string[i]
            
            # ÏòàÏ∏° (Î™®Îì† Ïä§ÌÖùÏóêÏÑú ÏàòÌñâ)
            if use_threshold:
                # ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö©
                prediction_result = predict_with_fallback_interval(
                    model,
                    current_prefix,
                    method=method,
                    threshold=threshold,
                    max_interval=max_interval,
                    current_interval=current_interval
                )
            else:
                # ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÎØ∏ÏÇ¨Ïö©: Î™®Îì† Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏° (Í∏∞Î≥∏ Í∑úÏπô)
                prediction_result = predict_for_prefix(model, current_prefix, method)
                # predict_for_prefixÎäî Ìï≠ÏÉÅ ÏòàÏ∏°Í∞íÏùÑ Î∞òÌôòÌïòÍ±∞ÎÇò NoneÏùÑ Î∞òÌôò
                # NoneÏù∏ Í≤ΩÏö∞ÎèÑ ÏûàÏúºÎØÄÎ°ú is_forcedÎäî FalseÎ°ú ÏÑ§Ï†ï
                if 'is_forced' not in prediction_result:
                    prediction_result['is_forced'] = False
            
            predicted_value = prediction_result.get('predicted')
            confidence = prediction_result.get('confidence', 0.0)
            is_forced = prediction_result.get('is_forced', False)
            
            # Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ: Í∞ïÏ†ú ÏòàÏ∏° Ïãú Î∞òÎåÄ Í∞í ÏÑ†ÌÉù
            if is_forced and reverse_forced_prediction and predicted_value is not None:
                predicted_value = 'p' if predicted_value == 'b' else 'b'
            
            has_prediction = predicted_value is not None
            
            # Ïã§Ï†úÍ∞íÍ≥º ÎπÑÍµê: ÏòàÏ∏°Í∞íÏù¥ ÏûàÎäî Î™®Îì† Ïä§ÌÖùÏóêÏÑú Í≤ÄÏ¶ù ÏàòÌñâ
            # Í∞ÑÍ≤© Ï°∞Í±¥ÏùÄ ÏòàÏ∏°Ïù¥ ÏóÜÎäî Ïä§ÌÖùÏùÑ Ïπ¥Ïö¥Ìä∏ÌïòÎäî Ïö©ÎèÑÎ°úÎßå ÏÇ¨Ïö©
            is_correct = None
            should_validate = False
            
            if has_prediction:
                # ÏòàÏ∏°Í∞íÏù¥ ÏûàÏúºÎ©¥ Ìï≠ÏÉÅ Í≤ÄÏ¶ù ÏàòÌñâ
                should_validate = True
                is_correct = predicted_value == actual_value
                
                if not is_correct:
                    consecutive_failures += 1
                    consecutive_matches = 0  # Î∂àÏùºÏπò Ïãú Ïó∞ÏÜç ÏùºÏπò Î¶¨ÏÖã
                    total_failures += 1
                    if consecutive_failures > max_consecutive_failures:
                        max_consecutive_failures = consecutive_failures
                else:
                    consecutive_failures = 0  # ÏùºÏπò Ïãú Ïó∞ÏÜç Î∂àÏùºÏπò Î¶¨ÏÖã
                    consecutive_matches += 1
                    if consecutive_matches > max_consecutive_matches:
                        max_consecutive_matches = consecutive_matches
                
                total_predictions += 1
                if is_forced:
                    total_forced_predictions += 1
                    if is_correct:
                        total_forced_successes += 1
            
            # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù (Î™®Îì† Ïä§ÌÖù Í∏∞Î°ù, ÏòàÏ∏°Í∞íÏù¥ ÏûàÏúºÎ©¥ Ìï≠ÏÉÅ Í≤ÄÏ¶ù)
            history.append({
                'step': total_steps,
                'prefix': current_prefix,
                'predicted': predicted_value,
                'actual': actual_value,
                'is_correct': is_correct,
                'confidence': confidence,
                'is_forced': is_forced,
                'current_interval': current_interval,  # ÏòàÏ∏° Ï†Ñ Í∞ÑÍ≤©
                'has_prediction': has_prediction,
                'validated': should_validate  # Ïù¥ Ïä§ÌÖùÏóêÏÑú Ïã§Ï†ú ÎπÑÍµêÍ∞Ä ÏàòÌñâÎêòÏóàÎäîÏßÄ
            })
            
            # Í∞ÑÍ≤© ÏóÖÎç∞Ïù¥Ìä∏ (Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÎÑòÏñ¥Í∞ÄÍ∏∞ Ï†ÑÏóê)
            if has_prediction:
                current_interval = 0  # ÏòàÏ∏°Ïù¥ ÏûàÏóàÏúºÎ©¥ Í∞ÑÍ≤© Î¶¨ÏÖã
            else:
                current_interval += 1  # ÏòàÏ∏°Ïù¥ ÏóÜÏóàÏúºÎ©¥ Í∞ÑÍ≤© Ï¶ùÍ∞Ä
            
            # Îã§Ïùå prefix ÏÉùÏÑ±
            current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
        
        # Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞ (ÏòàÏ∏°Ïù¥ ÏûàÏóàÎçò Ïä§ÌÖùÎßå Í≥†Î†§)
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # Í∞ïÏ†ú ÏòàÏ∏° ÎπÑÏú® Í≥ÑÏÇ∞
        forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # Í∞ïÏ†ú ÏòàÏ∏° ÏÑ±Í≥µ ÎπÑÏú® Í≥ÑÏÇ∞
        forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'max_consecutive_matches': max_consecutive_matches,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'total_forced_predictions': total_forced_predictions,
            'total_forced_successes': total_forced_successes,
            'forced_prediction_rate': forced_prediction_rate,
            'forced_success_rate': forced_success_rate,
            'accuracy': accuracy,
            'history': history
        }
        
    except Exception as e:
        st.error(f"Í≤ÄÏ¶ù Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_interactive_multi_step_scenario(
    cutoff_grid_string_id,
    window_size=7,
    method="ÎπàÎèÑ Í∏∞Î∞ò",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False
):
    """
    cutoff_grid_string_id Ïù¥ÌõÑÏùò Î™®Îì† grid_stringÏóê ÎåÄÌï¥ Î∞∞Ïπò Í≤ÄÏ¶ù Ïã§Ìñâ
    
    Args:
        cutoff_grid_string_id: Í∏∞Ï§Ä grid_string ID (Ïù¥ ID Ïù¥ÌõÑÏùò Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù)
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞ (Í∏∞Î≥∏Í∞í: 7)
        method: ÏòàÏ∏° Î∞©Î≤ï (Í∏∞Î≥∏Í∞í: "ÎπàÎèÑ Í∏∞Î∞ò")
        use_threshold: ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö© Ïó¨Î∂Ä (Í∏∞Î≥∏Í∞í: True)
        threshold: ÏûÑÍ≥ÑÍ∞í (Í∏∞Î≥∏Í∞í: 60)
        max_interval: ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤© (Í∏∞Î≥∏Í∞í: 6)
    
    Returns:
        dict: {
            'results': list,
            'summary': dict
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff_grid_string_id Ïù¥ÌõÑÏùò Î™®Îì† grid_string Î°úÎìú
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0,
                    'prediction_rate': 0.0
                },
                'grid_string_ids': []
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        all_history = []  # Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ ÏàòÏßëÏö©
        
        # Í∞Å grid_stringÏóê ÎåÄÌï¥ Í≤ÄÏ¶ù Ïã§Ìñâ
        for grid_string_id in grid_string_ids:
            result = validate_interactive_multi_step_scenario(
                grid_string_id,
                cutoff_grid_string_id,
                window_size=window_size,
                method=method,
                use_threshold=use_threshold,
                threshold=threshold,
                max_interval=max_interval,
                reverse_forced_prediction=reverse_forced_prediction
            )
            
            if result is not None:
                results.append(result)
                # ÌûàÏä§ÌÜ†Î¶¨ ÏàòÏßë (Ïã†Î¢∞ÎèÑ ÌÜµÍ≥ÑÏö©)
                all_history.extend(result.get('history', []))
        
        # ÏöîÏïΩ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            total_steps = sum(r['total_steps'] for r in results)
            total_failures = sum(r['total_failures'] for r in results)
            total_predictions = sum(r['total_predictions'] for r in results)
            total_forced_predictions = sum(r.get('total_forced_predictions', 0) for r in results)
            total_forced_successes = sum(r.get('total_forced_successes', 0) for r in results)
            prediction_rate = (total_predictions / total_steps * 100) if total_steps > 0 else 0.0
            forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
            forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': total_steps,
                'total_failures': total_failures,
                'total_predictions': total_predictions,
                'total_forced_predictions': total_forced_predictions,
                'total_forced_successes': total_forced_successes,
                'prediction_rate': prediction_rate,
                'forced_prediction_rate': forced_prediction_rate,
                'forced_success_rate': forced_success_rate
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_forced_successes': 0,
                'prediction_rate': 0.0,
                'forced_prediction_rate': 0.0,
                'forced_success_rate': 0.0
            }
        
        return {
            'results': results,
            'summary': summary,
            'all_history': all_history,  # Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ ÏàòÏßëÏö©
            'grid_string_ids': grid_string_ids  # Í≤ÄÏ¶ùÌïú grid_string_id Î¶¨Ïä§Ìä∏
        }
        
    except Exception as e:
        st.error(f"Î∞∞Ïπò Í≤ÄÏ¶ù Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_interactive_multi_step_scenario_with_confidence_skip(
    cutoff_grid_string_id,
    window_size=7,
    method="ÎπàÎèÑ Í∏∞Î∞ò",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False,
    confidence_skip_threshold=51,
    use_stored_predictions=False,
    stored_threshold=0
):
    """
    Ïã†Î¢∞ÎèÑ Í∏∞Î∞ò Ïä§ÌÇµ Í∑úÏπôÏù¥ ÏûàÎäî Î∞∞Ïπò Í≤ÄÏ¶ù
    
    Args:
        cutoff_grid_string_id: Í∏∞Ï§Ä grid_string ID
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞
        method: ÏòàÏ∏° Î∞©Î≤ï
        use_threshold: ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö© Ïó¨Î∂Ä
        threshold: ÏûÑÍ≥ÑÍ∞í
        max_interval: ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤©
        reverse_forced_prediction: Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ ÏÇ¨Ïö© Ïó¨Î∂Ä
        confidence_skip_threshold: Ïä§ÌÇµÌï† Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í
        use_stored_predictions: ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î(stored_predictions) ÏÇ¨Ïö© Ïó¨Î∂Ä (Í∏∞Î≥∏Í∞í: False)
        stored_threshold: stored_predictions Ï°∞Ìöå Ïãú ÏÇ¨Ïö©Ìï† ÏûÑÍ≥ÑÍ∞í (Í∏∞Î≥∏Í∞í: 0)
    
    Returns:
        dict: Î∞∞Ïπò Í≤ÄÏ¶ù Í≤∞Í≥º
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff_grid_string_id Ïù¥ÌõÑÏùò Î™®Îì† grid_string Î°úÎìú
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0,
                    'total_skipped_predictions': 0,
                    'prediction_rate': 0.0
                },
                'grid_string_ids': []
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        all_history = []  # Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ ÏàòÏßëÏö©
        
        # Í∞Å grid_stringÏóê ÎåÄÌï¥ Í≤ÄÏ¶ù Ïã§Ìñâ
        for grid_string_id in grid_string_ids:
            result = validate_interactive_multi_step_scenario_with_confidence_skip(
                grid_string_id,
                cutoff_grid_string_id,
                window_size=window_size,
                method=method,
                use_threshold=use_threshold,
                threshold=threshold,
                max_interval=max_interval,
                reverse_forced_prediction=reverse_forced_prediction,
                confidence_skip_threshold=confidence_skip_threshold,
                use_stored_predictions=use_stored_predictions,
                stored_threshold=stored_threshold
            )
            
            if result is not None:
                results.append(result)
                # ÌûàÏä§ÌÜ†Î¶¨ ÏàòÏßë (Ïã†Î¢∞ÎèÑ ÌÜµÍ≥ÑÏö©)
                all_history.extend(result.get('history', []))
        
        # ÏöîÏïΩ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            total_steps = sum(r['total_steps'] for r in results)
            total_failures = sum(r['total_failures'] for r in results)
            total_predictions = sum(r['total_predictions'] for r in results)
            total_skipped_predictions = sum(r.get('total_skipped_predictions', 0) for r in results)
            total_forced_predictions = sum(r.get('total_forced_predictions', 0) for r in results)
            total_forced_successes = sum(r.get('total_forced_successes', 0) for r in results)
            prediction_rate = (total_predictions / total_steps * 100) if total_steps > 0 else 0.0
            forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
            forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
            
            # Ï≤´ Î≤àÏß∏ ÏÑ±Í≥µ Ïä§ÌÖù ÌÜµÍ≥Ñ
            first_success_steps = [r.get('first_success_step') for r in results if r.get('first_success_step') is not None]
            avg_first_success_step = sum(first_success_steps) / len(first_success_steps) if len(first_success_steps) > 0 else None
            min_first_success_step = min(first_success_steps) if len(first_success_steps) > 0 else None
            max_first_success_step = max(first_success_steps) if len(first_success_steps) > 0 else None
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': total_steps,
                'total_failures': total_failures,
                'total_predictions': total_predictions,
                'total_skipped_predictions': total_skipped_predictions,
                'total_forced_predictions': total_forced_predictions,
                'total_forced_successes': total_forced_successes,
                'prediction_rate': prediction_rate,
                'forced_prediction_rate': forced_prediction_rate,
                'forced_success_rate': forced_success_rate,
                'avg_first_success_step': avg_first_success_step,
                'min_first_success_step': min_first_success_step,
                'max_first_success_step': max_first_success_step,
                'total_with_success': len(first_success_steps)  # ÏÑ±Í≥µÏù¥ ÏûàÏóàÎçò grid_string Ïàò
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_skipped_predictions': 0,
                'total_forced_predictions': 0,
                'total_forced_successes': 0,
                'prediction_rate': 0.0,
                'forced_prediction_rate': 0.0,
                'forced_success_rate': 0.0
            }
        
        return {
            'results': results,
            'summary': summary,
            'all_history': all_history,  # Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ ÏàòÏßëÏö©
            'grid_string_ids': grid_string_ids  # Í≤ÄÏ¶ùÌïú grid_string_id Î¶¨Ïä§Ìä∏
        }
        
    except Exception as e:
        st.error(f"Î∞∞Ïπò Í≤ÄÏ¶ù Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        return None
    finally:
        conn.close()

def get_failure_history_interactive(
    grid_string_id,
    cutoff_grid_string_id,
    window_size=7,
    method="ÎπàÎèÑ Í∏∞Î∞ò",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False
):
    """
    Ïã§Ìå® Grid StringÏùò ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨ Ï°∞Ìöå (Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Îã§Îã®Í≥Ñ ÏòàÏ∏° ÏãúÎÇòÎ¶¨Ïò§Ïö©)
    
    Args:
        grid_string_id: Ï°∞ÌöåÌï† grid_stringÏùò ID
        cutoff_grid_string_id: ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Í∏∞Ï§Ä ID
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞
        method: ÏòàÏ∏° Î∞©Î≤ï
        use_threshold: ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö© Ïó¨Î∂Ä
        threshold: ÏûÑÍ≥ÑÍ∞í
        max_interval: ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤©
    
    Returns:
        dict: ÌûàÏä§ÌÜ†Î¶¨ Îç∞Ïù¥ÌÑ∞
    """
    result = validate_interactive_multi_step_scenario(
        grid_string_id,
        cutoff_grid_string_id,
        window_size=window_size,
        method=method,
        use_threshold=use_threshold,
        threshold=threshold,
        max_interval=max_interval,
        reverse_forced_prediction=reverse_forced_prediction
    )
    
    if result is None:
        return None
    
    return result

def get_grid_strings_by_percentage_range(start_percentage, end_percentage):
    """
    ÎπÑÏú® Î≤îÏúÑÏóê Ìï¥ÎãπÌïòÎäî grid_stringÎì§ÏùÑ Î°úÎìú
    
    Args:
        start_percentage: ÏãúÏûë ÎπÑÏú® (0-100)
        end_percentage: Ï¢ÖÎ£å ÎπÑÏú® (0-100)
    
    Returns:
        DataFrame: Ìï¥Îãπ ÎπÑÏú® Î≤îÏúÑÏùò grid_string DataFrame (id Í∏∞Ï§Ä Ï†ïÎ†¨)
    """
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    try:
        # Ï†ÑÏ≤¥ grid_string Í∞úÏàò ÌôïÏù∏
        count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings"
        count_df = pd.read_sql_query(count_query, conn)
        total_count = count_df.iloc[0]['count'] if len(count_df) > 0 else 0
        
        if total_count == 0:
            return pd.DataFrame()
        
        # ÎπÑÏú®Ïóê Ìï¥ÎãπÌïòÎäî Ïù∏Îç±Ïä§ Í≥ÑÏÇ∞
        start_index = int(total_count * start_percentage / 100)
        end_index = int(total_count * end_percentage / 100)
        
        # Î™®Îì† grid_stringÏùÑ id Í∏∞Ï§ÄÏúºÎ°ú Ï†ïÎ†¨ÌïòÏó¨ Î°úÎìú
        query = "SELECT id, grid_string, created_at FROM preprocessed_grid_strings ORDER BY id"
        df_all = pd.read_sql_query(query, conn)
        
        if len(df_all) == 0:
            return pd.DataFrame()
        
        # Ìï¥Îãπ Î≤îÏúÑÏùò Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
        if start_index < len(df_all) and end_index <= len(df_all):
            df_range = df_all.iloc[start_index:end_index].copy()
        else:
            return pd.DataFrame()
        
        return df_range
        
    except Exception as e:
        st.error(f"Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        return pd.DataFrame()
    finally:
        conn.close()

def validate_forced_prediction_hypothesis(
    train_cutoff_id,
    validation_start_id,
    validation_end_id,
    window_size=7,
    method="ÎπàÎèÑ Í∏∞Î∞ò"
):
    """
    Í∞ïÏ†ú ÏòàÏ∏° Í∞ÄÏÑ§ Í≤ÄÏ¶ù (Îã®Ïùº Îã®Í≥Ñ)
    
    Î™®Îì† Ïä§ÌÖùÏóêÏÑú Í∞ïÏ†ú ÏòàÏ∏°ÏùÑ ÏàòÌñâÌïòÍ≥†, Í∞ÑÍ≤©ÏùÑ ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞ -1Î°ú ÏÑ§Ï†ï
    
    Args:
        train_cutoff_id: ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Í∏∞Ï§Ä ID (Ïù¥ ID Ïù¥ÌïòÎ•º ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Î°ú ÏÇ¨Ïö©)
        validation_start_id: Í≤ÄÏ¶ù ÏãúÏûë ID
        validation_end_id: Í≤ÄÏ¶ù Ï¢ÖÎ£å ID (Ïù¥ ID Ïù¥ÌïòÍπåÏßÄ Í≤ÄÏ¶ù)
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞
        method: ÏòàÏ∏° Î∞©Î≤ï
    
    Returns:
        dict: Í≤ÄÏ¶ù Í≤∞Í≥º
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Íµ¨Ï∂ï
        train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
        train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[train_cutoff_id])
        train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
        
        # N-gram Î°úÎìú
        train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
        
        if len(train_ngrams) == 0:
            return {
                'train_cutoff_id': train_cutoff_id,
                'validation_start_id': validation_start_id,
                'validation_end_id': validation_end_id,
                'total_grid_strings': 0,
                'tested_grid_strings': 0,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'accuracy': 0.0,
                'forced_success_rate': 0.0,
                'results': []
            }
        
        # Î™®Îç∏ Íµ¨Ï∂ï
        if method == "ÎπàÎèÑ Í∏∞Î∞ò":
            model = build_frequency_model(train_ngrams)
        elif method == "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò":
            model = build_weighted_model(train_ngrams)
        else:
            model = build_frequency_model(train_ngrams)
        
        # Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Î°úÎìú
        validation_query = """
            SELECT id, grid_string 
            FROM preprocessed_grid_strings 
            WHERE id > ? AND id <= ? 
            ORDER BY id
        """
        validation_df = pd.read_sql_query(
            validation_query, 
            conn, 
            params=[validation_start_id, validation_end_id]
        )
        
        if len(validation_df) == 0:
            return {
                'train_cutoff_id': train_cutoff_id,
                'validation_start_id': validation_start_id,
                'validation_end_id': validation_end_id,
                'total_grid_strings': 0,
                'tested_grid_strings': 0,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'accuracy': 0.0,
                'forced_success_rate': 0.0,
                'results': []
            }
        
        # Í≤ÄÏ¶ù Ïã§Ìñâ
        results = []
        max_consecutive_failures_all = 0
        max_consecutive_matches_all = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        total_forced_predictions = 0
        total_forced_successes = 0
        
        # max_interval = window_size - 1
        max_interval = window_size - 1
        
        for _, row in validation_df.iterrows():
            grid_string_id = row['id']
            grid_string = row['grid_string']
            
            if len(grid_string) < window_size:
                continue
            
            # Í≤ÄÏ¶ù Ïã§Ìñâ (use_threshold=False, Ìï≠ÏÉÅ ÏòàÏ∏°ÌïòÎêò max_interval=window_size-1Î°ú ÏÑ§Ï†ï)
            # Í∞ÄÏÑ§: Î™®Îì† Ïä§ÌÖùÏùÄ Í∞ïÏ†ú ÏòàÏ∏°, Í∞ÑÍ≤© = ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞ - 1
            # use_threshold=FalseÎ°ú ÏÑ§Ï†ïÌïòÎ©¥ Î™®Îì† Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏°Ïù¥ Î∞úÏÉù (Í∞ïÏ†ú ÏòàÏ∏° Í∞úÎÖê)
            result = validate_interactive_multi_step_scenario(
                grid_string_id,
                train_cutoff_id,
                window_size=window_size,
                method=method,
                use_threshold=False,  # ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö© Ïïà Ìï® (Î™®Îì† Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏°)
                threshold=60,
                max_interval=max_interval,  # ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞ - 1 (Í∞ÄÏÑ§ ÏöîÍµ¨ÏÇ¨Ìï≠)
                reverse_forced_prediction=False
            )
            
            if result is not None:
                results.append(result)
                max_consecutive_failures_all = max(max_consecutive_failures_all, result['max_consecutive_failures'])
                max_consecutive_matches_all = max(max_consecutive_matches_all, result.get('max_consecutive_matches', 0))
                total_steps += result['total_steps']
                total_failures += result['total_failures']
                total_predictions += result['total_predictions']
                total_forced_predictions += result['total_forced_predictions']
                total_forced_successes += result.get('total_forced_successes', 0)
        
        # Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # Í∞ïÏ†ú ÏòàÏ∏° ÏÑ±Í≥µÎ•† Í≥ÑÏÇ∞
        forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
        
        return {
            'train_cutoff_id': train_cutoff_id,
            'validation_start_id': validation_start_id,
            'validation_end_id': validation_end_id,
            'total_grid_strings': len(validation_df),
            'tested_grid_strings': len(results),
            'max_consecutive_failures': max_consecutive_failures_all,
            'max_consecutive_matches': max_consecutive_matches_all,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'total_forced_predictions': total_forced_predictions,
            'accuracy': accuracy,
            'forced_success_rate': forced_success_rate,
            'results': results
        }
        
    except Exception as e:
        st.error(f"Í≤ÄÏ¶ù Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        import traceback
        st.error(f"ÏÉÅÏÑ∏ Ïò§Î•ò: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def render_live_game_play(game_state):
    """
    ÎùºÏù¥Î∏å Í≤åÏûÑ ÏßÑÌñâ UI Î†åÎçîÎßÅ
    Í≤åÏûÑ ÏÉÅÌÉúÍ∞Ä ÏûàÏùÑ ÎïåÎßå Ìò∏Ï∂úÎêòÏñ¥Ïïº Ìï®
    """
    # ÏûêÎèô Ïã§Ìñâ ÏôÑÎ£å Î©îÏãúÏßÄ Ï†úÍ±∞ (ÏÑ±Îä• Í∞úÏÑ†)
    
    # ÌòÑÏû¨ Ïä§ÌÖù Ï†ïÎ≥¥
    st.markdown("---")
    st.markdown("### üìç ÌòÑÏû¨ Ïä§ÌÖù")
    
    # ÏòàÏ∏° ÏàòÌñâ
    current_prefix = game_state['current_prefix']
    current_interval = game_state['current_interval']
    model = game_state['model']
    
    if game_state['use_threshold']:
        prediction_result = predict_with_fallback_interval(
            model,
            current_prefix,
            method=game_state['method'],
            threshold=game_state['threshold'],
            max_interval=game_state['max_interval'],
            current_interval=current_interval
        )
    else:
        prediction_result = predict_for_prefix(model, current_prefix, game_state['method'])
        if 'is_forced' not in prediction_result:
            prediction_result['is_forced'] = False
    
    predicted_value = prediction_result.get('predicted')
    confidence = prediction_result.get('confidence', 0.0)
    is_forced = prediction_result.get('is_forced', False)
    has_prediction = predicted_value is not None
    
    # Ïä§ÌÇµ Í∑úÏπô Ï≤¥ÌÅ¨
    should_skip = False
    if game_state['use_threshold'] and has_prediction and is_forced and confidence < game_state['confidence_skip_threshold']:
        should_skip = True
    
    # ÌòÑÏû¨ Ïä§ÌÖù Ï†ïÎ≥¥ ÌëúÏãú (Ïª¥Ìå©Ìä∏ÌïòÍ≤å)
    col_info1, col_info2, col_info3, col_info4 = st.columns(4)
    with col_info1:
        st.caption("Prefix")
        st.markdown(f"<div style='font-size: 24px; font-weight: bold;'>{current_prefix}</div>", unsafe_allow_html=True)
    with col_info2:
        if has_prediction:
            forced_mark = "‚ö°" if is_forced else ""
            skip_mark = "‚è≠Ô∏è" if should_skip else ""
            st.caption("ÏòàÏ∏°Í∞í")
            st.text(f"{predicted_value}{forced_mark}{skip_mark}")
        else:
            st.caption("ÏòàÏ∏°Í∞í")
            st.text("ÏóÜÏùå")
    with col_info3:
        if has_prediction:
            st.caption("Ïã†Î¢∞ÎèÑ")
            st.text(f"{confidence:.1f}%")
        else:
            st.caption("Ïã†Î¢∞ÎèÑ")
            st.text("-")
    with col_info4:
        st.caption("Í∞ÑÍ≤©")
        st.text(f"{current_interval}/{game_state['max_interval']}")
    
    # Îã§Ïùå Ïä§ÌÖù Í≤ΩÎ°ú ÎØ∏Î¶¨Î≥¥Í∏∞
    st.markdown("---")
    st.markdown('<p style="font-size: 1em; color: #666; margin-top: -10px;"><strong>Îã§Ïùå Ïä§ÌÖù Í≤ΩÎ°ú ÎØ∏Î¶¨Î≥¥Í∏∞:</strong></p>', unsafe_allow_html=True)
    
    # Îã§Ïùå prefix ÏÉùÏÑ± (bÏôÄ p Îëê Í≤ΩÏö∞ Î™®Îëê)
    next_prefix_b = get_next_prefix(current_prefix, 'b', game_state['window_size'])
    next_prefix_p = get_next_prefix(current_prefix, 'p', game_state['window_size'])
    
    # Îã§Ïùå prefixÏóê ÎåÄÌïú ÏòàÏ∏° (Î™®Îç∏Ïù¥ ÏûàÎäî Í≤ΩÏö∞)
    if model is not None:
        next_pred_b = None
        next_pred_p = None
        next_conf_b = 0.0
        next_conf_p = 0.0
        next_forced_b = False
        next_forced_p = False
        
        try:
            if game_state['use_threshold']:
                # Îã§Ïùå Ïä§ÌÖù ÏòàÏ∏°Ïö© Í∞ÑÍ≤© Í≥ÑÏÇ∞
                # ÌòÑÏû¨ Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏°Ïù¥ ÏûàÏóàÏúºÎ©¥, Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÎÑòÏñ¥Í∞ÄÎ©¥ Í∞ÑÍ≤©Ïù¥ 0ÏúºÎ°ú Î¶¨ÏÖã
                # ÌòÑÏû¨ Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏°Ïù¥ ÏóÜÏóàÏúºÎ©¥, Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÎÑòÏñ¥Í∞ÄÎ©¥ Í∞ÑÍ≤©Ïù¥ 1 Ï¶ùÍ∞Ä
                if has_prediction:
                    # ÌòÑÏû¨ Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏°Ïù¥ ÏûàÏóàÏúºÎ©¥, Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÎÑòÏñ¥Í∞ÄÎ©¥ Í∞ÑÍ≤©Ïù¥ 0ÏúºÎ°ú Î¶¨ÏÖã
                    next_interval = 0
                else:
                    # ÌòÑÏû¨ Ïä§ÌÖùÏóêÏÑú ÏòàÏ∏°Ïù¥ ÏóÜÏóàÏúºÎ©¥, Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÎÑòÏñ¥Í∞ÄÎ©¥ Í∞ÑÍ≤©Ïù¥ 1 Ï¶ùÍ∞Ä
                    next_interval = current_interval + 1
                
                # Í∞ÑÍ≤©ÏùÑ Í≥†Î†§ÌïòÏó¨ ÏòàÏ∏°
                next_result_b = predict_with_fallback_interval(
                    model,
                    next_prefix_b,
                    game_state['method'],
                    threshold=game_state['threshold'],
                    max_interval=game_state['max_interval'],
                    current_interval=next_interval
                )
                next_result_p = predict_with_fallback_interval(
                    model,
                    next_prefix_p,
                    game_state['method'],
                    threshold=game_state['threshold'],
                    max_interval=game_state['max_interval'],
                    current_interval=next_interval
                )
                
                next_forced_b = next_result_b.get('is_forced', False)
                next_forced_p = next_result_p.get('is_forced', False)
            else:
                next_result_b = predict_for_prefix(model, next_prefix_b, game_state['method'])
                next_result_p = predict_for_prefix(model, next_prefix_p, game_state['method'])
                next_forced_b = False
                next_forced_p = False
            
            next_pred_b = next_result_b.get('predicted')
            next_pred_p = next_result_p.get('predicted')
            next_conf_b = next_result_b.get('confidence', 0.0)
            next_conf_p = next_result_p.get('confidence', 0.0)
        except Exception as e:
            pass
        
        # Í≤ΩÎ°ú ÌëúÏãú
        col_path1, col_path2 = st.columns(2)
        with col_path1:
            if next_pred_b is not None and str(next_pred_b).strip() != '':
                forced_marker = " ‚ö°" if next_forced_b else ""
                st.markdown(f'<p style="font-size: 0.95em; color: #333;">Ïã§Ï†úÍ∞í <strong>b</strong> ‚Üí Îã§Ïùå prefix: <code>{next_prefix_b}</code> ‚Üí ÏòàÏ∏°: <code>{next_pred_b}{forced_marker}</code> ({next_conf_b:.1f}%)</p>', unsafe_allow_html=True)
            else:
                st.markdown(f'<p style="font-size: 0.95em; color: #666;">Ïã§Ï†úÍ∞í <strong>b</strong> ‚Üí Îã§Ïùå prefix: <code>{next_prefix_b}</code> ‚Üí ÏòàÏ∏°: <code>-</code></p>', unsafe_allow_html=True)
        
        with col_path2:
            if next_pred_p is not None and str(next_pred_p).strip() != '':
                forced_marker = " ‚ö°" if next_forced_p else ""
                st.markdown(f'<p style="font-size: 0.95em; color: #333;">Ïã§Ï†úÍ∞í <strong>p</strong> ‚Üí Îã§Ïùå prefix: <code>{next_prefix_p}</code> ‚Üí ÏòàÏ∏°: <code>{next_pred_p}{forced_marker}</code> ({next_conf_p:.1f}%)</p>', unsafe_allow_html=True)
            else:
                st.markdown(f'<p style="font-size: 0.95em; color: #666;">Ïã§Ï†úÍ∞í <strong>p</strong> ‚Üí Îã§Ïùå prefix: <code>{next_prefix_p}</code> ‚Üí ÏòàÏ∏°: <code>-</code></p>', unsafe_allow_html=True)
    else:
        # Î™®Îç∏Ïù¥ ÏóÜÎäî Í≤ΩÏö∞ prefixÎßå ÌëúÏãú
        col_path1, col_path2 = st.columns(2)
        with col_path1:
            st.markdown(f'<p style="font-size: 0.95em; color: #666;">Ïã§Ï†úÍ∞í <strong>b</strong> ‚Üí Îã§Ïùå prefix: <code>{next_prefix_b}</code></p>', unsafe_allow_html=True)
        with col_path2:
            st.markdown(f'<p style="font-size: 0.95em; color: #666;">Ïã§Ï†úÍ∞í <strong>p</strong> ‚Üí Îã§Ïùå prefix: <code>{next_prefix_p}</code></p>', unsafe_allow_html=True)
    
    # Ïã§Ï†úÍ∞í ÏûÖÎ†• (Î≤ÑÌäºÏãù)
    if has_prediction and not should_skip:
        st.markdown("---")
        st.markdown("#### Ïã§Ï†úÍ∞í ÏÑ†ÌÉù")
        
        # Ïù¥Ï†Ñ ÏÉÅÌÉú Ï†ÄÏû• (Ï∑®ÏÜå Í∏∞Îä•Ïö©)
        if 'previous_game_state' not in st.session_state or st.session_state.get('previous_game_state_step', -1) != game_state['current_step']:
            st.session_state.previous_game_state = {
                'current_step': game_state['current_step'],
                'current_index': game_state['current_index'],
                'current_prefix': game_state['current_prefix'],
                'current_interval': game_state['current_interval'],
                'consecutive_failures': game_state['consecutive_failures'],
                'max_consecutive_failures': game_state['max_consecutive_failures'],
                'total_predictions': game_state['total_predictions'],
                'total_failures': game_state['total_failures'],
                'total_forced_predictions': game_state['total_forced_predictions'],
                'history': game_state['history'].copy()
            }
            st.session_state.previous_game_state_step = game_state['current_step']
        
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])
        with col_btn1:
            if st.button("üî¥ B", use_container_width=True, key=f"live_game_btn_b_{game_state['current_step']}"):
                actual_value = 'b'
                
                # Í≤ÄÏ¶ù ÏàòÌñâ
                is_correct = predicted_value == actual_value
                
                if not is_correct:
                    game_state['consecutive_failures'] += 1
                    game_state['total_failures'] += 1
                    if game_state['consecutive_failures'] > game_state['max_consecutive_failures']:
                        game_state['max_consecutive_failures'] = game_state['consecutive_failures']
                else:
                    game_state['consecutive_failures'] = 0
                
                game_state['total_predictions'] += 1
                if is_forced:
                    game_state['total_forced_predictions'] += 1
                
                # Í∞ÑÍ≤© Î¶¨ÏÖã
                game_state['current_interval'] = 0
                
                # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': 0,
                    'has_prediction': True,
                    'validated': True,
                    'skipped': False
                })
                
                # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                # prefix ÏóÖÎç∞Ïù¥Ìä∏ (Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Î™®ÎìúÏóêÏÑúÎäî Ìï≠ÏÉÅ ÏóÖÎç∞Ïù¥Ìä∏)
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn2:
            if st.button("üîµ P", use_container_width=True, key=f"live_game_btn_p_{game_state['current_step']}"):
                actual_value = 'p'
                
                # Í≤ÄÏ¶ù ÏàòÌñâ
                is_correct = predicted_value == actual_value
                
                if not is_correct:
                    game_state['consecutive_failures'] += 1
                    game_state['total_failures'] += 1
                    if game_state['consecutive_failures'] > game_state['max_consecutive_failures']:
                        game_state['max_consecutive_failures'] = game_state['consecutive_failures']
                else:
                    game_state['consecutive_failures'] = 0
                
                game_state['total_predictions'] += 1
                if is_forced:
                    game_state['total_forced_predictions'] += 1
                
                # Í∞ÑÍ≤© Î¶¨ÏÖã
                game_state['current_interval'] = 0
                
                # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': 0,
                    'has_prediction': True,
                    'validated': True,
                    'skipped': False
                })
                
                # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                # prefix ÏóÖÎç∞Ïù¥Ìä∏ (Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Î™®ÎìúÏóêÏÑúÎäî Ìï≠ÏÉÅ ÏóÖÎç∞Ïù¥Ìä∏)
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn3:
            if st.button("‚Ü©Ô∏è Ï∑®ÏÜå", use_container_width=True, key=f"live_game_btn_cancel_{game_state['current_step']}"):
                if 'previous_game_state' in st.session_state:
                    prev_state = st.session_state.previous_game_state
                    # Ïù¥Ï†Ñ ÏÉÅÌÉúÎ°ú Î≥µÏõê
                    game_state['current_step'] = prev_state['current_step']
                    game_state['current_index'] = prev_state['current_index']
                    game_state['current_prefix'] = prev_state['current_prefix']
                    game_state['current_interval'] = prev_state['current_interval']
                    game_state['consecutive_failures'] = prev_state['consecutive_failures']
                    game_state['max_consecutive_failures'] = prev_state['max_consecutive_failures']
                    game_state['total_predictions'] = prev_state['total_predictions']
                    game_state['total_failures'] = prev_state['total_failures']
                    game_state['total_forced_predictions'] = prev_state['total_forced_predictions']
                    game_state['history'] = prev_state['history'].copy()
                    st.rerun()
    elif has_prediction and should_skip:
        # Ïä§ÌÇµ ÏÉÅÌÉú
        st.markdown("---")
        st.markdown("#### Ïã§Ï†úÍ∞í ÏÑ†ÌÉù (Ïä§ÌÇµ Î™®Îìú)")
        
        # Ïù¥Ï†Ñ ÏÉÅÌÉú Ï†ÄÏû• (Ï∑®ÏÜå Í∏∞Îä•Ïö©)
        if 'previous_game_state' not in st.session_state or st.session_state.get('previous_game_state_step', -1) != game_state['current_step']:
            st.session_state.previous_game_state = {
                'current_step': game_state['current_step'],
                'current_index': game_state['current_index'],
                'current_prefix': game_state['current_prefix'],
                'current_interval': game_state['current_interval'],
                'consecutive_failures': game_state['consecutive_failures'],
                'max_consecutive_failures': game_state['max_consecutive_failures'],
                'total_predictions': game_state['total_predictions'],
                'total_failures': game_state['total_failures'],
                'total_forced_predictions': game_state['total_forced_predictions'],
                'total_skipped_predictions': game_state['total_skipped_predictions'],
                'history': game_state['history'].copy()
            }
            st.session_state.previous_game_state_step = game_state['current_step']
        
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])
        with col_btn1:
            if st.button("üî¥ B", use_container_width=True, key=f"live_game_btn_skip_b_{game_state['current_step']}"):
                actual_value = 'b'
                
                # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù (Ïä§ÌÇµ)
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': True,
                    'validated': False,
                    'skipped': True
                })
                
                game_state['total_skipped_predictions'] += 1
                
                # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ (Í∞ÑÍ≤©ÏùÄ Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÏùå)
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn2:
            if st.button("üîµ P", use_container_width=True, key=f"live_game_btn_skip_p_{game_state['current_step']}"):
                actual_value = 'p'
                
                # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù (Ïä§ÌÇµ)
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': True,
                    'validated': False,
                    'skipped': True
                })
                
                game_state['total_skipped_predictions'] += 1
                
                # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ (Í∞ÑÍ≤©ÏùÄ Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÏùå)
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn3:
            if st.button("‚Ü©Ô∏è Ï∑®ÏÜå", use_container_width=True, key=f"live_game_btn_skip_cancel_{game_state['current_step']}"):
                if 'previous_game_state' in st.session_state:
                    prev_state = st.session_state.previous_game_state
                    # Ïù¥Ï†Ñ ÏÉÅÌÉúÎ°ú Î≥µÏõê
                    game_state['current_step'] = prev_state['current_step']
                    game_state['current_index'] = prev_state['current_index']
                    game_state['current_prefix'] = prev_state['current_prefix']
                    game_state['current_interval'] = prev_state['current_interval']
                    game_state['consecutive_failures'] = prev_state['consecutive_failures']
                    game_state['max_consecutive_failures'] = prev_state['max_consecutive_failures']
                    game_state['total_predictions'] = prev_state['total_predictions']
                    game_state['total_failures'] = prev_state['total_failures']
                    game_state['total_forced_predictions'] = prev_state['total_forced_predictions']
                    game_state['total_skipped_predictions'] = prev_state.get('total_skipped_predictions', game_state['total_skipped_predictions'])
                    game_state['history'] = prev_state['history'].copy()
                    st.rerun()
    else:
        # ÏòàÏ∏°Í∞íÏù¥ ÏóÜÏùå
        st.markdown("---")
        st.markdown("#### Ïã§Ï†úÍ∞í ÏÑ†ÌÉù (ÏòàÏ∏°Í∞í ÏóÜÏùå)")
        
        # Ïù¥Ï†Ñ ÏÉÅÌÉú Ï†ÄÏû• (Ï∑®ÏÜå Í∏∞Îä•Ïö©)
        if 'previous_game_state' not in st.session_state or st.session_state.get('previous_game_state_step', -1) != game_state['current_step']:
            st.session_state.previous_game_state = {
                'current_step': game_state['current_step'],
                'current_index': game_state['current_index'],
                'current_prefix': game_state['current_prefix'],
                'current_interval': game_state['current_interval'],
                'consecutive_failures': game_state['consecutive_failures'],
                'max_consecutive_failures': game_state['max_consecutive_failures'],
                'total_predictions': game_state['total_predictions'],
                'total_failures': game_state['total_failures'],
                'total_forced_predictions': game_state['total_forced_predictions'],
                'total_skipped_predictions': game_state['total_skipped_predictions'],
                'history': game_state['history'].copy()
            }
            st.session_state.previous_game_state_step = game_state['current_step']
        
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])
        with col_btn1:
            if st.button("üî¥ B", use_container_width=True, key=f"live_game_btn_no_pred_b_{game_state['current_step']}"):
                actual_value = 'b'
                
                # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': False,
                    'current_interval': current_interval,
                    'has_prediction': False,
                    'validated': False,
                    'skipped': False
                })
                
                # Í∞ÑÍ≤© Ï¶ùÍ∞Ä
                game_state['current_interval'] += 1
                
                # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn2:
            if st.button("üîµ P", use_container_width=True, key=f"live_game_btn_no_pred_p_{game_state['current_step']}"):
                actual_value = 'p'
                
                # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': False,
                    'current_interval': current_interval,
                    'has_prediction': False,
                    'validated': False,
                    'skipped': False
                })
                
                # Í∞ÑÍ≤© Ï¶ùÍ∞Ä
                game_state['current_interval'] += 1
                
                # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn3:
            if st.button("‚Ü©Ô∏è Ï∑®ÏÜå", use_container_width=True, key=f"live_game_btn_no_pred_cancel_{game_state['current_step']}"):
                if 'previous_game_state' in st.session_state:
                    prev_state = st.session_state.previous_game_state
                    # Ïù¥Ï†Ñ ÏÉÅÌÉúÎ°ú Î≥µÏõê
                    game_state['current_step'] = prev_state['current_step']
                    game_state['current_index'] = prev_state['current_index']
                    game_state['current_prefix'] = prev_state['current_prefix']
                    game_state['current_interval'] = prev_state['current_interval']
                    game_state['consecutive_failures'] = prev_state['consecutive_failures']
                    game_state['max_consecutive_failures'] = prev_state['max_consecutive_failures']
                    game_state['total_predictions'] = prev_state['total_predictions']
                    game_state['total_failures'] = prev_state['total_failures']
                    game_state['total_forced_predictions'] = prev_state['total_forced_predictions']
                    game_state['total_skipped_predictions'] = prev_state.get('total_skipped_predictions', game_state['total_skipped_predictions'])
                    game_state['history'] = prev_state['history'].copy()
                    st.rerun()
    
    # ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨ ÌëúÏãú
    if len(game_state['history']) > 0:
        st.markdown("---")
        with st.expander("üìä ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨", expanded=True):
            history_data = []
            history_sorted = sorted(game_state['history'], key=lambda x: x.get('step', 0), reverse=True)
            
            for entry in history_sorted[:50]:  # ÏµúÏã† 50Í∞úÎßå ÌëúÏãú
                is_correct = entry.get('is_correct')
                match_status = '‚úÖ' if is_correct else ('‚ùå' if is_correct is False else '-')
                has_prediction = entry.get('has_prediction', False)
                is_forced = entry.get('is_forced', False)
                validated = entry.get('validated', False)
                skipped = entry.get('skipped', False)
                
                forced_mark = '‚ö°' if is_forced else ''
                skipped_mark = '‚è≠Ô∏è' if skipped else ''
                validated_mark = '‚úì' if validated else ''
                
                history_data.append({
                    'Step': entry.get('step', 0),
                    'Prefix': entry.get('prefix', ''),
                    'ÏòàÏ∏°': f"{entry.get('predicted', '-')}{forced_mark}{skipped_mark}",
                    'Ïã§Ï†úÍ∞í': entry.get('actual', '-'),
                    'ÏùºÏπò': match_status,
                    'Í≤ÄÏ¶ù': validated_mark,
                    'Ïã†Î¢∞ÎèÑ': f"{entry.get('confidence', 0):.1f}%" if has_prediction else '-',
                    'Í∞ÑÍ≤©': entry.get('current_interval', 0) if not has_prediction else 0
                })
            
            if len(history_data) > 0:
                history_df = pd.DataFrame(history_data)
                st.dataframe(history_df, use_container_width=True, hide_index=True)
                
                if len(game_state['history']) > 50:
                    st.caption(f"üí° Ï†ÑÏ≤¥ {len(game_state['history'])}Í∞ú Ï§ë ÏµúÏã† 50Í∞úÎßå ÌëúÏãúÎê©ÎãàÎã§.")
    
    # Í≤åÏûÑ ÏôÑÎ£å Ï≤¥ÌÅ¨ (Î©îÏãúÏßÄ Ï†úÍ±∞ - ÏÑ±Îä• Í∞úÏÑ†)
    if game_state['current_index'] >= len(game_state['grid_string']):
        st.markdown("---")
        
        accuracy = ((game_state['total_predictions'] - game_state['total_failures']) / game_state['total_predictions'] * 100) if game_state['total_predictions'] > 0 else 0.0
        
        col_final1, col_final2, col_final3, col_final4 = st.columns(4)
        with col_final1:
            st.metric("Ï¥ù Ïä§ÌÖù", game_state['current_step'])
        with col_final2:
            st.metric("Ï¥ù ÏòàÏ∏°", game_state['total_predictions'])
        with col_final3:
            st.metric("ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®", game_state['max_consecutive_failures'])
        with col_final4:
            st.metric("Ï†ïÌôïÎèÑ", f"{accuracy:.2f}%")

def progressive_validate_forced_prediction_hypothesis(
    window_size=7,
    method="ÎπàÎèÑ Í∏∞Î∞ò",
    start_ratio=70,
    step_ratio=5,
    max_ratio=100
):
    """
    Í∞ïÏ†ú ÏòàÏ∏° Í∞ÄÏÑ§ Ï†êÏßÑÏ†Å Í≤ÄÏ¶ù
    
    Args:
        window_size: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞
        method: ÏòàÏ∏° Î∞©Î≤ï
        start_ratio: ÏãúÏûë ÎπÑÏú® (Í∏∞Î≥∏Í∞í: 70)
        step_ratio: Îã®Í≥ÑÎ≥Ñ Ï¶ùÍ∞Ä ÎπÑÏú® (Í∏∞Î≥∏Í∞í: 5)
        max_ratio: ÏµúÎåÄ ÎπÑÏú® (Í∏∞Î≥∏Í∞í: 100)
    
    Returns:
        dict: Ï†êÏßÑÏ†Å Í≤ÄÏ¶ù Í≤∞Í≥º
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # Ï†ÑÏ≤¥ grid_string Í∞úÏàò ÌôïÏù∏
        count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings"
        count_df = pd.read_sql_query(count_query, conn)
        total_count = count_df.iloc[0]['count'] if len(count_df) > 0 else 0
        
        if total_count == 0:
            return None
        
        # Î™®Îì† grid_stringÏùÑ id Í∏∞Ï§ÄÏúºÎ°ú Ï†ïÎ†¨ÌïòÏó¨ Î°úÎìú
        query = "SELECT id FROM preprocessed_grid_strings ORDER BY id"
        df_all_ids = pd.read_sql_query(query, conn)
        all_ids = df_all_ids['id'].tolist()
        
        if len(all_ids) == 0:
            return None
        
        steps_results = []
        max_consecutive_failures_all_steps = 0
        max_consecutive_matches_all_steps = 0
        total_tested_grid_strings = 0
        total_steps_all = 0
        total_failures_all = 0
        total_accuracy_sum = 0.0
        step_count = 0
        
        # Ï†êÏßÑÏ†Å Í≤ÄÏ¶ù Ïã§Ìñâ
        current_ratio = start_ratio
        while current_ratio < max_ratio:
            # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Î≤îÏúÑ Í≥ÑÏÇ∞
            train_index = int(total_count * current_ratio / 100)
            if train_index >= len(all_ids):
                break
            
            train_cutoff_id = all_ids[train_index - 1] if train_index > 0 else all_ids[0]
            
            # Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Î≤îÏúÑ Í≥ÑÏÇ∞
            validation_end_ratio = min(current_ratio + step_ratio, max_ratio)
            validation_end_index = int(total_count * validation_end_ratio / 100)
            
            if validation_end_index >= len(all_ids):
                validation_end_index = len(all_ids)
            
            if validation_end_index <= train_index:
                break
            
            # Í≤ÄÏ¶ù ÏãúÏûë IDÏôÄ Ï¢ÖÎ£å ID
            # Í≤ÄÏ¶ù ÏãúÏûë IDÎäî ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Î≤îÏúÑ Î∞îÎ°ú Îã§Ïùå ID
            if train_index < len(all_ids):
                validation_start_id = all_ids[train_index] if train_index < len(all_ids) else all_ids[-1]
            else:
                validation_start_id = all_ids[-1]
            
            validation_end_id = all_ids[validation_end_index - 1] if validation_end_index > 0 and validation_end_index <= len(all_ids) else all_ids[-1]
            
            # Îã®Ïùº Îã®Í≥Ñ Í≤ÄÏ¶ù Ïã§Ìñâ
            validation_results = validate_forced_prediction_hypothesis(
                train_cutoff_id,
                validation_start_id,
                validation_end_id,
                window_size=window_size,
                method=method
            )
            
            if validation_results is not None:
                steps_results.append({
                    'train_ratio': current_ratio,
                    'validation_start_ratio': current_ratio,
                    'validation_end_ratio': validation_end_ratio,
                    'validation_results': validation_results
                })
                
                # ÌÜµÍ≥Ñ ÏßëÍ≥Ñ
                max_consecutive_failures_all_steps = max(
                    max_consecutive_failures_all_steps,
                    validation_results['max_consecutive_failures']
                )
                max_consecutive_matches_all_steps = max(
                    max_consecutive_matches_all_steps,
                    validation_results.get('max_consecutive_matches', 0)
                )
                total_tested_grid_strings += validation_results['tested_grid_strings']
                total_steps_all += validation_results['total_steps']
                total_failures_all += validation_results['total_failures']
                total_accuracy_sum += validation_results['accuracy']
                step_count += 1
            
            # Îã§Ïùå Îã®Í≥ÑÎ°ú Ïù¥Îèô
            current_ratio += step_ratio
        
        # ÏöîÏïΩ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
        avg_max_consecutive_failures = (
            sum(s['validation_results']['max_consecutive_failures'] for s in steps_results) / len(steps_results)
            if len(steps_results) > 0 else 0.0
        )
        avg_accuracy = total_accuracy_sum / step_count if step_count > 0 else 0.0
        
        # ÌèâÍ∑† ÏµúÎåÄ Ïó∞ÏÜç ÏùºÏπò Ïàò Í≥ÑÏÇ∞
        avg_max_consecutive_matches = (
            sum(s['validation_results'].get('max_consecutive_matches', 0) for s in steps_results) / len(steps_results)
            if len(steps_results) > 0 else 0.0
        )
        
        return {
            'window_size': window_size,
            'method': method,
            'steps': steps_results,
            'summary': {
                'max_consecutive_failures_all_steps': max_consecutive_failures_all_steps,
                'max_consecutive_matches_all_steps': max_consecutive_matches_all_steps,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'avg_max_consecutive_matches': avg_max_consecutive_matches,
                'total_tested_grid_strings': total_tested_grid_strings,
                'total_steps': total_steps_all,
                'total_failures': total_failures_all,
                'avg_accuracy': avg_accuracy,
                'step_count': step_count
            }
        }
        
    except Exception as e:
        st.error(f"Ï†êÏßÑÏ†Å Í≤ÄÏ¶ù Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
        import traceback
        st.error(f"ÏÉÅÏÑ∏ Ïò§Î•ò: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def main():
    # ÌÖåÏù¥Î∏î ÏÉùÏÑ± (Ïï± ÏãúÏûë Ïãú)
    if 'validation_tables_created' not in st.session_state:
        if create_validation_tables():
            st.session_state.validation_tables_created = True
        else:
            st.error("ÌÖåÏù¥Î∏î ÏÉùÏÑ± Ïã§Ìå®")
            return
    st.title("üå≥ Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Îã§Îã®Í≥Ñ ÏòàÏ∏° ÏãúÎÇòÎ¶¨Ïò§ Í≤ÄÏ¶ù")
    st.markdown("Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Îã§Îã®Í≥Ñ ÏòàÏ∏° ÏãúÎÇòÎ¶¨Ïò§Î•º ÏûêÎèôÏúºÎ°ú Í≤ÄÏ¶ùÌïòÏó¨ ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå® ÌöüÏàòÎ•º Î∂ÑÏÑùÌï©ÎãàÎã§.")
    
    # ÏÑ§Ï†ï ÏÑπÏÖò
    with st.form("validation_interactive_settings_form", clear_on_submit=False):
        st.markdown("### ‚öôÔ∏è ÏÑ§Ï†ï")
        
        col_setting1, col_setting2, col_setting3 = st.columns(3)
        
        with col_setting1:
            window_size = st.selectbox(
                "ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞",
                options=[5, 6, 7, 8, 9],
                index=2,  # 7ÏùÑ Í∏∞Î≥∏Í∞íÏúºÎ°ú
                key="validation_interactive_window_size",
                help="ÏòàÏ∏°Ïóê ÏÇ¨Ïö©Ìï† ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî"
            )
        
        with col_setting2:
            method = st.selectbox(
                "ÏòàÏ∏° Î∞©Î≤ï",
                options=["ÎπàÎèÑ Í∏∞Î∞ò", "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò", "ÏïàÏ†Ñ Ïö∞ÏÑ†"],
                index=0,
                key="validation_interactive_method",
                help="ÏòàÏ∏°Ïóê ÏÇ¨Ïö©Ìï† Î∞©Î≤ïÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî"
            )
        
        with col_setting3:
            use_threshold = st.checkbox(
                "ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö©",
                value=True,
                key="validation_interactive_use_threshold",
                help="ÏûÑÍ≥ÑÍ∞í Ïù¥ÏÉÅÏùº ÎïåÎßå ÏòàÏ∏°ÌïòÎèÑÎ°ù ÏÑ§Ï†ï"
            )
            threshold = None
            if use_threshold:
                threshold = st.number_input(
                    "ÏûÑÍ≥ÑÍ∞í (%)",
                    min_value=0,
                    max_value=100,
                    value=60,
                    step=1,
                    key="validation_interactive_threshold",
                    help="Ïù¥ Ïã†Î¢∞ÎèÑ Ïù¥ÏÉÅÏùº ÎïåÎßå ÏòàÏ∏°Ìï©ÎãàÎã§"
                )
        
        # ÏµúÎåÄ Í∞ÑÍ≤© ÏÑ§Ï†ï (Í∞ïÏ†ú ÏòàÏ∏°Ïö©)
        col_setting4, col_setting5 = st.columns(2)
        with col_setting4:
            max_interval = st.number_input(
                "ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤© (Ïä§ÌÖù)",
                min_value=1,
                max_value=20,
                value=6,
                step=1,
                key="validation_interactive_max_interval",
                help="Ïù¥ Í∞ÑÍ≤©ÏùÑ ÎÑòÍ∏∞Î©¥ ÏûÑÍ≥ÑÍ∞í Î¨¥ÏãúÌïòÍ≥† Í∞ïÏ†ú ÏòàÏ∏°Ìï©ÎãàÎã§"
            )
        
        with col_setting5:
            # Í∏∞Ï§Ä Grid String ID ÏÑ†ÌÉù
            df_all_strings = load_preprocessed_data()
            if len(df_all_strings) > 0:
                grid_string_options = []
                for _, row in df_all_strings.iterrows():
                    grid_string_options.append((row['id'], row['created_at']))
                
                grid_string_options.sort(key=lambda x: x[0], reverse=True)
                
                current_selected = st.session_state.get('validation_interactive_cutoff_id', None)
                default_index = 0
                if current_selected is not None:
                    option_ids = [None] + [opt[0] for opt in grid_string_options]
                    if current_selected in option_ids:
                        default_index = option_ids.index(current_selected)
                
                selected_cutoff_id = st.selectbox(
                    "Í∏∞Ï§Ä Grid String ID (Ïù¥ ID Ïù¥ÌõÑÏùò Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù)",
                    options=[None] + [opt[0] for opt in grid_string_options],
                    format_func=lambda x: "Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞" if x is None else next((f"ID {opt[0]} - {opt[1]}" for opt in grid_string_options if opt[0] == x), f"ID {x} Ïù¥ÌõÑ"),
                    index=default_index,
                    key="validation_interactive_cutoff_id_select"
                )
                
                if selected_cutoff_id is not None:
                    selected_info = df_all_strings[df_all_strings['id'] == selected_cutoff_id].iloc[0]
                    st.info(f"ÏÑ†ÌÉùÎêú Í∏∞Ï§Ä: ID {selected_cutoff_id} (Í∏∏Ïù¥: {selected_info['string_length']}, ÏÉùÏÑ±Ïùº: {selected_info['created_at']})")
                    
                    # Ïù¥ÌõÑ Îç∞Ïù¥ÌÑ∞ Í∞úÏàò ÌôïÏù∏
                    conn = get_db_connection()
                    if conn is not None:
                        try:
                            count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings WHERE id > ?"
                            count_df = pd.read_sql_query(count_query, conn, params=[selected_cutoff_id])
                            after_count = count_df.iloc[0]['count']
                            st.caption(f"Í≤ÄÏ¶ù ÎåÄÏÉÅ: {after_count}Í∞úÏùò grid_string")
                        except:
                            pass
                        finally:
                            conn.close()
            else:
                selected_cutoff_id = None
                st.warning("‚ö†Ô∏è Ï†ÄÏû•Îêú grid_stringÏù¥ ÏóÜÏäµÎãàÎã§.")
        
        # Í≤ÄÏ¶ù Ïã§Ìñâ Î≤ÑÌäº
        if st.form_submit_button("Í≤ÄÏ¶ù Ïã§Ìñâ", type="primary", use_container_width=True):
            if selected_cutoff_id is None:
                st.warning("‚ö†Ô∏è Í∏∞Ï§Ä Grid String IDÎ•º ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî.")
            else:
                st.session_state.validation_interactive_cutoff_id = selected_cutoff_id
                st.session_state.validation_interactive_results = None
                st.rerun()
    
    # Í≤ÄÏ¶ù Ïã§Ìñâ Î∞è Í≤∞Í≥º ÌëúÏãú
    if 'validation_interactive_cutoff_id' in st.session_state and st.session_state.validation_interactive_cutoff_id is not None:
        cutoff_id = st.session_state.validation_interactive_cutoff_id
        
        # ÌòÑÏû¨ ÏÑ§Ï†ï Í∞ÄÏ†∏Ïò§Í∏∞
        window_size = st.session_state.get('validation_interactive_window_size', 7)
        method = st.session_state.get('validation_interactive_method', 'ÎπàÎèÑ Í∏∞Î∞ò')
        use_threshold = st.session_state.get('validation_interactive_use_threshold', True)
        threshold = st.session_state.get('validation_interactive_threshold', 60) if use_threshold else None
        max_interval = st.session_state.get('validation_interactive_max_interval', 6)
        
        # Í≤∞Í≥ºÍ∞Ä Ï∫êÏãúÎêòÏñ¥ ÏûàÏúºÎ©¥ ÏÇ¨Ïö©, ÏóÜÏúºÎ©¥ Ïã§Ìñâ (Îëê Ï†ÑÎûµ Î™®Îëê)
        if 'validation_interactive_results_default' in st.session_state and 'validation_interactive_results_reverse' in st.session_state:
            batch_results_default = st.session_state.validation_interactive_results_default
            batch_results_reverse = st.session_state.validation_interactive_results_reverse
        else:
            with st.spinner("Í≤ÄÏ¶ù Ïã§Ìñâ Ï§ë... (Í∏∞Î≥∏ Ï†ÑÎûµ + Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ)"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    # Í∏∞Î≥∏ Ï†ÑÎûµ Ïã§Ìñâ
                    status_text.text("Í∏∞Î≥∏ Ï†ÑÎûµ Í≤ÄÏ¶ù Ï§ë...")
                    progress_bar.progress(0.3)
                    batch_results_default = batch_validate_interactive_multi_step_scenario(
                        cutoff_id,
                        window_size=window_size,
                        method=method,
                        use_threshold=use_threshold,
                        threshold=threshold if use_threshold else 60,
                        max_interval=max_interval,
                        reverse_forced_prediction=False
                    )
                    
                    # Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ Ïã§Ìñâ
                    status_text.text("Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ Í≤ÄÏ¶ù Ï§ë...")
                    progress_bar.progress(0.7)
                    batch_results_reverse = batch_validate_interactive_multi_step_scenario(
                        cutoff_id,
                        window_size=window_size,
                        method=method,
                        use_threshold=use_threshold,
                        threshold=threshold if use_threshold else 60,
                        max_interval=max_interval,
                        reverse_forced_prediction=True
                    )
                    
                    if batch_results_default is not None and batch_results_reverse is not None:
                        st.session_state.validation_interactive_results_default = batch_results_default
                        st.session_state.validation_interactive_results_reverse = batch_results_reverse
                        
                        # Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ ÏàòÏßë Î∞è Ï†ÄÏû• (Í∏∞Î≥∏ Ï†ÑÎûµ)
                        if 'all_history' in batch_results_default:
                            confidence_stats_default = collect_confidence_statistics(
                                batch_results_default['all_history'],
                                validation_id=None,
                                strategy_type='default'
                            )
                            if confidence_stats_default:
                                save_confidence_statistics(
                                    confidence_stats_default,
                                    validation_id=None,
                                    strategy_type='default'
                                )
                        
                        # Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ ÏàòÏßë Î∞è Ï†ÄÏû• (Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ)
                        if 'all_history' in batch_results_reverse:
                            confidence_stats_reverse = collect_confidence_statistics(
                                batch_results_reverse['all_history'],
                                validation_id=None,
                                strategy_type='reverse'
                            )
                            if confidence_stats_reverse:
                                save_confidence_statistics(
                                    confidence_stats_reverse,
                                    validation_id=None,
                                    strategy_type='reverse'
                                )
                        
                        # Í≤ÄÏ¶ù Í≤∞Í≥º ÏûêÎèô Ï†ÄÏû• (ÎπÑÌôúÏÑ±ÌôîÎê®)
                        # validation_id = save_validation_results(
                        #     cutoff_id,
                        #     window_size,
                        #     method,
                        #     use_threshold,
                        #     threshold if use_threshold else 60,
                        #     max_interval,
                        #     batch_results_default,
                        #     batch_results_reverse,
                        #     grid_string_ids=batch_results_default.get('grid_string_ids') if batch_results_default else None
                        # )
                        # 
                        # if validation_id:
                        #     st.session_state.validation_interactive_saved_id = validation_id
                        #     st.success(f"‚úÖ Í≤ÄÏ¶ù Í≤∞Í≥ºÍ∞Ä Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§. (ID: {validation_id[:8]}...)")
                        # else:
                        #     st.warning("‚ö†Ô∏è Í≤ÄÏ¶ù Í≤∞Í≥º Ï†ÄÏû•Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.")
                    else:
                        st.error("Í≤ÄÏ¶ù Ïã§Ìñâ Ïã§Ìå®")
                        batch_results_default = None
                        batch_results_reverse = None
                        
                except Exception as e:
                    st.error(f"Í≤ÄÏ¶ù Ïã§Ìñâ Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
                    import traceback
                    st.error(f"ÏÉÅÏÑ∏ Ïò§Î•ò: {traceback.format_exc()}")
                    batch_results_default = None
                    batch_results_reverse = None
                finally:
                    progress_bar.empty()
                    status_text.empty()
        
        # Í≤∞Í≥º ÎπÑÍµê ÌëúÏãú
        if batch_results_default is not None and batch_results_reverse is not None and len(batch_results_default['results']) > 0 and len(batch_results_reverse['results']) > 0:
            summary_default = batch_results_default['summary']
            summary_reverse = batch_results_reverse['summary']
            results_default = batch_results_default['results']
            results_reverse = batch_results_reverse['results']
            
            # Ï†ÑÎûµ ÎπÑÍµê Ìó§Îçî
            st.markdown("---")
            st.markdown("### Ï†ÑÎûµ ÎπÑÍµê")
            col1, col2 = st.columns(2)
            with col1:
                st.info("üìä **Í∏∞Î≥∏ Ï†ÑÎûµ**: Í∞ïÏ†ú ÏòàÏ∏° Ïãú ÌòÑÏû¨ ÏòàÏ∏°Í∞í ÏÇ¨Ïö©")
            with col2:
                st.info("üìä **Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ**: Í∞ïÏ†ú ÏòàÏ∏° Ïãú Î∞òÎåÄ Í∞í ÏÑ†ÌÉù")
            
            # ÏöîÏïΩ ÌÜµÍ≥Ñ ÎπÑÍµê
            st.markdown("---")
            st.markdown("### ÏöîÏïΩ ÌÜµÍ≥Ñ ÎπÑÍµê")
            
            # ÎπÑÍµê ÌÖåÏù¥Î∏î
            comparison_data = []
            comparison_data.append({
                'Ìï≠Î™©': 'Ï¥ù Grid String Ïàò',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default['total_grid_strings']}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse['total_grid_strings']}",
                'Ï∞®Ïù¥': f"{summary_reverse['total_grid_strings'] - summary_default['total_grid_strings']:+d}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÌèâÍ∑† Ï†ïÌôïÎèÑ (%)',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default['avg_accuracy']:.2f}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse['avg_accuracy']:.2f}",
                'Ï∞®Ïù¥': f"{summary_reverse['avg_accuracy'] - summary_default['avg_accuracy']:+.2f}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default['max_consecutive_failures']}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse['max_consecutive_failures']}",
                'Ï∞®Ïù¥': f"{summary_reverse['max_consecutive_failures'] - summary_default['max_consecutive_failures']:+d}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÌèâÍ∑† ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default['avg_max_consecutive_failures']:.2f}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse['avg_max_consecutive_failures']:.2f}",
                'Ï∞®Ïù¥': f"{summary_reverse['avg_max_consecutive_failures'] - summary_default['avg_max_consecutive_failures']:+.2f}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÏòàÏ∏°Î•† (%)',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default['prediction_rate']:.2f}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse['prediction_rate']:.2f}",
                'Ï∞®Ïù¥': f"{summary_reverse['prediction_rate'] - summary_default['prediction_rate']:+.2f}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'Í∞ïÏ†ú ÏòàÏ∏° ÎπÑÏú® (%)',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default.get('forced_prediction_rate', 0):.2f}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse.get('forced_prediction_rate', 0):.2f}",
                'Ï∞®Ïù¥': f"{summary_reverse.get('forced_prediction_rate', 0) - summary_default.get('forced_prediction_rate', 0):+.2f}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'Í∞ïÏ†ú ÏòàÏ∏° ÏÑ±Í≥µ ÎπÑÏú® (%)',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default.get('forced_success_rate', 0):.2f}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse.get('forced_success_rate', 0):.2f}",
                'Ï∞®Ïù¥': f"{summary_reverse.get('forced_success_rate', 0) - summary_default.get('forced_success_rate', 0):+.2f}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'Ï¥ù Ïä§ÌÖù Ïàò',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default['total_steps']}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse['total_steps']}",
                'Ï∞®Ïù¥': f"{summary_reverse['total_steps'] - summary_default['total_steps']:+d}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'Ï¥ù Ïã§Ìå® ÌöüÏàò',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default['total_failures']}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse['total_failures']}",
                'Ï∞®Ïù¥': f"{summary_reverse['total_failures'] - summary_default['total_failures']:+d}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'Ï¥ù ÏòàÏ∏° ÌöüÏàò',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default['total_predictions']}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse['total_predictions']}",
                'Ï∞®Ïù¥': f"{summary_reverse['total_predictions'] - summary_default['total_predictions']:+d}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'Ï¥ù Í∞ïÏ†ú ÏòàÏ∏° ÌöüÏàò',
                'Í∏∞Î≥∏ Ï†ÑÎûµ': f"{summary_default.get('total_forced_predictions', 0)}",
                'Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ': f"{summary_reverse.get('total_forced_predictions', 0)}",
                'Ï∞®Ïù¥': f"{summary_reverse.get('total_forced_predictions', 0) - summary_default.get('total_forced_predictions', 0):+d}"
            })
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)
            
            # Ïã†Î¢∞ÎèÑ Íµ¨Í∞ÑÎ≥Ñ ÌÜµÍ≥Ñ ÌëúÏãú
            st.markdown("---")
            st.markdown("### üìä Ïã†Î¢∞ÎèÑ Íµ¨Í∞ÑÎ≥Ñ ÌÜµÍ≥Ñ (50-60% Íµ¨Í∞Ñ)")
            
            # DBÏóêÏÑú Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ Ï°∞Ìöå
            conn = get_db_connection()
            if conn is not None:
                try:
                    # Í∏∞Î≥∏ Ï†ÑÎûµ ÌÜµÍ≥Ñ
                    stats_query_default = """
                        SELECT confidence_range, total_predictions, matches, mismatches, 
                               match_rate, avg_confidence
                        FROM confidence_statistics
                        WHERE strategy_type = 'default'
                        ORDER BY confidence_range
                    """
                    stats_df_default = pd.read_sql_query(stats_query_default, conn)
                    
                    # Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ ÌÜµÍ≥Ñ
                    stats_query_reverse = """
                        SELECT confidence_range, total_predictions, matches, mismatches, 
                               match_rate, avg_confidence
                        FROM confidence_statistics
                        WHERE strategy_type = 'reverse'
                        ORDER BY confidence_range
                    """
                    stats_df_reverse = pd.read_sql_query(stats_query_reverse, conn)
                    
                    if len(stats_df_default) > 0 or len(stats_df_reverse) > 0:
                        col_stats1, col_stats2 = st.columns(2)
                        
                        with col_stats1:
                            st.markdown("#### Í∏∞Î≥∏ Ï†ÑÎûµ")
                            if len(stats_df_default) > 0:
                                st.dataframe(stats_df_default, use_container_width=True, hide_index=True)
                            else:
                                st.info("ÌÜµÍ≥Ñ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
                        
                        with col_stats2:
                            st.markdown("#### Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ")
                            if len(stats_df_reverse) > 0:
                                st.dataframe(stats_df_reverse, use_container_width=True, hide_index=True)
                            else:
                                st.info("ÌÜµÍ≥Ñ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
                    else:
                        st.info("üí° Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§. Í≤ÄÏ¶ùÏùÑ Ïã§ÌñâÌïòÎ©¥ ÌÜµÍ≥ÑÍ∞Ä ÏàòÏßëÎê©ÎãàÎã§.")
                except Exception as e:
                    st.warning(f"Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ Ï°∞Ìöå Ï§ë Ïò§Î•ò: {str(e)}")
                finally:
                    conn.close()
            
            # ÎßàÏßÄÎßâ Grid String ÌûàÏä§ÌÜ†Î¶¨ ÏûêÎèô ÌëúÏãú (Í≤ÄÏ¶ùÏö©)
            st.markdown("---")
            st.markdown("### üîç ÎßàÏßÄÎßâ Grid String Í≤ÄÏ¶ù ÌûàÏä§ÌÜ†Î¶¨")
            st.markdown("**ÏùòÎèÑÎåÄÎ°ú ÎèôÏûëÌïòÎäîÏßÄ ÌôïÏù∏ÌïòÍ∏∞ ÏúÑÌïú ÎßàÏßÄÎßâ grid_string_idÏùò ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨**")
            
            if len(results_default) > 0 and len(results_reverse) > 0:
                # ÎßàÏßÄÎßâ grid_string_id Ï∞æÍ∏∞ (Îëê Í≤∞Í≥ºÎäî Í∞ôÏùÄ ÏàúÏÑúÏù¥ÎØÄÎ°ú ÎßàÏßÄÎßâ Ìï≠Î™© ÏÇ¨Ïö©)
                last_result_default = results_default[-1]
                last_result_reverse = results_reverse[-1]
                last_grid_id = last_result_default['grid_string_id']
                
                st.info(f"üìå **Í≤ÄÏ¶ù ÎåÄÏÉÅ**: Grid String ID {last_grid_id} (ÎßàÏßÄÎßâ Í≤ÄÏ¶ùÎêú grid_string)")
                
                # Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨ Î≥¥Í∏∞ ÏòµÏÖò
                show_full_history = st.checkbox(
                    "Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨ Î≥¥Í∏∞ (Í∏∞Î≥∏: ÏµúÍ∑º 50Í∞úÎßå ÌëúÏãú)",
                    value=False,
                    key="last_grid_full_history"
                )
                
                # Í∏∞Î≥∏ Ï†ÑÎûµÍ≥º Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ Î™®Îëê ÌëúÏãú
                col_last1, col_last2 = st.columns(2)
                
                with col_last1:
                    st.markdown("#### Í∏∞Î≥∏ Ï†ÑÎûµ ÌûàÏä§ÌÜ†Î¶¨")
                    
                    if last_result_default:
                        failure_history_default = get_failure_history_interactive(
                            last_grid_id,
                            cutoff_id,
                            window_size=window_size,
                            method=method,
                            use_threshold=use_threshold,
                            threshold=threshold if use_threshold else 60,
                            max_interval=max_interval,
                            reverse_forced_prediction=False
                        )
                        
                        if failure_history_default:
                            st.metric("ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®", f"{failure_history_default['max_consecutive_failures']}Ìöå")
                            st.metric("Ï¥ù Ïä§ÌÖù", f"{failure_history_default['total_steps']}")
                            st.metric("Ï¥ù ÏòàÏ∏°", f"{failure_history_default['total_predictions']}")
                            st.metric("Ï†ïÌôïÎèÑ", f"{failure_history_default['accuracy']:.2f}%")
                            
                            # ÌûàÏä§ÌÜ†Î¶¨ ÌÖåÏù¥Î∏î
                            history_default = failure_history_default.get('history', [])
                            if len(history_default) > 0:
                                history_limit = None if show_full_history else 50
                                history_title = "##### ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨" + (f" (ÏµúÏã† {history_limit}Í∞ú)" if history_limit else " (Ï†ÑÏ≤¥)")
                                st.markdown(history_title)
                                history_data_default = []
                                # ÌûàÏä§ÌÜ†Î¶¨Î•º ÏµúÏã†ÏàúÏúºÎ°ú Ï†ïÎ†¨ (step ÎÇ¥Î¶ºÏ∞®Ïàú)
                                history_default_sorted = sorted(history_default, key=lambda x: x.get('step', 0), reverse=True)
                                display_history = history_default_sorted[:history_limit] if history_limit else history_default_sorted
                                
                                for entry in display_history:
                                    is_correct = entry.get('is_correct')
                                    match_status = '‚úÖ' if is_correct else ('‚ùå' if is_correct is False else '-')
                                    has_prediction = entry.get('has_prediction', False)
                                    is_forced = entry.get('is_forced', False)
                                    validated = entry.get('validated', False)
                                    
                                    forced_mark = '‚ö°' if is_forced else ''
                                    no_pred_mark = 'üö´' if not has_prediction else ''
                                    validated_mark = '‚úì' if validated else ''
                                    
                                    history_data_default.append({
                                        'Step': entry.get('step', 0),
                                        'Prefix': entry.get('prefix', ''),
                                        'ÏòàÏ∏°': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}",
                                        'Ïã§Ï†úÍ∞í': entry.get('actual', '-'),
                                        'ÏùºÏπò': match_status,
                                        'Í≤ÄÏ¶ù': validated_mark,
                                        'Ïã†Î¢∞ÎèÑ': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                        'Í∞ÑÍ≤©': entry.get('current_interval', 0) if not has_prediction else 0
                                    })
                                
                                history_df_default = pd.DataFrame(history_data_default)
                                st.dataframe(history_df_default, use_container_width=True, hide_index=True)
                                
                                if not show_full_history and len(history_default) > 50:
                                    st.caption(f"üí° Ï†ÑÏ≤¥ {len(history_default)}Í∞ú Ï§ë ÏµúÏã† 50Í∞úÎßå ÌëúÏãúÎê©ÎãàÎã§. Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨Î•º Î≥¥Î†§Î©¥ ÏúÑÏùò Ï≤¥ÌÅ¨Î∞ïÏä§Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.")
                
                with col_last2:
                    st.markdown("#### Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ ÌûàÏä§ÌÜ†Î¶¨")
                    
                    if last_result_reverse:
                        failure_history_reverse = get_failure_history_interactive(
                            last_grid_id,
                            cutoff_id,
                            window_size=window_size,
                            method=method,
                            use_threshold=use_threshold,
                            threshold=threshold if use_threshold else 60,
                            max_interval=max_interval,
                            reverse_forced_prediction=True
                        )
                        
                        if failure_history_reverse:
                            st.metric("ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®", f"{failure_history_reverse['max_consecutive_failures']}Ìöå")
                            st.metric("Ï¥ù Ïä§ÌÖù", f"{failure_history_reverse['total_steps']}")
                            st.metric("Ï¥ù ÏòàÏ∏°", f"{failure_history_reverse['total_predictions']}")
                            st.metric("Ï†ïÌôïÎèÑ", f"{failure_history_reverse['accuracy']:.2f}%")
                            
                            # ÌûàÏä§ÌÜ†Î¶¨ ÌÖåÏù¥Î∏î
                            history_reverse = failure_history_reverse.get('history', [])
                            if len(history_reverse) > 0:
                                history_limit = None if show_full_history else 50
                                history_title = "##### ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨" + (f" (ÏµúÏã† {history_limit}Í∞ú)" if history_limit else " (Ï†ÑÏ≤¥)")
                                st.markdown(history_title)
                                history_data_reverse = []
                                # ÌûàÏä§ÌÜ†Î¶¨Î•º ÏµúÏã†ÏàúÏúºÎ°ú Ï†ïÎ†¨ (step ÎÇ¥Î¶ºÏ∞®Ïàú)
                                history_reverse_sorted = sorted(history_reverse, key=lambda x: x.get('step', 0), reverse=True)
                                display_history = history_reverse_sorted[:history_limit] if history_limit else history_reverse_sorted
                                
                                for entry in display_history:
                                    is_correct = entry.get('is_correct')
                                    match_status = '‚úÖ' if is_correct else ('‚ùå' if is_correct is False else '-')
                                    has_prediction = entry.get('has_prediction', False)
                                    is_forced = entry.get('is_forced', False)
                                    validated = entry.get('validated', False)
                                    
                                    forced_mark = '‚ö°' if is_forced else ''
                                    no_pred_mark = 'üö´' if not has_prediction else ''
                                    validated_mark = '‚úì' if validated else ''
                                    
                                    history_data_reverse.append({
                                        'Step': entry.get('step', 0),
                                        'Prefix': entry.get('prefix', ''),
                                        'ÏòàÏ∏°': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}",
                                        'Ïã§Ï†úÍ∞í': entry.get('actual', '-'),
                                        'ÏùºÏπò': match_status,
                                        'Í≤ÄÏ¶ù': validated_mark,
                                        'Ïã†Î¢∞ÎèÑ': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                        'Í∞ÑÍ≤©': entry.get('current_interval', 0) if not has_prediction else 0
                                    })
                                
                                history_df_reverse = pd.DataFrame(history_data_reverse)
                                st.dataframe(history_df_reverse, use_container_width=True, hide_index=True)
                                
                                if not show_full_history and len(history_reverse) > 50:
                                    st.caption(f"üí° Ï†ÑÏ≤¥ {len(history_reverse)}Í∞ú Ï§ë ÏµúÏã† 50Í∞úÎßå ÌëúÏãúÎê©ÎãàÎã§. Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨Î•º Î≥¥Î†§Î©¥ ÏúÑÏùò Ï≤¥ÌÅ¨Î∞ïÏä§Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.")
                
                # Í≤ÄÏ¶ù Ìè¨Ïù∏Ìä∏ ÏïàÎÇ¥
                st.markdown("---")
                st.markdown("#### üîç Í≤ÄÏ¶ù Ìè¨Ïù∏Ìä∏")
                st.markdown("""
                Îã§Ïùå ÏÇ¨Ìï≠Îì§ÏùÑ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî:
                1. **Í∞ÑÍ≤© Ï°∞Í±¥**: `validated` Ïª¨ÎüºÏù¥ '‚úì'Ïù∏ Ïä§ÌÖùÏóêÏÑúÎßå Ïã§Ï†ú ÎπÑÍµêÍ∞Ä ÏàòÌñâÎêòÎäîÏßÄ ÌôïÏù∏
                2. **Í∞ïÏ†ú ÏòàÏ∏°**: `‚ö°` ÌëúÏãúÍ∞Ä ÏûàÎäî Ïä§ÌÖùÏóêÏÑú Í∞ïÏ†ú ÏòàÏ∏°Ïù¥ Ïò¨Î∞îÎ•¥Í≤å ÏàòÌñâÎêòÎäîÏßÄ ÌôïÏù∏
                3. **Ïó∞ÏÜç Ïã§Ìå® Ï∂îÏ†Å**: Ïó∞ÏÜçÏúºÎ°ú Ïã§Ìå®ÌïòÎäî Í≤ΩÏö∞Í∞Ä Ïò¨Î∞îÎ•¥Í≤å Ïπ¥Ïö¥Ìä∏ÎêòÎäîÏßÄ ÌôïÏù∏
                4. **Í∞ÑÍ≤© Í≥ÑÏÇ∞**: ÏòàÏ∏°Ïù¥ ÏóÜÏùÑ Îïå Í∞ÑÍ≤©Ïù¥ Ïò¨Î∞îÎ•¥Í≤å Ï¶ùÍ∞ÄÌïòÎäîÏßÄ ÌôïÏù∏
                5. **Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ**: Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµÏóêÏÑú Í∞ïÏ†ú ÏòàÏ∏° Ïãú Î∞òÎåÄ Í∞íÏù¥ ÏÑ†ÌÉùÎêòÎäîÏßÄ ÌôïÏù∏
                """)
            else:
                st.warning("‚ö†Ô∏è ÎßàÏßÄÎßâ grid_string_idÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
            
            # ÏµúÏ†Å Ï†ÑÎûµ Ï∂îÏ≤ú
            st.markdown("---")
            st.markdown("### ÏµúÏ†Å Ï†ÑÎûµ Ï∂îÏ≤ú")
            
            # Ï†êÏàò Í≥ÑÏÇ∞ (ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå® Í∞êÏÜåÍ∞Ä Í∞ÄÏû• Ï§ëÏöî)
            default_score = (
                (100 - summary_default['max_consecutive_failures']) * 10 +
                summary_default['avg_accuracy'] * 0.1
            )
            reverse_score = (
                (100 - summary_reverse['max_consecutive_failures']) * 10 +
                summary_reverse['avg_accuracy'] * 0.1
            )
            
            if reverse_score > default_score:
                best_strategy = "Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ"
                best_summary = summary_reverse
                worst_summary = summary_default
                improvement = reverse_score - default_score
            else:
                best_strategy = "Í∏∞Î≥∏ Ï†ÑÎûµ"
                best_summary = summary_default
                worst_summary = summary_reverse
                improvement = default_score - reverse_score
            
            st.success(f"‚úÖ **Ï∂îÏ≤ú Ï†ÑÎûµ**: {best_strategy}")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®", 
                         f"{worst_summary['max_consecutive_failures']}Ìöå ‚Üí {best_summary['max_consecutive_failures']}Ìöå",
                         f"{best_summary['max_consecutive_failures'] - worst_summary['max_consecutive_failures']:+d}Ìöå")
            with col2:
                st.metric("ÌèâÍ∑† Ï†ïÌôïÎèÑ",
                         f"{worst_summary['avg_accuracy']:.2f}% ‚Üí {best_summary['avg_accuracy']:.2f}%",
                         f"{best_summary['avg_accuracy'] - worst_summary['avg_accuracy']:+.2f}%")
            
            # Í∞ïÏ†ú ÏòàÏ∏° ÏÑ±Í≥µÎ•† ÎπÑÍµê
            forced_success_default = summary_default.get('forced_success_rate', 0)
            forced_success_reverse = summary_reverse.get('forced_success_rate', 0)
            
            if forced_success_default < 30:
                st.warning(f"‚ö†Ô∏è Í∏∞Î≥∏ Ï†ÑÎûµÏùò Í∞ïÏ†ú ÏòàÏ∏° ÏÑ±Í≥µÎ•†Ïù¥ {forced_success_default:.2f}%Î°ú Îß§Ïö∞ ÎÇÆÏäµÎãàÎã§. Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµÏù¥ Îçî Ìö®Í≥ºÏ†ÅÏùº Ïàò ÏûàÏäµÎãàÎã§.")
            
            # Grid StringÎ≥Ñ ÎπÑÍµê Í≤∞Í≥º
            comparison_results_data = []
            for i, result_default in enumerate(results_default):
                result_reverse = results_reverse[i] if i < len(results_reverse) else None
                if result_reverse is None:
                    continue
                
                grid_id = result_default['grid_string_id']
                comparison_results_data.append({
                    'Grid String ID': grid_id,
                    'Í∏∞Î≥∏_ÏµúÎåÄÏó∞ÏÜçÏã§Ìå®': result_default['max_consecutive_failures'],
                    'Î∞òÎåÄ_ÏµúÎåÄÏó∞ÏÜçÏã§Ìå®': result_reverse['max_consecutive_failures'],
                    'ÏµúÎåÄÏó∞ÏÜçÏã§Ìå®_Ï∞®Ïù¥': f"{result_reverse['max_consecutive_failures'] - result_default['max_consecutive_failures']:+d}",
                    'Í∏∞Î≥∏_Ï†ïÌôïÎèÑ': f"{result_default['accuracy']:.2f}%",
                    'Î∞òÎåÄ_Ï†ïÌôïÎèÑ': f"{result_reverse['accuracy']:.2f}%",
                    'Ï†ïÌôïÎèÑ_Ï∞®Ïù¥': f"{result_reverse['accuracy'] - result_default['accuracy']:+.2f}%",
                    'Í∏∞Î≥∏_Í∞ïÏ†úÏÑ±Í≥µÎ•†': f"{result_default.get('forced_success_rate', 0):.2f}%",
                    'Î∞òÎåÄ_Í∞ïÏ†úÏÑ±Í≥µÎ•†': f"{result_reverse.get('forced_success_rate', 0):.2f}%"
                })
            
            comparison_results_df = pd.DataFrame(comparison_results_data)
            st.dataframe(comparison_results_df, use_container_width=True, hide_index=True)
            
            # ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå® Î∂ÑÌè¨ ÎπÑÍµê
            st.markdown("---")
            st.markdown("### ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå® Î∂ÑÌè¨ ÎπÑÍµê")
            
            max_failures_default = [r['max_consecutive_failures'] for r in results_default]
            max_failures_reverse = [r['max_consecutive_failures'] for r in results_reverse]
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### Í∏∞Î≥∏ Ï†ÑÎûµ")
                max_failures_list = max_failures_default
                
                if len(max_failures_list) > 0:
                    max_value = max(max_failures_list)
                    
                    # Íµ¨Í∞ÑÎ≥Ñ Î∂ÑÌè¨ Í≥ÑÏÇ∞
                    bins = defaultdict(int)
                    for value in max_failures_list:
                        if value == 0:
                            bins['0'] += 1
                        elif value <= 2:
                            bins['1-2'] += 1
                        elif value <= 5:
                            bins['3-5'] += 1
                        elif value <= 10:
                            bins['6-10'] += 1
                        else:
                            bins['11+'] += 1
                    
                    # ÌûàÏä§ÌÜ†Í∑∏Îû® ÌëúÏãú
                    st.markdown("##### Íµ¨Í∞ÑÎ≥Ñ Î∂ÑÌè¨")
                    max_count = max(bins.values()) if bins else 1
                    
                    for bin_range, count in sorted(bins.items(), key=lambda x: {
                        '0': 0, '1-2': 1, '3-5': 2, '6-10': 3, '11+': 4
                    }.get(x[0], 5)):
                        ratio = (count / len(results_default) * 100) if len(results_default) > 0 else 0
                        bar_length = int((count / max_count) * 50) if max_count > 0 else 0
                        bar = '‚ñà' * bar_length
                        st.text(f"{bin_range:>8}: {bar} {count:>4}Í∞ú ({ratio:>5.2f}%)")
                    
                    st.markdown("##### ÌÜµÍ≥Ñ")
                    st.metric("ÏµúÏÜåÍ∞í", min(max_failures_list))
                    st.metric("ÏµúÎåÄÍ∞í", max(max_failures_list))
                    st.metric("ÌèâÍ∑†Í∞í", f"{summary_default['avg_max_consecutive_failures']:.2f}")
            
            with col2:
                st.markdown("#### Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ")
                max_failures_list = max_failures_reverse
                
                if len(max_failures_list) > 0:
                    max_value = max(max_failures_list)
                    
                    # Íµ¨Í∞ÑÎ≥Ñ Î∂ÑÌè¨ Í≥ÑÏÇ∞
                    bins = defaultdict(int)
                    for value in max_failures_list:
                        if value == 0:
                            bins['0'] += 1
                        elif value <= 2:
                            bins['1-2'] += 1
                        elif value <= 5:
                            bins['3-5'] += 1
                        elif value <= 10:
                            bins['6-10'] += 1
                        else:
                            bins['11+'] += 1
                    
                    # ÌûàÏä§ÌÜ†Í∑∏Îû® ÌëúÏãú
                    st.markdown("##### Íµ¨Í∞ÑÎ≥Ñ Î∂ÑÌè¨")
                    max_count = max(bins.values()) if bins else 1
                    
                    for bin_range, count in sorted(bins.items(), key=lambda x: {
                        '0': 0, '1-2': 1, '3-5': 2, '6-10': 3, '11+': 4
                    }.get(x[0], 5)):
                        ratio = (count / len(results_reverse) * 100) if len(results_reverse) > 0 else 0
                        bar_length = int((count / max_count) * 50) if max_count > 0 else 0
                        bar = '‚ñà' * bar_length
                        st.text(f"{bin_range:>8}: {bar} {count:>4}Í∞ú ({ratio:>5.2f}%)")
                    
                    st.markdown("##### ÌÜµÍ≥Ñ")
                    st.metric("ÏµúÏÜåÍ∞í", min(max_failures_list))
                    st.metric("ÏµúÎåÄÍ∞í", max(max_failures_list))
                    st.metric("ÌèâÍ∑†Í∞í", f"{summary_reverse['avg_max_consecutive_failures']:.2f}")
            
            # ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨ Ï°∞Ìöå
            st.markdown("---")
            st.markdown("### ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨ Ï°∞Ìöå")
            
            # ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®Í∞Ä Î∞úÏÉùÌïú Grid String ÏÑ†ÌÉù (Îëê Ï†ÑÎûµ Ï§ë Îçî ÎÇòÏÅú Í≤∞Í≥º Í∏∞Ï§Ä)
            high_failure_results = []
            for i, result_default in enumerate(results_default):
                result_reverse = results_reverse[i] if i < len(results_reverse) else None
                if result_reverse is None:
                    continue
                
                max_fail = max(result_default.get('max_consecutive_failures', 0), 
                              result_reverse.get('max_consecutive_failures', 0))
                if max_fail >= 5:
                    high_failure_results.append({
                        'grid_string_id': result_default['grid_string_id'],
                        'max_consecutive_failures': max_fail,
                        'default_accuracy': result_default.get('accuracy', 0),
                        'reverse_accuracy': result_reverse.get('accuracy', 0) if result_reverse else 0
                    })
            
            if len(high_failure_results) > 0:
                st.markdown("#### ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå® Î∞úÏÉù Grid String")
                
                failure_options = []
                for result in high_failure_results:
                    display_text = f"ID {result['grid_string_id']} - ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®: {result['max_consecutive_failures']}Ìöå - Í∏∞Î≥∏: {result['default_accuracy']:.2f}% / Î∞òÎåÄ: {result['reverse_accuracy']:.2f}%"
                    failure_options.append((result['grid_string_id'], display_text))
                
                selected_history_id = st.selectbox(
                    "Grid String ÏÑ†ÌÉù",
                    options=[None] + [opt[0] for opt in failure_options],
                    format_func=lambda x: "ÏÑ†ÌÉù ÏïàÌï®" if x is None else f"ID {x}",
                    key="validation_interactive_selected_history_id"
                )
                
                if selected_history_id is not None:
                    col_hist1, col_hist2 = st.columns(2)
                    with col_hist1:
                        if st.button("Í∏∞Î≥∏ Ï†ÑÎûµ ÌûàÏä§ÌÜ†Î¶¨ Î≥¥Í∏∞", key="validation_interactive_view_history_default"):
                            st.session_state.validation_interactive_view_history_id = selected_history_id
                            st.session_state.validation_interactive_view_history_strategy = 'default'
                            st.rerun()
                    with col_hist2:
                        if st.button("Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ ÌûàÏä§ÌÜ†Î¶¨ Î≥¥Í∏∞", key="validation_interactive_view_history_reverse"):
                            st.session_state.validation_interactive_view_history_id = selected_history_id
                            st.session_state.validation_interactive_view_history_strategy = 'reverse'
                            st.rerun()
                
                # ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨ ÌëúÏãú
                if 'validation_interactive_view_history_id' in st.session_state:
                    history_id = st.session_state.validation_interactive_view_history_id
                    strategy_type = st.session_state.get('validation_interactive_view_history_strategy', 'default')
                    reverse_forced = (strategy_type == 'reverse')
                    
                    failure_history = get_failure_history_interactive(
                        history_id,
                        cutoff_id,
                        window_size=window_size,
                        method=method,
                        use_threshold=use_threshold,
                        threshold=threshold if use_threshold else 60,
                        max_interval=max_interval,
                        reverse_forced_prediction=reverse_forced
                    )
                    
                    if failure_history is not None:
                        st.markdown("---")
                        strategy_label = "Î∞òÎåÄ ÏÑ†ÌÉù Ï†ÑÎûµ" if reverse_forced else "Í∏∞Î≥∏ Ï†ÑÎûµ"
                        st.markdown(f"### Grid String ID {history_id} ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨ ({strategy_label})")
                        
                        # ÏöîÏïΩ Ï†ïÎ≥¥
                        col1, col2, col3, col4, col5 = st.columns(5)
                        with col1:
                            st.metric("ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®", f"{failure_history['max_consecutive_failures']}Ìöå")
                        with col2:
                            st.metric("Ï¥ù Ïä§ÌÖù", f"{failure_history['total_steps']}")
                        with col3:
                            st.metric("Ï¥ù Ïã§Ìå®", f"{failure_history['total_failures']}")
                        with col4:
                            st.metric("Ï¥ù ÏòàÏ∏°", f"{failure_history['total_predictions']}")
                        with col5:
                            st.metric("Ï†ïÌôïÎèÑ", f"{failure_history['accuracy']:.2f}%")
                        
                        # ÌûàÏä§ÌÜ†Î¶¨ ÌÖåÏù¥Î∏î
                        st.markdown("#### ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨")
                        history_data = []
                        history = failure_history.get('history', [])
                        
                        for entry in history:
                            is_correct = entry.get('is_correct')
                            match_status = '‚úÖ' if is_correct else ('‚ùå' if is_correct is False else '-')
                            has_prediction = entry.get('has_prediction', False)
                            is_forced = entry.get('is_forced', False)
                            
                            forced_mark = '‚ö°' if is_forced else ''
                            no_pred_mark = 'üö´' if not has_prediction else ''
                            
                            history_data.append({
                                'Step': entry.get('step', 0),
                                'Prefix': entry.get('prefix', ''),
                                'ÏòàÏ∏°': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}",
                                'Ïã§Ï†úÍ∞í': entry.get('actual', '-'),
                                'ÏùºÏπò': match_status,
                                'Ïã†Î¢∞ÎèÑ (%)': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                'Í∞ÑÍ≤©': entry.get('current_interval', 0) if not has_prediction else 0
                            })
                        
                        history_df = pd.DataFrame(history_data)
                        st.dataframe(history_df, use_container_width=True, hide_index=True)
            else:
                st.info("üí° ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®Í∞Ä 5Ìöå Ïù¥ÏÉÅÏù∏ Grid StringÏù¥ ÏóÜÏäµÎãàÎã§.")
        else:
            st.info("üí° Í≤ÄÏ¶ù Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§. Î®ºÏ†Ä Í≤ÄÏ¶ùÏùÑ Ïã§ÌñâÌïòÏÑ∏Ïöî.")
    else:
        st.info("üí° Í∏∞Ï§Ä Grid String IDÎ•º ÏÑ†ÌÉùÌïòÍ≥† Í≤ÄÏ¶ùÏùÑ Ïã§ÌñâÌïòÏÑ∏Ïöî.")
    
    # Ïã†Î¢∞ÎèÑ Í∏∞Î∞ò Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù ÏÑπÏÖò
    st.markdown("---")
    st.header("üéØ Ïã†Î¢∞ÎèÑ Í∏∞Î∞ò Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù")
    st.markdown("""
    **Ï†ÑÎûµ ÏÑ§Î™Ö:**
    - Í∏∞Î≥∏ Í∑úÏπôÏùÄ Í∏∞Ï°¥Í≥º ÎèôÏùº
    - Í∞ïÏ†ú ÏòàÏ∏° Ïã†Î¢∞ÎèÑÍ∞Ä 51% ÎØ∏ÎßåÏù∏ Í≤ΩÏö∞ Ìï¥Îãπ Ïä§ÌÖùÏùÄ Ïä§ÌÇµ (Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ)
    - Ïä§ÌÇµ ÏÉÅÌÉúÏóêÏÑú Í∞ÑÍ≤© Í≥ÑÏÇ∞ÏùÄ Î©àÏ∂§ (Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÏùå)
    - Îã§Ïùå Ïä§ÌÖùÏóêÏÑú ÏûÑÍ≥ÑÍ∞í ÎßåÏ°± ÏòàÏ∏° ÎòêÎäî Ïã†Î¢∞ÎèÑ 51% Ïù¥ÏÉÅ Í∞ïÏ†ú ÏòàÏ∏°Ïù¥ ÎÇòÏò¨ ÎïåÍπåÏßÄ ÎåÄÍ∏∞
    
    **Í≤ÄÏ¶ù Î™©Ï†Å:**
    - Ïã†Î¢∞ÎèÑ 51% ÎØ∏ÎßåÏù∏ Í∞ïÏ†ú ÏòàÏ∏°Ïùò ÏÑ±Í≥µ ÌôïÎ•†Ïù¥ ÎÇÆÏùÄÏßÄ Í≤ÄÏ¶ù
    - Ïä§ÌÇµ Ï†ÑÎûµÏù¥ ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®Î•º Ï§ÑÏù¥ÎäîÏßÄ ÌôïÏù∏
    """)
    
    # ÏÑ§Ï†ï ÏÑπÏÖò
    st.markdown("### ‚öôÔ∏è ÏÑ§Ï†ï")
    
    # Í∏∞Ï§Ä Grid String ID ÏÉàÎ°úÍ≥†Ïπ® Î≤ÑÌäº (form Î∞ñÏóê ÏúÑÏπò)
    col_refresh_header = st.columns([1, 4])
    with col_refresh_header[0]:
        if st.button("üîÑ Îç∞Ïù¥ÌÑ∞ ÏÉàÎ°úÍ≥†Ïπ®", key="confidence_skip_refresh_data", use_container_width=True):
            # Îç∞Ïù¥ÌÑ∞ ÏÉàÎ°úÍ≥†Ïπ®ÏùÑ ÏúÑÌï¥ Ï∫êÏãú Ï†úÍ±∞
            if 'preprocessed_data_cache' in st.session_state:
                del st.session_state.preprocessed_data_cache
            st.rerun()
    with col_refresh_header[1]:
        st.caption("Îç∞Ïù¥ÌÑ∞ Î™©Î°ùÏùÑ ÏóÖÎç∞Ïù¥Ìä∏Ìï©ÎãàÎã§")
    
    # Îç∞Ïù¥ÌÑ∞ Î°úÎìú (form Î∞ñÏóêÏÑú)
    df_all_strings_skip = load_preprocessed_data()
    grid_string_options_skip = []
    if len(df_all_strings_skip) > 0:
        for _, row in df_all_strings_skip.iterrows():
            grid_string_options_skip.append((row['id'], row['created_at']))
        grid_string_options_skip.sort(key=lambda x: x[0], reverse=True)
    
    with st.form("confidence_skip_settings_form", clear_on_submit=False):
        col_skip1, col_skip2, col_skip3 = st.columns(3)
        
        with col_skip1:
            skip_window_size = st.selectbox(
                "ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞",
                options=[5, 6, 7, 8, 9],
                index=0,
                key="confidence_skip_window_size",
                help="ÏòàÏ∏°Ïóê ÏÇ¨Ïö©Ìï† ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞"
            )
        
        with col_skip2:
            skip_method = st.selectbox(
                "ÏòàÏ∏° Î∞©Î≤ï",
                options=["ÎπàÎèÑ Í∏∞Î∞ò", "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò", "ÏïàÏ†Ñ Ïö∞ÏÑ†"],
                index=0,
                key="confidence_skip_method",
                help="ÏòàÏ∏°Ïóê ÏÇ¨Ïö©Ìï† Î∞©Î≤ï"
            )
        
        with col_skip3:
            skip_use_threshold = st.checkbox(
                "ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö©",
                value=True,
                key="confidence_skip_use_threshold",
                help="ÏûÑÍ≥ÑÍ∞í Ïù¥ÏÉÅÏùº ÎïåÎßå ÏòàÏ∏°"
            )
            skip_threshold = None
            if skip_use_threshold:
                skip_threshold = st.number_input(
                    "ÏûÑÍ≥ÑÍ∞í (%)",
                    min_value=0,
                    max_value=100,
                    value=56,
                    step=1,
                    key="confidence_skip_threshold_value",
                    help="Ïù¥ Ïã†Î¢∞ÎèÑ Ïù¥ÏÉÅÏùº ÎïåÎßå ÏòàÏ∏°"
                )
        
        # ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î ÏÇ¨Ïö© ÏòµÏÖò (ÏÉàÎ°úÏö¥ Ìñâ)
        st.markdown("---")
        st.markdown("**üìä ÏòàÏ∏° Î™®Îç∏ ÏÑ†ÌÉù**")
        col_model1, col_model2 = st.columns(2)
        
        with col_model1:
            skip_use_stored_predictions = st.checkbox(
                "ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î ÏÇ¨Ïö© (stored_predictions)",
                value=False,
                key="confidence_skip_use_stored_predictions",
                help="Ï≤¥ÌÅ¨ÌïòÎ©¥ stored_predictions ÌÖåÏù¥Î∏îÏùò ÏòàÏ∏°Í∞íÏùÑ ÏÇ¨Ïö©, Ï≤¥ÌÅ¨ Ìï¥Ï†úÌïòÎ©¥ Ïã§ÏãúÍ∞Ñ Î™®Îç∏ ÏÇ¨Ïö©"
            )
        
        with col_model2:
            skip_stored_threshold = st.number_input(
                "ÌÖåÏù¥Î∏î Ï°∞Ìöå ÏûÑÍ≥ÑÍ∞í",
                min_value=0,
                max_value=100,
                value=0,
                step=1,
                key="confidence_skip_stored_threshold",
                help="stored_predictions ÌÖåÏù¥Î∏îÏóêÏÑú Ï°∞ÌöåÌï† Îïå ÏÇ¨Ïö©Ìï† ÏûÑÍ≥ÑÍ∞í (Í∏∞Î≥∏Í∞í: 0)",
                disabled=not st.session_state.get('confidence_skip_use_stored_predictions', False)
            )
        
        col_skip4, col_skip5 = st.columns(2)
        with col_skip4:
            skip_max_interval = st.number_input(
                "ÏµúÎåÄ ÏòàÏ∏° ÏóÜÏùå Í∞ÑÍ≤©",
                min_value=1,
                max_value=20,
                value=5,
                step=1,
                key="confidence_skip_max_interval",
                help="Ïù¥ Í∞ÑÍ≤©ÏùÑ ÎÑòÍ∏∞Î©¥ Í∞ïÏ†ú ÏòàÏ∏°"
            )
            
            # Ïä§ÌÇµ Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í 2Í∞ú ÏÑ†ÌÉù
            st.markdown("**Ïä§ÌÇµ Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í**")
            col_threshold1, col_threshold2 = st.columns(2)
            with col_threshold1:
                skip_confidence_threshold_1 = st.number_input(
                    "ÏûÑÍ≥ÑÍ∞í 1 (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=50.9,
                    step=0.1,
                    key="confidence_skip_threshold_1",
                    help="Ï≤´ Î≤àÏß∏ Ïä§ÌÇµ Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í"
                )
            with col_threshold2:
                skip_confidence_threshold_2 = st.number_input(
                    "ÏûÑÍ≥ÑÍ∞í 2 (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=51.9,
                    step=0.1,
                    key="confidence_skip_threshold_2",
                    help="Îëê Î≤àÏß∏ Ïä§ÌÇµ Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í"
                )
        
        with col_skip5:
            # Í∏∞Ï§Ä Grid String ID ÏÑ†ÌÉù
            if len(grid_string_options_skip) > 0:
                current_selected_skip = st.session_state.get('confidence_skip_cutoff_id', None)
                default_index_skip = 0
                if current_selected_skip is not None:
                    option_ids_skip = [None] + [opt[0] for opt in grid_string_options_skip]
                    if current_selected_skip in option_ids_skip:
                        default_index_skip = option_ids_skip.index(current_selected_skip)
                
                selected_cutoff_id_skip = st.selectbox(
                    "Í∏∞Ï§Ä Grid String ID",
                    options=[None] + [opt[0] for opt in grid_string_options_skip],
                    format_func=lambda x: "Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞" if x is None else next((f"ID {opt[0]} - {opt[1]}" for opt in grid_string_options_skip if opt[0] == x), f"ID {x} Ïù¥ÌõÑ"),
                    index=default_index_skip,
                    key="confidence_skip_cutoff_id_select"
                )
                
                if selected_cutoff_id_skip is not None:
                    st.session_state.confidence_skip_cutoff_id = selected_cutoff_id_skip
            else:
                selected_cutoff_id_skip = None
                st.info("‚ö†Ô∏è Ï†ÄÏû•Îêú grid_stringÏù¥ ÏóÜÏäµÎãàÎã§.")
        
        # Í≤ÄÏ¶ù Ïã§Ìñâ Î≤ÑÌäº
        submitted = st.form_submit_button("Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù Ïã§Ìñâ", type="primary", use_container_width=True)
    
    # form Î∞ñÏóêÏÑú submit Ï≤òÎ¶¨
    if submitted:
        # form ÏïàÏóêÏÑú ÏÑ†ÌÉùÎêú Í∞íÏùÄ ÏúÑÏ†ØÏùò keyÎ•º ÌÜµÌï¥ session_stateÏóê ÏûêÎèô Ï†ÄÏû•Îê®
        selected_cutoff_id_skip = st.session_state.get('confidence_skip_cutoff_id_select', None)
        if selected_cutoff_id_skip is None:
            st.warning("‚ö†Ô∏è Í∏∞Ï§Ä Grid String IDÎ•º ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî.")
        else:
            # ÏÑ†ÌÉùÎêú Í∞íÏùÑ confidence_skip_cutoff_idÏóê Ï†ÄÏû•
            st.session_state.confidence_skip_cutoff_id = selected_cutoff_id_skip
            # Ïä§ÌÇµ Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞íÏùÄ ÏúÑÏ†ØÏóêÏÑú ÏûêÎèôÏúºÎ°ú session_stateÏóê Ï†ÄÏû•ÎêòÎØÄÎ°ú ÏùΩÍ∏∞Îßå Ìï®
            # Í≤∞Í≥º Ï∫êÏãú Ï†úÍ±∞ÌïòÏó¨ ÏÉàÎ°ú Ïã§ÌñâÌïòÎèÑÎ°ù Ìï®
            if 'confidence_skip_results_1' in st.session_state:
                del st.session_state.confidence_skip_results_1
            if 'confidence_skip_results_2' in st.session_state:
                del st.session_state.confidence_skip_results_2
            st.rerun()
    
    # Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù Ïã§Ìñâ Î∞è Í≤∞Í≥º ÌëúÏãú
    if 'confidence_skip_cutoff_id' in st.session_state and st.session_state.confidence_skip_cutoff_id is not None:
        cutoff_id_skip = st.session_state.confidence_skip_cutoff_id
        
        # ÌòÑÏû¨ ÏÑ§Ï†ï Í∞ÄÏ†∏Ïò§Í∏∞
        skip_window_size = st.session_state.get('confidence_skip_window_size', 6)
        skip_method = st.session_state.get('confidence_skip_method', 'ÎπàÎèÑ Í∏∞Î∞ò')
        skip_use_threshold = st.session_state.get('confidence_skip_use_threshold', True)
        skip_threshold_val = st.session_state.get('confidence_skip_threshold_value', 56) if skip_use_threshold else None
        skip_max_interval = st.session_state.get('confidence_skip_max_interval', 5)
        skip_confidence_threshold_1 = st.session_state.get('confidence_skip_threshold_1', 51)
        skip_confidence_threshold_2 = st.session_state.get('confidence_skip_threshold_2', 52)
        # ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î ÏÇ¨Ïö© ÏòµÏÖò
        skip_use_stored_predictions = st.session_state.get('confidence_skip_use_stored_predictions', False)
        skip_stored_threshold = st.session_state.get('confidence_skip_stored_threshold', 0)
        
        # ÏòàÏ∏° Î™®Îç∏ Ï†ïÎ≥¥ ÌëúÏãú
        if skip_use_stored_predictions:
            st.info(f"üìä **ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î ÏÇ¨Ïö©**: stored_predictions (ÏûÑÍ≥ÑÍ∞í: {skip_stored_threshold})")
        else:
            st.info("üß† **Ïã§ÏãúÍ∞Ñ Î™®Îç∏ ÏÇ¨Ïö©**: ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò Î™®Îç∏ ÏÉùÏÑ±")
        
        # Ï≤´ Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í Í≤ÄÏ¶ù Ïã§Ìñâ
        if 'confidence_skip_results_1' in st.session_state and st.session_state.confidence_skip_results_1 is not None:
            batch_results_skip_1 = st.session_state.confidence_skip_results_1
        else:
            model_type_str = "ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î" if skip_use_stored_predictions else "Ïã§ÏãúÍ∞Ñ Î™®Îç∏"
            with st.spinner(f"Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù Ïã§Ìñâ Ï§ë... (ÏûÑÍ≥ÑÍ∞í 1: {skip_confidence_threshold_1}%, {model_type_str})"):
                try:
                    batch_results_skip_1 = batch_validate_interactive_multi_step_scenario_with_confidence_skip(
                        cutoff_id_skip,
                        window_size=skip_window_size,
                        method=skip_method,
                        use_threshold=skip_use_threshold,
                        threshold=skip_threshold_val if skip_use_threshold else 60,
                        max_interval=skip_max_interval,
                        reverse_forced_prediction=False,
                        confidence_skip_threshold=skip_confidence_threshold_1,
                        use_stored_predictions=skip_use_stored_predictions,
                        stored_threshold=skip_stored_threshold
                    )
                    
                    if batch_results_skip_1 is not None:
                        st.session_state.confidence_skip_results_1 = batch_results_skip_1
                    else:
                        batch_results_skip_1 = None
                        st.session_state.confidence_skip_results_1 = None
                except Exception as e:
                    st.error(f"Í≤ÄÏ¶ù Ïã§Ìñâ Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
                    batch_results_skip_1 = None
                    st.session_state.confidence_skip_results_1 = None
        
        # Îëê Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í Í≤ÄÏ¶ù Ïã§Ìñâ
        if 'confidence_skip_results_2' in st.session_state and st.session_state.confidence_skip_results_2 is not None:
            batch_results_skip_2 = st.session_state.confidence_skip_results_2
        else:
            model_type_str = "ÏòàÏ∏°Í∞í ÌÖåÏù¥Î∏î" if skip_use_stored_predictions else "Ïã§ÏãúÍ∞Ñ Î™®Îç∏"
            with st.spinner(f"Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù Ïã§Ìñâ Ï§ë... (ÏûÑÍ≥ÑÍ∞í 2: {skip_confidence_threshold_2}%, {model_type_str})"):
                try:
                    batch_results_skip_2 = batch_validate_interactive_multi_step_scenario_with_confidence_skip(
                        cutoff_id_skip,
                        window_size=skip_window_size,
                        method=skip_method,
                        use_threshold=skip_use_threshold,
                        threshold=skip_threshold_val if skip_use_threshold else 60,
                        max_interval=skip_max_interval,
                        reverse_forced_prediction=False,
                        confidence_skip_threshold=skip_confidence_threshold_2,
                        use_stored_predictions=skip_use_stored_predictions,
                        stored_threshold=skip_stored_threshold
                    )
                    
                    if batch_results_skip_2 is not None:
                        st.session_state.confidence_skip_results_2 = batch_results_skip_2
                    else:
                        batch_results_skip_2 = None
                        st.session_state.confidence_skip_results_2 = None
                except Exception as e:
                    st.error(f"Í≤ÄÏ¶ù Ïã§Ìñâ Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}")
                    batch_results_skip_2 = None
                    st.session_state.confidence_skip_results_2 = None
        
        # Ï≤´ Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í Í≤∞Í≥º ÌëúÏãú
        if batch_results_skip_1 is None:
            st.info("üí° Í≤ÄÏ¶ùÏùÑ Ïã§ÌñâÌïòÎ©¥ Í≤∞Í≥ºÍ∞Ä ÌëúÏãúÎê©ÎãàÎã§.")
        elif len(batch_results_skip_1.get('results', [])) == 0:
            st.warning("‚ö†Ô∏è Í≤ÄÏ¶ù Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§. Í∏∞Ï§Ä Grid String ID Ïù¥ÌõÑÏùò Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏùÑ Ïàò ÏûàÏäµÎãàÎã§.")
        else:
            summary_skip_1 = batch_results_skip_1.get('summary', {})
            
            st.markdown("---")
            st.markdown(f"### Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù Í≤∞Í≥º (ÏûÑÍ≥ÑÍ∞í 1: {skip_confidence_threshold_1}%)")
            
            col_skip_result1, col_skip_result2, col_skip_result3, col_skip_result4, col_skip_result5, col_skip_result6 = st.columns(6)
            with col_skip_result1:
                st.metric("ÌèâÍ∑† Ï†ïÌôïÎèÑ", f"{summary_skip_1.get('avg_accuracy', 0):.2f}%")
            with col_skip_result2:
                st.metric("ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®", f"{summary_skip_1.get('max_consecutive_failures', 0)}Ìöå")
            with col_skip_result3:
                st.metric("Ï¥ù Ïä§ÌÇµ ÌöüÏàò", f"{summary_skip_1.get('total_skipped_predictions', 0)}Ìöå")
            with col_skip_result4:
                st.metric("ÏòàÏ∏°Î•†", f"{summary_skip_1.get('prediction_rate', 0):.2f}%")
            with col_skip_result5:
                first_success = summary_skip_1.get('avg_first_success_step')
                if first_success is not None:
                    st.metric("ÌèâÍ∑† Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", f"{first_success:.1f}")
                else:
                    st.metric("ÌèâÍ∑† Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", "-")
            with col_skip_result6:
                max_first_success = summary_skip_1.get('max_first_success_step')
                if max_first_success is not None and max_first_success > 0:
                    st.metric("ÏµúÎåÄ Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", f"{max_first_success}")
                else:
                    st.metric("ÏµúÎåÄ Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", "-")
            
            # Ï∂îÍ∞Ä ÌÜµÍ≥Ñ ÌëúÏãú
            st.markdown("---")
            st.markdown("#### ÏÉÅÏÑ∏ ÌÜµÍ≥Ñ")
            detail_stats_1 = {
                'Ï¥ù Grid String Ïàò': summary_skip_1.get('total_grid_strings', 0),
                'Ï¥ù Ïä§ÌÖù Ïàò': summary_skip_1.get('total_steps', 0),
                'Ï¥ù ÏòàÏ∏° ÌöüÏàò': summary_skip_1.get('total_predictions', 0),
                'Ï¥ù Ïã§Ìå® ÌöüÏàò': summary_skip_1.get('total_failures', 0),
                'Ï¥ù Í∞ïÏ†ú ÏòàÏ∏° ÌöüÏàò': summary_skip_1.get('total_forced_predictions', 0),
                'ÌèâÍ∑† ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®': f"{summary_skip_1.get('avg_max_consecutive_failures', 0):.2f}",
                'Í∞ïÏ†ú ÏòàÏ∏° ÎπÑÏú®': f"{summary_skip_1.get('forced_prediction_rate', 0):.2f}%",
                'Í∞ïÏ†ú ÏòàÏ∏° ÏÑ±Í≥µ ÎπÑÏú®': f"{summary_skip_1.get('forced_success_rate', 0):.2f}%",
                'ÌèâÍ∑† Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù': f"{summary_skip_1.get('avg_first_success_step', 0):.2f}" if summary_skip_1.get('avg_first_success_step') is not None else "-",
                'ÏµúÏÜå Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù': f"{summary_skip_1.get('min_first_success_step', 0)}" if summary_skip_1.get('min_first_success_step') is not None else "-",
                'ÏµúÎåÄ Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù': f"{summary_skip_1.get('max_first_success_step', 0)}" if summary_skip_1.get('max_first_success_step') is not None else "-",
                'ÏÑ±Í≥µÏù¥ ÏûàÏóàÎçò Grid String Ïàò': summary_skip_1.get('total_with_success', 0)
            }
            detail_df_1 = pd.DataFrame([detail_stats_1])
            st.dataframe(detail_df_1, use_container_width=True, hide_index=True)
            
            # Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ ÌëúÏãú
            st.markdown("---")
            st.markdown("### Ïã†Î¢∞ÎèÑ Íµ¨Í∞ÑÎ≥Ñ ÌÜµÍ≥Ñ (Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ)")
            
            conn = get_db_connection()
            if conn is not None:
                try:
                    stats_query_skip = """
                        SELECT confidence_range, total_predictions, matches, mismatches, 
                               match_rate, avg_confidence
                        FROM confidence_statistics
                        WHERE strategy_type = 'confidence_skip'
                        ORDER BY confidence_range
                    """
                    stats_df_skip = pd.read_sql_query(stats_query_skip, conn)
                    
                    if len(stats_df_skip) > 0:
                        st.dataframe(stats_df_skip, use_container_width=True, hide_index=True)
                    else:
                        st.info("üí° Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§. Í≤ÄÏ¶ùÏùÑ Ïã§ÌñâÌïòÎ©¥ ÌÜµÍ≥ÑÍ∞Ä ÏàòÏßëÎê©ÎãàÎã§.")
                except Exception as e:
                    st.warning(f"Ïã†Î¢∞ÎèÑ ÌÜµÍ≥Ñ Ï°∞Ìöå Ï§ë Ïò§Î•ò: {str(e)}")
                finally:
                    conn.close()
            
            # ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå® Grid String ÌûàÏä§ÌÜ†Î¶¨ ÏûêÎèô ÌëúÏãú (Í≤ÄÏ¶ùÏö©)
            st.markdown("---")
            st.markdown("### üîç ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå® Grid String Í≤ÄÏ¶ù ÌûàÏä§ÌÜ†Î¶¨ (Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ)")
            st.markdown("**ÏùòÎèÑÎåÄÎ°ú ÎèôÏûëÌïòÎäîÏßÄ ÌôïÏù∏ÌïòÍ∏∞ ÏúÑÌïú ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®Í∞Ä Î∞úÏÉùÌïú grid_string_idÏùò ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨**")
            
            results_skip_1 = batch_results_skip_1.get('results', [])
            if len(results_skip_1) > 0:
                # ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®Í∞Ä Î∞úÏÉùÌïú grid_string_id Ï∞æÍ∏∞
                max_failure_result = max(results_skip_1, key=lambda x: x.get('max_consecutive_failures', 0))
                max_failure_grid_id = max_failure_result['grid_string_id']
                max_failure_count = max_failure_result.get('max_consecutive_failures', 0)
                
                st.info(f"üìå **Í≤ÄÏ¶ù ÎåÄÏÉÅ**: Grid String ID {max_failure_grid_id} (ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®: {max_failure_count}Ìöå)")
                
                # Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨ Î≥¥Í∏∞ ÏòµÏÖò
                show_full_history_skip_1 = st.checkbox(
                    "Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨ Î≥¥Í∏∞ (Í∏∞Î≥∏: ÏµúÍ∑º 50Í∞úÎßå ÌëúÏãú)",
                    value=False,
                    key="last_grid_full_history_skip_1"
                )
                
                # ÌûàÏä§ÌÜ†Î¶¨ Í∞ÄÏ†∏Ïò§Í∏∞
                failure_history_skip_1 = validate_interactive_multi_step_scenario_with_confidence_skip(
                    max_failure_grid_id,
                    cutoff_id_skip,
                    window_size=skip_window_size,
                    method=skip_method,
                    use_threshold=skip_use_threshold,
                    threshold=skip_threshold_val if skip_use_threshold else 60,
                    max_interval=skip_max_interval,
                    reverse_forced_prediction=False,
                    confidence_skip_threshold=skip_confidence_threshold_1
                )
                
                if failure_history_skip_1:
                    st.markdown("#### ÏöîÏïΩ Ï†ïÎ≥¥")
                    col_hist1, col_hist2, col_hist3, col_hist4, col_hist5, col_hist6 = st.columns(6)
                    with col_hist1:
                        st.metric("ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®", f"{failure_history_skip_1['max_consecutive_failures']}Ìöå")
                    with col_hist2:
                        st.metric("Ï¥ù Ïä§ÌÖù", f"{failure_history_skip_1['total_steps']}")
                    with col_hist3:
                        st.metric("Ï¥ù ÏòàÏ∏°", f"{failure_history_skip_1['total_predictions']}")
                    with col_hist4:
                        st.metric("Ï¥ù Ïä§ÌÇµ", f"{failure_history_skip_1.get('total_skipped_predictions', 0)}Ìöå")
                    with col_hist5:
                        st.metric("Ï†ïÌôïÎèÑ", f"{failure_history_skip_1['accuracy']:.2f}%")
                    with col_hist6:
                        first_success_step = failure_history_skip_1.get('first_success_step')
                        if first_success_step is not None:
                            st.metric("Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", f"{first_success_step}")
                        else:
                            st.metric("Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", "-")
                    
                    # ÌûàÏä§ÌÜ†Î¶¨ ÌÖåÏù¥Î∏î (ÏµúÏã†ÏàúÏúºÎ°ú ÌëúÏãú)
                    st.markdown("#### ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨")
                    history_skip_1 = failure_history_skip_1.get('history', [])
                    if len(history_skip_1) > 0:
                        # ÌûàÏä§ÌÜ†Î¶¨Î•º ÏµúÏã†ÏàúÏúºÎ°ú Ï†ïÎ†¨ (step ÎÇ¥Î¶ºÏ∞®Ïàú)
                        history_skip_sorted_1 = sorted(history_skip_1, key=lambda x: x.get('step', 0), reverse=True)
                        
                        history_limit_skip_1 = None if show_full_history_skip_1 else 50
                        history_title_skip_1 = "##### ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨" + (f" (ÏµúÏã† {history_limit_skip_1}Í∞ú)" if history_limit_skip_1 else " (Ï†ÑÏ≤¥)")
                        st.markdown(history_title_skip_1)
                        history_data_skip_1 = []
                        # ÏµúÏã†ÏàúÏúºÎ°ú Ï†ïÎ†¨Îêú ÌûàÏä§ÌÜ†Î¶¨ÏóêÏÑú ÏµúÏã† NÍ∞ú ÏÑ†ÌÉù
                        display_history_skip_1 = history_skip_sorted_1[:history_limit_skip_1] if history_limit_skip_1 else history_skip_sorted_1
                        
                        for entry in display_history_skip_1:
                            is_correct = entry.get('is_correct')
                            match_status = '‚úÖ' if is_correct else ('‚ùå' if is_correct is False else '-')
                            has_prediction = entry.get('has_prediction', False)
                            is_forced = entry.get('is_forced', False)
                            validated = entry.get('validated', False)
                            skipped = entry.get('skipped', False)
                            
                            forced_mark = '‚ö°' if is_forced else ''
                            no_pred_mark = 'üö´' if not has_prediction else ''
                            validated_mark = '‚úì' if validated else ''
                            skipped_mark = '‚è≠Ô∏è' if skipped else ''
                            
                            history_data_skip_1.append({
                                'Step': entry.get('step', 0),
                                'Prefix': entry.get('prefix', ''),
                                'ÏòàÏ∏°': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}{skipped_mark}",
                                'Ïã§Ï†úÍ∞í': entry.get('actual', '-'),
                                'ÏùºÏπò': match_status,
                                'Í≤ÄÏ¶ù': validated_mark,
                                'Ïä§ÌÇµ': '‚è≠Ô∏è' if skipped else '',
                                'Ïã†Î¢∞ÎèÑ': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                'Í∞ÑÍ≤©': entry.get('current_interval', 0) if not has_prediction else 0
                            })
                        
                        history_df_skip_1 = pd.DataFrame(history_data_skip_1)
                        st.dataframe(history_df_skip_1, use_container_width=True, hide_index=True)
                        
                        if not show_full_history_skip_1 and len(history_skip_1) > 50:
                            st.caption(f"üí° Ï†ÑÏ≤¥ {len(history_skip_1)}Í∞ú Ï§ë ÏµúÏã† 50Í∞úÎßå ÌëúÏãúÎê©ÎãàÎã§. Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨Î•º Î≥¥Î†§Î©¥ ÏúÑÏùò Ï≤¥ÌÅ¨Î∞ïÏä§Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.")
                    
                    # Í≤ÄÏ¶ù Ìè¨Ïù∏Ìä∏ ÏïàÎÇ¥
                    st.markdown("---")
                    st.markdown("#### üîç Í≤ÄÏ¶ù Ìè¨Ïù∏Ìä∏")
                    st.markdown("""
                    Îã§Ïùå ÏÇ¨Ìï≠Îì§ÏùÑ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî:
                    1. **Ïä§ÌÇµ Í∑úÏπô**: Í∞ïÏ†ú ÏòàÏ∏°(`‚ö°`)Ïù¥Í≥† Ïã†Î¢∞ÎèÑÍ∞Ä 51% ÎØ∏ÎßåÏù∏ Í≤ΩÏö∞ `‚è≠Ô∏è` ÌëúÏãúÍ∞Ä ÏûàÎäîÏßÄ ÌôïÏù∏
                    2. **Í∞ÑÍ≤© Í≥ÑÏÇ∞**: Ïä§ÌÇµÎêú Ïä§ÌÖùÏóêÏÑú Í∞ÑÍ≤©Ïù¥ Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÎäîÏßÄ ÌôïÏù∏ (Í∞ÑÍ≤©Ïù¥ Î©àÏ∂∞ÏûàÎäîÏßÄ)
                    3. **Í≤ÄÏ¶ù ÏàòÌñâ**: `Í≤ÄÏ¶ù` Ïª¨ÎüºÏù¥ '‚úì'Ïù∏ Ïä§ÌÖùÏóêÏÑúÎßå Ïã§Ï†ú ÎπÑÍµêÍ∞Ä ÏàòÌñâÎêòÎäîÏßÄ ÌôïÏù∏
                    4. **Ïó∞ÏÜç Ïã§Ìå® Ï∂îÏ†Å**: Ïó∞ÏÜçÏúºÎ°ú Ïã§Ìå®ÌïòÎäî Í≤ΩÏö∞Í∞Ä Ïò¨Î∞îÎ•¥Í≤å Ïπ¥Ïö¥Ìä∏ÎêòÎäîÏßÄ ÌôïÏù∏
                    5. **Îã§Ïùå Ïä§ÌÖù ÏßÑÌñâ**: Ïä§ÌÇµ ÌõÑ Îã§Ïùå Ïä§ÌÖùÏùò prefixÎ°ú ÏòàÏ∏°Ïù¥ ÏàòÌñâÎêòÎäîÏßÄ ÌôïÏù∏
                    """)
            else:
                st.info("üí° Í≤ÄÏ¶ù Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.")
        
        # Îëê Î≤àÏß∏ ÏûÑÍ≥ÑÍ∞í Í≤∞Í≥º ÌëúÏãú
        if batch_results_skip_2 is None:
            pass  # Ï≤´ Î≤àÏß∏ Í≤∞Í≥ºÍ∞Ä ÏóÜÏúºÎ©¥ Îëê Î≤àÏß∏ÎèÑ ÌëúÏãúÌïòÏßÄ ÏïäÏùå
        elif len(batch_results_skip_2.get('results', [])) == 0:
            pass  # Í≤∞Í≥ºÍ∞Ä ÏóÜÏúºÎ©¥ ÌëúÏãúÌïòÏßÄ ÏïäÏùå
        else:
            summary_skip_2 = batch_results_skip_2.get('summary', {})
            
            st.markdown("---")
            st.markdown(f"### Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ Í≤ÄÏ¶ù Í≤∞Í≥º (ÏûÑÍ≥ÑÍ∞í 2: {skip_confidence_threshold_2}%)")
            
            col_skip_result2_1, col_skip_result2_2, col_skip_result2_3, col_skip_result2_4, col_skip_result2_5, col_skip_result2_6 = st.columns(6)
            with col_skip_result2_1:
                st.metric("ÌèâÍ∑† Ï†ïÌôïÎèÑ", f"{summary_skip_2.get('avg_accuracy', 0):.2f}%")
            with col_skip_result2_2:
                st.metric("ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®", f"{summary_skip_2.get('max_consecutive_failures', 0)}Ìöå")
            with col_skip_result2_3:
                st.metric("Ï¥ù Ïä§ÌÇµ ÌöüÏàò", f"{summary_skip_2.get('total_skipped_predictions', 0)}Ìöå")
            with col_skip_result2_4:
                st.metric("ÏòàÏ∏°Î•†", f"{summary_skip_2.get('prediction_rate', 0):.2f}%")
            with col_skip_result2_5:
                first_success_2 = summary_skip_2.get('avg_first_success_step')
                if first_success_2 is not None:
                    st.metric("ÌèâÍ∑† Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", f"{first_success_2:.1f}")
                else:
                    st.metric("ÌèâÍ∑† Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", "-")
            with col_skip_result2_6:
                max_first_success_2 = summary_skip_2.get('max_first_success_step')
                if max_first_success_2 is not None and max_first_success_2 > 0:
                    st.metric("ÏµúÎåÄ Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", f"{max_first_success_2}")
                else:
                    st.metric("ÏµúÎåÄ Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", "-")
            
            # Ï∂îÍ∞Ä ÌÜµÍ≥Ñ ÌëúÏãú
            st.markdown("---")
            st.markdown("#### ÏÉÅÏÑ∏ ÌÜµÍ≥Ñ")
            detail_stats_2 = {
                'Ï¥ù Grid String Ïàò': summary_skip_2.get('total_grid_strings', 0),
                'Ï¥ù Ïä§ÌÖù Ïàò': summary_skip_2.get('total_steps', 0),
                'Ï¥ù ÏòàÏ∏° ÌöüÏàò': summary_skip_2.get('total_predictions', 0),
                'Ï¥ù Ïã§Ìå® ÌöüÏàò': summary_skip_2.get('total_failures', 0),
                'Ï¥ù Í∞ïÏ†ú ÏòàÏ∏° ÌöüÏàò': summary_skip_2.get('total_forced_predictions', 0),
                'ÌèâÍ∑† ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®': f"{summary_skip_2.get('avg_max_consecutive_failures', 0):.2f}",
                'Í∞ïÏ†ú ÏòàÏ∏° ÎπÑÏú®': f"{summary_skip_2.get('forced_prediction_rate', 0):.2f}%",
                'Í∞ïÏ†ú ÏòàÏ∏° ÏÑ±Í≥µ ÎπÑÏú®': f"{summary_skip_2.get('forced_success_rate', 0):.2f}%",
                'ÌèâÍ∑† Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù': f"{summary_skip_2.get('avg_first_success_step', 0):.2f}" if summary_skip_2.get('avg_first_success_step') is not None else "-",
                'ÏµúÏÜå Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù': f"{summary_skip_2.get('min_first_success_step', 0)}" if summary_skip_2.get('min_first_success_step') is not None else "-",
                'ÏµúÎåÄ Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù': f"{summary_skip_2.get('max_first_success_step', 0)}" if summary_skip_2.get('max_first_success_step') is not None else "-",
                'ÏÑ±Í≥µÏù¥ ÏûàÏóàÎçò Grid String Ïàò': summary_skip_2.get('total_with_success', 0)
            }
            detail_df_2 = pd.DataFrame([detail_stats_2])
            st.dataframe(detail_df_2, use_container_width=True, hide_index=True)
            
            # ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå® Grid String ÌûàÏä§ÌÜ†Î¶¨ ÏûêÎèô ÌëúÏãú (Í≤ÄÏ¶ùÏö©)
            st.markdown("---")
            st.markdown(f"### üîç ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå® Grid String Í≤ÄÏ¶ù ÌûàÏä§ÌÜ†Î¶¨ (ÏûÑÍ≥ÑÍ∞í 2: {skip_confidence_threshold_2}%)")
            st.markdown("**ÏùòÎèÑÎåÄÎ°ú ÎèôÏûëÌïòÎäîÏßÄ ÌôïÏù∏ÌïòÍ∏∞ ÏúÑÌïú ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®Í∞Ä Î∞úÏÉùÌïú grid_string_idÏùò ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨**")
            
            results_skip_2 = batch_results_skip_2.get('results', [])
            if len(results_skip_2) > 0:
                # ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®Í∞Ä Î∞úÏÉùÌïú grid_string_id Ï∞æÍ∏∞
                max_failure_result_2 = max(results_skip_2, key=lambda x: x.get('max_consecutive_failures', 0))
                max_failure_grid_id_2 = max_failure_result_2['grid_string_id']
                max_failure_count_2 = max_failure_result_2.get('max_consecutive_failures', 0)
                
                st.info(f"üìå **Í≤ÄÏ¶ù ÎåÄÏÉÅ**: Grid String ID {max_failure_grid_id_2} (ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®: {max_failure_count_2}Ìöå)")
                
                # Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨ Î≥¥Í∏∞ ÏòµÏÖò
                show_full_history_skip_2 = st.checkbox(
                    "Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨ Î≥¥Í∏∞ (Í∏∞Î≥∏: ÏµúÍ∑º 50Í∞úÎßå ÌëúÏãú)",
                    value=False,
                    key="last_grid_full_history_skip_2"
                )
                
                # ÌûàÏä§ÌÜ†Î¶¨ Í∞ÄÏ†∏Ïò§Í∏∞
                failure_history_skip_2 = validate_interactive_multi_step_scenario_with_confidence_skip(
                    max_failure_grid_id_2,
                    cutoff_id_skip,
                    window_size=skip_window_size,
                    method=skip_method,
                    use_threshold=skip_use_threshold,
                    threshold=skip_threshold_val if skip_use_threshold else 60,
                    max_interval=skip_max_interval,
                    reverse_forced_prediction=False,
                    confidence_skip_threshold=skip_confidence_threshold_2
                )
                
                if failure_history_skip_2:
                    st.markdown("#### ÏöîÏïΩ Ï†ïÎ≥¥")
                    col_hist2_1, col_hist2_2, col_hist2_3, col_hist2_4, col_hist2_5, col_hist2_6 = st.columns(6)
                    with col_hist2_1:
                        st.metric("ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®", f"{failure_history_skip_2['max_consecutive_failures']}Ìöå")
                    with col_hist2_2:
                        st.metric("Ï¥ù Ïä§ÌÖù", f"{failure_history_skip_2['total_steps']}")
                    with col_hist2_3:
                        st.metric("Ï¥ù ÏòàÏ∏°", f"{failure_history_skip_2['total_predictions']}")
                    with col_hist2_4:
                        st.metric("Ï¥ù Ïä§ÌÇµ", f"{failure_history_skip_2.get('total_skipped_predictions', 0)}Ìöå")
                    with col_hist2_5:
                        st.metric("Ï†ïÌôïÎèÑ", f"{failure_history_skip_2['accuracy']:.2f}%")
                    with col_hist2_6:
                        first_success_step_2 = failure_history_skip_2.get('first_success_step')
                        if first_success_step_2 is not None:
                            st.metric("Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", f"{first_success_step_2}")
                        else:
                            st.metric("Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù", "-")
                    
                    # ÌûàÏä§ÌÜ†Î¶¨ ÌÖåÏù¥Î∏î (ÏµúÏã†ÏàúÏúºÎ°ú ÌëúÏãú)
                    st.markdown("#### ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨")
                    history_skip_2 = failure_history_skip_2.get('history', [])
                    if len(history_skip_2) > 0:
                        # ÌûàÏä§ÌÜ†Î¶¨Î•º ÏµúÏã†ÏàúÏúºÎ°ú Ï†ïÎ†¨ (step ÎÇ¥Î¶ºÏ∞®Ïàú)
                        history_skip_sorted_2 = sorted(history_skip_2, key=lambda x: x.get('step', 0), reverse=True)
                        
                        history_limit_skip_2 = None if show_full_history_skip_2 else 50
                        history_title_skip_2 = "##### ÏÉÅÏÑ∏ ÌûàÏä§ÌÜ†Î¶¨" + (f" (ÏµúÏã† {history_limit_skip_2}Í∞ú)" if history_limit_skip_2 else " (Ï†ÑÏ≤¥)")
                        st.markdown(history_title_skip_2)
                        history_data_skip_2 = []
                        # ÏµúÏã†ÏàúÏúºÎ°ú Ï†ïÎ†¨Îêú ÌûàÏä§ÌÜ†Î¶¨ÏóêÏÑú ÏµúÏã† NÍ∞ú ÏÑ†ÌÉù
                        display_history_skip_2 = history_skip_sorted_2[:history_limit_skip_2] if history_limit_skip_2 else history_skip_sorted_2
                        
                        for entry in display_history_skip_2:
                            is_correct = entry.get('is_correct')
                            match_status = '‚úÖ' if is_correct else ('‚ùå' if is_correct is False else '-')
                            has_prediction = entry.get('has_prediction', False)
                            is_forced = entry.get('is_forced', False)
                            validated = entry.get('validated', False)
                            skipped = entry.get('skipped', False)
                            
                            forced_mark = '‚ö°' if is_forced else ''
                            no_pred_mark = 'üö´' if not has_prediction else ''
                            validated_mark = '‚úì' if validated else ''
                            skipped_mark = '‚è≠Ô∏è' if skipped else ''
                            
                            history_data_skip_2.append({
                                'Step': entry.get('step', 0),
                                'Prefix': entry.get('prefix', ''),
                                'ÏòàÏ∏°': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}{skipped_mark}",
                                'Ïã§Ï†úÍ∞í': entry.get('actual', '-'),
                                'ÏùºÏπò': match_status,
                                'Í≤ÄÏ¶ù': validated_mark,
                                'Ïä§ÌÇµ': '‚è≠Ô∏è' if skipped else '',
                                'Ïã†Î¢∞ÎèÑ': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                'Í∞ÑÍ≤©': entry.get('current_interval', 0) if not has_prediction else 0
                            })
                        
                        history_df_skip_2 = pd.DataFrame(history_data_skip_2)
                        st.dataframe(history_df_skip_2, use_container_width=True, hide_index=True)
                        
                        if not show_full_history_skip_2 and len(history_skip_2) > 50:
                            st.caption(f"üí° Ï†ÑÏ≤¥ {len(history_skip_2)}Í∞ú Ï§ë ÏµúÏã† 50Í∞úÎßå ÌëúÏãúÎê©ÎãàÎã§. Ï†ÑÏ≤¥ ÌûàÏä§ÌÜ†Î¶¨Î•º Î≥¥Î†§Î©¥ ÏúÑÏùò Ï≤¥ÌÅ¨Î∞ïÏä§Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.")
        
        # ÌûàÏä§ÌÜ†Î¶¨ Ï†ÄÏû• ÏÉÅÌÉú ÌôïÏù∏ ÏÑπÏÖò Ï∂îÍ∞Ä
        st.markdown("---")
        st.markdown("### üìã ÌûàÏä§ÌÜ†Î¶¨ Ï†ÄÏû• ÏÉÅÌÉú ÌôïÏù∏")
        
        # ÌòÑÏû¨ ÏÑ∏ÏÖòÏùò ÌûàÏä§ÌÜ†Î¶¨ Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏
        if batch_results_skip_1 and batch_results_skip_2:
            col_check1, col_check2 = st.columns(2)
            
            with col_check1:
                if 'results' in batch_results_skip_1 and len(batch_results_skip_1['results']) > 0:
                    total_history_1 = sum(len(r.get('history', [])) for r in batch_results_skip_1['results'])
                    grid_with_history_1 = sum(1 for r in batch_results_skip_1['results'] if r.get('history'))
                    st.metric("ÏûÑÍ≥ÑÍ∞í 1 - ÌûàÏä§ÌÜ†Î¶¨ ÏûàÎäî Grid String", f"{grid_with_history_1}/{len(batch_results_skip_1['results'])}")
                    st.metric("ÏûÑÍ≥ÑÍ∞í 1 - Ï¥ù ÌûàÏä§ÌÜ†Î¶¨ Ïä§ÌÖù Ïàò", f"{total_history_1}")
                    
                    if grid_with_history_1 < len(batch_results_skip_1['results']):
                        st.warning(f"‚ö†Ô∏è {len(batch_results_skip_1['results']) - grid_with_history_1}Í∞úÏùò Grid StringÏóê ÌûàÏä§ÌÜ†Î¶¨Í∞Ä ÏóÜÏäµÎãàÎã§.")
            
            with col_check2:
                if 'results' in batch_results_skip_2 and len(batch_results_skip_2['results']) > 0:
                    total_history_2 = sum(len(r.get('history', [])) for r in batch_results_skip_2['results'])
                    grid_with_history_2 = sum(1 for r in batch_results_skip_2['results'] if r.get('history'))
                    st.metric("ÏûÑÍ≥ÑÍ∞í 2 - ÌûàÏä§ÌÜ†Î¶¨ ÏûàÎäî Grid String", f"{grid_with_history_2}/{len(batch_results_skip_2['results'])}")
                    st.metric("ÏûÑÍ≥ÑÍ∞í 2 - Ï¥ù ÌûàÏä§ÌÜ†Î¶¨ Ïä§ÌÖù Ïàò", f"{total_history_2}")
                    
                    if grid_with_history_2 < len(batch_results_skip_2['results']):
                        st.warning(f"‚ö†Ô∏è {len(batch_results_skip_2['results']) - grid_with_history_2}Í∞úÏùò Grid StringÏóê ÌûàÏä§ÌÜ†Î¶¨Í∞Ä ÏóÜÏäµÎãàÎã§.")
            
            # Ï†ÄÏû•Îêú validation_id ÌôïÏù∏ Í∏∞Îä•
            st.markdown("#### Ï†ÄÏû•Îêú Í≤ÄÏ¶ù ÏÑ∏ÏÖò ÌôïÏù∏")
            validation_id_input = st.text_input(
                "ÌôïÏù∏Ìï† Validation ID ÏûÖÎ†• (ÎòêÎäî Ï†ÑÏ≤¥ Î™©Î°ù Ï°∞Ìöå)",
                key="check_validation_id",
                placeholder="Ïòà: f81bfed8 ÎòêÎäî ÎπàÏπ∏"
            )
            
            if validation_id_input:
                # ÌäπÏ†ï validation_id ÌôïÏù∏
                conn = get_db_connection()
                if conn is not None:
                    try:
                        cursor = conn.cursor()
                        # validation_idÎ°ú ÏãúÏûëÌïòÎäî ÏÑ∏ÏÖòÎì§ Ï∞æÍ∏∞
                        cursor.execute('''
                            SELECT validation_id, created_at,
                                   (SELECT COUNT(*) FROM confidence_skip_validation_grid_results 
                                    WHERE validation_id = s.validation_id) as grid_count,
                                   (SELECT COUNT(*) FROM confidence_skip_validation_steps 
                                    WHERE validation_id = s.validation_id) as step_count
                            FROM confidence_skip_validation_sessions s
                            WHERE validation_id LIKE ?
                            ORDER BY created_at DESC
                        ''', (f"{validation_id_input}%",))
                        
                        matching_sessions = cursor.fetchall()
                        
                        if len(matching_sessions) > 0:
                            st.markdown("##### ÏùºÏπòÌïòÎäî ÏÑ∏ÏÖò Î™©Î°ù")
                            session_info = []
                            for row in matching_sessions:
                                session_info.append({
                                    'Validation ID': row[0],
                                    'ÏÉùÏÑ±Ïùº': row[1],
                                    'Grid String Ïàò': row[2],
                                    'Ï†ÄÏû•Îêú Ïä§ÌÖù Ïàò': row[3]
                                })
                            session_df = pd.DataFrame(session_info)
                            st.dataframe(session_df, use_container_width=True, hide_index=True)
                        else:
                            st.info(f"üí° '{validation_id_input}'Î°ú ÏãúÏûëÌïòÎäî Í≤ÄÏ¶ù ÏÑ∏ÏÖòÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
                    except Exception as e:
                        st.error(f"Ï°∞Ìöå Ï§ë Ïò§Î•ò: {str(e)}")
                    finally:
                        conn.close()
            else:
                # Ï†ÑÏ≤¥ ÏÑ∏ÏÖò Î™©Î°ù Ï°∞Ìöå (ÏµúÍ∑º 10Í∞ú)
                conn = get_db_connection()
                if conn is not None:
                    try:
                        cursor = conn.cursor()
                        cursor.execute('''
                            SELECT s.validation_id, s.created_at,
                                   (SELECT COUNT(DISTINCT grid_string_id) FROM confidence_skip_validation_grid_results 
                                    WHERE validation_id = s.validation_id) as grid_count,
                                   (SELECT COUNT(*) FROM confidence_skip_validation_steps 
                                    WHERE validation_id = s.validation_id) as step_count
                            FROM confidence_skip_validation_sessions s
                            ORDER BY s.created_at DESC
                            LIMIT 10
                        ''')
                        
                        all_sessions = cursor.fetchall()
                        
                        if len(all_sessions) > 0:
                            st.markdown("##### ÏµúÍ∑º Í≤ÄÏ¶ù ÏÑ∏ÏÖò Î™©Î°ù (ÏµúÍ∑º 10Í∞ú)")
                            session_info = []
                            for row in all_sessions:
                                session_info.append({
                                    'Validation ID': row[0][:12] + '...',
                                    'Ï†ÑÏ≤¥ ID': row[0],
                                    'ÏÉùÏÑ±Ïùº': row[1],
                                    'Grid String Ïàò': row[2],
                                    'Ï†ÄÏû•Îêú Ïä§ÌÖù Ïàò': row[3]
                                })
                            session_df = pd.DataFrame(session_info)
                            st.dataframe(session_df, use_container_width=True, hide_index=True)
                            
                            # Ïä§ÌÖùÏù¥ ÏóÜÎäî ÏÑ∏ÏÖò Í∞ïÏ°∞
                            no_steps_sessions = [s for s in all_sessions if s[3] == 0]
                            if len(no_steps_sessions) > 0:
                                st.warning(f"‚ö†Ô∏è {len(no_steps_sessions)}Í∞úÏùò ÏÑ∏ÏÖòÏóê Ï†ÄÏû•Îêú Ïä§ÌÖùÏù¥ ÏóÜÏäµÎãàÎã§.")
                        else:
                            st.info("üí° Ï†ÄÏû•Îêú Í≤ÄÏ¶ù ÏÑ∏ÏÖòÏù¥ ÏóÜÏäµÎãàÎã§.")
                    except Exception as e:
                        st.error(f"Ï°∞Ìöå Ï§ë Ïò§Î•ò: {str(e)}")
                    finally:
                        conn.close()
        
        # ÎπÑÍµê ÌÖåÏù¥Î∏î (ÌôîÎ©¥ Í∞ÄÏû• ÌïòÎã®Ïóê Ï∂îÍ∞Ä)
        if (batch_results_skip_1 is not None and len(batch_results_skip_1.get('results', [])) > 0 and
            batch_results_skip_2 is not None and len(batch_results_skip_2.get('results', [])) > 0):
            st.markdown("---")
            st.markdown("### üìä ÏûÑÍ≥ÑÍ∞í ÎπÑÍµê ÌÖåÏù¥Î∏î")
            
            summary_skip_1 = batch_results_skip_1.get('summary', {})
            summary_skip_2 = batch_results_skip_2.get('summary', {})
            
            # ÎπÑÍµê ÌÖåÏù¥Î∏î
            comparison_data = []
            comparison_data.append({
                'Ìï≠Î™©': 'Ïä§ÌÇµ Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í',
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_1:.1f}%': f"{skip_confidence_threshold_1:.1f}%",
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_2:.1f}%': f"{skip_confidence_threshold_2:.1f}%",
                'Ï∞®Ïù¥': f"{skip_confidence_threshold_2 - skip_confidence_threshold_1:+.1f}%"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÌèâÍ∑† Ï†ïÌôïÎèÑ (%)',
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_1}%': f"{summary_skip_1.get('avg_accuracy', 0):.2f}",
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_2}%': f"{summary_skip_2.get('avg_accuracy', 0):.2f}",
                'Ï∞®Ïù¥': f"{summary_skip_2.get('avg_accuracy', 0) - summary_skip_1.get('avg_accuracy', 0):+.2f}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®',
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_1}%': f"{summary_skip_1.get('max_consecutive_failures', 0)}",
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_2}%': f"{summary_skip_2.get('max_consecutive_failures', 0)}",
                'Ï∞®Ïù¥': f"{summary_skip_2.get('max_consecutive_failures', 0) - summary_skip_1.get('max_consecutive_failures', 0):+d}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÌèâÍ∑† ÏµúÎåÄ Ïó∞ÏÜç Ïã§Ìå®',
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_1}%': f"{summary_skip_1.get('avg_max_consecutive_failures', 0):.2f}",
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_2}%': f"{summary_skip_2.get('avg_max_consecutive_failures', 0):.2f}",
                'Ï∞®Ïù¥': f"{summary_skip_2.get('avg_max_consecutive_failures', 0) - summary_skip_1.get('avg_max_consecutive_failures', 0):+.2f}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'Ï¥ù Ïä§ÌÇµ ÌöüÏàò',
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_1}%': f"{summary_skip_1.get('total_skipped_predictions', 0)}",
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_2}%': f"{summary_skip_2.get('total_skipped_predictions', 0)}",
                'Ï∞®Ïù¥': f"{summary_skip_2.get('total_skipped_predictions', 0) - summary_skip_1.get('total_skipped_predictions', 0):+d}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÏòàÏ∏°Î•† (%)',
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_1}%': f"{summary_skip_1.get('prediction_rate', 0):.2f}",
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_2}%': f"{summary_skip_2.get('prediction_rate', 0):.2f}",
                'Ï∞®Ïù¥': f"{summary_skip_2.get('prediction_rate', 0) - summary_skip_1.get('prediction_rate', 0):+.2f}"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÌèâÍ∑† Ï≤´ ÏÑ±Í≥µ Ïä§ÌÖù',
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_1}%': f"{summary_skip_1.get('avg_first_success_step', 0):.2f}" if summary_skip_1.get('avg_first_success_step') is not None else "-",
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_2}%': f"{summary_skip_2.get('avg_first_success_step', 0):.2f}" if summary_skip_2.get('avg_first_success_step') is not None else "-",
                'Ï∞®Ïù¥': f"{(summary_skip_2.get('avg_first_success_step', 0) - summary_skip_1.get('avg_first_success_step', 0)):+.2f}" if (summary_skip_1.get('avg_first_success_step') is not None and summary_skip_2.get('avg_first_success_step') is not None) else "-"
            })
            comparison_data.append({
                'Ìï≠Î™©': 'ÏÑ±Í≥µÏù¥ ÏûàÏóàÎçò Grid String Ïàò',
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_1}%': f"{summary_skip_1.get('total_with_success', 0)}",
                f'ÏûÑÍ≥ÑÍ∞í {skip_confidence_threshold_2}%': f"{summary_skip_2.get('total_with_success', 0)}",
                'Ï∞®Ïù¥': f"{summary_skip_2.get('total_with_success', 0) - summary_skip_1.get('total_with_success', 0):+d}"
            })
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)
            
            # Í≤ÄÏ¶ù Í≤∞Í≥º Ï†ÄÏû• Î≤ÑÌäº
            st.markdown("---")
            col_save1, col_save2 = st.columns([1, 4])
            with col_save1:
                if st.button("üíæ Í≤ÄÏ¶ù Í≤∞Í≥º Ï†ÄÏû•", type="primary", use_container_width=True, key="save_confidence_skip_results"):
                    # Ï†ÄÏû• Ï†Ñ ÌûàÏä§ÌÜ†Î¶¨ ÌôïÏù∏
                    has_history_1 = False
                    has_history_2 = False
                    total_steps_count_1 = 0
                    total_steps_count_2 = 0
                    
                    if batch_results_skip_1 and 'results' in batch_results_skip_1:
                        for result in batch_results_skip_1['results']:
                            if 'history' in result and result['history']:
                                has_history_1 = True
                                total_steps_count_1 += len(result['history'])
                    
                    if batch_results_skip_2 and 'results' in batch_results_skip_2:
                        for result in batch_results_skip_2['results']:
                            if 'history' in result and result['history']:
                                has_history_2 = True
                                total_steps_count_2 += len(result['history'])
                    
                    if not has_history_1 or not has_history_2:
                        st.warning(f"‚ö†Ô∏è ÌûàÏä§ÌÜ†Î¶¨ Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏: ÏûÑÍ≥ÑÍ∞í1={has_history_1} ({total_steps_count_1}Í∞ú), ÏûÑÍ≥ÑÍ∞í2={has_history_2} ({total_steps_count_2}Í∞ú)")
                    
                    validation_id = save_confidence_skip_validation_results(
                        cutoff_id_skip,
                        skip_window_size,
                        skip_method,
                        skip_use_threshold,
                        skip_threshold_val if skip_use_threshold else None,
                        skip_max_interval,
                        skip_confidence_threshold_1,
                        skip_confidence_threshold_2,
                        batch_results_skip_1,
                        batch_results_skip_2,
                        grid_string_ids=batch_results_skip_1.get('grid_string_ids') if batch_results_skip_1 else None
                    )
                    
                    if validation_id:
                        st.session_state.confidence_skip_saved_validation_id = validation_id
                        
                        # Ï†ÄÏû• ÌõÑ Ïã§Ï†ú Ï†ÄÏû•Îêú Ïä§ÌÖù Ïàò ÌôïÏù∏
                        conn = get_db_connection()
                        if conn is not None:
                            try:
                                cursor = conn.cursor()
                                cursor.execute('''
                                    SELECT COUNT(*) as count 
                                    FROM confidence_skip_validation_steps 
                                    WHERE validation_id = ?
                                ''', (validation_id,))
                                saved_steps_count = cursor.fetchone()[0]
                                
                                st.success(f"‚úÖ Í≤ÄÏ¶ù Í≤∞Í≥ºÍ∞Ä Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§. (ID: {validation_id[:8]}..., Ï†ÄÏû•Îêú Ïä§ÌÖù: {saved_steps_count}Í∞ú)")
                            except:
                                st.success(f"‚úÖ Í≤ÄÏ¶ù Í≤∞Í≥ºÍ∞Ä Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§. (ID: {validation_id[:8]}...)")
                            finally:
                                conn.close()
                        else:
                            st.success(f"‚úÖ Í≤ÄÏ¶ù Í≤∞Í≥ºÍ∞Ä Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§. (ID: {validation_id[:8]}...)")
                    else:
                        st.warning("‚ö†Ô∏è Í≤ÄÏ¶ù Í≤∞Í≥º Ï†ÄÏû•Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.")
            
            with col_save2:
                if 'confidence_skip_saved_validation_id' in st.session_state:
                    saved_id = st.session_state.confidence_skip_saved_validation_id
                    
                    # Ï†ÄÏû•Îêú Ïä§ÌÖù Ïàò ÌôïÏù∏
                    conn = get_db_connection()
                    if conn is not None:
                        try:
                            cursor = conn.cursor()
                            cursor.execute('''
                                SELECT 
                                    COUNT(*) as total_steps,
                                    COUNT(DISTINCT grid_string_id) as grid_strings
                                FROM confidence_skip_validation_steps 
                                WHERE validation_id = ?
                            ''', (saved_id,))
                            row = cursor.fetchone()
                            total_steps = row[0] if row else 0
                            grid_strings = row[1] if row else 0
                            
                            st.info(f"üíæ ÎßàÏßÄÎßâ Ï†ÄÏû• ID: {saved_id[:8]}... | Ï†ÄÏû•Îêú Ïä§ÌÖù: {total_steps}Í∞ú | Grid String: {grid_strings}Í∞ú")
                        except:
                            st.info(f"üíæ ÎßàÏßÄÎßâ Ï†ÄÏû• ID: {saved_id[:8]}...")
                        finally:
                            conn.close()
                    else:
                        st.info(f"üíæ ÎßàÏßÄÎßâ Ï†ÄÏû• ID: {saved_id[:8]}...")
    
    # ÎùºÏù¥Î∏å Í≤åÏûÑ ÏÑπÏÖò (ÌôîÎ©¥ÏóêÏÑú Ïà®ÍπÄ Ï≤òÎ¶¨)
    # ============================================
    # ÏïÑÎûò ÎùºÏù¥Î∏å Í≤åÏûÑ ÏÑπÏÖòÏùÄ if FalseÎ°ú Ïà®ÍπÄ Ï≤òÎ¶¨ÎêòÏñ¥ ÌôîÎ©¥Ïóê ÌëúÏãúÎêòÏßÄ ÏïäÏäµÎãàÎã§.
    # ÌïÑÏöîÏãú ÏïÑÎûò Ï°∞Í±¥Î¨∏Ïùò FalseÎ•º TrueÎ°ú Î≥ÄÍ≤ΩÌïòÏó¨ ÌôúÏÑ±ÌôîÌï† Ïàò ÏûàÏäµÎãàÎã§.
    # ============================================
    if False:  # ÎùºÏù¥Î∏å Í≤åÏûÑ ÏÑπÏÖò Ïà®ÍπÄ Ï≤òÎ¶¨
        st.markdown("---")
        st.header("üéÆ Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ Ï†ÑÎûµ ÎùºÏù¥Î∏å Í≤åÏûÑ")
        st.markdown("**Ïä§ÌÖùÎ≥ÑÎ°ú ÏòàÏ∏°Í∞íÏùÑ ÌôïÏù∏ÌïòÍ≥† Ïã§Ï†úÍ∞íÏùÑ ÏûÖÎ†•ÌïòÏó¨ Í≤ÄÏ¶ùÌïòÎäî ÎùºÏù¥Î∏å Í≤åÏûÑ**")
        
        # Í≤åÏûÑ ÏÑ§Ï†ï Ï¥àÍ∏∞Ìôî
        if 'live_game_settings' not in st.session_state:
            st.session_state.live_game_settings = None
        
        # Í≤åÏûÑ ÏÑ§Ï†ï
        with st.expander("‚öôÔ∏è Í≤åÏûÑ ÏÑ§Ï†ï", expanded=True):
            st.markdown("### ÏÑ§Ï†ïÍ∞í")
            
            col_game1, col_game2 = st.columns(2)
        
        with col_game1:
            live_window_size = st.selectbox(
                "ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞",
                options=[5, 6, 7, 8, 9],
                index=0,
                key="live_game_window_size"
            )
            
            live_method = st.selectbox(
                "ÏòàÏ∏° Î∞©Î≤ï",
                options=["ÎπàÎèÑ Í∏∞Î∞ò", "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò", "ÏïàÏ†Ñ Ïö∞ÏÑ†"],
                index=0,
                key="live_game_method"
            )
        
        with col_game2:
            live_use_threshold = st.checkbox(
                "ÏûÑÍ≥ÑÍ∞í Ï†ÑÎûµ ÏÇ¨Ïö©",
                value=True,
                key="live_game_use_threshold"
            )
            
            live_threshold = st.number_input(
                "ÏûÑÍ≥ÑÍ∞í (%)",
                min_value=0,
                max_value=100,
                value=56,
                step=1,
                key="live_game_threshold",
                disabled=not live_use_threshold
            )
            
            live_max_interval = st.number_input(
                "ÏµúÎåÄ Í∞ÑÍ≤©",
                min_value=1,
                max_value=20,
                value=5,
                step=1,
                key="live_game_max_interval"
            )
            
            live_confidence_skip_threshold = st.number_input(
                "Ïã†Î¢∞ÎèÑ Ïä§ÌÇµ ÏûÑÍ≥ÑÍ∞í (%)",
                min_value=0,
                max_value=100,
                value=51,
                step=1,
                key="live_game_confidence_skip_threshold"
            )
        
        # ÏÑ§Ï†ï Ï†ÄÏû• Î≤ÑÌäº
        col_save1, col_save2 = st.columns([1, 4])
        with col_save1:
                if st.button("üíæ ÏÑ§Ï†ï Ï†ÄÏû•", type="primary", use_container_width=True):
                    st.session_state.live_game_settings = {
                        'window_size': live_window_size,
                        'method': live_method,
                        'use_threshold': live_use_threshold,
                        'threshold': live_threshold,
                        'max_interval': live_max_interval,
                        'confidence_skip_threshold': live_confidence_skip_threshold
                    }
                    # st.success Ï†úÍ±∞ (ÏÑ±Îä• Í∞úÏÑ†)
                    st.rerun()
        
        with col_save2:
            pass  # Î©îÏãúÏßÄ Ï†úÍ±∞
        
        # Grid String ÏûÖÎ†• ÏÑπÏÖò
        st.markdown("---")
        st.markdown("### Grid String ÏûÖÎ†•")
        live_grid_string = st.text_area(
        "Grid String",
        value="",
        height=80,
        key="live_game_grid_string",
            help="ÎùºÏù¥Î∏å Í≤åÏûÑÏóêÏÑú ÏÇ¨Ïö©Ìï† grid_stringÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî. Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Îäî Î™®Îëê ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Î°ú ÏÇ¨Ïö©Îê©ÎãàÎã§.",
            disabled=st.session_state.live_game_settings is None
        )
        
        if st.session_state.live_game_settings is None:
            st.warning("‚ö†Ô∏è Î®ºÏ†Ä Í≤åÏûÑ ÏÑ§Ï†ïÏùÑ Ï†ÄÏû•Ìï¥Ï£ºÏÑ∏Ïöî.")
        
        # Í≤åÏûÑ Ï¥àÍ∏∞Ìôî
        if 'live_game_state' not in st.session_state:
            st.session_state.live_game_state = None
        
        # Í≤åÏûÑ ÏãúÏûë/Ïû¨ÏãúÏûë Î≤ÑÌäº
        col_start1, col_start2 = st.columns([1, 4])
        with col_start1:
            # ÏÑ§Ï†ïÏù¥ Ï†ÄÏû•ÎêòÏñ¥ ÏûàÍ≥† grid stringÏù¥ ÏûÖÎ†•ÎêòÏñ¥ ÏûàÎäîÏßÄ ÌôïÏù∏ (ÏµúÏ†ÅÌôî: Îã®Ïàú Ï≤¥ÌÅ¨Îßå)
            settings_saved = st.session_state.live_game_settings is not None
            grid_string_entered = bool(live_grid_string and live_grid_string.strip())
            
            if st.button("üéÆ Í≤åÏûÑ ÏãúÏûë", type="primary", use_container_width=True, disabled=not settings_saved or not grid_string_entered):
                if not settings_saved:
                    st.error("Í≤åÏûÑ ÏÑ§Ï†ïÏùÑ Î®ºÏ†Ä Ï†ÄÏû•Ìï¥Ï£ºÏÑ∏Ïöî.")
                elif not grid_string_entered:
                    st.error("Grid StringÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
                else:
                    grid_string = live_grid_string.strip()
                    settings = st.session_state.live_game_settings
                    
                    if len(grid_string) < settings['window_size']:
                        st.error(f"Grid StringÏù¥ ÎÑàÎ¨¥ ÏßßÏäµÎãàÎã§. (Í∏∏Ïù¥: {len(grid_string)}, ÏµúÏÜå ÌïÑÏöî: {settings['window_size']})")
                    else:
                        # Í≤åÏûÑ Ï¥àÍ∏∞Ìôî
                        conn = get_db_connection()
                        if conn is None:
                            st.error("Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Ïã§Ìå®")
                        else:
                            try:
                                # Î™®Îì† Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Î•º ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Î°ú ÏÇ¨Ïö© (Ï∫êÏã± ÌôïÏù∏)
                                model_cache_key = f"live_game_model_{settings['window_size']}_{settings['method']}"
                                
                                if model_cache_key in st.session_state:
                                    # Ï∫êÏãúÎêú Î™®Îç∏ Ïû¨ÏÇ¨Ïö©
                                    model = st.session_state[model_cache_key]
                                else:
                                    # Î™®Îç∏ Íµ¨Ï∂ï
                                    train_ids_query = "SELECT id FROM preprocessed_grid_strings ORDER BY id"
                                    train_ids_df = pd.read_sql_query(train_ids_query, conn)
                                    train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
                                    
                                    # N-gram Î°úÎìú
                                    train_ngrams = load_ngram_chunks(window_size=settings['window_size'], grid_string_ids=train_ids)
                                    
                                    if len(train_ngrams) == 0:
                                        st.warning("‚ö†Ô∏è ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§. Îπà Î™®Îç∏Î°ú ÏãúÏûëÌï©ÎãàÎã§.")
                                        train_ngrams = []
                                    
                                    # Î™®Îç∏ Íµ¨Ï∂ï
                                    if settings['method'] == "ÎπàÎèÑ Í∏∞Î∞ò":
                                        model = build_frequency_model(train_ngrams)
                                    elif settings['method'] == "Í∞ÄÏ§ëÏπò Í∏∞Î∞ò":
                                        model = build_weighted_model(train_ngrams)
                                    else:
                                        model = build_frequency_model(train_ngrams)
                                    
                                    # Î™®Îç∏ Ï∫êÏã±
                                    st.session_state[model_cache_key] = model
                                
                                # Í≤åÏûÑ ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî
                                prefix_length = settings['window_size'] - 1
                                initial_prefix = grid_string[:prefix_length]
                                
                                # ÏûÖÎ†•Îêú grid_string Í∏∏Ïù¥ÎßåÌÅº ÏûêÎèô Ïã§Ìñâ
                                history = []
                                consecutive_failures = 0
                                max_consecutive_failures = 0
                                total_predictions = 0
                                total_failures = 0
                                total_forced_predictions = 0
                                total_skipped_predictions = 0
                                current_interval = 0
                                current_index = prefix_length
                                current_prefix = initial_prefix
                                current_step = 0
                                
                                # grid_stringÏùò ÎßàÏßÄÎßâÍπåÏßÄ ÏûêÎèô Ïã§Ìñâ
                                while current_index < len(grid_string):
                                        # ÏòàÏ∏° ÏàòÌñâ
                                        if settings['use_threshold']:
                                            prediction_result = predict_with_fallback_interval(
                                                model,
                                                current_prefix,
                                                method=settings['method'],
                                                threshold=settings['threshold'],
                                                max_interval=settings['max_interval'],
                                                current_interval=current_interval
                                            )
                                        else:
                                            prediction_result = predict_for_prefix(model, current_prefix, settings['method'])
                                            if 'is_forced' not in prediction_result:
                                                prediction_result['is_forced'] = False
                                        
                                        predicted_value = prediction_result.get('predicted')
                                        confidence = prediction_result.get('confidence', 0.0)
                                        is_forced = prediction_result.get('is_forced', False)
                                        has_prediction = predicted_value is not None
                                        
                                        # Ïä§ÌÇµ Í∑úÏπô Ï≤¥ÌÅ¨
                                        should_skip = False
                                        if settings['use_threshold'] and has_prediction and is_forced and confidence < settings['confidence_skip_threshold']:
                                            should_skip = True
                                            total_skipped_predictions += 1
                                        
                                        # Ïã§Ï†úÍ∞í Í∞ÄÏ†∏Ïò§Í∏∞ (grid_stringÏóêÏÑú)
                                        actual_value = grid_string[current_index]
                                        
                                        # Í≤ÄÏ¶ù ÏàòÌñâ (ÏòàÏ∏°Í∞íÏù¥ ÏûàÍ≥† Ïä§ÌÇµÌïòÏßÄ ÏïäÎäî Í≤ΩÏö∞)
                                        if has_prediction and not should_skip:
                                            is_correct = predicted_value == actual_value
                                            
                                            if not is_correct:
                                                consecutive_failures += 1
                                                total_failures += 1
                                                if consecutive_failures > max_consecutive_failures:
                                                    max_consecutive_failures = consecutive_failures
                                            else:
                                                consecutive_failures = 0
                                            
                                            total_predictions += 1
                                            if is_forced:
                                                total_forced_predictions += 1
                                            
                                            # Í∞ÑÍ≤© Î¶¨ÏÖã
                                            current_interval = 0
                                            
                                            # ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù
                                            history.append({
                                                'step': current_step + 1,
                                                'prefix': current_prefix,
                                                'predicted': predicted_value,
                                                'actual': actual_value,
                                                'is_correct': is_correct,
                                                'confidence': confidence,
                                                'is_forced': is_forced,
                                                'current_interval': 0,
                                                'has_prediction': True,
                                                'validated': True,
                                                'skipped': False
                                            })
                                        elif has_prediction and should_skip:
                                            # Ïä§ÌÇµÎêú Í≤ΩÏö∞ ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù
                                            history.append({
                                                'step': current_step + 1,
                                                'prefix': current_prefix,
                                                'predicted': predicted_value,
                                                'actual': actual_value,
                                                'is_correct': None,
                                                'confidence': confidence,
                                                'is_forced': is_forced,
                                                'current_interval': current_interval,
                                                'has_prediction': True,
                                                'validated': False,
                                                'skipped': True
                                            })
                                            # Ïä§ÌÇµ ÏÉÅÌÉúÏóêÏÑú Í∞ÑÍ≤© Í≥ÑÏÇ∞ÏùÄ Î©àÏ∂§ (Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÏùå)
                                        else:
                                            # ÏòàÏ∏°Í∞íÏù¥ ÏóÜÎäî Í≤ΩÏö∞ ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù (Ï†ÑÏ≤¥ Ïä§ÌÖù ÌëúÏãúÎ•º ÏúÑÌï¥)
                                            history.append({
                                                'step': current_step + 1,
                                                'prefix': current_prefix,
                                                'predicted': None,
                                                'actual': actual_value,
                                                'is_correct': None,
                                                'confidence': 0.0,
                                                'is_forced': False,
                                                'current_interval': current_interval,
                                                'has_prediction': False,
                                                'validated': False,
                                                'skipped': False
                                            })
                                            # ÏòàÏ∏°Í∞íÏù¥ ÏóÜÎäî Í≤ΩÏö∞ Í∞ÑÍ≤© Ï¶ùÍ∞Ä
                                            if settings['use_threshold']:
                                                current_interval += 1
                                        
                                        # Îã§Ïùå Ïä§ÌÖùÏúºÎ°ú ÏßÑÌñâ
                                        current_step += 1
                                        current_index += 1
                                        
                                        # prefix ÏóÖÎç∞Ïù¥Ìä∏ (Ïù∏ÌÑ∞ÎûôÌã∞Î∏å Î™®Îìú Ï†ÑÌôòÏùÑ ÏúÑÌï¥ Ìï≠ÏÉÅ ÏóÖÎç∞Ïù¥Ìä∏)
                                        current_prefix = get_next_prefix(
                                            current_prefix,
                                            actual_value,
                                            settings['window_size']
                                        )
                                
                                # Í≤åÏûÑ ÏÉÅÌÉú Ï†ÄÏû• (Îã§Ïùå Ïä§ÌÖùÎ∂ÄÌÑ∞ Ïù∏ÌÑ∞ÎûôÌã∞Î∏åÎ°ú ÏßÑÌñâ)
                                st.session_state.live_game_state = {
                                    'grid_string': grid_string,
                                    'model': model,
                                    'current_step': current_step,
                                    'current_index': current_index,
                                    'current_prefix': current_prefix,
                                    'current_interval': current_interval,
                                    'history': history,
                                    'consecutive_failures': consecutive_failures,
                                    'max_consecutive_failures': max_consecutive_failures,
                                    'total_predictions': total_predictions,
                                    'total_failures': total_failures,
                                    'total_forced_predictions': total_forced_predictions,
                                    'total_skipped_predictions': total_skipped_predictions,
                                    'window_size': settings['window_size'],
                                    'method': settings['method'],
                                    'use_threshold': settings['use_threshold'],
                                    'threshold': settings['threshold'],
                                    'max_interval': settings['max_interval'],
                                    'confidence_skip_threshold': settings['confidence_skip_threshold'],
                                    'auto_executed': True  # ÏûêÎèô Ïã§Ìñâ ÏôÑÎ£å ÌîåÎûòÍ∑∏
                                }
                                
                                # st.success Ï†úÍ±∞ (ÏÑ±Îä• Í∞úÏÑ†)
                                st.rerun()
                            except Exception as e:
                                st.error(f"Í≤åÏûÑ Ï¥àÍ∏∞Ìôî Ï§ë Ïò§Î•ò: {str(e)}")
                                import traceback
                                st.error(f"ÏÉÅÏÑ∏ Ïò§Î•ò: {traceback.format_exc()}")
                            finally:
                                conn.close()
        
        with col_start2:
            if st.session_state.live_game_state is not None:
                if st.button("üîÑ Í≤åÏûÑ Ïû¨ÏãúÏûë", use_container_width=True):
                    st.session_state.live_game_state = None
                    st.rerun()
        
            # Í≤åÏûÑ ÏßÑÌñâ (Í≤åÏûÑ ÏÉÅÌÉúÍ∞Ä ÏûàÏùÑ ÎïåÎßå Ìï®Ïàò Ìò∏Ï∂ú - ÏÑ±Îä• Í∞úÏÑ†)
            if st.session_state.live_game_state is not None:
                render_live_game_play(st.session_state.live_game_state)

if __name__ == "__main__":
    main()

