"""
ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ ì•±
ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìë™ìœ¼ë¡œ ê²€ì¦í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import streamlit as st

# í˜ì´ì§€ ì„¤ì • (ëª¨ë“  import ì „ì— ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
st.set_page_config(
    page_title="Interactive Multi-Step Validation",
    page_icon="ğŸŒ³",
    layout="wide"
)

import pandas as pd
import sqlite3
import uuid
from collections import defaultdict
from datetime import datetime

# ê¸°ì¡´ ì•±ì˜ í•¨ìˆ˜ë“¤ import
# ì£¼ì˜: hypothesis_validation_app.pyë„ set_page_config()ë¥¼ í˜¸ì¶œí•˜ì§€ë§Œ,
# ì´ë¯¸ ìœ„ì—ì„œ í˜¸ì¶œí–ˆìœ¼ë¯€ë¡œ ë¬´ì‹œë©ë‹ˆë‹¤.
from hypothesis_validation_app import (
    get_db_connection,
    load_preprocessed_data,
    load_ngram_chunks,
    build_frequency_model,
    build_weighted_model,
    predict_for_prefix,
    predict_with_fallback_interval,
    get_next_prefix
)

# DB ê²½ë¡œ
DB_PATH = 'hypothesis_validation.db'

def create_validation_tables():
    """ê²€ì¦ ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ìƒì„±"""
    conn = get_db_connection()
    if conn is None:
        return False
    
    cursor = conn.cursor()
    
    try:
        # 1. ê²€ì¦ ì„¸ì…˜ ë©”íƒ€ë°ì´í„° í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS interactive_validation_sessions (
                session_id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL UNIQUE,
                cutoff_grid_string_id INTEGER NOT NULL,
                window_size INTEGER NOT NULL,
                method TEXT NOT NULL,
                use_threshold BOOLEAN NOT NULL,
                threshold REAL,
                max_interval INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
            )
        ''')
        
        # 2. ì „ëµë³„ ìš”ì•½ í†µê³„ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS interactive_validation_summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                strategy_type TEXT NOT NULL,
                total_grid_strings INTEGER NOT NULL,
                avg_accuracy REAL NOT NULL,
                max_consecutive_failures INTEGER NOT NULL,
                avg_max_consecutive_failures REAL NOT NULL,
                prediction_rate REAL NOT NULL,
                forced_prediction_rate REAL NOT NULL,
                forced_success_rate REAL NOT NULL,
                total_steps INTEGER NOT NULL,
                total_failures INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                total_forced_predictions INTEGER NOT NULL,
                total_forced_successes INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES interactive_validation_sessions(validation_id),
                UNIQUE(validation_id, strategy_type)
            )
        ''')
        
        # 3. Grid Stringë³„ ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS interactive_validation_grid_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                strategy_type TEXT NOT NULL,
                grid_string_id INTEGER NOT NULL,
                max_consecutive_failures INTEGER NOT NULL,
                total_steps INTEGER NOT NULL,
                total_failures INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                accuracy REAL NOT NULL,
                forced_prediction_rate REAL NOT NULL,
                forced_success_rate REAL NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES interactive_validation_sessions(validation_id),
                FOREIGN KEY (grid_string_id) REFERENCES preprocessed_grid_strings(id),
                UNIQUE(validation_id, strategy_type, grid_string_id)
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_sessions_created_at 
            ON interactive_validation_sessions(created_at)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_sessions_cutoff 
            ON interactive_validation_sessions(cutoff_grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_sessions_settings 
            ON interactive_validation_sessions(window_size, method, use_threshold)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_summaries_validation_id 
            ON interactive_validation_summaries(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_summaries_strategy 
            ON interactive_validation_summaries(strategy_type)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_summaries_max_failures 
            ON interactive_validation_summaries(max_consecutive_failures)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_summaries_accuracy 
            ON interactive_validation_summaries(avg_accuracy)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_validation_id 
            ON interactive_validation_grid_results(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_strategy 
            ON interactive_validation_grid_results(strategy_type)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_grid_string_id 
            ON interactive_validation_grid_results(grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_max_failures 
            ON interactive_validation_grid_results(max_consecutive_failures)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_grid_results_accuracy 
            ON interactive_validation_grid_results(accuracy)
        ''')
        
        # 4. ì‹ ë¢°ë„ êµ¬ê°„ë³„ í†µê³„ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS confidence_statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT,
                strategy_type TEXT,
                confidence_range TEXT NOT NULL,
                total_predictions INTEGER NOT NULL,
                matches INTEGER NOT NULL,
                mismatches INTEGER NOT NULL,
                match_rate REAL NOT NULL,
                avg_confidence REAL NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                UNIQUE(validation_id, strategy_type, confidence_range)
            )
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_statistics_validation_id 
            ON confidence_statistics(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_statistics_strategy 
            ON confidence_statistics(strategy_type)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_statistics_range 
            ON confidence_statistics(confidence_range)
        ''')
        
        # 5. ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê²€ì¦ ì„¸ì…˜ í…Œì´ë¸” (2ê°œ ì„ê³„ê°’ ë¹„êµìš©)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS confidence_skip_validation_sessions (
                session_id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL UNIQUE,
                cutoff_grid_string_id INTEGER NOT NULL,
                window_size INTEGER NOT NULL,
                method TEXT NOT NULL,
                use_threshold BOOLEAN NOT NULL,
                threshold REAL,
                max_interval INTEGER NOT NULL,
                confidence_skip_threshold_1 REAL NOT NULL,
                confidence_skip_threshold_2 REAL NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
            )
        ''')
        
        # 6. ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ìš”ì•½ í†µê³„ í…Œì´ë¸” (ì„ê³„ê°’ë³„)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS confidence_skip_validation_summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                confidence_skip_threshold REAL NOT NULL,
                total_grid_strings INTEGER NOT NULL,
                avg_accuracy REAL NOT NULL,
                max_consecutive_failures INTEGER NOT NULL,
                avg_max_consecutive_failures REAL NOT NULL,
                prediction_rate REAL NOT NULL,
                forced_prediction_rate REAL NOT NULL,
                forced_success_rate REAL NOT NULL,
                total_steps INTEGER NOT NULL,
                total_failures INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                total_forced_predictions INTEGER NOT NULL,
                total_forced_successes INTEGER NOT NULL,
                total_skipped_predictions INTEGER NOT NULL,
                avg_first_success_step REAL,
                min_first_success_step INTEGER,
                max_first_success_step INTEGER,
                total_with_success INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES confidence_skip_validation_sessions(validation_id),
                UNIQUE(validation_id, confidence_skip_threshold)
            )
        ''')
        
        # 7. ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ Grid Stringë³„ ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS confidence_skip_validation_grid_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                confidence_skip_threshold REAL NOT NULL,
                grid_string_id INTEGER NOT NULL,
                max_consecutive_failures INTEGER NOT NULL,
                total_steps INTEGER NOT NULL,
                total_failures INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                total_skipped_predictions INTEGER NOT NULL,
                accuracy REAL NOT NULL,
                forced_prediction_rate REAL NOT NULL,
                forced_success_rate REAL NOT NULL,
                first_success_step INTEGER,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES confidence_skip_validation_sessions(validation_id),
                FOREIGN KEY (grid_string_id) REFERENCES preprocessed_grid_strings(id),
                UNIQUE(validation_id, confidence_skip_threshold, grid_string_id)
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_sessions_created_at 
            ON confidence_skip_validation_sessions(created_at)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_sessions_cutoff 
            ON confidence_skip_validation_sessions(cutoff_grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_summaries_validation_id 
            ON confidence_skip_validation_summaries(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_summaries_threshold 
            ON confidence_skip_validation_summaries(confidence_skip_threshold)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_grid_results_validation_id 
            ON confidence_skip_validation_grid_results(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_grid_results_threshold 
            ON confidence_skip_validation_grid_results(confidence_skip_threshold)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_grid_results_grid_string_id 
            ON confidence_skip_validation_grid_results(grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_confidence_skip_grid_results_first_success 
            ON confidence_skip_validation_grid_results(first_success_step)
        ''')
        
        conn.commit()
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False
    finally:
        conn.close()

def collect_confidence_statistics(history, validation_id=None, strategy_type=None):
    """
    íˆìŠ¤í† ë¦¬ì—ì„œ ì‹ ë¢°ë„ êµ¬ê°„ë³„ í†µê³„ ìˆ˜ì§‘ (50-60% êµ¬ê°„, 1% ê°„ê²©)
    
    Args:
        history: ê²€ì¦ íˆìŠ¤í† ë¦¬ ë¦¬ìŠ¤íŠ¸
        validation_id: ê²€ì¦ ID (ì„ íƒì )
        strategy_type: ì „ëµ íƒ€ì… (ì„ íƒì )
    
    Returns:
        dict: ì‹ ë¢°ë„ êµ¬ê°„ë³„ í†µê³„
    """
    # ì‹ ë¢°ë„ êµ¬ê°„ë³„ í†µê³„ ì´ˆê¸°í™” (50-60%, 1% ê°„ê²©)
    confidence_ranges = {}
    for i in range(50, 61):  # 50, 51, 52, ..., 60
        range_key = f"{i}-{i+1}" if i < 60 else "60+"
        confidence_ranges[range_key] = {
            'total_predictions': 0,
            'matches': 0,
            'mismatches': 0,
            'confidence_sum': 0.0
        }
    
    # íˆìŠ¤í† ë¦¬ì—ì„œ í†µê³„ ìˆ˜ì§‘
    for entry in history:
        has_prediction = entry.get('has_prediction', False)
        is_correct = entry.get('is_correct')
        confidence = entry.get('confidence', 0.0)
        validated = entry.get('validated', False)
        
        # ì˜ˆì¸¡ê°’ì´ ìˆê³  ê²€ì¦ëœ ê²½ìš°ë§Œ í†µê³„ì— í¬í•¨
        if has_prediction and validated and is_correct is not None:
            # ì‹ ë¢°ë„ êµ¬ê°„ ê²°ì •
            conf_int = int(confidence)
            if conf_int < 50:
                continue  # 50% ë¯¸ë§Œì€ ì œì™¸
            elif conf_int >= 60:
                range_key = "60+"
            else:
                range_key = f"{conf_int}-{conf_int+1}"
            
            if range_key in confidence_ranges:
                confidence_ranges[range_key]['total_predictions'] += 1
                confidence_ranges[range_key]['confidence_sum'] += confidence
                
                if is_correct:
                    confidence_ranges[range_key]['matches'] += 1
                else:
                    confidence_ranges[range_key]['mismatches'] += 1
    
    # í†µê³„ ê³„ì‚° ë° ì •ë¦¬
    statistics = []
    for range_key, stats in confidence_ranges.items():
        if stats['total_predictions'] > 0:
            match_rate = (stats['matches'] / stats['total_predictions']) * 100
            avg_confidence = stats['confidence_sum'] / stats['total_predictions']
            
            statistics.append({
                'confidence_range': range_key,
                'total_predictions': stats['total_predictions'],
                'matches': stats['matches'],
                'mismatches': stats['mismatches'],
                'match_rate': match_rate,
                'avg_confidence': avg_confidence
            })
    
    return statistics

def save_confidence_statistics(statistics, validation_id=None, strategy_type=None):
    """
    ì‹ ë¢°ë„ í†µê³„ë¥¼ DBì— ì €ì¥
    
    Args:
        statistics: collect_confidence_statistics()ì˜ ë°˜í™˜ê°’
        validation_id: ê²€ì¦ ID (ì„ íƒì )
        strategy_type: ì „ëµ íƒ€ì… (ì„ íƒì )
    """
    conn = get_db_connection()
    if conn is None:
        return False
    
    cursor = conn.cursor()
    
    try:
        for stat in statistics:
            cursor.execute('''
                INSERT OR REPLACE INTO confidence_statistics (
                    validation_id, strategy_type, confidence_range,
                    total_predictions, matches, mismatches,
                    match_rate, avg_confidence, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                strategy_type,
                stat['confidence_range'],
                stat['total_predictions'],
                stat['matches'],
                stat['mismatches'],
                stat['match_rate'],
                stat['avg_confidence']
            ))
        
        conn.commit()
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"ì‹ ë¢°ë„ í†µê³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False
    finally:
        conn.close()

def save_confidence_skip_validation_results(
    cutoff_grid_string_id,
    window_size,
    method,
    use_threshold,
    threshold,
    max_interval,
    confidence_skip_threshold_1,
    confidence_skip_threshold_2,
    batch_results_1,
    batch_results_2
):
    """
    ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê²€ì¦ ê²°ê³¼ë¥¼ DBì— ì €ì¥ (2ê°œ ì„ê³„ê°’ ë¹„êµ)
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        threshold: ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
        confidence_skip_threshold_1: ì²« ë²ˆì§¸ ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’
        confidence_skip_threshold_2: ë‘ ë²ˆì§¸ ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’
        batch_results_1: ì²« ë²ˆì§¸ ì„ê³„ê°’ ê²€ì¦ ê²°ê³¼
        batch_results_2: ë‘ ë²ˆì§¸ ì„ê³„ê°’ ê²€ì¦ ê²°ê³¼
    
    Returns:
        str: validation_id (ì €ì¥ ì„±ê³µ ì‹œ), None (ì‹¤íŒ¨ ì‹œ)
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    cursor = conn.cursor()
    
    try:
        # validation_id ìƒì„± (UUID)
        validation_id = str(uuid.uuid4())
        
        # 1. ê²€ì¦ ì„¸ì…˜ ì €ì¥
        cursor.execute('''
            INSERT INTO confidence_skip_validation_sessions (
                validation_id, cutoff_grid_string_id, window_size, method,
                use_threshold, threshold, max_interval,
                confidence_skip_threshold_1, confidence_skip_threshold_2,
                created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
        ''', (
            validation_id,
            cutoff_grid_string_id,
            window_size,
            method,
            use_threshold,
            threshold if use_threshold else None,
            max_interval,
            confidence_skip_threshold_1,
            confidence_skip_threshold_2
        ))
        
        # 2. ì²« ë²ˆì§¸ ì„ê³„ê°’ ìš”ì•½ í†µê³„ ì €ì¥
        if batch_results_1 and 'summary' in batch_results_1:
            summary_1 = batch_results_1['summary']
            cursor.execute('''
                INSERT INTO confidence_skip_validation_summaries (
                    validation_id, confidence_skip_threshold,
                    total_grid_strings, avg_accuracy, max_consecutive_failures,
                    avg_max_consecutive_failures, prediction_rate,
                    forced_prediction_rate, forced_success_rate,
                    total_steps, total_failures, total_predictions,
                    total_forced_predictions, total_forced_successes,
                    total_skipped_predictions,
                    avg_first_success_step, min_first_success_step, max_first_success_step,
                    total_with_success, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                confidence_skip_threshold_1,
                summary_1.get('total_grid_strings', 0),
                summary_1.get('avg_accuracy', 0.0),
                summary_1.get('max_consecutive_failures', 0),
                summary_1.get('avg_max_consecutive_failures', 0.0),
                summary_1.get('prediction_rate', 0.0),
                summary_1.get('forced_prediction_rate', 0.0),
                summary_1.get('forced_success_rate', 0.0),
                summary_1.get('total_steps', 0),
                summary_1.get('total_failures', 0),
                summary_1.get('total_predictions', 0),
                summary_1.get('total_forced_predictions', 0),
                summary_1.get('total_forced_successes', 0),
                summary_1.get('total_skipped_predictions', 0),
                summary_1.get('avg_first_success_step'),
                summary_1.get('min_first_success_step'),
                summary_1.get('max_first_success_step'),
                summary_1.get('total_with_success', 0)
            ))
            
            # Grid Stringë³„ ê²°ê³¼ ì €ì¥ (ì²« ë²ˆì§¸ ì„ê³„ê°’)
            if 'results' in batch_results_1:
                for result in batch_results_1['results']:
                    cursor.execute('''
                        INSERT OR REPLACE INTO confidence_skip_validation_grid_results (
                            validation_id, confidence_skip_threshold, grid_string_id,
                            max_consecutive_failures, total_steps, total_failures,
                            total_predictions, total_skipped_predictions,
                            accuracy, forced_prediction_rate, forced_success_rate,
                            first_success_step, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                    ''', (
                        validation_id,
                        confidence_skip_threshold_1,
                        result.get('grid_string_id'),
                        result.get('max_consecutive_failures', 0),
                        result.get('total_steps', 0),
                        result.get('total_failures', 0),
                        result.get('total_predictions', 0),
                        result.get('total_skipped_predictions', 0),
                        result.get('accuracy', 0.0),
                        result.get('forced_prediction_rate', 0.0),
                        result.get('forced_success_rate', 0.0),
                        result.get('first_success_step')
                    ))
        
        # 3. ë‘ ë²ˆì§¸ ì„ê³„ê°’ ìš”ì•½ í†µê³„ ì €ì¥
        if batch_results_2 and 'summary' in batch_results_2:
            summary_2 = batch_results_2['summary']
            cursor.execute('''
                INSERT INTO confidence_skip_validation_summaries (
                    validation_id, confidence_skip_threshold,
                    total_grid_strings, avg_accuracy, max_consecutive_failures,
                    avg_max_consecutive_failures, prediction_rate,
                    forced_prediction_rate, forced_success_rate,
                    total_steps, total_failures, total_predictions,
                    total_forced_predictions, total_forced_successes,
                    total_skipped_predictions,
                    avg_first_success_step, min_first_success_step, max_first_success_step,
                    total_with_success, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                confidence_skip_threshold_2,
                summary_2.get('total_grid_strings', 0),
                summary_2.get('avg_accuracy', 0.0),
                summary_2.get('max_consecutive_failures', 0),
                summary_2.get('avg_max_consecutive_failures', 0.0),
                summary_2.get('prediction_rate', 0.0),
                summary_2.get('forced_prediction_rate', 0.0),
                summary_2.get('forced_success_rate', 0.0),
                summary_2.get('total_steps', 0),
                summary_2.get('total_failures', 0),
                summary_2.get('total_predictions', 0),
                summary_2.get('total_forced_predictions', 0),
                summary_2.get('total_forced_successes', 0),
                summary_2.get('total_skipped_predictions', 0),
                summary_2.get('avg_first_success_step'),
                summary_2.get('min_first_success_step'),
                summary_2.get('max_first_success_step'),
                summary_2.get('total_with_success', 0)
            ))
            
            # Grid Stringë³„ ê²°ê³¼ ì €ì¥ (ë‘ ë²ˆì§¸ ì„ê³„ê°’)
            if 'results' in batch_results_2:
                for result in batch_results_2['results']:
                    cursor.execute('''
                        INSERT OR REPLACE INTO confidence_skip_validation_grid_results (
                            validation_id, confidence_skip_threshold, grid_string_id,
                            max_consecutive_failures, total_steps, total_failures,
                            total_predictions, total_skipped_predictions,
                            accuracy, forced_prediction_rate, forced_success_rate,
                            first_success_step, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                    ''', (
                        validation_id,
                        confidence_skip_threshold_2,
                        result.get('grid_string_id'),
                        result.get('max_consecutive_failures', 0),
                        result.get('total_steps', 0),
                        result.get('total_failures', 0),
                        result.get('total_predictions', 0),
                        result.get('total_skipped_predictions', 0),
                        result.get('accuracy', 0.0),
                        result.get('forced_prediction_rate', 0.0),
                        result.get('forced_success_rate', 0.0),
                        result.get('first_success_step')
                    ))
        
        conn.commit()
        return validation_id
        
    except Exception as e:
        conn.rollback()
        st.error(f"ê²€ì¦ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def save_validation_results(
    cutoff_grid_string_id,
    window_size,
    method,
    use_threshold,
    threshold,
    max_interval,
    batch_results_default,
    batch_results_reverse
):
    """ê²€ì¦ ê²°ê³¼ë¥¼ DBì— ì €ì¥"""
    conn = get_db_connection()
    if conn is None:
        return None
    
    cursor = conn.cursor()
    
    try:
        # validation_id ìƒì„± (UUID)
        validation_id = str(uuid.uuid4())
        
        # 1. ê²€ì¦ ì„¸ì…˜ ì €ì¥
        cursor.execute('''
            INSERT INTO interactive_validation_sessions (
                validation_id, cutoff_grid_string_id, window_size, method,
                use_threshold, threshold, max_interval, created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
        ''', (
            validation_id,
            cutoff_grid_string_id,
            window_size,
            method,
            use_threshold,
            threshold if use_threshold else None,
            max_interval
        ))
        
        # 2. ìš”ì•½ í†µê³„ ì €ì¥ (ê¸°ë³¸ ì „ëµ)
        if batch_results_default and 'summary' in batch_results_default:
            summary_default = batch_results_default['summary']
            cursor.execute('''
                INSERT INTO interactive_validation_summaries (
                    validation_id, strategy_type, total_grid_strings,
                    avg_accuracy, max_consecutive_failures, avg_max_consecutive_failures,
                    prediction_rate, forced_prediction_rate, forced_success_rate,
                    total_steps, total_failures, total_predictions,
                    total_forced_predictions, total_forced_successes, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                'default',
                summary_default.get('total_grid_strings', 0),
                summary_default.get('avg_accuracy', 0.0),
                summary_default.get('max_consecutive_failures', 0),
                summary_default.get('avg_max_consecutive_failures', 0.0),
                summary_default.get('prediction_rate', 0.0),
                summary_default.get('forced_prediction_rate', 0.0),
                summary_default.get('forced_success_rate', 0.0),
                summary_default.get('total_steps', 0),
                summary_default.get('total_failures', 0),
                summary_default.get('total_predictions', 0),
                summary_default.get('total_forced_predictions', 0),
                summary_default.get('total_forced_successes', 0)
            ))
            
            # Grid Stringë³„ ê²°ê³¼ ì €ì¥ (ê¸°ë³¸ ì „ëµ)
            if 'results' in batch_results_default:
                for result in batch_results_default['results']:
                    cursor.execute('''
                        INSERT OR REPLACE INTO interactive_validation_grid_results (
                            validation_id, strategy_type, grid_string_id,
                            max_consecutive_failures, total_steps, total_failures,
                            total_predictions, accuracy, forced_prediction_rate,
                            forced_success_rate, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                    ''', (
                        validation_id,
                        'default',
                        result.get('grid_string_id'),
                        result.get('max_consecutive_failures', 0),
                        result.get('total_steps', 0),
                        result.get('total_failures', 0),
                        result.get('total_predictions', 0),
                        result.get('accuracy', 0.0),
                        result.get('forced_prediction_rate', 0.0),
                        result.get('forced_success_rate', 0.0)
                    ))
        
        # 3. ìš”ì•½ í†µê³„ ì €ì¥ (ë°˜ëŒ€ ì„ íƒ ì „ëµ)
        if batch_results_reverse and 'summary' in batch_results_reverse:
            summary_reverse = batch_results_reverse['summary']
            cursor.execute('''
                INSERT INTO interactive_validation_summaries (
                    validation_id, strategy_type, total_grid_strings,
                    avg_accuracy, max_consecutive_failures, avg_max_consecutive_failures,
                    prediction_rate, forced_prediction_rate, forced_success_rate,
                    total_steps, total_failures, total_predictions,
                    total_forced_predictions, total_forced_successes, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                'reverse',
                summary_reverse.get('total_grid_strings', 0),
                summary_reverse.get('avg_accuracy', 0.0),
                summary_reverse.get('max_consecutive_failures', 0),
                summary_reverse.get('avg_max_consecutive_failures', 0.0),
                summary_reverse.get('prediction_rate', 0.0),
                summary_reverse.get('forced_prediction_rate', 0.0),
                summary_reverse.get('forced_success_rate', 0.0),
                summary_reverse.get('total_steps', 0),
                summary_reverse.get('total_failures', 0),
                summary_reverse.get('total_predictions', 0),
                summary_reverse.get('total_forced_predictions', 0),
                summary_reverse.get('total_forced_successes', 0)
            ))
            
            # Grid Stringë³„ ê²°ê³¼ ì €ì¥ (ë°˜ëŒ€ ì„ íƒ ì „ëµ)
            if 'results' in batch_results_reverse:
                for result in batch_results_reverse['results']:
                    cursor.execute('''
                        INSERT OR REPLACE INTO interactive_validation_grid_results (
                            validation_id, strategy_type, grid_string_id,
                            max_consecutive_failures, total_steps, total_failures,
                            total_predictions, accuracy, forced_prediction_rate,
                            forced_success_rate, created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                    ''', (
                        validation_id,
                        'reverse',
                        result.get('grid_string_id'),
                        result.get('max_consecutive_failures', 0),
                        result.get('total_steps', 0),
                        result.get('total_failures', 0),
                        result.get('total_predictions', 0),
                        result.get('accuracy', 0.0),
                        result.get('forced_prediction_rate', 0.0),
                        result.get('forced_success_rate', 0.0)
                    ))
        
        conn.commit()
        return validation_id
        
    except Exception as e:
        conn.rollback()
        st.error(f"ê²€ì¦ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def validate_interactive_multi_step_scenario_with_confidence_skip(
    grid_string_id,
    cutoff_grid_string_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False,
    confidence_skip_threshold=51
):
    """
    ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤í‚µ ê·œì¹™ì´ ìˆëŠ” ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦
    
    ê·œì¹™:
    1. ê¸°ë³¸ ê·œì¹™ì€ ê¸°ì¡´ê³¼ ë™ì¼
    2. ê°•ì œ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ 51% ë¯¸ë§Œì¸ ê²½ìš° í•´ë‹¹ ìŠ¤í…ì€ ìŠ¤í‚µ (ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰)
    3. ìŠ¤í‚µ ìƒíƒœì—ì„œ ê°„ê²© ê³„ì‚°ì€ ë©ˆì¶¤ (ì¦ê°€í•˜ì§€ ì•ŠìŒ)
    4. ë‹¤ìŒ ìŠ¤í…ì—ì„œ ì„ê³„ê°’ ë§Œì¡± ì˜ˆì¸¡ ë˜ëŠ” ì‹ ë¢°ë„ 51% ì´ìƒ ê°•ì œ ì˜ˆì¸¡ì´ ë‚˜ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°
    
    Args:
        grid_string_id: ê²€ì¦í•  grid_stringì˜ ID
        cutoff_grid_string_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        threshold: ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
        reverse_forced_prediction: ë°˜ëŒ€ ì„ íƒ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        confidence_skip_threshold: ìŠ¤í‚µí•  ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 51)
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string ë¡œë“œ
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        
        if len(grid_string) < window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_skipped_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'first_success_step': None,
                'history': []
            }
        
        # í•™ìŠµ ë°ì´í„° êµ¬ì¶•
        train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
        train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[cutoff_grid_string_id])
        train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
        
        # N-gram ë¡œë“œ
        train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
        
        if len(train_ngrams) == 0:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_skipped_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'first_success_step': None,
                'history': []
            }
        
        # ëª¨ë¸ êµ¬ì¶•
        if method == "ë¹ˆë„ ê¸°ë°˜":
            model = build_frequency_model(train_ngrams)
        elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
            model = build_weighted_model(train_ngrams)
        else:
            model = build_frequency_model(train_ngrams)
        
        # ì‹œë‚˜ë¦¬ì˜¤ ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        prefix_length = window_size - 1
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        consecutive_matches = 0
        max_consecutive_matches = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        total_forced_predictions = 0
        total_skipped_predictions = 0
        total_forced_successes = 0
        current_interval = 0
        first_success_step = None  # ì²« ë²ˆì§¸ ì„±ê³µ ìŠ¤í… ì¶”ì 
        
        # ì´ˆê¸° prefix ìƒì„±
        if len(grid_string) < prefix_length:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_skipped_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'first_success_step': None,
                'history': []
            }
        
        current_prefix = grid_string[:prefix_length]
        
        # ê° ìŠ¤í…ë§ˆë‹¤ ì˜ˆì¸¡
        i = prefix_length
        while i < len(grid_string):
            total_steps += 1
            actual_value = grid_string[i]
            
            # ì˜ˆì¸¡ ìˆ˜í–‰ (ê¸°ë³¸ ê·œì¹™: ëª¨ë“  ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ ì‹œë„)
            if use_threshold:
                # ì„ê³„ê°’ ì „ëµ ì‚¬ìš©: ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡, ì•„ë‹ˆë©´ ê°•ì œ ì˜ˆì¸¡
                prediction_result = predict_with_fallback_interval(
                    model,
                    current_prefix,
                    method=method,
                    threshold=threshold,
                    max_interval=max_interval,
                    current_interval=current_interval
                )
            else:
                # ì„ê³„ê°’ ì „ëµ ë¯¸ì‚¬ìš©: ëª¨ë“  ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ (ê¸°ë³¸ ê·œì¹™)
                prediction_result = predict_for_prefix(model, current_prefix, method)
                # predict_for_prefixëŠ” í•­ìƒ ì˜ˆì¸¡ê°’ì„ ë°˜í™˜í•˜ê±°ë‚˜ Noneì„ ë°˜í™˜
                # Noneì¸ ê²½ìš°ë„ ìˆìœ¼ë¯€ë¡œ is_forcedëŠ” Falseë¡œ ì„¤ì •
                if 'is_forced' not in prediction_result:
                    prediction_result['is_forced'] = False
            
            predicted_value = prediction_result.get('predicted')
            confidence = prediction_result.get('confidence', 0.0)
            is_forced = prediction_result.get('is_forced', False)
            
            # ë°˜ëŒ€ ì„ íƒ ì „ëµ: ê°•ì œ ì˜ˆì¸¡ ì‹œ ë°˜ëŒ€ ê°’ ì„ íƒ
            if is_forced and reverse_forced_prediction and predicted_value is not None:
                predicted_value = 'p' if predicted_value == 'b' else 'b'
            
            has_prediction = predicted_value is not None
            
            # ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤í‚µ ê·œì¹™ ì²´í¬
            should_skip = False
            # ê¸°ë³¸ ê·œì¹™: use_threshold=Falseì¼ ë•ŒëŠ” ëª¨ë“  ì˜ˆì¸¡ê°’ì— ëŒ€í•´ ê²€ì¦ ìˆ˜í–‰
            # ìŠ¤í‚µ ê·œì¹™ì€ use_threshold=Trueì´ê³  ê°•ì œ ì˜ˆì¸¡ì¼ ë•Œë§Œ ì ìš©
            if use_threshold and has_prediction and is_forced and confidence < confidence_skip_threshold:
                # ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì¤‘ì´ê³ , ê°•ì œ ì˜ˆì¸¡ì´ê³  ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
                should_skip = True
                total_skipped_predictions += 1
            
            # ê²€ì¦ ìˆ˜í–‰ ì—¬ë¶€ ê²°ì • (ê¸°ë³¸ ê·œì¹™: ì˜ˆì¸¡ê°’ì´ ìˆìœ¼ë©´ í•­ìƒ ê²€ì¦)
            is_correct = None
            should_validate = False
            
            if has_prediction and not should_skip:
                # ê¸°ë³¸ ê·œì¹™: ì˜ˆì¸¡ê°’ì´ ìˆê³  ìŠ¤í‚µí•˜ì§€ ì•Šìœ¼ë©´ í•­ìƒ ê²€ì¦ ìˆ˜í–‰
                should_validate = True
                is_correct = predicted_value == actual_value
                
                if not is_correct:
                    consecutive_failures += 1
                    consecutive_matches = 0
                    total_failures += 1
                    if consecutive_failures > max_consecutive_failures:
                        max_consecutive_failures = consecutive_failures
                else:
                    consecutive_failures = 0
                    consecutive_matches += 1
                    if consecutive_matches > max_consecutive_matches:
                        max_consecutive_matches = consecutive_matches
                    # ì²« ë²ˆì§¸ ì„±ê³µ ìŠ¤í… ê¸°ë¡
                    if first_success_step is None:
                        first_success_step = total_steps
                
                total_predictions += 1
                if is_forced:
                    total_forced_predictions += 1
                    if is_correct:
                        total_forced_successes += 1
                
                # ê²€ì¦ í›„ ê°„ê²© ë¦¬ì…‹
                current_interval = 0
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                history.append({
                    'step': total_steps,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': has_prediction,
                    'validated': True,
                    'skipped': False
                })
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰
                i += 1
                current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
            elif has_prediction and should_skip:
                # ìŠ¤í‚µ: ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰í•˜ë˜ ê°„ê²©ì€ ì¦ê°€í•˜ì§€ ì•ŠìŒ (ë©ˆì¶¤)
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                history.append({
                    'step': total_steps,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': has_prediction,
                    'validated': False,
                    'skipped': True
                })
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰ (ê°„ê²©ì€ ì¦ê°€í•˜ì§€ ì•ŠìŒ - ë©ˆì¶¤ ìƒíƒœ)
                i += 1
                current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
                # current_intervalì€ ì¦ê°€í•˜ì§€ ì•ŠìŒ (ë©ˆì¶¤)
            else:
                # ì˜ˆì¸¡ê°’ì´ ì—†ìŒ: ê°„ê²© ì¦ê°€
                history.append({
                    'step': total_steps,
                    'prefix': current_prefix,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': False,
                    'current_interval': current_interval,
                    'has_prediction': False,
                    'validated': False,
                    'skipped': False
                })
                
                current_interval += 1
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰
                i += 1
                current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ ê³„ì‚°
        forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # ê°•ì œ ì˜ˆì¸¡ ì„±ê³µ ë¹„ìœ¨ ê³„ì‚°
        forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'max_consecutive_matches': max_consecutive_matches,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'total_forced_predictions': total_forced_predictions,
            'total_skipped_predictions': total_skipped_predictions,
            'forced_prediction_rate': forced_prediction_rate,
            'forced_success_rate': forced_success_rate,
            'accuracy': accuracy,
            'first_success_step': first_success_step,  # ì²« ë²ˆì§¸ ì„±ê³µ ìŠ¤í…
            'history': history
        }
        
    except Exception as e:
        st.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    finally:
        conn.close()

def validate_interactive_multi_step_scenario(
    grid_string_id,
    cutoff_grid_string_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False
):
    """
    ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ ë°©ì‹ìœ¼ë¡œ ë‹¨ì¼ grid_string ê²€ì¦
    
    Args:
        grid_string_id: ê²€ì¦í•  grid_stringì˜ ID
        cutoff_grid_string_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID (ì´ ID ì´í•˜ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©)
        window_size: ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 7)
        method: ì˜ˆì¸¡ ë°©ë²• ("ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ ", ê¸°ë³¸ê°’: "ë¹ˆë„ ê¸°ë°˜")
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        threshold: ì„ê³„ê°’ (ê¸°ë³¸ê°’: 60)
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© (ê¸°ë³¸ê°’: 6)
    
    Returns:
        dict: {
            'grid_string_id': int,
            'max_consecutive_failures': int,
            'total_steps': int,
            'total_failures': int,
            'total_predictions': int,
            'accuracy': float,
            'history': list
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string ë¡œë“œ
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        
        if len(grid_string) < window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'history': []
            }
        
        # í•™ìŠµ ë°ì´í„° êµ¬ì¶• (cutoff_grid_string_id ì´í•˜)
        train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
        train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[cutoff_grid_string_id])
        train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
        
        # N-gram ë¡œë“œ
        train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
        
        if len(train_ngrams) == 0:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'history': []
            }
        
        # ëª¨ë¸ êµ¬ì¶•
        if method == "ë¹ˆë„ ê¸°ë°˜":
            model = build_frequency_model(train_ngrams)
        elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
            model = build_weighted_model(train_ngrams)
        else:
            # ì•ˆì „ ìš°ì„ ì€ ë³„ë„ ì²˜ë¦¬ í•„ìš” (ì¼ë‹¨ ë¹ˆë„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´)
            model = build_frequency_model(train_ngrams)
        
        # ì‹œë‚˜ë¦¬ì˜¤ ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        prefix_length = window_size - 1
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        consecutive_matches = 0
        max_consecutive_matches = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        total_forced_predictions = 0
        total_forced_successes = 0
        current_interval = 0
        
        # ì´ˆê¸° prefix ìƒì„±
        if len(grid_string) < prefix_length:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'history': []
            }
        
        current_prefix = grid_string[:prefix_length]
        
        # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ëª¨ë“  ìŠ¤í…ì—ì„œ ê²€ì¦ ìˆ˜í–‰
        # ê°„ê²© ì¡°ê±´ì€ ì˜ˆì¸¡ì´ ì—†ëŠ” ìŠ¤í…ì„ ì¶”ì í•˜ëŠ” ìš©ë„ë¡œë§Œ ì‚¬ìš© (current_interval)
        
        # ê° ìŠ¤í…ë§ˆë‹¤ ì˜ˆì¸¡ (ëª¨ë“  ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ê°’ ìƒì„±)
        for i in range(prefix_length, len(grid_string)):
            total_steps += 1
            actual_value = grid_string[i]
            
            # ì˜ˆì¸¡ (ëª¨ë“  ìŠ¤í…ì—ì„œ ìˆ˜í–‰)
            if use_threshold:
                # ì„ê³„ê°’ ì „ëµ ì‚¬ìš©
                prediction_result = predict_with_fallback_interval(
                    model,
                    current_prefix,
                    method=method,
                    threshold=threshold,
                    max_interval=max_interval,
                    current_interval=current_interval
                )
            else:
                # ì„ê³„ê°’ ì „ëµ ë¯¸ì‚¬ìš©: ëª¨ë“  ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ (ê¸°ë³¸ ê·œì¹™)
                prediction_result = predict_for_prefix(model, current_prefix, method)
                # predict_for_prefixëŠ” í•­ìƒ ì˜ˆì¸¡ê°’ì„ ë°˜í™˜í•˜ê±°ë‚˜ Noneì„ ë°˜í™˜
                # Noneì¸ ê²½ìš°ë„ ìˆìœ¼ë¯€ë¡œ is_forcedëŠ” Falseë¡œ ì„¤ì •
                if 'is_forced' not in prediction_result:
                    prediction_result['is_forced'] = False
            
            predicted_value = prediction_result.get('predicted')
            confidence = prediction_result.get('confidence', 0.0)
            is_forced = prediction_result.get('is_forced', False)
            
            # ë°˜ëŒ€ ì„ íƒ ì „ëµ: ê°•ì œ ì˜ˆì¸¡ ì‹œ ë°˜ëŒ€ ê°’ ì„ íƒ
            if is_forced and reverse_forced_prediction and predicted_value is not None:
                predicted_value = 'p' if predicted_value == 'b' else 'b'
            
            has_prediction = predicted_value is not None
            
            # ì‹¤ì œê°’ê³¼ ë¹„êµ: ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ëª¨ë“  ìŠ¤í…ì—ì„œ ê²€ì¦ ìˆ˜í–‰
            # ê°„ê²© ì¡°ê±´ì€ ì˜ˆì¸¡ì´ ì—†ëŠ” ìŠ¤í…ì„ ì¹´ìš´íŠ¸í•˜ëŠ” ìš©ë„ë¡œë§Œ ì‚¬ìš©
            is_correct = None
            should_validate = False
            
            if has_prediction:
                # ì˜ˆì¸¡ê°’ì´ ìˆìœ¼ë©´ í•­ìƒ ê²€ì¦ ìˆ˜í–‰
                should_validate = True
                is_correct = predicted_value == actual_value
                
                if not is_correct:
                    consecutive_failures += 1
                    consecutive_matches = 0  # ë¶ˆì¼ì¹˜ ì‹œ ì—°ì† ì¼ì¹˜ ë¦¬ì…‹
                    total_failures += 1
                    if consecutive_failures > max_consecutive_failures:
                        max_consecutive_failures = consecutive_failures
                else:
                    consecutive_failures = 0  # ì¼ì¹˜ ì‹œ ì—°ì† ë¶ˆì¼ì¹˜ ë¦¬ì…‹
                    consecutive_matches += 1
                    if consecutive_matches > max_consecutive_matches:
                        max_consecutive_matches = consecutive_matches
                
                total_predictions += 1
                if is_forced:
                    total_forced_predictions += 1
                    if is_correct:
                        total_forced_successes += 1
            
            # íˆìŠ¤í† ë¦¬ ê¸°ë¡ (ëª¨ë“  ìŠ¤í… ê¸°ë¡, ì˜ˆì¸¡ê°’ì´ ìˆìœ¼ë©´ í•­ìƒ ê²€ì¦)
            history.append({
                'step': total_steps,
                'prefix': current_prefix,
                'predicted': predicted_value,
                'actual': actual_value,
                'is_correct': is_correct,
                'confidence': confidence,
                'is_forced': is_forced,
                'current_interval': current_interval,  # ì˜ˆì¸¡ ì „ ê°„ê²©
                'has_prediction': has_prediction,
                'validated': should_validate  # ì´ ìŠ¤í…ì—ì„œ ì‹¤ì œ ë¹„êµê°€ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€
            })
            
            # ê°„ê²© ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° ì „ì—)
            if has_prediction:
                current_interval = 0  # ì˜ˆì¸¡ì´ ìˆì—ˆìœ¼ë©´ ê°„ê²© ë¦¬ì…‹
            else:
                current_interval += 1  # ì˜ˆì¸¡ì´ ì—†ì—ˆìœ¼ë©´ ê°„ê²© ì¦ê°€
            
            # ë‹¤ìŒ prefix ìƒì„±
            current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
        
        # ì •í™•ë„ ê³„ì‚° (ì˜ˆì¸¡ì´ ìˆì—ˆë˜ ìŠ¤í…ë§Œ ê³ ë ¤)
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ ê³„ì‚°
        forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # ê°•ì œ ì˜ˆì¸¡ ì„±ê³µ ë¹„ìœ¨ ê³„ì‚°
        forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'max_consecutive_matches': max_consecutive_matches,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'total_forced_predictions': total_forced_predictions,
            'total_forced_successes': total_forced_successes,
            'forced_prediction_rate': forced_prediction_rate,
            'forced_success_rate': forced_success_rate,
            'accuracy': accuracy,
            'history': history
        }
        
    except Exception as e:
        st.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_interactive_multi_step_scenario(
    cutoff_grid_string_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False
):
    """
    cutoff_grid_string_id ì´í›„ì˜ ëª¨ë“  grid_stringì— ëŒ€í•´ ë°°ì¹˜ ê²€ì¦ ì‹¤í–‰
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID (ì´ ID ì´í›„ì˜ ë°ì´í„° ê²€ì¦)
        window_size: ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 7)
        method: ì˜ˆì¸¡ ë°©ë²• (ê¸°ë³¸ê°’: "ë¹ˆë„ ê¸°ë°˜")
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        threshold: ì„ê³„ê°’ (ê¸°ë³¸ê°’: 60)
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© (ê¸°ë³¸ê°’: 6)
    
    Returns:
        dict: {
            'results': list,
            'summary': dict
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff_grid_string_id ì´í›„ì˜ ëª¨ë“  grid_string ë¡œë“œ
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0,
                    'prediction_rate': 0.0
                }
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        all_history = []  # ì‹ ë¢°ë„ í†µê³„ ìˆ˜ì§‘ìš©
        
        # ê° grid_stringì— ëŒ€í•´ ê²€ì¦ ì‹¤í–‰
        for grid_string_id in grid_string_ids:
            result = validate_interactive_multi_step_scenario(
                grid_string_id,
                cutoff_grid_string_id,
                window_size=window_size,
                method=method,
                use_threshold=use_threshold,
                threshold=threshold,
                max_interval=max_interval,
                reverse_forced_prediction=reverse_forced_prediction
            )
            
            if result is not None:
                results.append(result)
                # íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ (ì‹ ë¢°ë„ í†µê³„ìš©)
                all_history.extend(result.get('history', []))
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            total_steps = sum(r['total_steps'] for r in results)
            total_failures = sum(r['total_failures'] for r in results)
            total_predictions = sum(r['total_predictions'] for r in results)
            total_forced_predictions = sum(r.get('total_forced_predictions', 0) for r in results)
            total_forced_successes = sum(r.get('total_forced_successes', 0) for r in results)
            prediction_rate = (total_predictions / total_steps * 100) if total_steps > 0 else 0.0
            forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
            forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': total_steps,
                'total_failures': total_failures,
                'total_predictions': total_predictions,
                'total_forced_predictions': total_forced_predictions,
                'total_forced_successes': total_forced_successes,
                'prediction_rate': prediction_rate,
                'forced_prediction_rate': forced_prediction_rate,
                'forced_success_rate': forced_success_rate
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_forced_successes': 0,
                'prediction_rate': 0.0,
                'forced_prediction_rate': 0.0,
                'forced_success_rate': 0.0
            }
        
        return {
            'results': results,
            'summary': summary,
            'all_history': all_history  # ì‹ ë¢°ë„ í†µê³„ ìˆ˜ì§‘ìš©
        }
        
    except Exception as e:
        st.error(f"ë°°ì¹˜ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_interactive_multi_step_scenario_with_confidence_skip(
    cutoff_grid_string_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False,
    confidence_skip_threshold=51
):
    """
    ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤í‚µ ê·œì¹™ì´ ìˆëŠ” ë°°ì¹˜ ê²€ì¦
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        threshold: ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
        reverse_forced_prediction: ë°˜ëŒ€ ì„ íƒ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        confidence_skip_threshold: ìŠ¤í‚µí•  ì‹ ë¢°ë„ ì„ê³„ê°’
    
    Returns:
        dict: ë°°ì¹˜ ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff_grid_string_id ì´í›„ì˜ ëª¨ë“  grid_string ë¡œë“œ
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0,
                    'total_skipped_predictions': 0,
                    'prediction_rate': 0.0
                }
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        all_history = []  # ì‹ ë¢°ë„ í†µê³„ ìˆ˜ì§‘ìš©
        
        # ê° grid_stringì— ëŒ€í•´ ê²€ì¦ ì‹¤í–‰
        for grid_string_id in grid_string_ids:
            result = validate_interactive_multi_step_scenario_with_confidence_skip(
                grid_string_id,
                cutoff_grid_string_id,
                window_size=window_size,
                method=method,
                use_threshold=use_threshold,
                threshold=threshold,
                max_interval=max_interval,
                reverse_forced_prediction=reverse_forced_prediction,
                confidence_skip_threshold=confidence_skip_threshold
            )
            
            if result is not None:
                results.append(result)
                # íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ (ì‹ ë¢°ë„ í†µê³„ìš©)
                all_history.extend(result.get('history', []))
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            total_steps = sum(r['total_steps'] for r in results)
            total_failures = sum(r['total_failures'] for r in results)
            total_predictions = sum(r['total_predictions'] for r in results)
            total_skipped_predictions = sum(r.get('total_skipped_predictions', 0) for r in results)
            total_forced_predictions = sum(r.get('total_forced_predictions', 0) for r in results)
            total_forced_successes = sum(r.get('total_forced_successes', 0) for r in results)
            prediction_rate = (total_predictions / total_steps * 100) if total_steps > 0 else 0.0
            forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
            forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
            
            # ì²« ë²ˆì§¸ ì„±ê³µ ìŠ¤í… í†µê³„
            first_success_steps = [r.get('first_success_step') for r in results if r.get('first_success_step') is not None]
            avg_first_success_step = sum(first_success_steps) / len(first_success_steps) if len(first_success_steps) > 0 else None
            min_first_success_step = min(first_success_steps) if len(first_success_steps) > 0 else None
            max_first_success_step = max(first_success_steps) if len(first_success_steps) > 0 else None
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': total_steps,
                'total_failures': total_failures,
                'total_predictions': total_predictions,
                'total_skipped_predictions': total_skipped_predictions,
                'total_forced_predictions': total_forced_predictions,
                'total_forced_successes': total_forced_successes,
                'prediction_rate': prediction_rate,
                'forced_prediction_rate': forced_prediction_rate,
                'forced_success_rate': forced_success_rate,
                'avg_first_success_step': avg_first_success_step,
                'min_first_success_step': min_first_success_step,
                'max_first_success_step': max_first_success_step,
                'total_with_success': len(first_success_steps)  # ì„±ê³µì´ ìˆì—ˆë˜ grid_string ìˆ˜
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_skipped_predictions': 0,
                'total_forced_predictions': 0,
                'total_forced_successes': 0,
                'prediction_rate': 0.0,
                'forced_prediction_rate': 0.0,
                'forced_success_rate': 0.0
            }
        
        return {
            'results': results,
            'summary': summary,
            'all_history': all_history  # ì‹ ë¢°ë„ í†µê³„ ìˆ˜ì§‘ìš©
        }
        
    except Exception as e:
        st.error(f"ë°°ì¹˜ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    finally:
        conn.close()

def get_failure_history_interactive(
    grid_string_id,
    cutoff_grid_string_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False
):
    """
    ì‹¤íŒ¨ Grid Stringì˜ ìƒì„¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ìš©)
    
    Args:
        grid_string_id: ì¡°íšŒí•  grid_stringì˜ ID
        cutoff_grid_string_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        threshold: ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
    
    Returns:
        dict: íˆìŠ¤í† ë¦¬ ë°ì´í„°
    """
    result = validate_interactive_multi_step_scenario(
        grid_string_id,
        cutoff_grid_string_id,
        window_size=window_size,
        method=method,
        use_threshold=use_threshold,
        threshold=threshold,
        max_interval=max_interval,
        reverse_forced_prediction=reverse_forced_prediction
    )
    
    if result is None:
        return None
    
    return result

def get_grid_strings_by_percentage_range(start_percentage, end_percentage):
    """
    ë¹„ìœ¨ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” grid_stringë“¤ì„ ë¡œë“œ
    
    Args:
        start_percentage: ì‹œì‘ ë¹„ìœ¨ (0-100)
        end_percentage: ì¢…ë£Œ ë¹„ìœ¨ (0-100)
    
    Returns:
        DataFrame: í•´ë‹¹ ë¹„ìœ¨ ë²”ìœ„ì˜ grid_string DataFrame (id ê¸°ì¤€ ì •ë ¬)
    """
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    try:
        # ì „ì²´ grid_string ê°œìˆ˜ í™•ì¸
        count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings"
        count_df = pd.read_sql_query(count_query, conn)
        total_count = count_df.iloc[0]['count'] if len(count_df) > 0 else 0
        
        if total_count == 0:
            return pd.DataFrame()
        
        # ë¹„ìœ¨ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ ê³„ì‚°
        start_index = int(total_count * start_percentage / 100)
        end_index = int(total_count * end_percentage / 100)
        
        # ëª¨ë“  grid_stringì„ id ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë¡œë“œ
        query = "SELECT id, grid_string, created_at FROM preprocessed_grid_strings ORDER BY id"
        df_all = pd.read_sql_query(query, conn)
        
        if len(df_all) == 0:
            return pd.DataFrame()
        
        # í•´ë‹¹ ë²”ìœ„ì˜ ë°ì´í„° ì¶”ì¶œ
        if start_index < len(df_all) and end_index <= len(df_all):
            df_range = df_all.iloc[start_index:end_index].copy()
        else:
            return pd.DataFrame()
        
        return df_range
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()
    finally:
        conn.close()

def validate_forced_prediction_hypothesis(
    train_cutoff_id,
    validation_start_id,
    validation_end_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜"
):
    """
    ê°•ì œ ì˜ˆì¸¡ ê°€ì„¤ ê²€ì¦ (ë‹¨ì¼ ë‹¨ê³„)
    
    ëª¨ë“  ìŠ¤í…ì—ì„œ ê°•ì œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³ , ê°„ê²©ì„ ìœˆë„ìš° í¬ê¸° -1ë¡œ ì„¤ì •
    
    Args:
        train_cutoff_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID (ì´ ID ì´í•˜ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©)
        validation_start_id: ê²€ì¦ ì‹œì‘ ID
        validation_end_id: ê²€ì¦ ì¢…ë£Œ ID (ì´ ID ì´í•˜ê¹Œì§€ ê²€ì¦)
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # í•™ìŠµ ë°ì´í„° êµ¬ì¶•
        train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
        train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[train_cutoff_id])
        train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
        
        # N-gram ë¡œë“œ
        train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
        
        if len(train_ngrams) == 0:
            return {
                'train_cutoff_id': train_cutoff_id,
                'validation_start_id': validation_start_id,
                'validation_end_id': validation_end_id,
                'total_grid_strings': 0,
                'tested_grid_strings': 0,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'accuracy': 0.0,
                'forced_success_rate': 0.0,
                'results': []
            }
        
        # ëª¨ë¸ êµ¬ì¶•
        if method == "ë¹ˆë„ ê¸°ë°˜":
            model = build_frequency_model(train_ngrams)
        elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
            model = build_weighted_model(train_ngrams)
        else:
            model = build_frequency_model(train_ngrams)
        
        # ê²€ì¦ ë°ì´í„° ë¡œë“œ
        validation_query = """
            SELECT id, grid_string 
            FROM preprocessed_grid_strings 
            WHERE id > ? AND id <= ? 
            ORDER BY id
        """
        validation_df = pd.read_sql_query(
            validation_query, 
            conn, 
            params=[validation_start_id, validation_end_id]
        )
        
        if len(validation_df) == 0:
            return {
                'train_cutoff_id': train_cutoff_id,
                'validation_start_id': validation_start_id,
                'validation_end_id': validation_end_id,
                'total_grid_strings': 0,
                'tested_grid_strings': 0,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'accuracy': 0.0,
                'forced_success_rate': 0.0,
                'results': []
            }
        
        # ê²€ì¦ ì‹¤í–‰
        results = []
        max_consecutive_failures_all = 0
        max_consecutive_matches_all = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        total_forced_predictions = 0
        total_forced_successes = 0
        
        # max_interval = window_size - 1
        max_interval = window_size - 1
        
        for _, row in validation_df.iterrows():
            grid_string_id = row['id']
            grid_string = row['grid_string']
            
            if len(grid_string) < window_size:
                continue
            
            # ê²€ì¦ ì‹¤í–‰ (use_threshold=False, í•­ìƒ ì˜ˆì¸¡í•˜ë˜ max_interval=window_size-1ë¡œ ì„¤ì •)
            # ê°€ì„¤: ëª¨ë“  ìŠ¤í…ì€ ê°•ì œ ì˜ˆì¸¡, ê°„ê²© = ìœˆë„ìš° í¬ê¸° - 1
            # use_threshold=Falseë¡œ ì„¤ì •í•˜ë©´ ëª¨ë“  ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ë°œìƒ (ê°•ì œ ì˜ˆì¸¡ ê°œë…)
            result = validate_interactive_multi_step_scenario(
                grid_string_id,
                train_cutoff_id,
                window_size=window_size,
                method=method,
                use_threshold=False,  # ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì•ˆ í•¨ (ëª¨ë“  ìŠ¤í…ì—ì„œ ì˜ˆì¸¡)
                threshold=60,
                max_interval=max_interval,  # ìœˆë„ìš° í¬ê¸° - 1 (ê°€ì„¤ ìš”êµ¬ì‚¬í•­)
                reverse_forced_prediction=False
            )
            
            if result is not None:
                results.append(result)
                max_consecutive_failures_all = max(max_consecutive_failures_all, result['max_consecutive_failures'])
                max_consecutive_matches_all = max(max_consecutive_matches_all, result.get('max_consecutive_matches', 0))
                total_steps += result['total_steps']
                total_failures += result['total_failures']
                total_predictions += result['total_predictions']
                total_forced_predictions += result['total_forced_predictions']
                total_forced_successes += result.get('total_forced_successes', 0)
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # ê°•ì œ ì˜ˆì¸¡ ì„±ê³µë¥  ê³„ì‚°
        forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
        
        return {
            'train_cutoff_id': train_cutoff_id,
            'validation_start_id': validation_start_id,
            'validation_end_id': validation_end_id,
            'total_grid_strings': len(validation_df),
            'tested_grid_strings': len(results),
            'max_consecutive_failures': max_consecutive_failures_all,
            'max_consecutive_matches': max_consecutive_matches_all,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'total_forced_predictions': total_forced_predictions,
            'accuracy': accuracy,
            'forced_success_rate': forced_success_rate,
            'results': results
        }
        
    except Exception as e:
        st.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def render_live_game_play(game_state):
    """
    ë¼ì´ë¸Œ ê²Œì„ ì§„í–‰ UI ë Œë”ë§
    ê²Œì„ ìƒíƒœê°€ ìˆì„ ë•Œë§Œ í˜¸ì¶œë˜ì–´ì•¼ í•¨
    """
    # ìë™ ì‹¤í–‰ ì™„ë£Œ ë©”ì‹œì§€ ì œê±° (ì„±ëŠ¥ ê°œì„ )
    
    # í˜„ì¬ ìŠ¤í… ì •ë³´
    st.markdown("---")
    st.markdown("### ğŸ“ í˜„ì¬ ìŠ¤í…")
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    current_prefix = game_state['current_prefix']
    current_interval = game_state['current_interval']
    model = game_state['model']
    
    if game_state['use_threshold']:
        prediction_result = predict_with_fallback_interval(
            model,
            current_prefix,
            method=game_state['method'],
            threshold=game_state['threshold'],
            max_interval=game_state['max_interval'],
            current_interval=current_interval
        )
    else:
        prediction_result = predict_for_prefix(model, current_prefix, game_state['method'])
        if 'is_forced' not in prediction_result:
            prediction_result['is_forced'] = False
    
    predicted_value = prediction_result.get('predicted')
    confidence = prediction_result.get('confidence', 0.0)
    is_forced = prediction_result.get('is_forced', False)
    has_prediction = predicted_value is not None
    
    # ìŠ¤í‚µ ê·œì¹™ ì²´í¬
    should_skip = False
    if game_state['use_threshold'] and has_prediction and is_forced and confidence < game_state['confidence_skip_threshold']:
        should_skip = True
    
    # í˜„ì¬ ìŠ¤í… ì •ë³´ í‘œì‹œ (ì»´íŒ©íŠ¸í•˜ê²Œ)
    col_info1, col_info2, col_info3, col_info4 = st.columns(4)
    with col_info1:
        st.caption("Prefix")
        st.markdown(f"<div style='font-size: 24px; font-weight: bold;'>{current_prefix}</div>", unsafe_allow_html=True)
    with col_info2:
        if has_prediction:
            forced_mark = "âš¡" if is_forced else ""
            skip_mark = "â­ï¸" if should_skip else ""
            st.caption("ì˜ˆì¸¡ê°’")
            st.text(f"{predicted_value}{forced_mark}{skip_mark}")
        else:
            st.caption("ì˜ˆì¸¡ê°’")
            st.text("ì—†ìŒ")
    with col_info3:
        if has_prediction:
            st.caption("ì‹ ë¢°ë„")
            st.text(f"{confidence:.1f}%")
        else:
            st.caption("ì‹ ë¢°ë„")
            st.text("-")
    with col_info4:
        st.caption("ê°„ê²©")
        st.text(f"{current_interval}/{game_state['max_interval']}")
    
    # ë‹¤ìŒ ìŠ¤í… ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°
    st.markdown("---")
    st.markdown('<p style="font-size: 1em; color: #666; margin-top: -10px;"><strong>ë‹¤ìŒ ìŠ¤í… ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°:</strong></p>', unsafe_allow_html=True)
    
    # ë‹¤ìŒ prefix ìƒì„± (bì™€ p ë‘ ê²½ìš° ëª¨ë‘)
    next_prefix_b = get_next_prefix(current_prefix, 'b', game_state['window_size'])
    next_prefix_p = get_next_prefix(current_prefix, 'p', game_state['window_size'])
    
    # ë‹¤ìŒ prefixì— ëŒ€í•œ ì˜ˆì¸¡ (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
    if model is not None:
        next_pred_b = None
        next_pred_p = None
        next_conf_b = 0.0
        next_conf_p = 0.0
        next_forced_b = False
        next_forced_p = False
        
        try:
            if game_state['use_threshold']:
                # ë‹¤ìŒ ìŠ¤í… ì˜ˆì¸¡ìš© ê°„ê²© ê³„ì‚°
                # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 0ìœ¼ë¡œ ë¦¬ì…‹
                # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ì—†ì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 1 ì¦ê°€
                if has_prediction:
                    # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 0ìœ¼ë¡œ ë¦¬ì…‹
                    next_interval = 0
                else:
                    # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ì—†ì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 1 ì¦ê°€
                    next_interval = current_interval + 1
                
                # ê°„ê²©ì„ ê³ ë ¤í•˜ì—¬ ì˜ˆì¸¡
                next_result_b = predict_with_fallback_interval(
                    model,
                    next_prefix_b,
                    game_state['method'],
                    threshold=game_state['threshold'],
                    max_interval=game_state['max_interval'],
                    current_interval=next_interval
                )
                next_result_p = predict_with_fallback_interval(
                    model,
                    next_prefix_p,
                    game_state['method'],
                    threshold=game_state['threshold'],
                    max_interval=game_state['max_interval'],
                    current_interval=next_interval
                )
                
                next_forced_b = next_result_b.get('is_forced', False)
                next_forced_p = next_result_p.get('is_forced', False)
            else:
                next_result_b = predict_for_prefix(model, next_prefix_b, game_state['method'])
                next_result_p = predict_for_prefix(model, next_prefix_p, game_state['method'])
                next_forced_b = False
                next_forced_p = False
            
            next_pred_b = next_result_b.get('predicted')
            next_pred_p = next_result_p.get('predicted')
            next_conf_b = next_result_b.get('confidence', 0.0)
            next_conf_p = next_result_p.get('confidence', 0.0)
        except Exception as e:
            pass
        
        # ê²½ë¡œ í‘œì‹œ
        col_path1, col_path2 = st.columns(2)
        with col_path1:
            if next_pred_b is not None and str(next_pred_b).strip() != '':
                forced_marker = " âš¡" if next_forced_b else ""
                st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_b}{forced_marker}</code> ({next_conf_b:.1f}%)</p>', unsafe_allow_html=True)
            else:
                st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
        
        with col_path2:
            if next_pred_p is not None and str(next_pred_p).strip() != '':
                forced_marker = " âš¡" if next_forced_p else ""
                st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_p}{forced_marker}</code> ({next_conf_p:.1f}%)</p>', unsafe_allow_html=True)
            else:
                st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
    else:
        # ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° prefixë§Œ í‘œì‹œ
        col_path1, col_path2 = st.columns(2)
        with col_path1:
            st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code></p>', unsafe_allow_html=True)
        with col_path2:
            st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code></p>', unsafe_allow_html=True)
    
    # ì‹¤ì œê°’ ì…ë ¥ (ë²„íŠ¼ì‹)
    if has_prediction and not should_skip:
        st.markdown("---")
        st.markdown("#### ì‹¤ì œê°’ ì„ íƒ")
        
        # ì´ì „ ìƒíƒœ ì €ì¥ (ì·¨ì†Œ ê¸°ëŠ¥ìš©)
        if 'previous_game_state' not in st.session_state or st.session_state.get('previous_game_state_step', -1) != game_state['current_step']:
            st.session_state.previous_game_state = {
                'current_step': game_state['current_step'],
                'current_index': game_state['current_index'],
                'current_prefix': game_state['current_prefix'],
                'current_interval': game_state['current_interval'],
                'consecutive_failures': game_state['consecutive_failures'],
                'max_consecutive_failures': game_state['max_consecutive_failures'],
                'total_predictions': game_state['total_predictions'],
                'total_failures': game_state['total_failures'],
                'total_forced_predictions': game_state['total_forced_predictions'],
                'history': game_state['history'].copy()
            }
            st.session_state.previous_game_state_step = game_state['current_step']
        
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])
        with col_btn1:
            if st.button("ğŸ”´ B", use_container_width=True, key=f"live_game_btn_b_{game_state['current_step']}"):
                actual_value = 'b'
                
                # ê²€ì¦ ìˆ˜í–‰
                is_correct = predicted_value == actual_value
                
                if not is_correct:
                    game_state['consecutive_failures'] += 1
                    game_state['total_failures'] += 1
                    if game_state['consecutive_failures'] > game_state['max_consecutive_failures']:
                        game_state['max_consecutive_failures'] = game_state['consecutive_failures']
                else:
                    game_state['consecutive_failures'] = 0
                
                game_state['total_predictions'] += 1
                if is_forced:
                    game_state['total_forced_predictions'] += 1
                
                # ê°„ê²© ë¦¬ì…‹
                game_state['current_interval'] = 0
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': 0,
                    'has_prediction': True,
                    'validated': True,
                    'skipped': False
                })
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                # prefix ì—…ë°ì´íŠ¸ (ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œì—ì„œëŠ” í•­ìƒ ì—…ë°ì´íŠ¸)
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn2:
            if st.button("ğŸ”µ P", use_container_width=True, key=f"live_game_btn_p_{game_state['current_step']}"):
                actual_value = 'p'
                
                # ê²€ì¦ ìˆ˜í–‰
                is_correct = predicted_value == actual_value
                
                if not is_correct:
                    game_state['consecutive_failures'] += 1
                    game_state['total_failures'] += 1
                    if game_state['consecutive_failures'] > game_state['max_consecutive_failures']:
                        game_state['max_consecutive_failures'] = game_state['consecutive_failures']
                else:
                    game_state['consecutive_failures'] = 0
                
                game_state['total_predictions'] += 1
                if is_forced:
                    game_state['total_forced_predictions'] += 1
                
                # ê°„ê²© ë¦¬ì…‹
                game_state['current_interval'] = 0
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': 0,
                    'has_prediction': True,
                    'validated': True,
                    'skipped': False
                })
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                # prefix ì—…ë°ì´íŠ¸ (ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œì—ì„œëŠ” í•­ìƒ ì—…ë°ì´íŠ¸)
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn3:
            if st.button("â†©ï¸ ì·¨ì†Œ", use_container_width=True, key=f"live_game_btn_cancel_{game_state['current_step']}"):
                if 'previous_game_state' in st.session_state:
                    prev_state = st.session_state.previous_game_state
                    # ì´ì „ ìƒíƒœë¡œ ë³µì›
                    game_state['current_step'] = prev_state['current_step']
                    game_state['current_index'] = prev_state['current_index']
                    game_state['current_prefix'] = prev_state['current_prefix']
                    game_state['current_interval'] = prev_state['current_interval']
                    game_state['consecutive_failures'] = prev_state['consecutive_failures']
                    game_state['max_consecutive_failures'] = prev_state['max_consecutive_failures']
                    game_state['total_predictions'] = prev_state['total_predictions']
                    game_state['total_failures'] = prev_state['total_failures']
                    game_state['total_forced_predictions'] = prev_state['total_forced_predictions']
                    game_state['history'] = prev_state['history'].copy()
                    st.rerun()
    elif has_prediction and should_skip:
        # ìŠ¤í‚µ ìƒíƒœ
        st.markdown("---")
        st.markdown("#### ì‹¤ì œê°’ ì„ íƒ (ìŠ¤í‚µ ëª¨ë“œ)")
        
        # ì´ì „ ìƒíƒœ ì €ì¥ (ì·¨ì†Œ ê¸°ëŠ¥ìš©)
        if 'previous_game_state' not in st.session_state or st.session_state.get('previous_game_state_step', -1) != game_state['current_step']:
            st.session_state.previous_game_state = {
                'current_step': game_state['current_step'],
                'current_index': game_state['current_index'],
                'current_prefix': game_state['current_prefix'],
                'current_interval': game_state['current_interval'],
                'consecutive_failures': game_state['consecutive_failures'],
                'max_consecutive_failures': game_state['max_consecutive_failures'],
                'total_predictions': game_state['total_predictions'],
                'total_failures': game_state['total_failures'],
                'total_forced_predictions': game_state['total_forced_predictions'],
                'total_skipped_predictions': game_state['total_skipped_predictions'],
                'history': game_state['history'].copy()
            }
            st.session_state.previous_game_state_step = game_state['current_step']
        
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])
        with col_btn1:
            if st.button("ğŸ”´ B", use_container_width=True, key=f"live_game_btn_skip_b_{game_state['current_step']}"):
                actual_value = 'b'
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡ (ìŠ¤í‚µ)
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': True,
                    'validated': False,
                    'skipped': True
                })
                
                game_state['total_skipped_predictions'] += 1
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰ (ê°„ê²©ì€ ì¦ê°€í•˜ì§€ ì•ŠìŒ)
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn2:
            if st.button("ğŸ”µ P", use_container_width=True, key=f"live_game_btn_skip_p_{game_state['current_step']}"):
                actual_value = 'p'
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡ (ìŠ¤í‚µ)
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': True,
                    'validated': False,
                    'skipped': True
                })
                
                game_state['total_skipped_predictions'] += 1
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰ (ê°„ê²©ì€ ì¦ê°€í•˜ì§€ ì•ŠìŒ)
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn3:
            if st.button("â†©ï¸ ì·¨ì†Œ", use_container_width=True, key=f"live_game_btn_skip_cancel_{game_state['current_step']}"):
                if 'previous_game_state' in st.session_state:
                    prev_state = st.session_state.previous_game_state
                    # ì´ì „ ìƒíƒœë¡œ ë³µì›
                    game_state['current_step'] = prev_state['current_step']
                    game_state['current_index'] = prev_state['current_index']
                    game_state['current_prefix'] = prev_state['current_prefix']
                    game_state['current_interval'] = prev_state['current_interval']
                    game_state['consecutive_failures'] = prev_state['consecutive_failures']
                    game_state['max_consecutive_failures'] = prev_state['max_consecutive_failures']
                    game_state['total_predictions'] = prev_state['total_predictions']
                    game_state['total_failures'] = prev_state['total_failures']
                    game_state['total_forced_predictions'] = prev_state['total_forced_predictions']
                    game_state['total_skipped_predictions'] = prev_state.get('total_skipped_predictions', game_state['total_skipped_predictions'])
                    game_state['history'] = prev_state['history'].copy()
                    st.rerun()
    else:
        # ì˜ˆì¸¡ê°’ì´ ì—†ìŒ
        st.markdown("---")
        st.markdown("#### ì‹¤ì œê°’ ì„ íƒ (ì˜ˆì¸¡ê°’ ì—†ìŒ)")
        
        # ì´ì „ ìƒíƒœ ì €ì¥ (ì·¨ì†Œ ê¸°ëŠ¥ìš©)
        if 'previous_game_state' not in st.session_state or st.session_state.get('previous_game_state_step', -1) != game_state['current_step']:
            st.session_state.previous_game_state = {
                'current_step': game_state['current_step'],
                'current_index': game_state['current_index'],
                'current_prefix': game_state['current_prefix'],
                'current_interval': game_state['current_interval'],
                'consecutive_failures': game_state['consecutive_failures'],
                'max_consecutive_failures': game_state['max_consecutive_failures'],
                'total_predictions': game_state['total_predictions'],
                'total_failures': game_state['total_failures'],
                'total_forced_predictions': game_state['total_forced_predictions'],
                'total_skipped_predictions': game_state['total_skipped_predictions'],
                'history': game_state['history'].copy()
            }
            st.session_state.previous_game_state_step = game_state['current_step']
        
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 1])
        with col_btn1:
            if st.button("ğŸ”´ B", use_container_width=True, key=f"live_game_btn_no_pred_b_{game_state['current_step']}"):
                actual_value = 'b'
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': False,
                    'current_interval': current_interval,
                    'has_prediction': False,
                    'validated': False,
                    'skipped': False
                })
                
                # ê°„ê²© ì¦ê°€
                game_state['current_interval'] += 1
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn2:
            if st.button("ğŸ”µ P", use_container_width=True, key=f"live_game_btn_no_pred_p_{game_state['current_step']}"):
                actual_value = 'p'
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                game_state['history'].append({
                    'step': game_state['current_step'] + 1,
                    'prefix': current_prefix,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': False,
                    'current_interval': current_interval,
                    'has_prediction': False,
                    'validated': False,
                    'skipped': False
                })
                
                # ê°„ê²© ì¦ê°€
                game_state['current_interval'] += 1
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰
                game_state['current_step'] += 1
                game_state['current_index'] += 1
                game_state['current_prefix'] = get_next_prefix(
                    current_prefix,
                    actual_value,
                    game_state['window_size']
                )
                
                st.rerun()
        
        with col_btn3:
            if st.button("â†©ï¸ ì·¨ì†Œ", use_container_width=True, key=f"live_game_btn_no_pred_cancel_{game_state['current_step']}"):
                if 'previous_game_state' in st.session_state:
                    prev_state = st.session_state.previous_game_state
                    # ì´ì „ ìƒíƒœë¡œ ë³µì›
                    game_state['current_step'] = prev_state['current_step']
                    game_state['current_index'] = prev_state['current_index']
                    game_state['current_prefix'] = prev_state['current_prefix']
                    game_state['current_interval'] = prev_state['current_interval']
                    game_state['consecutive_failures'] = prev_state['consecutive_failures']
                    game_state['max_consecutive_failures'] = prev_state['max_consecutive_failures']
                    game_state['total_predictions'] = prev_state['total_predictions']
                    game_state['total_failures'] = prev_state['total_failures']
                    game_state['total_forced_predictions'] = prev_state['total_forced_predictions']
                    game_state['total_skipped_predictions'] = prev_state.get('total_skipped_predictions', game_state['total_skipped_predictions'])
                    game_state['history'] = prev_state['history'].copy()
                    st.rerun()
    
    # ìƒì„¸ íˆìŠ¤í† ë¦¬ í‘œì‹œ
    if len(game_state['history']) > 0:
        st.markdown("---")
        with st.expander("ğŸ“Š ìƒì„¸ íˆìŠ¤í† ë¦¬", expanded=True):
            history_data = []
            history_sorted = sorted(game_state['history'], key=lambda x: x.get('step', 0), reverse=True)
            
            for entry in history_sorted[:50]:  # ìµœì‹  50ê°œë§Œ í‘œì‹œ
                is_correct = entry.get('is_correct')
                match_status = 'âœ…' if is_correct else ('âŒ' if is_correct is False else '-')
                has_prediction = entry.get('has_prediction', False)
                is_forced = entry.get('is_forced', False)
                validated = entry.get('validated', False)
                skipped = entry.get('skipped', False)
                
                forced_mark = 'âš¡' if is_forced else ''
                skipped_mark = 'â­ï¸' if skipped else ''
                validated_mark = 'âœ“' if validated else ''
                
                history_data.append({
                    'Step': entry.get('step', 0),
                    'Prefix': entry.get('prefix', ''),
                    'ì˜ˆì¸¡': f"{entry.get('predicted', '-')}{forced_mark}{skipped_mark}",
                    'ì‹¤ì œê°’': entry.get('actual', '-'),
                    'ì¼ì¹˜': match_status,
                    'ê²€ì¦': validated_mark,
                    'ì‹ ë¢°ë„': f"{entry.get('confidence', 0):.1f}%" if has_prediction else '-',
                    'ê°„ê²©': entry.get('current_interval', 0) if not has_prediction else 0
                })
            
            if len(history_data) > 0:
                history_df = pd.DataFrame(history_data)
                st.dataframe(history_df, use_container_width=True, hide_index=True)
                
                if len(game_state['history']) > 50:
                    st.caption(f"ğŸ’¡ ì „ì²´ {len(game_state['history'])}ê°œ ì¤‘ ìµœì‹  50ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
    
    # ê²Œì„ ì™„ë£Œ ì²´í¬ (ë©”ì‹œì§€ ì œê±° - ì„±ëŠ¥ ê°œì„ )
    if game_state['current_index'] >= len(game_state['grid_string']):
        st.markdown("---")
        
        accuracy = ((game_state['total_predictions'] - game_state['total_failures']) / game_state['total_predictions'] * 100) if game_state['total_predictions'] > 0 else 0.0
        
        col_final1, col_final2, col_final3, col_final4 = st.columns(4)
        with col_final1:
            st.metric("ì´ ìŠ¤í…", game_state['current_step'])
        with col_final2:
            st.metric("ì´ ì˜ˆì¸¡", game_state['total_predictions'])
        with col_final3:
            st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", game_state['max_consecutive_failures'])
        with col_final4:
            st.metric("ì •í™•ë„", f"{accuracy:.2f}%")

def progressive_validate_forced_prediction_hypothesis(
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    start_ratio=70,
    step_ratio=5,
    max_ratio=100
):
    """
    ê°•ì œ ì˜ˆì¸¡ ê°€ì„¤ ì ì§„ì  ê²€ì¦
    
    Args:
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        start_ratio: ì‹œì‘ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 70)
        step_ratio: ë‹¨ê³„ë³„ ì¦ê°€ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 5)
        max_ratio: ìµœëŒ€ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 100)
    
    Returns:
        dict: ì ì§„ì  ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # ì „ì²´ grid_string ê°œìˆ˜ í™•ì¸
        count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings"
        count_df = pd.read_sql_query(count_query, conn)
        total_count = count_df.iloc[0]['count'] if len(count_df) > 0 else 0
        
        if total_count == 0:
            return None
        
        # ëª¨ë“  grid_stringì„ id ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë¡œë“œ
        query = "SELECT id FROM preprocessed_grid_strings ORDER BY id"
        df_all_ids = pd.read_sql_query(query, conn)
        all_ids = df_all_ids['id'].tolist()
        
        if len(all_ids) == 0:
            return None
        
        steps_results = []
        max_consecutive_failures_all_steps = 0
        max_consecutive_matches_all_steps = 0
        total_tested_grid_strings = 0
        total_steps_all = 0
        total_failures_all = 0
        total_accuracy_sum = 0.0
        step_count = 0
        
        # ì ì§„ì  ê²€ì¦ ì‹¤í–‰
        current_ratio = start_ratio
        while current_ratio < max_ratio:
            # í•™ìŠµ ë°ì´í„° ë²”ìœ„ ê³„ì‚°
            train_index = int(total_count * current_ratio / 100)
            if train_index >= len(all_ids):
                break
            
            train_cutoff_id = all_ids[train_index - 1] if train_index > 0 else all_ids[0]
            
            # ê²€ì¦ ë°ì´í„° ë²”ìœ„ ê³„ì‚°
            validation_end_ratio = min(current_ratio + step_ratio, max_ratio)
            validation_end_index = int(total_count * validation_end_ratio / 100)
            
            if validation_end_index >= len(all_ids):
                validation_end_index = len(all_ids)
            
            if validation_end_index <= train_index:
                break
            
            # ê²€ì¦ ì‹œì‘ IDì™€ ì¢…ë£Œ ID
            # ê²€ì¦ ì‹œì‘ IDëŠ” í•™ìŠµ ë°ì´í„° ë²”ìœ„ ë°”ë¡œ ë‹¤ìŒ ID
            if train_index < len(all_ids):
                validation_start_id = all_ids[train_index] if train_index < len(all_ids) else all_ids[-1]
            else:
                validation_start_id = all_ids[-1]
            
            validation_end_id = all_ids[validation_end_index - 1] if validation_end_index > 0 and validation_end_index <= len(all_ids) else all_ids[-1]
            
            # ë‹¨ì¼ ë‹¨ê³„ ê²€ì¦ ì‹¤í–‰
            validation_results = validate_forced_prediction_hypothesis(
                train_cutoff_id,
                validation_start_id,
                validation_end_id,
                window_size=window_size,
                method=method
            )
            
            if validation_results is not None:
                steps_results.append({
                    'train_ratio': current_ratio,
                    'validation_start_ratio': current_ratio,
                    'validation_end_ratio': validation_end_ratio,
                    'validation_results': validation_results
                })
                
                # í†µê³„ ì§‘ê³„
                max_consecutive_failures_all_steps = max(
                    max_consecutive_failures_all_steps,
                    validation_results['max_consecutive_failures']
                )
                max_consecutive_matches_all_steps = max(
                    max_consecutive_matches_all_steps,
                    validation_results.get('max_consecutive_matches', 0)
                )
                total_tested_grid_strings += validation_results['tested_grid_strings']
                total_steps_all += validation_results['total_steps']
                total_failures_all += validation_results['total_failures']
                total_accuracy_sum += validation_results['accuracy']
                step_count += 1
            
            # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
            current_ratio += step_ratio
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        avg_max_consecutive_failures = (
            sum(s['validation_results']['max_consecutive_failures'] for s in steps_results) / len(steps_results)
            if len(steps_results) > 0 else 0.0
        )
        avg_accuracy = total_accuracy_sum / step_count if step_count > 0 else 0.0
        
        # í‰ê·  ìµœëŒ€ ì—°ì† ì¼ì¹˜ ìˆ˜ ê³„ì‚°
        avg_max_consecutive_matches = (
            sum(s['validation_results'].get('max_consecutive_matches', 0) for s in steps_results) / len(steps_results)
            if len(steps_results) > 0 else 0.0
        )
        
        return {
            'window_size': window_size,
            'method': method,
            'steps': steps_results,
            'summary': {
                'max_consecutive_failures_all_steps': max_consecutive_failures_all_steps,
                'max_consecutive_matches_all_steps': max_consecutive_matches_all_steps,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'avg_max_consecutive_matches': avg_max_consecutive_matches,
                'total_tested_grid_strings': total_tested_grid_strings,
                'total_steps': total_steps_all,
                'total_failures': total_failures_all,
                'avg_accuracy': avg_accuracy,
                'step_count': step_count
            }
        }
        
    except Exception as e:
        st.error(f"ì ì§„ì  ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def main():
    # í…Œì´ë¸” ìƒì„± (ì•± ì‹œì‘ ì‹œ)
    if 'validation_tables_created' not in st.session_state:
        if create_validation_tables():
            st.session_state.validation_tables_created = True
        else:
            st.error("í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨")
            return
    st.title("ğŸŒ³ ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦")
    st.markdown("ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìë™ìœ¼ë¡œ ê²€ì¦í•˜ì—¬ ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # ì„¤ì • ì„¹ì…˜
    with st.form("validation_interactive_settings_form", clear_on_submit=False):
        st.markdown("### âš™ï¸ ì„¤ì •")
        
        col_setting1, col_setting2, col_setting3 = st.columns(3)
        
        with col_setting1:
            window_size = st.selectbox(
                "ìœˆë„ìš° í¬ê¸°",
                options=[5, 6, 7, 8, 9],
                index=2,  # 7ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
                key="validation_interactive_window_size",
                help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ìœˆë„ìš° í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col_setting2:
            method = st.selectbox(
                "ì˜ˆì¸¡ ë°©ë²•",
                options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
                index=0,
                key="validation_interactive_method",
                help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col_setting3:
            use_threshold = st.checkbox(
                "ì„ê³„ê°’ ì „ëµ ì‚¬ìš©",
                value=True,
                key="validation_interactive_use_threshold",
                help="ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•˜ë„ë¡ ì„¤ì •"
            )
            threshold = None
            if use_threshold:
                threshold = st.number_input(
                    "ì„ê³„ê°’ (%)",
                    min_value=0,
                    max_value=100,
                    value=60,
                    step=1,
                    key="validation_interactive_threshold",
                    help="ì´ ì‹ ë¢°ë„ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤"
                )
        
        # ìµœëŒ€ ê°„ê²© ì„¤ì • (ê°•ì œ ì˜ˆì¸¡ìš©)
        col_setting4, col_setting5 = st.columns(2)
        with col_setting4:
            max_interval = st.number_input(
                "ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© (ìŠ¤í…)",
                min_value=1,
                max_value=20,
                value=6,
                step=1,
                key="validation_interactive_max_interval",
                help="ì´ ê°„ê²©ì„ ë„˜ê¸°ë©´ ì„ê³„ê°’ ë¬´ì‹œí•˜ê³  ê°•ì œ ì˜ˆì¸¡í•©ë‹ˆë‹¤"
            )
        
        with col_setting5:
            # ê¸°ì¤€ Grid String ID ì„ íƒ
            df_all_strings = load_preprocessed_data()
            if len(df_all_strings) > 0:
                grid_string_options = []
                for _, row in df_all_strings.iterrows():
                    grid_string_options.append((row['id'], row['created_at']))
                
                grid_string_options.sort(key=lambda x: x[0], reverse=True)
                
                current_selected = st.session_state.get('validation_interactive_cutoff_id', None)
                default_index = 0
                if current_selected is not None:
                    option_ids = [None] + [opt[0] for opt in grid_string_options]
                    if current_selected in option_ids:
                        default_index = option_ids.index(current_selected)
                
                selected_cutoff_id = st.selectbox(
                    "ê¸°ì¤€ Grid String ID (ì´ ID ì´í›„ì˜ ë°ì´í„° ê²€ì¦)",
                    options=[None] + [opt[0] for opt in grid_string_options],
                    format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else next((f"ID {opt[0]} - {opt[1]}" for opt in grid_string_options if opt[0] == x), f"ID {x} ì´í›„"),
                    index=default_index,
                    key="validation_interactive_cutoff_id_select"
                )
                
                if selected_cutoff_id is not None:
                    selected_info = df_all_strings[df_all_strings['id'] == selected_cutoff_id].iloc[0]
                    st.info(f"ì„ íƒëœ ê¸°ì¤€: ID {selected_cutoff_id} (ê¸¸ì´: {selected_info['string_length']}, ìƒì„±ì¼: {selected_info['created_at']})")
                    
                    # ì´í›„ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                    conn = get_db_connection()
                    if conn is not None:
                        try:
                            count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings WHERE id > ?"
                            count_df = pd.read_sql_query(count_query, conn, params=[selected_cutoff_id])
                            after_count = count_df.iloc[0]['count']
                            st.caption(f"ê²€ì¦ ëŒ€ìƒ: {after_count}ê°œì˜ grid_string")
                        except:
                            pass
                        finally:
                            conn.close()
            else:
                selected_cutoff_id = None
                st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê²€ì¦ ì‹¤í–‰ ë²„íŠ¼
        if st.form_submit_button("ê²€ì¦ ì‹¤í–‰", type="primary", use_container_width=True):
            if selected_cutoff_id is None:
                st.warning("âš ï¸ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                st.session_state.validation_interactive_cutoff_id = selected_cutoff_id
                st.session_state.validation_interactive_results = None
                st.rerun()
    
    # ê²€ì¦ ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œ
    if 'validation_interactive_cutoff_id' in st.session_state and st.session_state.validation_interactive_cutoff_id is not None:
        cutoff_id = st.session_state.validation_interactive_cutoff_id
        
        # í˜„ì¬ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        window_size = st.session_state.get('validation_interactive_window_size', 7)
        method = st.session_state.get('validation_interactive_method', 'ë¹ˆë„ ê¸°ë°˜')
        use_threshold = st.session_state.get('validation_interactive_use_threshold', True)
        threshold = st.session_state.get('validation_interactive_threshold', 60) if use_threshold else None
        max_interval = st.session_state.get('validation_interactive_max_interval', 6)
        
        # ê²°ê³¼ê°€ ìºì‹œë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‹¤í–‰ (ë‘ ì „ëµ ëª¨ë‘)
        if 'validation_interactive_results_default' in st.session_state and 'validation_interactive_results_reverse' in st.session_state:
            batch_results_default = st.session_state.validation_interactive_results_default
            batch_results_reverse = st.session_state.validation_interactive_results_reverse
        else:
            with st.spinner("ê²€ì¦ ì‹¤í–‰ ì¤‘... (ê¸°ë³¸ ì „ëµ + ë°˜ëŒ€ ì„ íƒ ì „ëµ)"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    # ê¸°ë³¸ ì „ëµ ì‹¤í–‰
                    status_text.text("ê¸°ë³¸ ì „ëµ ê²€ì¦ ì¤‘...")
                    progress_bar.progress(0.3)
                    batch_results_default = batch_validate_interactive_multi_step_scenario(
                        cutoff_id,
                        window_size=window_size,
                        method=method,
                        use_threshold=use_threshold,
                        threshold=threshold if use_threshold else 60,
                        max_interval=max_interval,
                        reverse_forced_prediction=False
                    )
                    
                    # ë°˜ëŒ€ ì„ íƒ ì „ëµ ì‹¤í–‰
                    status_text.text("ë°˜ëŒ€ ì„ íƒ ì „ëµ ê²€ì¦ ì¤‘...")
                    progress_bar.progress(0.7)
                    batch_results_reverse = batch_validate_interactive_multi_step_scenario(
                        cutoff_id,
                        window_size=window_size,
                        method=method,
                        use_threshold=use_threshold,
                        threshold=threshold if use_threshold else 60,
                        max_interval=max_interval,
                        reverse_forced_prediction=True
                    )
                    
                    if batch_results_default is not None and batch_results_reverse is not None:
                        st.session_state.validation_interactive_results_default = batch_results_default
                        st.session_state.validation_interactive_results_reverse = batch_results_reverse
                        
                        # ì‹ ë¢°ë„ í†µê³„ ìˆ˜ì§‘ ë° ì €ì¥ (ê¸°ë³¸ ì „ëµ)
                        if 'all_history' in batch_results_default:
                            confidence_stats_default = collect_confidence_statistics(
                                batch_results_default['all_history'],
                                validation_id=None,
                                strategy_type='default'
                            )
                            if confidence_stats_default:
                                save_confidence_statistics(
                                    confidence_stats_default,
                                    validation_id=None,
                                    strategy_type='default'
                                )
                        
                        # ì‹ ë¢°ë„ í†µê³„ ìˆ˜ì§‘ ë° ì €ì¥ (ë°˜ëŒ€ ì„ íƒ ì „ëµ)
                        if 'all_history' in batch_results_reverse:
                            confidence_stats_reverse = collect_confidence_statistics(
                                batch_results_reverse['all_history'],
                                validation_id=None,
                                strategy_type='reverse'
                            )
                            if confidence_stats_reverse:
                                save_confidence_statistics(
                                    confidence_stats_reverse,
                                    validation_id=None,
                                    strategy_type='reverse'
                                )
                        
                        # ê²€ì¦ ê²°ê³¼ ìë™ ì €ì¥ (ë¹„í™œì„±í™”ë¨)
                        # validation_id = save_validation_results(
                        #     cutoff_id,
                        #     window_size,
                        #     method,
                        #     use_threshold,
                        #     threshold if use_threshold else 60,
                        #     max_interval,
                        #     batch_results_default,
                        #     batch_results_reverse
                        # )
                        # 
                        # if validation_id:
                        #     st.session_state.validation_interactive_saved_id = validation_id
                        #     st.success(f"âœ… ê²€ì¦ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {validation_id[:8]}...)")
                        # else:
                        #     st.warning("âš ï¸ ê²€ì¦ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error("ê²€ì¦ ì‹¤í–‰ ì‹¤íŒ¨")
                        batch_results_default = None
                        batch_results_reverse = None
                        
                except Exception as e:
                    st.error(f"ê²€ì¦ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    import traceback
                    st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                    batch_results_default = None
                    batch_results_reverse = None
                finally:
                    progress_bar.empty()
                    status_text.empty()
        
        # ê²°ê³¼ ë¹„êµ í‘œì‹œ
        if batch_results_default is not None and batch_results_reverse is not None and len(batch_results_default['results']) > 0 and len(batch_results_reverse['results']) > 0:
            summary_default = batch_results_default['summary']
            summary_reverse = batch_results_reverse['summary']
            results_default = batch_results_default['results']
            results_reverse = batch_results_reverse['results']
            
            # ì „ëµ ë¹„êµ í—¤ë”
            st.markdown("---")
            st.markdown("### ì „ëµ ë¹„êµ")
            col1, col2 = st.columns(2)
            with col1:
                st.info("ğŸ“Š **ê¸°ë³¸ ì „ëµ**: ê°•ì œ ì˜ˆì¸¡ ì‹œ í˜„ì¬ ì˜ˆì¸¡ê°’ ì‚¬ìš©")
            with col2:
                st.info("ğŸ“Š **ë°˜ëŒ€ ì„ íƒ ì „ëµ**: ê°•ì œ ì˜ˆì¸¡ ì‹œ ë°˜ëŒ€ ê°’ ì„ íƒ")
            
            # ìš”ì•½ í†µê³„ ë¹„êµ
            st.markdown("---")
            st.markdown("### ìš”ì•½ í†µê³„ ë¹„êµ")
            
            # ë¹„êµ í…Œì´ë¸”
            comparison_data = []
            comparison_data.append({
                'í•­ëª©': 'ì´ Grid String ìˆ˜',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default['total_grid_strings']}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse['total_grid_strings']}",
                'ì°¨ì´': f"{summary_reverse['total_grid_strings'] - summary_default['total_grid_strings']:+d}"
            })
            comparison_data.append({
                'í•­ëª©': 'í‰ê·  ì •í™•ë„ (%)',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default['avg_accuracy']:.2f}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse['avg_accuracy']:.2f}",
                'ì°¨ì´': f"{summary_reverse['avg_accuracy'] - summary_default['avg_accuracy']:+.2f}"
            })
            comparison_data.append({
                'í•­ëª©': 'ìµœëŒ€ ì—°ì† ì‹¤íŒ¨',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default['max_consecutive_failures']}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse['max_consecutive_failures']}",
                'ì°¨ì´': f"{summary_reverse['max_consecutive_failures'] - summary_default['max_consecutive_failures']:+d}"
            })
            comparison_data.append({
                'í•­ëª©': 'í‰ê·  ìµœëŒ€ ì—°ì† ì‹¤íŒ¨',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default['avg_max_consecutive_failures']:.2f}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse['avg_max_consecutive_failures']:.2f}",
                'ì°¨ì´': f"{summary_reverse['avg_max_consecutive_failures'] - summary_default['avg_max_consecutive_failures']:+.2f}"
            })
            comparison_data.append({
                'í•­ëª©': 'ì˜ˆì¸¡ë¥  (%)',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default['prediction_rate']:.2f}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse['prediction_rate']:.2f}",
                'ì°¨ì´': f"{summary_reverse['prediction_rate'] - summary_default['prediction_rate']:+.2f}"
            })
            comparison_data.append({
                'í•­ëª©': 'ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ (%)',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default.get('forced_prediction_rate', 0):.2f}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse.get('forced_prediction_rate', 0):.2f}",
                'ì°¨ì´': f"{summary_reverse.get('forced_prediction_rate', 0) - summary_default.get('forced_prediction_rate', 0):+.2f}"
            })
            comparison_data.append({
                'í•­ëª©': 'ê°•ì œ ì˜ˆì¸¡ ì„±ê³µ ë¹„ìœ¨ (%)',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default.get('forced_success_rate', 0):.2f}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse.get('forced_success_rate', 0):.2f}",
                'ì°¨ì´': f"{summary_reverse.get('forced_success_rate', 0) - summary_default.get('forced_success_rate', 0):+.2f}"
            })
            comparison_data.append({
                'í•­ëª©': 'ì´ ìŠ¤í… ìˆ˜',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default['total_steps']}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse['total_steps']}",
                'ì°¨ì´': f"{summary_reverse['total_steps'] - summary_default['total_steps']:+d}"
            })
            comparison_data.append({
                'í•­ëª©': 'ì´ ì‹¤íŒ¨ íšŸìˆ˜',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default['total_failures']}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse['total_failures']}",
                'ì°¨ì´': f"{summary_reverse['total_failures'] - summary_default['total_failures']:+d}"
            })
            comparison_data.append({
                'í•­ëª©': 'ì´ ì˜ˆì¸¡ íšŸìˆ˜',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default['total_predictions']}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse['total_predictions']}",
                'ì°¨ì´': f"{summary_reverse['total_predictions'] - summary_default['total_predictions']:+d}"
            })
            comparison_data.append({
                'í•­ëª©': 'ì´ ê°•ì œ ì˜ˆì¸¡ íšŸìˆ˜',
                'ê¸°ë³¸ ì „ëµ': f"{summary_default.get('total_forced_predictions', 0)}",
                'ë°˜ëŒ€ ì„ íƒ ì „ëµ': f"{summary_reverse.get('total_forced_predictions', 0)}",
                'ì°¨ì´': f"{summary_reverse.get('total_forced_predictions', 0) - summary_default.get('total_forced_predictions', 0):+d}"
            })
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)
            
            # ì‹ ë¢°ë„ êµ¬ê°„ë³„ í†µê³„ í‘œì‹œ
            st.markdown("---")
            st.markdown("### ğŸ“Š ì‹ ë¢°ë„ êµ¬ê°„ë³„ í†µê³„ (50-60% êµ¬ê°„)")
            
            # DBì—ì„œ ì‹ ë¢°ë„ í†µê³„ ì¡°íšŒ
            conn = get_db_connection()
            if conn is not None:
                try:
                    # ê¸°ë³¸ ì „ëµ í†µê³„
                    stats_query_default = """
                        SELECT confidence_range, total_predictions, matches, mismatches, 
                               match_rate, avg_confidence
                        FROM confidence_statistics
                        WHERE strategy_type = 'default'
                        ORDER BY confidence_range
                    """
                    stats_df_default = pd.read_sql_query(stats_query_default, conn)
                    
                    # ë°˜ëŒ€ ì„ íƒ ì „ëµ í†µê³„
                    stats_query_reverse = """
                        SELECT confidence_range, total_predictions, matches, mismatches, 
                               match_rate, avg_confidence
                        FROM confidence_statistics
                        WHERE strategy_type = 'reverse'
                        ORDER BY confidence_range
                    """
                    stats_df_reverse = pd.read_sql_query(stats_query_reverse, conn)
                    
                    if len(stats_df_default) > 0 or len(stats_df_reverse) > 0:
                        col_stats1, col_stats2 = st.columns(2)
                        
                        with col_stats1:
                            st.markdown("#### ê¸°ë³¸ ì „ëµ")
                            if len(stats_df_default) > 0:
                                st.dataframe(stats_df_default, use_container_width=True, hide_index=True)
                            else:
                                st.info("í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                        with col_stats2:
                            st.markdown("#### ë°˜ëŒ€ ì„ íƒ ì „ëµ")
                            if len(stats_df_reverse) > 0:
                                st.dataframe(stats_df_reverse, use_container_width=True, hide_index=True)
                            else:
                                st.info("í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ğŸ’¡ ì‹ ë¢°ë„ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²€ì¦ì„ ì‹¤í–‰í•˜ë©´ í†µê³„ê°€ ìˆ˜ì§‘ë©ë‹ˆë‹¤.")
                except Exception as e:
                    st.warning(f"ì‹ ë¢°ë„ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                finally:
                    conn.close()
            
            # ë§ˆì§€ë§‰ Grid String íˆìŠ¤í† ë¦¬ ìë™ í‘œì‹œ (ê²€ì¦ìš©)
            st.markdown("---")
            st.markdown("### ğŸ” ë§ˆì§€ë§‰ Grid String ê²€ì¦ íˆìŠ¤í† ë¦¬")
            st.markdown("**ì˜ë„ëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ë§ˆì§€ë§‰ grid_string_idì˜ ìƒì„¸ íˆìŠ¤í† ë¦¬**")
            
            if len(results_default) > 0 and len(results_reverse) > 0:
                # ë§ˆì§€ë§‰ grid_string_id ì°¾ê¸° (ë‘ ê²°ê³¼ëŠ” ê°™ì€ ìˆœì„œì´ë¯€ë¡œ ë§ˆì§€ë§‰ í•­ëª© ì‚¬ìš©)
                last_result_default = results_default[-1]
                last_result_reverse = results_reverse[-1]
                last_grid_id = last_result_default['grid_string_id']
                
                st.info(f"ğŸ“Œ **ê²€ì¦ ëŒ€ìƒ**: Grid String ID {last_grid_id} (ë§ˆì§€ë§‰ ê²€ì¦ëœ grid_string)")
                
                # ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸° ì˜µì…˜
                show_full_history = st.checkbox(
                    "ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸° (ê¸°ë³¸: ìµœê·¼ 50ê°œë§Œ í‘œì‹œ)",
                    value=False,
                    key="last_grid_full_history"
                )
                
                # ê¸°ë³¸ ì „ëµê³¼ ë°˜ëŒ€ ì„ íƒ ì „ëµ ëª¨ë‘ í‘œì‹œ
                col_last1, col_last2 = st.columns(2)
                
                with col_last1:
                    st.markdown("#### ê¸°ë³¸ ì „ëµ íˆìŠ¤í† ë¦¬")
                    
                    if last_result_default:
                        failure_history_default = get_failure_history_interactive(
                            last_grid_id,
                            cutoff_id,
                            window_size=window_size,
                            method=method,
                            use_threshold=use_threshold,
                            threshold=threshold if use_threshold else 60,
                            max_interval=max_interval,
                            reverse_forced_prediction=False
                        )
                        
                        if failure_history_default:
                            st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", f"{failure_history_default['max_consecutive_failures']}íšŒ")
                            st.metric("ì´ ìŠ¤í…", f"{failure_history_default['total_steps']}")
                            st.metric("ì´ ì˜ˆì¸¡", f"{failure_history_default['total_predictions']}")
                            st.metric("ì •í™•ë„", f"{failure_history_default['accuracy']:.2f}%")
                            
                            # íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
                            history_default = failure_history_default.get('history', [])
                            if len(history_default) > 0:
                                history_limit = None if show_full_history else 50
                                history_title = "##### ìƒì„¸ íˆìŠ¤í† ë¦¬" + (f" (ìµœì‹  {history_limit}ê°œ)" if history_limit else " (ì „ì²´)")
                                st.markdown(history_title)
                                history_data_default = []
                                # íˆìŠ¤í† ë¦¬ë¥¼ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ (step ë‚´ë¦¼ì°¨ìˆœ)
                                history_default_sorted = sorted(history_default, key=lambda x: x.get('step', 0), reverse=True)
                                display_history = history_default_sorted[:history_limit] if history_limit else history_default_sorted
                                
                                for entry in display_history:
                                    is_correct = entry.get('is_correct')
                                    match_status = 'âœ…' if is_correct else ('âŒ' if is_correct is False else '-')
                                    has_prediction = entry.get('has_prediction', False)
                                    is_forced = entry.get('is_forced', False)
                                    validated = entry.get('validated', False)
                                    
                                    forced_mark = 'âš¡' if is_forced else ''
                                    no_pred_mark = 'ğŸš«' if not has_prediction else ''
                                    validated_mark = 'âœ“' if validated else ''
                                    
                                    history_data_default.append({
                                        'Step': entry.get('step', 0),
                                        'Prefix': entry.get('prefix', ''),
                                        'ì˜ˆì¸¡': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}",
                                        'ì‹¤ì œê°’': entry.get('actual', '-'),
                                        'ì¼ì¹˜': match_status,
                                        'ê²€ì¦': validated_mark,
                                        'ì‹ ë¢°ë„': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                        'ê°„ê²©': entry.get('current_interval', 0) if not has_prediction else 0
                                    })
                                
                                history_df_default = pd.DataFrame(history_data_default)
                                st.dataframe(history_df_default, use_container_width=True, hide_index=True)
                                
                                if not show_full_history and len(history_default) > 50:
                                    st.caption(f"ğŸ’¡ ì „ì²´ {len(history_default)}ê°œ ì¤‘ ìµœì‹  50ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤. ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ë³´ë ¤ë©´ ìœ„ì˜ ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                
                with col_last2:
                    st.markdown("#### ë°˜ëŒ€ ì„ íƒ ì „ëµ íˆìŠ¤í† ë¦¬")
                    
                    if last_result_reverse:
                        failure_history_reverse = get_failure_history_interactive(
                            last_grid_id,
                            cutoff_id,
                            window_size=window_size,
                            method=method,
                            use_threshold=use_threshold,
                            threshold=threshold if use_threshold else 60,
                            max_interval=max_interval,
                            reverse_forced_prediction=True
                        )
                        
                        if failure_history_reverse:
                            st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", f"{failure_history_reverse['max_consecutive_failures']}íšŒ")
                            st.metric("ì´ ìŠ¤í…", f"{failure_history_reverse['total_steps']}")
                            st.metric("ì´ ì˜ˆì¸¡", f"{failure_history_reverse['total_predictions']}")
                            st.metric("ì •í™•ë„", f"{failure_history_reverse['accuracy']:.2f}%")
                            
                            # íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
                            history_reverse = failure_history_reverse.get('history', [])
                            if len(history_reverse) > 0:
                                history_limit = None if show_full_history else 50
                                history_title = "##### ìƒì„¸ íˆìŠ¤í† ë¦¬" + (f" (ìµœì‹  {history_limit}ê°œ)" if history_limit else " (ì „ì²´)")
                                st.markdown(history_title)
                                history_data_reverse = []
                                # íˆìŠ¤í† ë¦¬ë¥¼ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ (step ë‚´ë¦¼ì°¨ìˆœ)
                                history_reverse_sorted = sorted(history_reverse, key=lambda x: x.get('step', 0), reverse=True)
                                display_history = history_reverse_sorted[:history_limit] if history_limit else history_reverse_sorted
                                
                                for entry in display_history:
                                    is_correct = entry.get('is_correct')
                                    match_status = 'âœ…' if is_correct else ('âŒ' if is_correct is False else '-')
                                    has_prediction = entry.get('has_prediction', False)
                                    is_forced = entry.get('is_forced', False)
                                    validated = entry.get('validated', False)
                                    
                                    forced_mark = 'âš¡' if is_forced else ''
                                    no_pred_mark = 'ğŸš«' if not has_prediction else ''
                                    validated_mark = 'âœ“' if validated else ''
                                    
                                    history_data_reverse.append({
                                        'Step': entry.get('step', 0),
                                        'Prefix': entry.get('prefix', ''),
                                        'ì˜ˆì¸¡': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}",
                                        'ì‹¤ì œê°’': entry.get('actual', '-'),
                                        'ì¼ì¹˜': match_status,
                                        'ê²€ì¦': validated_mark,
                                        'ì‹ ë¢°ë„': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                        'ê°„ê²©': entry.get('current_interval', 0) if not has_prediction else 0
                                    })
                                
                                history_df_reverse = pd.DataFrame(history_data_reverse)
                                st.dataframe(history_df_reverse, use_container_width=True, hide_index=True)
                                
                                if not show_full_history and len(history_reverse) > 50:
                                    st.caption(f"ğŸ’¡ ì „ì²´ {len(history_reverse)}ê°œ ì¤‘ ìµœì‹  50ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤. ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ë³´ë ¤ë©´ ìœ„ì˜ ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                
                # ê²€ì¦ í¬ì¸íŠ¸ ì•ˆë‚´
                st.markdown("---")
                st.markdown("#### ğŸ” ê²€ì¦ í¬ì¸íŠ¸")
                st.markdown("""
                ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”:
                1. **ê°„ê²© ì¡°ê±´**: `validated` ì»¬ëŸ¼ì´ 'âœ“'ì¸ ìŠ¤í…ì—ì„œë§Œ ì‹¤ì œ ë¹„êµê°€ ìˆ˜í–‰ë˜ëŠ”ì§€ í™•ì¸
                2. **ê°•ì œ ì˜ˆì¸¡**: `âš¡` í‘œì‹œê°€ ìˆëŠ” ìŠ¤í…ì—ì„œ ê°•ì œ ì˜ˆì¸¡ì´ ì˜¬ë°”ë¥´ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ í™•ì¸
                3. **ì—°ì† ì‹¤íŒ¨ ì¶”ì **: ì—°ì†ìœ¼ë¡œ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ê°€ ì˜¬ë°”ë¥´ê²Œ ì¹´ìš´íŠ¸ë˜ëŠ”ì§€ í™•ì¸
                4. **ê°„ê²© ê³„ì‚°**: ì˜ˆì¸¡ì´ ì—†ì„ ë•Œ ê°„ê²©ì´ ì˜¬ë°”ë¥´ê²Œ ì¦ê°€í•˜ëŠ”ì§€ í™•ì¸
                5. **ë°˜ëŒ€ ì„ íƒ ì „ëµ**: ë°˜ëŒ€ ì„ íƒ ì „ëµì—ì„œ ê°•ì œ ì˜ˆì¸¡ ì‹œ ë°˜ëŒ€ ê°’ì´ ì„ íƒë˜ëŠ”ì§€ í™•ì¸
                """)
            else:
                st.warning("âš ï¸ ë§ˆì§€ë§‰ grid_string_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ìµœì  ì „ëµ ì¶”ì²œ
            st.markdown("---")
            st.markdown("### ìµœì  ì „ëµ ì¶”ì²œ")
            
            # ì ìˆ˜ ê³„ì‚° (ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ê°ì†Œê°€ ê°€ì¥ ì¤‘ìš”)
            default_score = (
                (100 - summary_default['max_consecutive_failures']) * 10 +
                summary_default['avg_accuracy'] * 0.1
            )
            reverse_score = (
                (100 - summary_reverse['max_consecutive_failures']) * 10 +
                summary_reverse['avg_accuracy'] * 0.1
            )
            
            if reverse_score > default_score:
                best_strategy = "ë°˜ëŒ€ ì„ íƒ ì „ëµ"
                best_summary = summary_reverse
                worst_summary = summary_default
                improvement = reverse_score - default_score
            else:
                best_strategy = "ê¸°ë³¸ ì „ëµ"
                best_summary = summary_default
                worst_summary = summary_reverse
                improvement = default_score - reverse_score
            
            st.success(f"âœ… **ì¶”ì²œ ì „ëµ**: {best_strategy}")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", 
                         f"{worst_summary['max_consecutive_failures']}íšŒ â†’ {best_summary['max_consecutive_failures']}íšŒ",
                         f"{best_summary['max_consecutive_failures'] - worst_summary['max_consecutive_failures']:+d}íšŒ")
            with col2:
                st.metric("í‰ê·  ì •í™•ë„",
                         f"{worst_summary['avg_accuracy']:.2f}% â†’ {best_summary['avg_accuracy']:.2f}%",
                         f"{best_summary['avg_accuracy'] - worst_summary['avg_accuracy']:+.2f}%")
            
            # ê°•ì œ ì˜ˆì¸¡ ì„±ê³µë¥  ë¹„êµ
            forced_success_default = summary_default.get('forced_success_rate', 0)
            forced_success_reverse = summary_reverse.get('forced_success_rate', 0)
            
            if forced_success_default < 30:
                st.warning(f"âš ï¸ ê¸°ë³¸ ì „ëµì˜ ê°•ì œ ì˜ˆì¸¡ ì„±ê³µë¥ ì´ {forced_success_default:.2f}%ë¡œ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤. ë°˜ëŒ€ ì„ íƒ ì „ëµì´ ë” íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # Grid Stringë³„ ë¹„êµ ê²°ê³¼
            comparison_results_data = []
            for i, result_default in enumerate(results_default):
                result_reverse = results_reverse[i] if i < len(results_reverse) else None
                if result_reverse is None:
                    continue
                
                grid_id = result_default['grid_string_id']
                comparison_results_data.append({
                    'Grid String ID': grid_id,
                    'ê¸°ë³¸_ìµœëŒ€ì—°ì†ì‹¤íŒ¨': result_default['max_consecutive_failures'],
                    'ë°˜ëŒ€_ìµœëŒ€ì—°ì†ì‹¤íŒ¨': result_reverse['max_consecutive_failures'],
                    'ìµœëŒ€ì—°ì†ì‹¤íŒ¨_ì°¨ì´': f"{result_reverse['max_consecutive_failures'] - result_default['max_consecutive_failures']:+d}",
                    'ê¸°ë³¸_ì •í™•ë„': f"{result_default['accuracy']:.2f}%",
                    'ë°˜ëŒ€_ì •í™•ë„': f"{result_reverse['accuracy']:.2f}%",
                    'ì •í™•ë„_ì°¨ì´': f"{result_reverse['accuracy'] - result_default['accuracy']:+.2f}%",
                    'ê¸°ë³¸_ê°•ì œì„±ê³µë¥ ': f"{result_default.get('forced_success_rate', 0):.2f}%",
                    'ë°˜ëŒ€_ê°•ì œì„±ê³µë¥ ': f"{result_reverse.get('forced_success_rate', 0):.2f}%"
                })
            
            comparison_results_df = pd.DataFrame(comparison_results_data)
            st.dataframe(comparison_results_df, use_container_width=True, hide_index=True)
            
            # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ë¶„í¬ ë¹„êµ
            st.markdown("---")
            st.markdown("### ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ë¶„í¬ ë¹„êµ")
            
            max_failures_default = [r['max_consecutive_failures'] for r in results_default]
            max_failures_reverse = [r['max_consecutive_failures'] for r in results_reverse]
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ê¸°ë³¸ ì „ëµ")
                max_failures_list = max_failures_default
                
                if len(max_failures_list) > 0:
                    max_value = max(max_failures_list)
                    
                    # êµ¬ê°„ë³„ ë¶„í¬ ê³„ì‚°
                    bins = defaultdict(int)
                    for value in max_failures_list:
                        if value == 0:
                            bins['0'] += 1
                        elif value <= 2:
                            bins['1-2'] += 1
                        elif value <= 5:
                            bins['3-5'] += 1
                        elif value <= 10:
                            bins['6-10'] += 1
                        else:
                            bins['11+'] += 1
                    
                    # íˆìŠ¤í† ê·¸ë¨ í‘œì‹œ
                    st.markdown("##### êµ¬ê°„ë³„ ë¶„í¬")
                    max_count = max(bins.values()) if bins else 1
                    
                    for bin_range, count in sorted(bins.items(), key=lambda x: {
                        '0': 0, '1-2': 1, '3-5': 2, '6-10': 3, '11+': 4
                    }.get(x[0], 5)):
                        ratio = (count / len(results_default) * 100) if len(results_default) > 0 else 0
                        bar_length = int((count / max_count) * 50) if max_count > 0 else 0
                        bar = 'â–ˆ' * bar_length
                        st.text(f"{bin_range:>8}: {bar} {count:>4}ê°œ ({ratio:>5.2f}%)")
                    
                    st.markdown("##### í†µê³„")
                    st.metric("ìµœì†Œê°’", min(max_failures_list))
                    st.metric("ìµœëŒ€ê°’", max(max_failures_list))
                    st.metric("í‰ê· ê°’", f"{summary_default['avg_max_consecutive_failures']:.2f}")
            
            with col2:
                st.markdown("#### ë°˜ëŒ€ ì„ íƒ ì „ëµ")
                max_failures_list = max_failures_reverse
                
                if len(max_failures_list) > 0:
                    max_value = max(max_failures_list)
                    
                    # êµ¬ê°„ë³„ ë¶„í¬ ê³„ì‚°
                    bins = defaultdict(int)
                    for value in max_failures_list:
                        if value == 0:
                            bins['0'] += 1
                        elif value <= 2:
                            bins['1-2'] += 1
                        elif value <= 5:
                            bins['3-5'] += 1
                        elif value <= 10:
                            bins['6-10'] += 1
                        else:
                            bins['11+'] += 1
                    
                    # íˆìŠ¤í† ê·¸ë¨ í‘œì‹œ
                    st.markdown("##### êµ¬ê°„ë³„ ë¶„í¬")
                    max_count = max(bins.values()) if bins else 1
                    
                    for bin_range, count in sorted(bins.items(), key=lambda x: {
                        '0': 0, '1-2': 1, '3-5': 2, '6-10': 3, '11+': 4
                    }.get(x[0], 5)):
                        ratio = (count / len(results_reverse) * 100) if len(results_reverse) > 0 else 0
                        bar_length = int((count / max_count) * 50) if max_count > 0 else 0
                        bar = 'â–ˆ' * bar_length
                        st.text(f"{bin_range:>8}: {bar} {count:>4}ê°œ ({ratio:>5.2f}%)")
                    
                    st.markdown("##### í†µê³„")
                    st.metric("ìµœì†Œê°’", min(max_failures_list))
                    st.metric("ìµœëŒ€ê°’", max(max_failures_list))
                    st.metric("í‰ê· ê°’", f"{summary_reverse['avg_max_consecutive_failures']:.2f}")
            
            # ìƒì„¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
            st.markdown("---")
            st.markdown("### ìƒì„¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ")
            
            # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ ë°œìƒí•œ Grid String ì„ íƒ (ë‘ ì „ëµ ì¤‘ ë” ë‚˜ìœ ê²°ê³¼ ê¸°ì¤€)
            high_failure_results = []
            for i, result_default in enumerate(results_default):
                result_reverse = results_reverse[i] if i < len(results_reverse) else None
                if result_reverse is None:
                    continue
                
                max_fail = max(result_default.get('max_consecutive_failures', 0), 
                              result_reverse.get('max_consecutive_failures', 0))
                if max_fail >= 5:
                    high_failure_results.append({
                        'grid_string_id': result_default['grid_string_id'],
                        'max_consecutive_failures': max_fail,
                        'default_accuracy': result_default.get('accuracy', 0),
                        'reverse_accuracy': result_reverse.get('accuracy', 0) if result_reverse else 0
                    })
            
            if len(high_failure_results) > 0:
                st.markdown("#### ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ë°œìƒ Grid String")
                
                failure_options = []
                for result in high_failure_results:
                    display_text = f"ID {result['grid_string_id']} - ìµœëŒ€ ì—°ì† ì‹¤íŒ¨: {result['max_consecutive_failures']}íšŒ - ê¸°ë³¸: {result['default_accuracy']:.2f}% / ë°˜ëŒ€: {result['reverse_accuracy']:.2f}%"
                    failure_options.append((result['grid_string_id'], display_text))
                
                selected_history_id = st.selectbox(
                    "Grid String ì„ íƒ",
                    options=[None] + [opt[0] for opt in failure_options],
                    format_func=lambda x: "ì„ íƒ ì•ˆí•¨" if x is None else f"ID {x}",
                    key="validation_interactive_selected_history_id"
                )
                
                if selected_history_id is not None:
                    col_hist1, col_hist2 = st.columns(2)
                    with col_hist1:
                        if st.button("ê¸°ë³¸ ì „ëµ íˆìŠ¤í† ë¦¬ ë³´ê¸°", key="validation_interactive_view_history_default"):
                            st.session_state.validation_interactive_view_history_id = selected_history_id
                            st.session_state.validation_interactive_view_history_strategy = 'default'
                            st.rerun()
                    with col_hist2:
                        if st.button("ë°˜ëŒ€ ì„ íƒ ì „ëµ íˆìŠ¤í† ë¦¬ ë³´ê¸°", key="validation_interactive_view_history_reverse"):
                            st.session_state.validation_interactive_view_history_id = selected_history_id
                            st.session_state.validation_interactive_view_history_strategy = 'reverse'
                            st.rerun()
                
                # ìƒì„¸ íˆìŠ¤í† ë¦¬ í‘œì‹œ
                if 'validation_interactive_view_history_id' in st.session_state:
                    history_id = st.session_state.validation_interactive_view_history_id
                    strategy_type = st.session_state.get('validation_interactive_view_history_strategy', 'default')
                    reverse_forced = (strategy_type == 'reverse')
                    
                    failure_history = get_failure_history_interactive(
                        history_id,
                        cutoff_id,
                        window_size=window_size,
                        method=method,
                        use_threshold=use_threshold,
                        threshold=threshold if use_threshold else 60,
                        max_interval=max_interval,
                        reverse_forced_prediction=reverse_forced
                    )
                    
                    if failure_history is not None:
                        st.markdown("---")
                        strategy_label = "ë°˜ëŒ€ ì„ íƒ ì „ëµ" if reverse_forced else "ê¸°ë³¸ ì „ëµ"
                        st.markdown(f"### Grid String ID {history_id} ìƒì„¸ íˆìŠ¤í† ë¦¬ ({strategy_label})")
                        
                        # ìš”ì•½ ì •ë³´
                        col1, col2, col3, col4, col5 = st.columns(5)
                        with col1:
                            st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", f"{failure_history['max_consecutive_failures']}íšŒ")
                        with col2:
                            st.metric("ì´ ìŠ¤í…", f"{failure_history['total_steps']}")
                        with col3:
                            st.metric("ì´ ì‹¤íŒ¨", f"{failure_history['total_failures']}")
                        with col4:
                            st.metric("ì´ ì˜ˆì¸¡", f"{failure_history['total_predictions']}")
                        with col5:
                            st.metric("ì •í™•ë„", f"{failure_history['accuracy']:.2f}%")
                        
                        # íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
                        st.markdown("#### ìƒì„¸ íˆìŠ¤í† ë¦¬")
                        history_data = []
                        history = failure_history.get('history', [])
                        
                        for entry in history:
                            is_correct = entry.get('is_correct')
                            match_status = 'âœ…' if is_correct else ('âŒ' if is_correct is False else '-')
                            has_prediction = entry.get('has_prediction', False)
                            is_forced = entry.get('is_forced', False)
                            
                            forced_mark = 'âš¡' if is_forced else ''
                            no_pred_mark = 'ğŸš«' if not has_prediction else ''
                            
                            history_data.append({
                                'Step': entry.get('step', 0),
                                'Prefix': entry.get('prefix', ''),
                                'ì˜ˆì¸¡': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}",
                                'ì‹¤ì œê°’': entry.get('actual', '-'),
                                'ì¼ì¹˜': match_status,
                                'ì‹ ë¢°ë„ (%)': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                'ê°„ê²©': entry.get('current_interval', 0) if not has_prediction else 0
                            })
                        
                        history_df = pd.DataFrame(history_data)
                        st.dataframe(history_df, use_container_width=True, hide_index=True)
            else:
                st.info("ğŸ’¡ ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ 5íšŒ ì´ìƒì¸ Grid Stringì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ’¡ ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ê²€ì¦ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        st.info("ğŸ’¡ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•˜ê³  ê²€ì¦ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    # ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤í‚µ ì „ëµ ê²€ì¦ ì„¹ì…˜
    st.markdown("---")
    st.header("ğŸ¯ ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤í‚µ ì „ëµ ê²€ì¦")
    st.markdown("""
    **ì „ëµ ì„¤ëª…:**
    - ê¸°ë³¸ ê·œì¹™ì€ ê¸°ì¡´ê³¼ ë™ì¼
    - ê°•ì œ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ 51% ë¯¸ë§Œì¸ ê²½ìš° í•´ë‹¹ ìŠ¤í…ì€ ìŠ¤í‚µ (ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰)
    - ìŠ¤í‚µ ìƒíƒœì—ì„œ ê°„ê²© ê³„ì‚°ì€ ë©ˆì¶¤ (ì¦ê°€í•˜ì§€ ì•ŠìŒ)
    - ë‹¤ìŒ ìŠ¤í…ì—ì„œ ì„ê³„ê°’ ë§Œì¡± ì˜ˆì¸¡ ë˜ëŠ” ì‹ ë¢°ë„ 51% ì´ìƒ ê°•ì œ ì˜ˆì¸¡ì´ ë‚˜ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°
    
    **ê²€ì¦ ëª©ì :**
    - ì‹ ë¢°ë„ 51% ë¯¸ë§Œì¸ ê°•ì œ ì˜ˆì¸¡ì˜ ì„±ê³µ í™•ë¥ ì´ ë‚®ì€ì§€ ê²€ì¦
    - ìŠ¤í‚µ ì „ëµì´ ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ë¥¼ ì¤„ì´ëŠ”ì§€ í™•ì¸
    """)
    
    # ì„¤ì • ì„¹ì…˜
    st.markdown("### âš™ï¸ ì„¤ì •")
    
    # ê¸°ì¤€ Grid String ID ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ (form ë°–ì— ìœ„ì¹˜)
    col_refresh_header = st.columns([1, 4])
    with col_refresh_header[0]:
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", key="confidence_skip_refresh_data", use_container_width=True):
            # ë°ì´í„° ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•´ ìºì‹œ ì œê±°
            if 'preprocessed_data_cache' in st.session_state:
                del st.session_state.preprocessed_data_cache
            st.rerun()
    with col_refresh_header[1]:
        st.caption("ë°ì´í„° ëª©ë¡ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤")
    
    # ë°ì´í„° ë¡œë“œ (form ë°–ì—ì„œ)
    df_all_strings_skip = load_preprocessed_data()
    grid_string_options_skip = []
    if len(df_all_strings_skip) > 0:
        for _, row in df_all_strings_skip.iterrows():
            grid_string_options_skip.append((row['id'], row['created_at']))
        grid_string_options_skip.sort(key=lambda x: x[0], reverse=True)
    
    with st.form("confidence_skip_settings_form", clear_on_submit=False):
        col_skip1, col_skip2, col_skip3 = st.columns(3)
        
        with col_skip1:
            skip_window_size = st.selectbox(
                "ìœˆë„ìš° í¬ê¸°",
                options=[5, 6, 7, 8, 9],
                index=0,
                key="confidence_skip_window_size",
                help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ìœˆë„ìš° í¬ê¸°"
            )
        
        with col_skip2:
            skip_method = st.selectbox(
                "ì˜ˆì¸¡ ë°©ë²•",
                options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
                index=0,
                key="confidence_skip_method",
                help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ë°©ë²•"
            )
        
        with col_skip3:
            skip_use_threshold = st.checkbox(
                "ì„ê³„ê°’ ì „ëµ ì‚¬ìš©",
                value=True,
                key="confidence_skip_use_threshold",
                help="ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡"
            )
            skip_threshold = None
            if skip_use_threshold:
                skip_threshold = st.number_input(
                    "ì„ê³„ê°’ (%)",
                    min_value=0,
                    max_value=100,
                    value=56,
                    step=1,
                    key="confidence_skip_threshold_value",
                    help="ì´ ì‹ ë¢°ë„ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡"
                )
        
        col_skip4, col_skip5 = st.columns(2)
        with col_skip4:
            skip_max_interval = st.number_input(
                "ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©",
                min_value=1,
                max_value=20,
                value=5,
                step=1,
                key="confidence_skip_max_interval",
                help="ì´ ê°„ê²©ì„ ë„˜ê¸°ë©´ ê°•ì œ ì˜ˆì¸¡"
            )
            
            # ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’ 2ê°œ ì„ íƒ
            st.markdown("**ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’**")
            col_threshold1, col_threshold2 = st.columns(2)
            with col_threshold1:
                skip_confidence_threshold_1 = st.number_input(
                    "ì„ê³„ê°’ 1 (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=50.9,
                    step=0.1,
                    key="confidence_skip_threshold_1",
                    help="ì²« ë²ˆì§¸ ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’"
                )
            with col_threshold2:
                skip_confidence_threshold_2 = st.number_input(
                    "ì„ê³„ê°’ 2 (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=51.9,
                    step=0.1,
                    key="confidence_skip_threshold_2",
                    help="ë‘ ë²ˆì§¸ ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’"
                )
        
        with col_skip5:
            # ê¸°ì¤€ Grid String ID ì„ íƒ
            if len(grid_string_options_skip) > 0:
                current_selected_skip = st.session_state.get('confidence_skip_cutoff_id', None)
                default_index_skip = 0
                if current_selected_skip is not None:
                    option_ids_skip = [None] + [opt[0] for opt in grid_string_options_skip]
                    if current_selected_skip in option_ids_skip:
                        default_index_skip = option_ids_skip.index(current_selected_skip)
                
                selected_cutoff_id_skip = st.selectbox(
                    "ê¸°ì¤€ Grid String ID",
                    options=[None] + [opt[0] for opt in grid_string_options_skip],
                    format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else next((f"ID {opt[0]} - {opt[1]}" for opt in grid_string_options_skip if opt[0] == x), f"ID {x} ì´í›„"),
                    index=default_index_skip,
                    key="confidence_skip_cutoff_id_select"
                )
                
                if selected_cutoff_id_skip is not None:
                    st.session_state.confidence_skip_cutoff_id = selected_cutoff_id_skip
            else:
                selected_cutoff_id_skip = None
                st.info("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê²€ì¦ ì‹¤í–‰ ë²„íŠ¼
        submitted = st.form_submit_button("ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê²€ì¦ ì‹¤í–‰", type="primary", use_container_width=True)
    
    # form ë°–ì—ì„œ submit ì²˜ë¦¬
    if submitted:
        # form ì•ˆì—ì„œ ì„ íƒëœ ê°’ì€ ìœ„ì ¯ì˜ keyë¥¼ í†µí•´ session_stateì— ìë™ ì €ì¥ë¨
        selected_cutoff_id_skip = st.session_state.get('confidence_skip_cutoff_id_select', None)
        if selected_cutoff_id_skip is None:
            st.warning("âš ï¸ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            # ì„ íƒëœ ê°’ì„ confidence_skip_cutoff_idì— ì €ì¥
            st.session_state.confidence_skip_cutoff_id = selected_cutoff_id_skip
            # ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’ì€ ìœ„ì ¯ì—ì„œ ìë™ìœ¼ë¡œ session_stateì— ì €ì¥ë˜ë¯€ë¡œ ì½ê¸°ë§Œ í•¨
            # ê²°ê³¼ ìºì‹œ ì œê±°í•˜ì—¬ ìƒˆë¡œ ì‹¤í–‰í•˜ë„ë¡ í•¨
            if 'confidence_skip_results_1' in st.session_state:
                del st.session_state.confidence_skip_results_1
            if 'confidence_skip_results_2' in st.session_state:
                del st.session_state.confidence_skip_results_2
            st.rerun()
    
    # ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê²€ì¦ ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œ
    if 'confidence_skip_cutoff_id' in st.session_state and st.session_state.confidence_skip_cutoff_id is not None:
        cutoff_id_skip = st.session_state.confidence_skip_cutoff_id
        
        # í˜„ì¬ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        skip_window_size = st.session_state.get('confidence_skip_window_size', 6)
        skip_method = st.session_state.get('confidence_skip_method', 'ë¹ˆë„ ê¸°ë°˜')
        skip_use_threshold = st.session_state.get('confidence_skip_use_threshold', True)
        skip_threshold_val = st.session_state.get('confidence_skip_threshold_value', 56) if skip_use_threshold else None
        skip_max_interval = st.session_state.get('confidence_skip_max_interval', 5)
        skip_confidence_threshold_1 = st.session_state.get('confidence_skip_threshold_1', 51)
        skip_confidence_threshold_2 = st.session_state.get('confidence_skip_threshold_2', 52)
        
        # ì²« ë²ˆì§¸ ì„ê³„ê°’ ê²€ì¦ ì‹¤í–‰
        if 'confidence_skip_results_1' in st.session_state and st.session_state.confidence_skip_results_1 is not None:
            batch_results_skip_1 = st.session_state.confidence_skip_results_1
        else:
            with st.spinner(f"ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê²€ì¦ ì‹¤í–‰ ì¤‘... (ì„ê³„ê°’ 1: {skip_confidence_threshold_1}%)"):
                try:
                    batch_results_skip_1 = batch_validate_interactive_multi_step_scenario_with_confidence_skip(
                        cutoff_id_skip,
                        window_size=skip_window_size,
                        method=skip_method,
                        use_threshold=skip_use_threshold,
                        threshold=skip_threshold_val if skip_use_threshold else 60,
                        max_interval=skip_max_interval,
                        reverse_forced_prediction=False,
                        confidence_skip_threshold=skip_confidence_threshold_1
                    )
                    
                    if batch_results_skip_1 is not None:
                        st.session_state.confidence_skip_results_1 = batch_results_skip_1
                    else:
                        batch_results_skip_1 = None
                        st.session_state.confidence_skip_results_1 = None
                except Exception as e:
                    st.error(f"ê²€ì¦ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    batch_results_skip_1 = None
                    st.session_state.confidence_skip_results_1 = None
        
        # ë‘ ë²ˆì§¸ ì„ê³„ê°’ ê²€ì¦ ì‹¤í–‰
        if 'confidence_skip_results_2' in st.session_state and st.session_state.confidence_skip_results_2 is not None:
            batch_results_skip_2 = st.session_state.confidence_skip_results_2
        else:
            with st.spinner(f"ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê²€ì¦ ì‹¤í–‰ ì¤‘... (ì„ê³„ê°’ 2: {skip_confidence_threshold_2}%)"):
                try:
                    batch_results_skip_2 = batch_validate_interactive_multi_step_scenario_with_confidence_skip(
                        cutoff_id_skip,
                        window_size=skip_window_size,
                        method=skip_method,
                        use_threshold=skip_use_threshold,
                        threshold=skip_threshold_val if skip_use_threshold else 60,
                        max_interval=skip_max_interval,
                        reverse_forced_prediction=False,
                        confidence_skip_threshold=skip_confidence_threshold_2
                    )
                    
                    if batch_results_skip_2 is not None:
                        st.session_state.confidence_skip_results_2 = batch_results_skip_2
                    else:
                        batch_results_skip_2 = None
                        st.session_state.confidence_skip_results_2 = None
                except Exception as e:
                    st.error(f"ê²€ì¦ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    batch_results_skip_2 = None
                    st.session_state.confidence_skip_results_2 = None
        
        # ì²« ë²ˆì§¸ ì„ê³„ê°’ ê²°ê³¼ í‘œì‹œ
        if batch_results_skip_1 is None:
            st.info("ğŸ’¡ ê²€ì¦ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
        elif len(batch_results_skip_1.get('results', [])) == 0:
            st.warning("âš ï¸ ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ì¤€ Grid String ID ì´í›„ì˜ ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            summary_skip_1 = batch_results_skip_1.get('summary', {})
            
            st.markdown("---")
            st.markdown(f"### ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê²€ì¦ ê²°ê³¼ (ì„ê³„ê°’ 1: {skip_confidence_threshold_1}%)")
            
            col_skip_result1, col_skip_result2, col_skip_result3, col_skip_result4, col_skip_result5, col_skip_result6 = st.columns(6)
            with col_skip_result1:
                st.metric("í‰ê·  ì •í™•ë„", f"{summary_skip_1.get('avg_accuracy', 0):.2f}%")
            with col_skip_result2:
                st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", f"{summary_skip_1.get('max_consecutive_failures', 0)}íšŒ")
            with col_skip_result3:
                st.metric("ì´ ìŠ¤í‚µ íšŸìˆ˜", f"{summary_skip_1.get('total_skipped_predictions', 0)}íšŒ")
            with col_skip_result4:
                st.metric("ì˜ˆì¸¡ë¥ ", f"{summary_skip_1.get('prediction_rate', 0):.2f}%")
            with col_skip_result5:
                first_success = summary_skip_1.get('avg_first_success_step')
                if first_success is not None:
                    st.metric("í‰ê·  ì²« ì„±ê³µ ìŠ¤í…", f"{first_success:.1f}")
                else:
                    st.metric("í‰ê·  ì²« ì„±ê³µ ìŠ¤í…", "-")
            with col_skip_result6:
                max_first_success = summary_skip_1.get('max_first_success_step')
                if max_first_success is not None and max_first_success > 0:
                    st.metric("ìµœëŒ€ ì²« ì„±ê³µ ìŠ¤í…", f"{max_first_success}")
                else:
                    st.metric("ìµœëŒ€ ì²« ì„±ê³µ ìŠ¤í…", "-")
            
            # ì¶”ê°€ í†µê³„ í‘œì‹œ
            st.markdown("---")
            st.markdown("#### ìƒì„¸ í†µê³„")
            detail_stats_1 = {
                'ì´ Grid String ìˆ˜': summary_skip_1.get('total_grid_strings', 0),
                'ì´ ìŠ¤í… ìˆ˜': summary_skip_1.get('total_steps', 0),
                'ì´ ì˜ˆì¸¡ íšŸìˆ˜': summary_skip_1.get('total_predictions', 0),
                'ì´ ì‹¤íŒ¨ íšŸìˆ˜': summary_skip_1.get('total_failures', 0),
                'ì´ ê°•ì œ ì˜ˆì¸¡ íšŸìˆ˜': summary_skip_1.get('total_forced_predictions', 0),
                'í‰ê·  ìµœëŒ€ ì—°ì† ì‹¤íŒ¨': f"{summary_skip_1.get('avg_max_consecutive_failures', 0):.2f}",
                'ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨': f"{summary_skip_1.get('forced_prediction_rate', 0):.2f}%",
                'ê°•ì œ ì˜ˆì¸¡ ì„±ê³µ ë¹„ìœ¨': f"{summary_skip_1.get('forced_success_rate', 0):.2f}%",
                'í‰ê·  ì²« ì„±ê³µ ìŠ¤í…': f"{summary_skip_1.get('avg_first_success_step', 0):.2f}" if summary_skip_1.get('avg_first_success_step') is not None else "-",
                'ìµœì†Œ ì²« ì„±ê³µ ìŠ¤í…': f"{summary_skip_1.get('min_first_success_step', 0)}" if summary_skip_1.get('min_first_success_step') is not None else "-",
                'ìµœëŒ€ ì²« ì„±ê³µ ìŠ¤í…': f"{summary_skip_1.get('max_first_success_step', 0)}" if summary_skip_1.get('max_first_success_step') is not None else "-",
                'ì„±ê³µì´ ìˆì—ˆë˜ Grid String ìˆ˜': summary_skip_1.get('total_with_success', 0)
            }
            detail_df_1 = pd.DataFrame([detail_stats_1])
            st.dataframe(detail_df_1, use_container_width=True, hide_index=True)
            
            # ì‹ ë¢°ë„ í†µê³„ í‘œì‹œ
            st.markdown("---")
            st.markdown("### ì‹ ë¢°ë„ êµ¬ê°„ë³„ í†µê³„ (ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ)")
            
            conn = get_db_connection()
            if conn is not None:
                try:
                    stats_query_skip = """
                        SELECT confidence_range, total_predictions, matches, mismatches, 
                               match_rate, avg_confidence
                        FROM confidence_statistics
                        WHERE strategy_type = 'confidence_skip'
                        ORDER BY confidence_range
                    """
                    stats_df_skip = pd.read_sql_query(stats_query_skip, conn)
                    
                    if len(stats_df_skip) > 0:
                        st.dataframe(stats_df_skip, use_container_width=True, hide_index=True)
                    else:
                        st.info("ğŸ’¡ ì‹ ë¢°ë„ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²€ì¦ì„ ì‹¤í–‰í•˜ë©´ í†µê³„ê°€ ìˆ˜ì§‘ë©ë‹ˆë‹¤.")
                except Exception as e:
                    st.warning(f"ì‹ ë¢°ë„ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                finally:
                    conn.close()
            
            # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ Grid String íˆìŠ¤í† ë¦¬ ìë™ í‘œì‹œ (ê²€ì¦ìš©)
            st.markdown("---")
            st.markdown("### ğŸ” ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ Grid String ê²€ì¦ íˆìŠ¤í† ë¦¬ (ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ)")
            st.markdown("**ì˜ë„ëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ ë°œìƒí•œ grid_string_idì˜ ìƒì„¸ íˆìŠ¤í† ë¦¬**")
            
            results_skip_1 = batch_results_skip_1.get('results', [])
            if len(results_skip_1) > 0:
                # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ ë°œìƒí•œ grid_string_id ì°¾ê¸°
                max_failure_result = max(results_skip_1, key=lambda x: x.get('max_consecutive_failures', 0))
                max_failure_grid_id = max_failure_result['grid_string_id']
                max_failure_count = max_failure_result.get('max_consecutive_failures', 0)
                
                st.info(f"ğŸ“Œ **ê²€ì¦ ëŒ€ìƒ**: Grid String ID {max_failure_grid_id} (ìµœëŒ€ ì—°ì† ì‹¤íŒ¨: {max_failure_count}íšŒ)")
                
                # ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸° ì˜µì…˜
                show_full_history_skip_1 = st.checkbox(
                    "ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸° (ê¸°ë³¸: ìµœê·¼ 50ê°œë§Œ í‘œì‹œ)",
                    value=False,
                    key="last_grid_full_history_skip_1"
                )
                
                # íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
                failure_history_skip_1 = validate_interactive_multi_step_scenario_with_confidence_skip(
                    max_failure_grid_id,
                    cutoff_id_skip,
                    window_size=skip_window_size,
                    method=skip_method,
                    use_threshold=skip_use_threshold,
                    threshold=skip_threshold_val if skip_use_threshold else 60,
                    max_interval=skip_max_interval,
                    reverse_forced_prediction=False,
                    confidence_skip_threshold=skip_confidence_threshold_1
                )
                
                if failure_history_skip_1:
                    st.markdown("#### ìš”ì•½ ì •ë³´")
                    col_hist1, col_hist2, col_hist3, col_hist4, col_hist5, col_hist6 = st.columns(6)
                    with col_hist1:
                        st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", f"{failure_history_skip_1['max_consecutive_failures']}íšŒ")
                    with col_hist2:
                        st.metric("ì´ ìŠ¤í…", f"{failure_history_skip_1['total_steps']}")
                    with col_hist3:
                        st.metric("ì´ ì˜ˆì¸¡", f"{failure_history_skip_1['total_predictions']}")
                    with col_hist4:
                        st.metric("ì´ ìŠ¤í‚µ", f"{failure_history_skip_1.get('total_skipped_predictions', 0)}íšŒ")
                    with col_hist5:
                        st.metric("ì •í™•ë„", f"{failure_history_skip_1['accuracy']:.2f}%")
                    with col_hist6:
                        first_success_step = failure_history_skip_1.get('first_success_step')
                        if first_success_step is not None:
                            st.metric("ì²« ì„±ê³µ ìŠ¤í…", f"{first_success_step}")
                        else:
                            st.metric("ì²« ì„±ê³µ ìŠ¤í…", "-")
                    
                    # íˆìŠ¤í† ë¦¬ í…Œì´ë¸” (ìµœì‹ ìˆœìœ¼ë¡œ í‘œì‹œ)
                    st.markdown("#### ìƒì„¸ íˆìŠ¤í† ë¦¬")
                    history_skip_1 = failure_history_skip_1.get('history', [])
                    if len(history_skip_1) > 0:
                        # íˆìŠ¤í† ë¦¬ë¥¼ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ (step ë‚´ë¦¼ì°¨ìˆœ)
                        history_skip_sorted_1 = sorted(history_skip_1, key=lambda x: x.get('step', 0), reverse=True)
                        
                        history_limit_skip_1 = None if show_full_history_skip_1 else 50
                        history_title_skip_1 = "##### ìƒì„¸ íˆìŠ¤í† ë¦¬" + (f" (ìµœì‹  {history_limit_skip_1}ê°œ)" if history_limit_skip_1 else " (ì „ì²´)")
                        st.markdown(history_title_skip_1)
                        history_data_skip_1 = []
                        # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ëœ íˆìŠ¤í† ë¦¬ì—ì„œ ìµœì‹  Nê°œ ì„ íƒ
                        display_history_skip_1 = history_skip_sorted_1[:history_limit_skip_1] if history_limit_skip_1 else history_skip_sorted_1
                        
                        for entry in display_history_skip_1:
                            is_correct = entry.get('is_correct')
                            match_status = 'âœ…' if is_correct else ('âŒ' if is_correct is False else '-')
                            has_prediction = entry.get('has_prediction', False)
                            is_forced = entry.get('is_forced', False)
                            validated = entry.get('validated', False)
                            skipped = entry.get('skipped', False)
                            
                            forced_mark = 'âš¡' if is_forced else ''
                            no_pred_mark = 'ğŸš«' if not has_prediction else ''
                            validated_mark = 'âœ“' if validated else ''
                            skipped_mark = 'â­ï¸' if skipped else ''
                            
                            history_data_skip_1.append({
                                'Step': entry.get('step', 0),
                                'Prefix': entry.get('prefix', ''),
                                'ì˜ˆì¸¡': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}{skipped_mark}",
                                'ì‹¤ì œê°’': entry.get('actual', '-'),
                                'ì¼ì¹˜': match_status,
                                'ê²€ì¦': validated_mark,
                                'ìŠ¤í‚µ': 'â­ï¸' if skipped else '',
                                'ì‹ ë¢°ë„': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                'ê°„ê²©': entry.get('current_interval', 0) if not has_prediction else 0
                            })
                        
                        history_df_skip_1 = pd.DataFrame(history_data_skip_1)
                        st.dataframe(history_df_skip_1, use_container_width=True, hide_index=True)
                        
                        if not show_full_history_skip_1 and len(history_skip_1) > 50:
                            st.caption(f"ğŸ’¡ ì „ì²´ {len(history_skip_1)}ê°œ ì¤‘ ìµœì‹  50ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤. ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ë³´ë ¤ë©´ ìœ„ì˜ ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                    
                    # ê²€ì¦ í¬ì¸íŠ¸ ì•ˆë‚´
                    st.markdown("---")
                    st.markdown("#### ğŸ” ê²€ì¦ í¬ì¸íŠ¸")
                    st.markdown("""
                    ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”:
                    1. **ìŠ¤í‚µ ê·œì¹™**: ê°•ì œ ì˜ˆì¸¡(`âš¡`)ì´ê³  ì‹ ë¢°ë„ê°€ 51% ë¯¸ë§Œì¸ ê²½ìš° `â­ï¸` í‘œì‹œê°€ ìˆëŠ”ì§€ í™•ì¸
                    2. **ê°„ê²© ê³„ì‚°**: ìŠ¤í‚µëœ ìŠ¤í…ì—ì„œ ê°„ê²©ì´ ì¦ê°€í•˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸ (ê°„ê²©ì´ ë©ˆì¶°ìˆëŠ”ì§€)
                    3. **ê²€ì¦ ìˆ˜í–‰**: `ê²€ì¦` ì»¬ëŸ¼ì´ 'âœ“'ì¸ ìŠ¤í…ì—ì„œë§Œ ì‹¤ì œ ë¹„êµê°€ ìˆ˜í–‰ë˜ëŠ”ì§€ í™•ì¸
                    4. **ì—°ì† ì‹¤íŒ¨ ì¶”ì **: ì—°ì†ìœ¼ë¡œ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ê°€ ì˜¬ë°”ë¥´ê²Œ ì¹´ìš´íŠ¸ë˜ëŠ”ì§€ í™•ì¸
                    5. **ë‹¤ìŒ ìŠ¤í… ì§„í–‰**: ìŠ¤í‚µ í›„ ë‹¤ìŒ ìŠ¤í…ì˜ prefixë¡œ ì˜ˆì¸¡ì´ ìˆ˜í–‰ë˜ëŠ”ì§€ í™•ì¸
                    """)
            else:
                st.info("ğŸ’¡ ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë‘ ë²ˆì§¸ ì„ê³„ê°’ ê²°ê³¼ í‘œì‹œ
        if batch_results_skip_2 is None:
            pass  # ì²« ë²ˆì§¸ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë‘ ë²ˆì§¸ë„ í‘œì‹œí•˜ì§€ ì•ŠìŒ
        elif len(batch_results_skip_2.get('results', [])) == 0:
            pass  # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í‘œì‹œí•˜ì§€ ì•ŠìŒ
        else:
            summary_skip_2 = batch_results_skip_2.get('summary', {})
            
            st.markdown("---")
            st.markdown(f"### ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê²€ì¦ ê²°ê³¼ (ì„ê³„ê°’ 2: {skip_confidence_threshold_2}%)")
            
            col_skip_result2_1, col_skip_result2_2, col_skip_result2_3, col_skip_result2_4, col_skip_result2_5, col_skip_result2_6 = st.columns(6)
            with col_skip_result2_1:
                st.metric("í‰ê·  ì •í™•ë„", f"{summary_skip_2.get('avg_accuracy', 0):.2f}%")
            with col_skip_result2_2:
                st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", f"{summary_skip_2.get('max_consecutive_failures', 0)}íšŒ")
            with col_skip_result2_3:
                st.metric("ì´ ìŠ¤í‚µ íšŸìˆ˜", f"{summary_skip_2.get('total_skipped_predictions', 0)}íšŒ")
            with col_skip_result2_4:
                st.metric("ì˜ˆì¸¡ë¥ ", f"{summary_skip_2.get('prediction_rate', 0):.2f}%")
            with col_skip_result2_5:
                first_success_2 = summary_skip_2.get('avg_first_success_step')
                if first_success_2 is not None:
                    st.metric("í‰ê·  ì²« ì„±ê³µ ìŠ¤í…", f"{first_success_2:.1f}")
                else:
                    st.metric("í‰ê·  ì²« ì„±ê³µ ìŠ¤í…", "-")
            with col_skip_result2_6:
                max_first_success_2 = summary_skip_2.get('max_first_success_step')
                if max_first_success_2 is not None and max_first_success_2 > 0:
                    st.metric("ìµœëŒ€ ì²« ì„±ê³µ ìŠ¤í…", f"{max_first_success_2}")
                else:
                    st.metric("ìµœëŒ€ ì²« ì„±ê³µ ìŠ¤í…", "-")
            
            # ì¶”ê°€ í†µê³„ í‘œì‹œ
            st.markdown("---")
            st.markdown("#### ìƒì„¸ í†µê³„")
            detail_stats_2 = {
                'ì´ Grid String ìˆ˜': summary_skip_2.get('total_grid_strings', 0),
                'ì´ ìŠ¤í… ìˆ˜': summary_skip_2.get('total_steps', 0),
                'ì´ ì˜ˆì¸¡ íšŸìˆ˜': summary_skip_2.get('total_predictions', 0),
                'ì´ ì‹¤íŒ¨ íšŸìˆ˜': summary_skip_2.get('total_failures', 0),
                'ì´ ê°•ì œ ì˜ˆì¸¡ íšŸìˆ˜': summary_skip_2.get('total_forced_predictions', 0),
                'í‰ê·  ìµœëŒ€ ì—°ì† ì‹¤íŒ¨': f"{summary_skip_2.get('avg_max_consecutive_failures', 0):.2f}",
                'ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨': f"{summary_skip_2.get('forced_prediction_rate', 0):.2f}%",
                'ê°•ì œ ì˜ˆì¸¡ ì„±ê³µ ë¹„ìœ¨': f"{summary_skip_2.get('forced_success_rate', 0):.2f}%",
                'í‰ê·  ì²« ì„±ê³µ ìŠ¤í…': f"{summary_skip_2.get('avg_first_success_step', 0):.2f}" if summary_skip_2.get('avg_first_success_step') is not None else "-",
                'ìµœì†Œ ì²« ì„±ê³µ ìŠ¤í…': f"{summary_skip_2.get('min_first_success_step', 0)}" if summary_skip_2.get('min_first_success_step') is not None else "-",
                'ìµœëŒ€ ì²« ì„±ê³µ ìŠ¤í…': f"{summary_skip_2.get('max_first_success_step', 0)}" if summary_skip_2.get('max_first_success_step') is not None else "-",
                'ì„±ê³µì´ ìˆì—ˆë˜ Grid String ìˆ˜': summary_skip_2.get('total_with_success', 0)
            }
            detail_df_2 = pd.DataFrame([detail_stats_2])
            st.dataframe(detail_df_2, use_container_width=True, hide_index=True)
            
            # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ Grid String íˆìŠ¤í† ë¦¬ ìë™ í‘œì‹œ (ê²€ì¦ìš©)
            st.markdown("---")
            st.markdown(f"### ğŸ” ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ Grid String ê²€ì¦ íˆìŠ¤í† ë¦¬ (ì„ê³„ê°’ 2: {skip_confidence_threshold_2}%)")
            st.markdown("**ì˜ë„ëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ ë°œìƒí•œ grid_string_idì˜ ìƒì„¸ íˆìŠ¤í† ë¦¬**")
            
            results_skip_2 = batch_results_skip_2.get('results', [])
            if len(results_skip_2) > 0:
                # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ ë°œìƒí•œ grid_string_id ì°¾ê¸°
                max_failure_result_2 = max(results_skip_2, key=lambda x: x.get('max_consecutive_failures', 0))
                max_failure_grid_id_2 = max_failure_result_2['grid_string_id']
                max_failure_count_2 = max_failure_result_2.get('max_consecutive_failures', 0)
                
                st.info(f"ğŸ“Œ **ê²€ì¦ ëŒ€ìƒ**: Grid String ID {max_failure_grid_id_2} (ìµœëŒ€ ì—°ì† ì‹¤íŒ¨: {max_failure_count_2}íšŒ)")
                
                # ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸° ì˜µì…˜
                show_full_history_skip_2 = st.checkbox(
                    "ì „ì²´ íˆìŠ¤í† ë¦¬ ë³´ê¸° (ê¸°ë³¸: ìµœê·¼ 50ê°œë§Œ í‘œì‹œ)",
                    value=False,
                    key="last_grid_full_history_skip_2"
                )
                
                # íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
                failure_history_skip_2 = validate_interactive_multi_step_scenario_with_confidence_skip(
                    max_failure_grid_id_2,
                    cutoff_id_skip,
                    window_size=skip_window_size,
                    method=skip_method,
                    use_threshold=skip_use_threshold,
                    threshold=skip_threshold_val if skip_use_threshold else 60,
                    max_interval=skip_max_interval,
                    reverse_forced_prediction=False,
                    confidence_skip_threshold=skip_confidence_threshold_2
                )
                
                if failure_history_skip_2:
                    st.markdown("#### ìš”ì•½ ì •ë³´")
                    col_hist2_1, col_hist2_2, col_hist2_3, col_hist2_4, col_hist2_5, col_hist2_6 = st.columns(6)
                    with col_hist2_1:
                        st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", f"{failure_history_skip_2['max_consecutive_failures']}íšŒ")
                    with col_hist2_2:
                        st.metric("ì´ ìŠ¤í…", f"{failure_history_skip_2['total_steps']}")
                    with col_hist2_3:
                        st.metric("ì´ ì˜ˆì¸¡", f"{failure_history_skip_2['total_predictions']}")
                    with col_hist2_4:
                        st.metric("ì´ ìŠ¤í‚µ", f"{failure_history_skip_2.get('total_skipped_predictions', 0)}íšŒ")
                    with col_hist2_5:
                        st.metric("ì •í™•ë„", f"{failure_history_skip_2['accuracy']:.2f}%")
                    with col_hist2_6:
                        first_success_step_2 = failure_history_skip_2.get('first_success_step')
                        if first_success_step_2 is not None:
                            st.metric("ì²« ì„±ê³µ ìŠ¤í…", f"{first_success_step_2}")
                        else:
                            st.metric("ì²« ì„±ê³µ ìŠ¤í…", "-")
                    
                    # íˆìŠ¤í† ë¦¬ í…Œì´ë¸” (ìµœì‹ ìˆœìœ¼ë¡œ í‘œì‹œ)
                    st.markdown("#### ìƒì„¸ íˆìŠ¤í† ë¦¬")
                    history_skip_2 = failure_history_skip_2.get('history', [])
                    if len(history_skip_2) > 0:
                        # íˆìŠ¤í† ë¦¬ë¥¼ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ (step ë‚´ë¦¼ì°¨ìˆœ)
                        history_skip_sorted_2 = sorted(history_skip_2, key=lambda x: x.get('step', 0), reverse=True)
                        
                        history_limit_skip_2 = None if show_full_history_skip_2 else 50
                        history_title_skip_2 = "##### ìƒì„¸ íˆìŠ¤í† ë¦¬" + (f" (ìµœì‹  {history_limit_skip_2}ê°œ)" if history_limit_skip_2 else " (ì „ì²´)")
                        st.markdown(history_title_skip_2)
                        history_data_skip_2 = []
                        # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ëœ íˆìŠ¤í† ë¦¬ì—ì„œ ìµœì‹  Nê°œ ì„ íƒ
                        display_history_skip_2 = history_skip_sorted_2[:history_limit_skip_2] if history_limit_skip_2 else history_skip_sorted_2
                        
                        for entry in display_history_skip_2:
                            is_correct = entry.get('is_correct')
                            match_status = 'âœ…' if is_correct else ('âŒ' if is_correct is False else '-')
                            has_prediction = entry.get('has_prediction', False)
                            is_forced = entry.get('is_forced', False)
                            validated = entry.get('validated', False)
                            skipped = entry.get('skipped', False)
                            
                            forced_mark = 'âš¡' if is_forced else ''
                            no_pred_mark = 'ğŸš«' if not has_prediction else ''
                            validated_mark = 'âœ“' if validated else ''
                            skipped_mark = 'â­ï¸' if skipped else ''
                            
                            history_data_skip_2.append({
                                'Step': entry.get('step', 0),
                                'Prefix': entry.get('prefix', ''),
                                'ì˜ˆì¸¡': f"{entry.get('predicted', '-')}{forced_mark}{no_pred_mark}{skipped_mark}",
                                'ì‹¤ì œê°’': entry.get('actual', '-'),
                                'ì¼ì¹˜': match_status,
                                'ê²€ì¦': validated_mark,
                                'ìŠ¤í‚µ': 'â­ï¸' if skipped else '',
                                'ì‹ ë¢°ë„': f"{entry.get('confidence', 0):.1f}" if has_prediction else '-',
                                'ê°„ê²©': entry.get('current_interval', 0) if not has_prediction else 0
                            })
                        
                        history_df_skip_2 = pd.DataFrame(history_data_skip_2)
                        st.dataframe(history_df_skip_2, use_container_width=True, hide_index=True)
                        
                        if not show_full_history_skip_2 and len(history_skip_2) > 50:
                            st.caption(f"ğŸ’¡ ì „ì²´ {len(history_skip_2)}ê°œ ì¤‘ ìµœì‹  50ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤. ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ë³´ë ¤ë©´ ìœ„ì˜ ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        
        # ë¹„êµ í…Œì´ë¸” (í™”ë©´ ê°€ì¥ í•˜ë‹¨ì— ì¶”ê°€)
        if (batch_results_skip_1 is not None and len(batch_results_skip_1.get('results', [])) > 0 and
            batch_results_skip_2 is not None and len(batch_results_skip_2.get('results', [])) > 0):
            st.markdown("---")
            st.markdown("### ğŸ“Š ì„ê³„ê°’ ë¹„êµ í…Œì´ë¸”")
            
            summary_skip_1 = batch_results_skip_1.get('summary', {})
            summary_skip_2 = batch_results_skip_2.get('summary', {})
            
            # ë¹„êµ í…Œì´ë¸”
            comparison_data = []
            comparison_data.append({
                'í•­ëª©': 'ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’',
                f'ì„ê³„ê°’ {skip_confidence_threshold_1:.1f}%': f"{skip_confidence_threshold_1:.1f}%",
                f'ì„ê³„ê°’ {skip_confidence_threshold_2:.1f}%': f"{skip_confidence_threshold_2:.1f}%",
                'ì°¨ì´': f"{skip_confidence_threshold_2 - skip_confidence_threshold_1:+.1f}%"
            })
            comparison_data.append({
                'í•­ëª©': 'í‰ê·  ì •í™•ë„ (%)',
                f'ì„ê³„ê°’ {skip_confidence_threshold_1}%': f"{summary_skip_1.get('avg_accuracy', 0):.2f}",
                f'ì„ê³„ê°’ {skip_confidence_threshold_2}%': f"{summary_skip_2.get('avg_accuracy', 0):.2f}",
                'ì°¨ì´': f"{summary_skip_2.get('avg_accuracy', 0) - summary_skip_1.get('avg_accuracy', 0):+.2f}"
            })
            comparison_data.append({
                'í•­ëª©': 'ìµœëŒ€ ì—°ì† ì‹¤íŒ¨',
                f'ì„ê³„ê°’ {skip_confidence_threshold_1}%': f"{summary_skip_1.get('max_consecutive_failures', 0)}",
                f'ì„ê³„ê°’ {skip_confidence_threshold_2}%': f"{summary_skip_2.get('max_consecutive_failures', 0)}",
                'ì°¨ì´': f"{summary_skip_2.get('max_consecutive_failures', 0) - summary_skip_1.get('max_consecutive_failures', 0):+d}"
            })
            comparison_data.append({
                'í•­ëª©': 'í‰ê·  ìµœëŒ€ ì—°ì† ì‹¤íŒ¨',
                f'ì„ê³„ê°’ {skip_confidence_threshold_1}%': f"{summary_skip_1.get('avg_max_consecutive_failures', 0):.2f}",
                f'ì„ê³„ê°’ {skip_confidence_threshold_2}%': f"{summary_skip_2.get('avg_max_consecutive_failures', 0):.2f}",
                'ì°¨ì´': f"{summary_skip_2.get('avg_max_consecutive_failures', 0) - summary_skip_1.get('avg_max_consecutive_failures', 0):+.2f}"
            })
            comparison_data.append({
                'í•­ëª©': 'ì´ ìŠ¤í‚µ íšŸìˆ˜',
                f'ì„ê³„ê°’ {skip_confidence_threshold_1}%': f"{summary_skip_1.get('total_skipped_predictions', 0)}",
                f'ì„ê³„ê°’ {skip_confidence_threshold_2}%': f"{summary_skip_2.get('total_skipped_predictions', 0)}",
                'ì°¨ì´': f"{summary_skip_2.get('total_skipped_predictions', 0) - summary_skip_1.get('total_skipped_predictions', 0):+d}"
            })
            comparison_data.append({
                'í•­ëª©': 'ì˜ˆì¸¡ë¥  (%)',
                f'ì„ê³„ê°’ {skip_confidence_threshold_1}%': f"{summary_skip_1.get('prediction_rate', 0):.2f}",
                f'ì„ê³„ê°’ {skip_confidence_threshold_2}%': f"{summary_skip_2.get('prediction_rate', 0):.2f}",
                'ì°¨ì´': f"{summary_skip_2.get('prediction_rate', 0) - summary_skip_1.get('prediction_rate', 0):+.2f}"
            })
            comparison_data.append({
                'í•­ëª©': 'í‰ê·  ì²« ì„±ê³µ ìŠ¤í…',
                f'ì„ê³„ê°’ {skip_confidence_threshold_1}%': f"{summary_skip_1.get('avg_first_success_step', 0):.2f}" if summary_skip_1.get('avg_first_success_step') is not None else "-",
                f'ì„ê³„ê°’ {skip_confidence_threshold_2}%': f"{summary_skip_2.get('avg_first_success_step', 0):.2f}" if summary_skip_2.get('avg_first_success_step') is not None else "-",
                'ì°¨ì´': f"{(summary_skip_2.get('avg_first_success_step', 0) - summary_skip_1.get('avg_first_success_step', 0)):+.2f}" if (summary_skip_1.get('avg_first_success_step') is not None and summary_skip_2.get('avg_first_success_step') is not None) else "-"
            })
            comparison_data.append({
                'í•­ëª©': 'ì„±ê³µì´ ìˆì—ˆë˜ Grid String ìˆ˜',
                f'ì„ê³„ê°’ {skip_confidence_threshold_1}%': f"{summary_skip_1.get('total_with_success', 0)}",
                f'ì„ê³„ê°’ {skip_confidence_threshold_2}%': f"{summary_skip_2.get('total_with_success', 0)}",
                'ì°¨ì´': f"{summary_skip_2.get('total_with_success', 0) - summary_skip_1.get('total_with_success', 0):+d}"
            })
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)
            
            # ê²€ì¦ ê²°ê³¼ ì €ì¥ ë²„íŠ¼
            st.markdown("---")
            col_save1, col_save2 = st.columns([1, 4])
            with col_save1:
                if st.button("ğŸ’¾ ê²€ì¦ ê²°ê³¼ ì €ì¥", type="primary", use_container_width=True, key="save_confidence_skip_results"):
                    validation_id = save_confidence_skip_validation_results(
                        cutoff_id_skip,
                        skip_window_size,
                        skip_method,
                        skip_use_threshold,
                        skip_threshold_val if skip_use_threshold else None,
                        skip_max_interval,
                        skip_confidence_threshold_1,
                        skip_confidence_threshold_2,
                        batch_results_skip_1,
                        batch_results_skip_2
                    )
                    
                    if validation_id:
                        st.session_state.confidence_skip_saved_validation_id = validation_id
                        st.success(f"âœ… ê²€ì¦ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {validation_id[:8]}...)")
                    else:
                        st.warning("âš ï¸ ê²€ì¦ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            with col_save2:
                if 'confidence_skip_saved_validation_id' in st.session_state:
                    saved_id = st.session_state.confidence_skip_saved_validation_id
                    st.info(f"ğŸ’¾ ë§ˆì§€ë§‰ ì €ì¥ ID: {saved_id[:8]}...")
    
    # ë¼ì´ë¸Œ ê²Œì„ ì„¹ì…˜ (í™”ë©´ì—ì„œ ìˆ¨ê¹€ ì²˜ë¦¬)
    # ============================================
    # ì•„ë˜ ë¼ì´ë¸Œ ê²Œì„ ì„¹ì…˜ì€ if Falseë¡œ ìˆ¨ê¹€ ì²˜ë¦¬ë˜ì–´ í™”ë©´ì— í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    # í•„ìš”ì‹œ ì•„ë˜ ì¡°ê±´ë¬¸ì˜ Falseë¥¼ Trueë¡œ ë³€ê²½í•˜ì—¬ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ============================================
    if False:  # ë¼ì´ë¸Œ ê²Œì„ ì„¹ì…˜ ìˆ¨ê¹€ ì²˜ë¦¬
        st.markdown("---")
        st.header("ğŸ® ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ë¼ì´ë¸Œ ê²Œì„")
        st.markdown("**ìŠ¤í…ë³„ë¡œ ì˜ˆì¸¡ê°’ì„ í™•ì¸í•˜ê³  ì‹¤ì œê°’ì„ ì…ë ¥í•˜ì—¬ ê²€ì¦í•˜ëŠ” ë¼ì´ë¸Œ ê²Œì„**")
        
        # ê²Œì„ ì„¤ì • ì´ˆê¸°í™”
        if 'live_game_settings' not in st.session_state:
            st.session_state.live_game_settings = None
        
        # ê²Œì„ ì„¤ì •
        with st.expander("âš™ï¸ ê²Œì„ ì„¤ì •", expanded=True):
            st.markdown("### ì„¤ì •ê°’")
            
            col_game1, col_game2 = st.columns(2)
        
        with col_game1:
            live_window_size = st.selectbox(
                "ìœˆë„ìš° í¬ê¸°",
                options=[5, 6, 7, 8, 9],
                index=0,
                key="live_game_window_size"
            )
            
            live_method = st.selectbox(
                "ì˜ˆì¸¡ ë°©ë²•",
                options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
                index=0,
                key="live_game_method"
            )
        
        with col_game2:
            live_use_threshold = st.checkbox(
                "ì„ê³„ê°’ ì „ëµ ì‚¬ìš©",
                value=True,
                key="live_game_use_threshold"
            )
            
            live_threshold = st.number_input(
                "ì„ê³„ê°’ (%)",
                min_value=0,
                max_value=100,
                value=56,
                step=1,
                key="live_game_threshold",
                disabled=not live_use_threshold
            )
            
            live_max_interval = st.number_input(
                "ìµœëŒ€ ê°„ê²©",
                min_value=1,
                max_value=20,
                value=5,
                step=1,
                key="live_game_max_interval"
            )
            
            live_confidence_skip_threshold = st.number_input(
                "ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ (%)",
                min_value=0,
                max_value=100,
                value=51,
                step=1,
                key="live_game_confidence_skip_threshold"
            )
        
        # ì„¤ì • ì €ì¥ ë²„íŠ¼
        col_save1, col_save2 = st.columns([1, 4])
        with col_save1:
                if st.button("ğŸ’¾ ì„¤ì • ì €ì¥", type="primary", use_container_width=True):
                    st.session_state.live_game_settings = {
                        'window_size': live_window_size,
                        'method': live_method,
                        'use_threshold': live_use_threshold,
                        'threshold': live_threshold,
                        'max_interval': live_max_interval,
                        'confidence_skip_threshold': live_confidence_skip_threshold
                    }
                    # st.success ì œê±° (ì„±ëŠ¥ ê°œì„ )
                    st.rerun()
        
        with col_save2:
            pass  # ë©”ì‹œì§€ ì œê±°
        
        # Grid String ì…ë ¥ ì„¹ì…˜
        st.markdown("---")
        st.markdown("### Grid String ì…ë ¥")
        live_grid_string = st.text_area(
        "Grid String",
        value="",
        height=80,
        key="live_game_grid_string",
            help="ë¼ì´ë¸Œ ê²Œì„ì—ì„œ ì‚¬ìš©í•  grid_stringì„ ì…ë ¥í•˜ì„¸ìš”. ê¸°ì¡´ ë°ì´í„°ëŠ” ëª¨ë‘ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.",
            disabled=st.session_state.live_game_settings is None
        )
        
        if st.session_state.live_game_settings is None:
            st.warning("âš ï¸ ë¨¼ì € ê²Œì„ ì„¤ì •ì„ ì €ì¥í•´ì£¼ì„¸ìš”.")
        
        # ê²Œì„ ì´ˆê¸°í™”
        if 'live_game_state' not in st.session_state:
            st.session_state.live_game_state = None
        
        # ê²Œì„ ì‹œì‘/ì¬ì‹œì‘ ë²„íŠ¼
        col_start1, col_start2 = st.columns([1, 4])
        with col_start1:
            # ì„¤ì •ì´ ì €ì¥ë˜ì–´ ìˆê³  grid stringì´ ì…ë ¥ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ìµœì í™”: ë‹¨ìˆœ ì²´í¬ë§Œ)
            settings_saved = st.session_state.live_game_settings is not None
            grid_string_entered = bool(live_grid_string and live_grid_string.strip())
            
            if st.button("ğŸ® ê²Œì„ ì‹œì‘", type="primary", use_container_width=True, disabled=not settings_saved or not grid_string_entered):
                if not settings_saved:
                    st.error("ê²Œì„ ì„¤ì •ì„ ë¨¼ì € ì €ì¥í•´ì£¼ì„¸ìš”.")
                elif not grid_string_entered:
                    st.error("Grid Stringì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    grid_string = live_grid_string.strip()
                    settings = st.session_state.live_game_settings
                    
                    if len(grid_string) < settings['window_size']:
                        st.error(f"Grid Stringì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. (ê¸¸ì´: {len(grid_string)}, ìµœì†Œ í•„ìš”: {settings['window_size']})")
                    else:
                        # ê²Œì„ ì´ˆê¸°í™”
                        conn = get_db_connection()
                        if conn is None:
                            st.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                        else:
                            try:
                                # ëª¨ë“  ê¸°ì¡´ ë°ì´í„°ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš© (ìºì‹± í™•ì¸)
                                model_cache_key = f"live_game_model_{settings['window_size']}_{settings['method']}"
                                
                                if model_cache_key in st.session_state:
                                    # ìºì‹œëœ ëª¨ë¸ ì¬ì‚¬ìš©
                                    model = st.session_state[model_cache_key]
                                else:
                                    # ëª¨ë¸ êµ¬ì¶•
                                    train_ids_query = "SELECT id FROM preprocessed_grid_strings ORDER BY id"
                                    train_ids_df = pd.read_sql_query(train_ids_query, conn)
                                    train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
                                    
                                    # N-gram ë¡œë“œ
                                    train_ngrams = load_ngram_chunks(window_size=settings['window_size'], grid_string_ids=train_ids)
                                    
                                    if len(train_ngrams) == 0:
                                        st.warning("âš ï¸ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ëª¨ë¸ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
                                        train_ngrams = []
                                    
                                    # ëª¨ë¸ êµ¬ì¶•
                                    if settings['method'] == "ë¹ˆë„ ê¸°ë°˜":
                                        model = build_frequency_model(train_ngrams)
                                    elif settings['method'] == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                                        model = build_weighted_model(train_ngrams)
                                    else:
                                        model = build_frequency_model(train_ngrams)
                                    
                                    # ëª¨ë¸ ìºì‹±
                                    st.session_state[model_cache_key] = model
                                
                                # ê²Œì„ ìƒíƒœ ì´ˆê¸°í™”
                                prefix_length = settings['window_size'] - 1
                                initial_prefix = grid_string[:prefix_length]
                                
                                # ì…ë ¥ëœ grid_string ê¸¸ì´ë§Œí¼ ìë™ ì‹¤í–‰
                                history = []
                                consecutive_failures = 0
                                max_consecutive_failures = 0
                                total_predictions = 0
                                total_failures = 0
                                total_forced_predictions = 0
                                total_skipped_predictions = 0
                                current_interval = 0
                                current_index = prefix_length
                                current_prefix = initial_prefix
                                current_step = 0
                                
                                # grid_stringì˜ ë§ˆì§€ë§‰ê¹Œì§€ ìë™ ì‹¤í–‰
                                while current_index < len(grid_string):
                                        # ì˜ˆì¸¡ ìˆ˜í–‰
                                        if settings['use_threshold']:
                                            prediction_result = predict_with_fallback_interval(
                                                model,
                                                current_prefix,
                                                method=settings['method'],
                                                threshold=settings['threshold'],
                                                max_interval=settings['max_interval'],
                                                current_interval=current_interval
                                            )
                                        else:
                                            prediction_result = predict_for_prefix(model, current_prefix, settings['method'])
                                            if 'is_forced' not in prediction_result:
                                                prediction_result['is_forced'] = False
                                        
                                        predicted_value = prediction_result.get('predicted')
                                        confidence = prediction_result.get('confidence', 0.0)
                                        is_forced = prediction_result.get('is_forced', False)
                                        has_prediction = predicted_value is not None
                                        
                                        # ìŠ¤í‚µ ê·œì¹™ ì²´í¬
                                        should_skip = False
                                        if settings['use_threshold'] and has_prediction and is_forced and confidence < settings['confidence_skip_threshold']:
                                            should_skip = True
                                            total_skipped_predictions += 1
                                        
                                        # ì‹¤ì œê°’ ê°€ì ¸ì˜¤ê¸° (grid_stringì—ì„œ)
                                        actual_value = grid_string[current_index]
                                        
                                        # ê²€ì¦ ìˆ˜í–‰ (ì˜ˆì¸¡ê°’ì´ ìˆê³  ìŠ¤í‚µí•˜ì§€ ì•ŠëŠ” ê²½ìš°)
                                        if has_prediction and not should_skip:
                                            is_correct = predicted_value == actual_value
                                            
                                            if not is_correct:
                                                consecutive_failures += 1
                                                total_failures += 1
                                                if consecutive_failures > max_consecutive_failures:
                                                    max_consecutive_failures = consecutive_failures
                                            else:
                                                consecutive_failures = 0
                                            
                                            total_predictions += 1
                                            if is_forced:
                                                total_forced_predictions += 1
                                            
                                            # ê°„ê²© ë¦¬ì…‹
                                            current_interval = 0
                                            
                                            # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                                            history.append({
                                                'step': current_step + 1,
                                                'prefix': current_prefix,
                                                'predicted': predicted_value,
                                                'actual': actual_value,
                                                'is_correct': is_correct,
                                                'confidence': confidence,
                                                'is_forced': is_forced,
                                                'current_interval': 0,
                                                'has_prediction': True,
                                                'validated': True,
                                                'skipped': False
                                            })
                                        elif has_prediction and should_skip:
                                            # ìŠ¤í‚µëœ ê²½ìš° íˆìŠ¤í† ë¦¬ ê¸°ë¡
                                            history.append({
                                                'step': current_step + 1,
                                                'prefix': current_prefix,
                                                'predicted': predicted_value,
                                                'actual': actual_value,
                                                'is_correct': None,
                                                'confidence': confidence,
                                                'is_forced': is_forced,
                                                'current_interval': current_interval,
                                                'has_prediction': True,
                                                'validated': False,
                                                'skipped': True
                                            })
                                            # ìŠ¤í‚µ ìƒíƒœì—ì„œ ê°„ê²© ê³„ì‚°ì€ ë©ˆì¶¤ (ì¦ê°€í•˜ì§€ ì•ŠìŒ)
                                        else:
                                            # ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê²½ìš° íˆìŠ¤í† ë¦¬ ê¸°ë¡ (ì „ì²´ ìŠ¤í… í‘œì‹œë¥¼ ìœ„í•´)
                                            history.append({
                                                'step': current_step + 1,
                                                'prefix': current_prefix,
                                                'predicted': None,
                                                'actual': actual_value,
                                                'is_correct': None,
                                                'confidence': 0.0,
                                                'is_forced': False,
                                                'current_interval': current_interval,
                                                'has_prediction': False,
                                                'validated': False,
                                                'skipped': False
                                            })
                                            # ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê²½ìš° ê°„ê²© ì¦ê°€
                                            if settings['use_threshold']:
                                                current_interval += 1
                                        
                                        # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰
                                        current_step += 1
                                        current_index += 1
                                        
                                        # prefix ì—…ë°ì´íŠ¸ (ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ ì „í™˜ì„ ìœ„í•´ í•­ìƒ ì—…ë°ì´íŠ¸)
                                        current_prefix = get_next_prefix(
                                            current_prefix,
                                            actual_value,
                                            settings['window_size']
                                        )
                                
                                # ê²Œì„ ìƒíƒœ ì €ì¥ (ë‹¤ìŒ ìŠ¤í…ë¶€í„° ì¸í„°ë™í‹°ë¸Œë¡œ ì§„í–‰)
                                st.session_state.live_game_state = {
                                    'grid_string': grid_string,
                                    'model': model,
                                    'current_step': current_step,
                                    'current_index': current_index,
                                    'current_prefix': current_prefix,
                                    'current_interval': current_interval,
                                    'history': history,
                                    'consecutive_failures': consecutive_failures,
                                    'max_consecutive_failures': max_consecutive_failures,
                                    'total_predictions': total_predictions,
                                    'total_failures': total_failures,
                                    'total_forced_predictions': total_forced_predictions,
                                    'total_skipped_predictions': total_skipped_predictions,
                                    'window_size': settings['window_size'],
                                    'method': settings['method'],
                                    'use_threshold': settings['use_threshold'],
                                    'threshold': settings['threshold'],
                                    'max_interval': settings['max_interval'],
                                    'confidence_skip_threshold': settings['confidence_skip_threshold'],
                                    'auto_executed': True  # ìë™ ì‹¤í–‰ ì™„ë£Œ í”Œë˜ê·¸
                                }
                                
                                # st.success ì œê±° (ì„±ëŠ¥ ê°œì„ )
                                st.rerun()
                            except Exception as e:
                                st.error(f"ê²Œì„ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
                                import traceback
                                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                            finally:
                                conn.close()
        
        with col_start2:
            if st.session_state.live_game_state is not None:
                if st.button("ğŸ”„ ê²Œì„ ì¬ì‹œì‘", use_container_width=True):
                    st.session_state.live_game_state = None
                    st.rerun()
        
            # ê²Œì„ ì§„í–‰ (ê²Œì„ ìƒíƒœê°€ ìˆì„ ë•Œë§Œ í•¨ìˆ˜ í˜¸ì¶œ - ì„±ëŠ¥ ê°œì„ )
            if st.session_state.live_game_state is not None:
                render_live_game_play(st.session_state.live_game_state)

if __name__ == "__main__":
    main()

