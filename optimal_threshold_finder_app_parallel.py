"""
ìµœì  ìŠ¤í‚µ ì„ê³„ê°’ íƒìƒ‰ ì‹œë®¬ë ˆì´ì…˜ ì•±
50.5 ~ 51.5 ë²”ìœ„ì—ì„œ 0.1 ë‹¨ìœ„ë¡œ ìŠ¤í‚µ ì„ê³„ê°’ì„ í…ŒìŠ¤íŠ¸í•˜ì—¬
ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ 5 ì´í•˜ë¥¼ ë§Œì¡±í•˜ëŠ” ìµœì  ì„ê³„ê°’ì„ ì°¾ìŠµë‹ˆë‹¤.
"""

import streamlit as st

# í˜ì´ì§€ ì„¤ì • (ëª¨ë“  import ì „ì— ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
st.set_page_config(
    page_title="Optimal Threshold Finder",
    page_icon="ğŸ¯",
    layout="wide"
)

import pandas as pd
import sqlite3
import uuid
import time
import random
from collections import defaultdict
from datetime import datetime
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed

# ê¸°ì¡´ ì•±ì˜ í•¨ìˆ˜ë“¤ import
from hypothesis_validation_app import (
    get_db_connection,
    load_preprocessed_data,
    create_stored_predictions_table,
    save_or_update_predictions_for_historical_data,
    load_ngram_chunks,
    build_frequency_model,
    build_weighted_model,
    predict_frequency,
    predict_weighted,
    predict_for_prefix
)

# interactive_multi_step_validation_appì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ import
from interactive_multi_step_validation_app import (
    batch_validate_interactive_multi_step_scenario_with_confidence_skip
)

# DB ê²½ë¡œ
DB_PATH = 'hypothesis_validation.db'

def create_simulation_tables():
    """
    ìµœì  ì„ê³„ê°’ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ìƒì„±
    """
    conn = get_db_connection()
    if conn is None:
        return False
    
    cursor = conn.cursor()
    
    try:
        # 1. ì‹œë®¬ë ˆì´ì…˜ ì„¸ì…˜ ë©”íƒ€ë°ì´í„° í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS optimal_threshold_simulation_sessions (
                session_id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL UNIQUE,
                cutoff_grid_string_id INTEGER NOT NULL,
                window_size INTEGER,
                method TEXT NOT NULL,
                use_threshold BOOLEAN NOT NULL,
                threshold REAL,
                max_interval INTEGER,
                min_skip_threshold REAL,
                max_skip_threshold REAL,
                step REAL,
                search_method TEXT DEFAULT 'single',
                window_size_min INTEGER,
                window_size_max INTEGER,
                max_interval_min INTEGER,
                max_interval_max INTEGER,
                num_samples INTEGER,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
            )
        ''')
        
        # 2. ê° ì„ê³„ê°’ë³„ ìš”ì•½ í†µê³„ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS optimal_threshold_simulation_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                confidence_skip_threshold REAL NOT NULL,
                window_size INTEGER,
                max_interval INTEGER,
                max_consecutive_failures INTEGER NOT NULL,
                avg_max_consecutive_failures REAL NOT NULL,
                total_skipped_predictions INTEGER NOT NULL,
                avg_skip_rate REAL NOT NULL,
                below_5_ratio REAL NOT NULL,
                avg_accuracy REAL NOT NULL,
                prediction_rate REAL NOT NULL,
                total_grid_strings INTEGER NOT NULL,
                total_steps INTEGER NOT NULL,
                total_failures INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES optimal_threshold_simulation_sessions(validation_id)
            )
        ''')
        
        # 3. Grid Stringë³„ ìƒì„¸ ê²°ê³¼ í…Œì´ë¸” (ì„ íƒì )
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS optimal_threshold_simulation_grid_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                confidence_skip_threshold REAL NOT NULL,
                grid_string_id INTEGER NOT NULL,
                max_consecutive_failures INTEGER NOT NULL,
                total_skipped_predictions INTEGER NOT NULL,
                accuracy REAL NOT NULL,
                total_steps INTEGER NOT NULL,
                total_predictions INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                FOREIGN KEY (validation_id) REFERENCES optimal_threshold_simulation_sessions(validation_id),
                FOREIGN KEY (grid_string_id) REFERENCES preprocessed_grid_strings(id),
                UNIQUE(validation_id, confidence_skip_threshold, grid_string_id)
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_simulation_sessions_created_at 
            ON optimal_threshold_simulation_sessions(created_at)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_simulation_sessions_cutoff 
            ON optimal_threshold_simulation_sessions(cutoff_grid_string_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_simulation_results_validation_id 
            ON optimal_threshold_simulation_results(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_simulation_results_threshold 
            ON optimal_threshold_simulation_results(confidence_skip_threshold)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_simulation_results_max_failures 
            ON optimal_threshold_simulation_results(max_consecutive_failures)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_simulation_grid_results_validation_id 
            ON optimal_threshold_simulation_grid_results(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_simulation_grid_results_threshold 
            ON optimal_threshold_simulation_grid_results(confidence_skip_threshold)
        ''')
        
        # ê¸°ì¡´ í…Œì´ë¸”ì— ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ (ë§ˆì´ê·¸ë ˆì´ì…˜)
        try:
            # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='optimal_threshold_simulation_sessions'")
            table_exists = cursor.fetchone()
            
            if table_exists:
                # ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (PRAGMA table_info ì‚¬ìš©)
                cursor.execute("PRAGMA table_info(optimal_threshold_simulation_sessions)")
                existing_columns = [row[1] for row in cursor.fetchall()]
                
                # ì»¬ëŸ¼ ì¶”ê°€
                new_columns = [
                    ('search_method', 'TEXT DEFAULT "single"'),
                    ('window_size_min', 'INTEGER'),
                    ('window_size_max', 'INTEGER'),
                    ('max_interval_min', 'INTEGER'),
                    ('max_interval_max', 'INTEGER'),
                    ('num_samples', 'INTEGER')
                ]
                
                for col_name, col_def in new_columns:
                    if col_name not in existing_columns:
                        try:
                            cursor.execute(f"ALTER TABLE optimal_threshold_simulation_sessions ADD COLUMN {col_name} {col_def}")
                        except sqlite3.OperationalError:
                            pass  # ë¬´ì‹œ
            
            # optimal_threshold_simulation_results í…Œì´ë¸” í™•ì¸ ë° ë§ˆì´ê·¸ë ˆì´ì…˜
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='optimal_threshold_simulation_results'")
            results_table_exists = cursor.fetchone()
            
            if results_table_exists:
                cursor.execute("PRAGMA table_info(optimal_threshold_simulation_results)")
                existing_result_columns = [row[1] for row in cursor.fetchall()]
                
                new_result_columns = [
                    ('window_size', 'INTEGER'),
                    ('max_interval', 'INTEGER')
                ]
                
                for col_name, col_def in new_result_columns:
                    if col_name not in existing_result_columns:
                        try:
                            cursor.execute(f"ALTER TABLE optimal_threshold_simulation_results ADD COLUMN {col_name} {col_def}")
                        except sqlite3.OperationalError:
                            pass  # ë¬´ì‹œ
            
            conn.commit()
        except Exception as e:
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨í•´ë„ í…Œì´ë¸” ìƒì„±ì€ ì„±ê³µí•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
            try:
                conn.rollback()
            except:
                pass
        
        conn.commit()
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False
    finally:
        conn.close()

def simulate_single_threshold(
    cutoff_id,
    confidence_skip_threshold,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    main_threshold=56,
    max_interval=6
):
    """
    ë‹¨ì¼ ì„ê³„ê°’ì— ëŒ€í•œ ê²€ì¦ ì‹¤í–‰ ë° ì§€í‘œ ìˆ˜ì§‘
    
    Args:
        cutoff_id: ê¸°ì¤€ grid_string ID
        confidence_skip_threshold: ìŠ¤í‚µ ì„ê³„ê°’
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        main_threshold: ë©”ì¸ ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼ ë° ì§€í‘œ
    """
    try:
        # ë°°ì¹˜ ê²€ì¦ ì‹¤í–‰
        batch_results = batch_validate_interactive_multi_step_scenario_with_confidence_skip(
            cutoff_id,
            window_size=window_size,
            method=method,
            use_threshold=use_threshold,
            threshold=main_threshold,
            max_interval=max_interval,
            reverse_forced_prediction=False,
            confidence_skip_threshold=confidence_skip_threshold
        )
        
        if batch_results is None or len(batch_results.get('results', [])) == 0:
            return None
        
        summary = batch_results.get('summary', {})
        results = batch_results.get('results', [])
        
        # ì¶”ê°€ ì§€í‘œ ê³„ì‚°
        # 5 ì´í•˜ ë¹„ìœ¨ ê³„ì‚°
        below_5_count = sum(1 for r in results if r.get('max_consecutive_failures', 0) <= 5)
        below_5_ratio = (below_5_count / len(results) * 100) if len(results) > 0 else 0.0
        
        # í‰ê·  ìŠ¤í‚µ ë¹„ìœ¨ ê³„ì‚°
        total_skipped = summary.get('total_skipped_predictions', 0)
        total_grid_strings = summary.get('total_grid_strings', 0)
        avg_skip_rate = (total_skipped / total_grid_strings) if total_grid_strings > 0 else 0.0
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            'confidence_skip_threshold': confidence_skip_threshold,
            'max_consecutive_failures': summary.get('max_consecutive_failures', 0),
            'avg_max_consecutive_failures': summary.get('avg_max_consecutive_failures', 0.0),
            'total_skipped_predictions': total_skipped,
            'avg_skip_rate': avg_skip_rate,
            'below_5_ratio': below_5_ratio,
            'below_5_count': below_5_count,
            'avg_accuracy': summary.get('avg_accuracy', 0.0),
            'prediction_rate': summary.get('prediction_rate', 0.0),
            'total_grid_strings': total_grid_strings,
            'total_steps': summary.get('total_steps', 0),
            'total_failures': summary.get('total_failures', 0),
            'total_predictions': summary.get('total_predictions', 0),
            'batch_results': batch_results  # ìƒì„¸ ê²°ê³¼ í¬í•¨
        }
        
    except Exception as e:
        st.error(f"ì„ê³„ê°’ {confidence_skip_threshold} ì‹œë®¬ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def _simulate_single_worker(args):
    """
    ë³‘ë ¬ ì²˜ë¦¬ìš© worker í•¨ìˆ˜
    ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, DB ì—°ê²°ë„ ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ìƒì„±ë¨
    
    Args:
        args: (cutoff_id, confidence_skip_threshold, window_size, method, 
               use_threshold, main_threshold, max_interval, combo)
    
    Returns:
        tuple: (result_dict, combo_tuple)
    """
    (cutoff_id, confidence_skip_threshold, window_size, method,
     use_threshold, main_threshold, max_interval, combo) = args
    
    # ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ import (pickle ë¬¸ì œ ë°©ì§€)
    try:
        # simulate_single_thresholdëŠ” ëª¨ë“ˆ ë ˆë²¨ í•¨ìˆ˜ì´ë¯€ë¡œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥
        # í•˜ì§€ë§Œ ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ í•¨ìˆ˜ë¥¼ ì¬ì •ì˜í•´ì•¼ í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ í˜¸ì¶œ
        from interactive_multi_step_validation_app import (
            batch_validate_interactive_multi_step_scenario_with_confidence_skip
        )
        
        # ë°°ì¹˜ ê²€ì¦ ì‹¤í–‰
        batch_results = batch_validate_interactive_multi_step_scenario_with_confidence_skip(
            cutoff_id,
            window_size=window_size,
            method=method,
            use_threshold=use_threshold,
            threshold=main_threshold,
            max_interval=max_interval,
            reverse_forced_prediction=False,
            confidence_skip_threshold=confidence_skip_threshold
        )
        
        if batch_results is None or len(batch_results.get('results', [])) == 0:
            return None, combo
        
        summary = batch_results.get('summary', {})
        results = batch_results.get('results', [])
        
        # ì§€í‘œ ê³„ì‚°
        below_5_count = sum(1 for r in results if r.get('max_consecutive_failures', 0) <= 5)
        below_5_ratio = (below_5_count / len(results) * 100) if len(results) > 0 else 0.0
        
        total_skipped = summary.get('total_skipped_predictions', 0)
        total_grid_strings = summary.get('total_grid_strings', 0)
        avg_skip_rate = (total_skipped / total_grid_strings) if total_grid_strings > 0 else 0.0
        
        result = {
            'confidence_skip_threshold': confidence_skip_threshold,
            'max_consecutive_failures': summary.get('max_consecutive_failures', 0),
            'avg_max_consecutive_failures': summary.get('avg_max_consecutive_failures', 0.0),
            'total_skipped_predictions': total_skipped,
            'avg_skip_rate': avg_skip_rate,
            'below_5_ratio': below_5_ratio,
            'below_5_count': below_5_count,
            'avg_accuracy': summary.get('avg_accuracy', 0.0),
            'prediction_rate': summary.get('prediction_rate', 0.0),
            'total_grid_strings': total_grid_strings,
            'total_steps': summary.get('total_steps', 0),
            'total_failures': summary.get('total_failures', 0),
            'total_predictions': summary.get('total_predictions', 0)
        }
        
        return result, combo
        
    except Exception as e:
        # st.errorëŠ” ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ ì‘ë™í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¬´ì‹œ
        return None, combo

def random_search_multi_dimensional(
    cutoff_id,
    window_size_range=(5, 9),
    max_interval_range=(1, 20),
    confidence_skip_range=(51.0, 53.5, 0.1),
    num_samples=100,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    main_threshold=56,
    progress_bar=None,
    status_text=None,
    enable_early_stop=False,
    min_meaningful_results=5,
    max_workers=None,  # Noneì´ë©´ ìë™ ê³„ì‚°, ìˆ˜ë™ ì„¤ì • ê°€ëŠ¥
    use_threading=False  # Trueë©´ ThreadPoolExecutor ì‚¬ìš© (I/O ë°”ìš´ë“œì— ìœ ë¦¬)
):
    """
    ë‹¤ì°¨ì› ìµœì í™”: ìœˆë„ìš° í¬ê¸°, ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©, ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ì„ ëœë¤ ì„œì¹˜ë¡œ ë™ì‹œì— íƒìƒ‰
    
    Args:
        cutoff_id: ê¸°ì¤€ grid_string ID
        window_size_range: (min, max) íŠœí”Œ - ìœˆë„ìš° í¬ê¸° ë²”ìœ„
        max_interval_range: (min, max) íŠœí”Œ - ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© ë²”ìœ„
        confidence_skip_range: (min, max, step) íŠœí”Œ - ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ë²”ìœ„ ë° ê°„ê²©
        num_samples: í…ŒìŠ¤íŠ¸í•  ë¬´ì‘ìœ„ ì¡°í•© ê°œìˆ˜
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        main_threshold: ë©”ì¸ ì„ê³„ê°’
        progress_bar: Streamlit progress bar ê°ì²´ (ì„ íƒì )
        status_text: Streamlit status text ê°ì²´ (ì„ íƒì )
        enable_early_stop: ì¡°ê¸° ì¢…ë£Œ í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        min_meaningful_results: ì¡°ê¸° ì¢…ë£Œë¥¼ ìœ„í•œ ìµœì†Œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
    
    Returns:
        dict: ëª¨ë“  ì¡°í•©ì˜ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
    """
    # íŒŒë¼ë¯¸í„° ë²”ìœ„ì—ì„œ ìœ íš¨í•œ ê°’ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    window_size_min, window_size_max = window_size_range
    max_interval_min, max_interval_max = max_interval_range
    skip_min, skip_max, skip_step = confidence_skip_range
    
    # ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
    window_sizes = list(range(window_size_min, window_size_max + 1))
    
    # ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© ë¦¬ìŠ¤íŠ¸
    max_intervals = list(range(max_interval_min, max_interval_max + 1))
    
    # ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ë¦¬ìŠ¤íŠ¸
    confidence_skips = []
    current = skip_min
    while current <= skip_max + 0.001:  # ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ ê³ ë ¤
        confidence_skips.append(round(current, 1))
        current += skip_step
    
    # ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•© ìƒì„±
    all_combinations = []
    for ws in window_sizes:
        for mi in max_intervals:
            for cs in confidence_skips:
                all_combinations.append((ws, mi, cs))
    
    total_possible = len(all_combinations)
    
    # ìƒ˜í”Œë§ ê°œìˆ˜ ì¡°ì •
    if num_samples >= total_possible:
        # ì „ì²´ ì¡°í•© ì‚¬ìš©
        selected_combinations = all_combinations
        if status_text:
            status_text.text(f"ì „ì²´ ì¡°í•© {total_possible}ê°œë¥¼ ëª¨ë‘ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
    else:
        # ë¬´ì‘ìœ„ ìƒ˜í”Œë§
        selected_combinations = random.sample(all_combinations, num_samples)
    
    total_to_test = len(selected_combinations)
    
    if status_text:
        status_text.text(f"ë‹¤ì°¨ì› ìµœì í™” ì‹œì‘: {total_to_test}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸ ì˜ˆì • (ì „ì²´ ê°€ëŠ¥í•œ ì¡°í•©: {total_possible}ê°œ)")
    
    results = []
    tested_combinations = []
    start_time = time.time()
    best_so_far = None
    best_max_failures = 999
    meaningful_count = 0  # ìœ ì˜ë¯¸í•œ ê²°ê³¼ ê°œìˆ˜ ì¶”ì 
    
    # ë³‘ë ¬ ì²˜ë¦¬ìš© ì‘ì—… ì¸ì ì¤€ë¹„
    tasks = [
        (cutoff_id, cs, ws, method, use_threshold, main_threshold, mi, (ws, mi, cs))
        for (ws, mi, cs) in selected_combinations
    ]
    
    # CPU ì½”ì–´ ìˆ˜ ê²°ì •
    if max_workers is None:
        # i5-10400F ê¸°ì¤€: 6ì½”ì–´ 12ìŠ¤ë ˆë“œ
        # CPU ì‚¬ìš©ë¥ ì„ 50-60% ìˆ˜ì¤€ìœ¼ë¡œ ìœ ì§€í•˜ì—¬ ë‹¤ë¥¸ ì‘ì—… ì—¬ìœ  í™•ë³´
        # ì½”ì–´ ìˆ˜ì˜ 50% ì‚¬ìš© (ìµœì†Œ 2ê°œ, ìµœëŒ€ 4ê°œ)
        cpu_count = mp.cpu_count()
        max_workers = max(2, min(int(cpu_count * 0.5), 4))
        # ë§Œì•½ CPUê°€ ë§ìœ¼ë©´ ì¢€ ë” ì‚¬ìš© (8ì½”ì–´ ì´ìƒì´ë©´ 4ê°œê¹Œì§€)
        if cpu_count >= 8:
            max_workers = min(4, max_workers)
    else:
        max_workers = max(1, min(max_workers, mp.cpu_count()))
    
    executor_class = None
    if use_threading:
        executor_class = ThreadPoolExecutor
        executor_type = "ìŠ¤ë ˆë“œ"
    else:
        executor_class = ProcessPoolExecutor
        executor_type = "í”„ë¡œì„¸ìŠ¤"
    
    if status_text:
        status_text.text(
            f"ë‹¤ì°¨ì› ìµœì í™” ì‹œì‘: {total_to_test}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸ ì˜ˆì • "
            f"(ë³‘ë ¬ ì²˜ë¦¬: {max_workers}ê°œ {executor_type} ì‘ì—…ì ì‚¬ìš©, "
            f"ì˜ˆìƒ CPU ì‚¬ìš©ë¥ : {max_workers/mp.cpu_count()*100:.0f}%)"
        )
    
    completed_count = 0
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
    with executor_class(max_workers=max_workers) as executor:
        # ëª¨ë“  ì‘ì—… ì œì¶œ
        future_to_combo = {
            executor.submit(_simulate_single_worker, task): combo
            for task, combo in zip(tasks, selected_combinations)
        }
        
        # ì™„ë£Œëœ ì‘ì—…ë¶€í„° ì²˜ë¦¬ (as_completed ì‚¬ìš©)
        for future in as_completed(future_to_combo):
            combo = future_to_combo[future]
            ws, mi, cs = combo
            completed_count += 1
            
            try:
                result, _ = future.result()
                
                if result is not None:
                    # ì¶”ê°€ íŒŒë¼ë¯¸í„° ì •ë³´ ì €ì¥
                    result['window_size'] = ws
                    result['max_interval'] = mi
                    result['combination'] = combo
                    
                    results.append(result)
                    tested_combinations.append(combo)
                    
                    # ìœ ì˜ë¯¸í•œ ê²°ê³¼ì¸ì§€ í™•ì¸ (ì˜ˆì¸¡ë¥  >= 10%, ìŠ¤í‚µ ë¹„ìœ¨ <= 90%, ìµœì†Œ 10íšŒ ì˜ˆì¸¡)
                    is_meaningful = (
                        result.get('prediction_rate', 0.0) >= 10.0
                        and result.get('avg_skip_rate', 100.0) <= 90.0
                        and result.get('total_predictions', 0) >= 10
                    )
                    
                    if is_meaningful:
                        meaningful_count += 1
                    
                    # í˜„ì¬ê¹Œì§€ ìµœê³  ê²°ê³¼ ì¶”ì 
                    max_failures = result.get('max_consecutive_failures', 999)
                    if max_failures < best_max_failures:
                        best_max_failures = max_failures
                        best_so_far = {
                            'window_size': ws,
                            'max_interval': mi,
                            'confidence_skip_threshold': cs,
                            'max_consecutive_failures': max_failures
                        }
                    
                    # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ í™•ì¸ (ë³‘ë ¬ ì²˜ë¦¬ì—ì„œëŠ” ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œëœ í›„ í™•ì¸)
                    # ì°¸ê³ : ë³‘ë ¬ ì²˜ë¦¬ì—ì„œëŠ” ì •í™•í•œ ì¡°ê¸° ì¢…ë£Œê°€ ì–´ë µì§€ë§Œ,
                    # ëª¨ë“  ê²°ê³¼ë¥¼ ë°›ì€ í›„ ì˜ë¯¸ ìˆëŠ” ê²°ê³¼ë¥¼ í•„í„°ë§í•  ìˆ˜ ìˆìŒ
                    
                # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì—…ë°ì´íŠ¸
                if progress_bar:
                    progress = completed_count / total_to_test
                    progress_bar.progress(progress)
                
                # ì˜ˆìƒ ì‹œê°„ ê³„ì‚° ë° í‘œì‹œ
                if status_text:
                    elapsed = time.time() - start_time
                    if completed_count > 0:
                        avg_time_per_combo = elapsed / completed_count
                        remaining = (total_to_test - completed_count) * avg_time_per_combo
                        
                        elapsed_min = int(elapsed // 60)
                        elapsed_sec = int(elapsed % 60)
                        remaining_min = int(remaining // 60)
                        remaining_sec = int(remaining % 60)
                        
                        if elapsed_min > 0:
                            elapsed_str = f"{elapsed_min}ë¶„ {elapsed_sec}ì´ˆ"
                        else:
                            elapsed_str = f"{elapsed_sec}ì´ˆ"
                        
                        if remaining_min > 0:
                            remaining_str = f"{remaining_min}ë¶„ {remaining_sec}ì´ˆ"
                        else:
                            remaining_str = f"{remaining_sec}ì´ˆ"
                        
                        status_text.text(
                            f"ì™„ë£Œ: {completed_count}/{total_to_test} | "
                            f"ê²½ê³¼: {elapsed_str} | ë‚¨ì€ ì‹œê°„: {remaining_str} | "
                            f"í˜„ì¬ ìµœê³ : {best_max_failures}ê°œ ë¶ˆì¼ì¹˜ | "
                            f"ë³‘ë ¬ ì‘ì—…ì: {max_workers}ê°œ"
                        )
                
                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                if 'simulation_progress' not in st.session_state:
                    st.session_state.simulation_progress = {}
                combo_key = f"{ws}_{mi}_{cs}"
                st.session_state.simulation_progress[combo_key] = {
                    'completed': True,
                    'result': result is not None,
                    'window_size': ws,
                    'max_interval': mi,
                    'confidence_skip_threshold': cs
                }
                    
            except Exception as e:
                # ì—ëŸ¬ëŠ” ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ í‘œì‹œ ê°€ëŠ¥
                if status_text:
                    status_text.text(f"ì¡°í•© {combo} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ê³„ì† ì§„í–‰)")
                # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ê³„ì† ì§„í–‰
                pass
    
    return {
        'results': results,
        'tested_combinations': tested_combinations,
        'total_combinations_possible': total_possible,
        'total_tested': len(results),  # ì‹¤ì œ í…ŒìŠ¤íŠ¸í•œ ê°œìˆ˜
        'total_planned': total_to_test,  # ì›ë˜ ê³„íšëœ í…ŒìŠ¤íŠ¸ ê°œìˆ˜
        'successful': len(results),
        'failed': total_to_test - len(results),
        'meaningful_count': meaningful_count,  # ìœ ì˜ë¯¸í•œ ê²°ê³¼ ê°œìˆ˜
        'early_stopped': False,  # ë³‘ë ¬ ì²˜ë¦¬ì—ì„œëŠ” ì¡°ê¸° ì¢…ë£Œê°€ ì–´ë ¤ì›€
        'search_method': 'random_multi_dimensional_parallel',
        'best_so_far': best_so_far,
        'parallel_workers': max_workers  # ì‚¬ìš©ëœ ë³‘ë ¬ ì‘ì—…ì ìˆ˜
    }

def batch_simulate_threshold_range(
    cutoff_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    main_threshold=56,
    max_interval=6,
    min_skip_threshold=50.5,
    max_skip_threshold=51.5,
    step=0.1,
    progress_bar=None,
    status_text=None
):
    """
    ë²”ìœ„ ë‚´ ëª¨ë“  ì„ê³„ê°’ì— ëŒ€í•œ ì‹œë®¬ë ˆì´ì…˜
    
    Args:
        cutoff_id: ê¸°ì¤€ grid_string ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        main_threshold: ë©”ì¸ ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
        min_skip_threshold: ìµœì†Œ ìŠ¤í‚µ ì„ê³„ê°’
        max_skip_threshold: ìµœëŒ€ ìŠ¤í‚µ ì„ê³„ê°’
        step: ì„ê³„ê°’ ê°„ê²©
        progress_bar: Streamlit progress bar ê°ì²´ (ì„ íƒì )
        status_text: Streamlit status text ê°ì²´ (ì„ íƒì )
    
    Returns:
        dict: ëª¨ë“  ì„ê³„ê°’ì˜ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
    """
    # ì„ê³„ê°’ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    thresholds = []
    current = min_skip_threshold
    while current <= max_skip_threshold + 0.001:  # ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ ê³ ë ¤
        thresholds.append(round(current, 1))
        current += step
    
    results = []
    total = len(thresholds)
    start_time = time.time()
    first_completion_time = None
    
    # ê° ì„ê³„ê°’ì— ëŒ€í•´ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    for idx, threshold in enumerate(thresholds):
        threshold_start = time.time()
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        if status_text:
            status_text.text(f"ì„ê³„ê°’ {threshold}% í…ŒìŠ¤íŠ¸ ì¤‘... ({idx+1}/{total})")
        
        result = simulate_single_threshold(
            cutoff_id,
            threshold,
            window_size=window_size,
            method=method,
            use_threshold=use_threshold,
            main_threshold=main_threshold,
            max_interval=max_interval
        )
        
        threshold_elapsed = time.time() - threshold_start
        
        if result is not None:
            results.append(result)
        
        # ì²« ë²ˆì§¸ ì™„ë£Œ ì‹œê°„ ê¸°ë¡ (ì˜ˆìƒ ì‹œê°„ ê³„ì‚°ìš©)
        if first_completion_time is None and result is not None:
            first_completion_time = threshold_elapsed
        
        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì—…ë°ì´íŠ¸
        if progress_bar:
            progress = (idx + 1) / total
            progress_bar.progress(progress)
        
        # ì˜ˆìƒ ì‹œê°„ ê³„ì‚° ë° í‘œì‹œ
        if status_text and idx >= 0:
            elapsed = time.time() - start_time
            if idx > 0:
                avg_time_per_threshold = elapsed / (idx + 1)
                remaining = (total - idx - 1) * avg_time_per_threshold
                
                elapsed_min = int(elapsed // 60)
                elapsed_sec = int(elapsed % 60)
                remaining_min = int(remaining // 60)
                remaining_sec = int(remaining % 60)
                
                if elapsed_min > 0:
                    elapsed_str = f"{elapsed_min}ë¶„ {elapsed_sec}ì´ˆ"
                else:
                    elapsed_str = f"{elapsed_sec}ì´ˆ"
                
                if remaining_min > 0:
                    remaining_str = f"{remaining_min}ë¶„ {remaining_sec}ì´ˆ"
                else:
                    remaining_str = f"{remaining_sec}ì´ˆ"
                
                status_text.text(
                    f"ì„ê³„ê°’ {threshold}% ì™„ë£Œ ({idx+1}/{total}) | "
                    f"ê²½ê³¼: {elapsed_str} | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining_str}"
                )
            else:
                # ì²« ë²ˆì§¸ ì„ê³„ê°’ ì™„ë£Œ í›„ ì˜ˆìƒ ì‹œê°„ í‘œì‹œ
                if first_completion_time:
                    estimated_total = first_completion_time * total
                    estimated_min = int(estimated_total // 60)
                    estimated_sec = int(estimated_total % 60)
                    
                    if estimated_min > 0:
                        estimated_str = f"{estimated_min}ë¶„ {estimated_sec}ì´ˆ"
                    else:
                        estimated_str = f"{estimated_sec}ì´ˆ"
                    
                    status_text.text(
                        f"ì„ê³„ê°’ {threshold}% ì™„ë£Œ ({idx+1}/{total}) | "
                        f"ì˜ˆìƒ ì´ ì†Œìš” ì‹œê°„: ì•½ {estimated_str}"
                    )
        
        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (session_stateì— ì €ì¥)
        if 'simulation_progress' not in st.session_state:
            st.session_state.simulation_progress = {}
        st.session_state.simulation_progress[threshold] = {
            'completed': True,
            'result': result is not None
        }
    
    return {
        'results': results,
        'thresholds_tested': thresholds,
        'total_tested': total,
        'successful': len(results),
        'failed': total - len(results)
    }

def hybrid_search_optimal_threshold(
    cutoff_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    main_threshold=56,
    max_interval=6,
    min_skip_threshold=50.5,
    max_skip_threshold=51.5,
    step=0.1,
    target_max_failures=5,
    tolerance=1.0,
    max_binary_iterations=10,
    progress_bar=None,
    status_text=None
):
    """
    í•˜ì´ë¸Œë¦¬ë“œ íƒìƒ‰: ì´ì§„ íƒìƒ‰ìœ¼ë¡œ ë²”ìœ„ë¥¼ ì¢íŒ í›„ ìˆœì°¨ ê·¸ë¦¬ë“œ ì„œì¹˜ë¡œ ì •ë°€ íƒìƒ‰
    
    Args:
        cutoff_id: ê¸°ì¤€ grid_string ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        main_threshold: ë©”ì¸ ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
        min_skip_threshold: ìµœì†Œ ìŠ¤í‚µ ì„ê³„ê°’
        max_skip_threshold: ìµœëŒ€ ìŠ¤í‚µ ì„ê³„ê°’
        step: ìµœì¢… ì •ë°€ íƒìƒ‰ ì‹œ ì„ê³„ê°’ ê°„ê²©
        target_max_failures: ëª©í‘œ ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜
        tolerance: ì´ì§„ íƒìƒ‰ ì¢…ë£Œ í—ˆìš© ì˜¤ì°¨
        max_binary_iterations: ìµœëŒ€ ì´ì§„ íƒìƒ‰ ë°˜ë³µ íšŸìˆ˜
        progress_bar: Streamlit progress bar ê°ì²´ (ì„ íƒì )
        status_text: Streamlit status text ê°ì²´ (ì„ íƒì )
    
    Returns:
        dict: ëª¨ë“  ì„ê³„ê°’ì˜ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ (batch_simulate_threshold_rangeì™€ ë™ì¼í•œ í˜•ì‹)
    """
    # 1ë‹¨ê³„: ì´ì§„ íƒìƒ‰ìœ¼ë¡œ ë²”ìœ„ ì¢íˆê¸°
    left = min_skip_threshold
    right = max_skip_threshold
    iteration = 0
    best_threshold = None
    best_result = None
    binary_search_history = []
    
    if status_text:
        status_text.text(f"1ë‹¨ê³„: ì´ì§„ íƒìƒ‰ ì‹œì‘ (ë²”ìœ„: {left:.1f}% ~ {right:.1f}%)")
    
    # ì´ì§„ íƒìƒ‰ ì‹¤í–‰
    while (right - left) > tolerance and iteration < max_binary_iterations:
        iteration += 1
        mid = round((left + right) / 2, 1)
        
        if status_text:
            status_text.text(
                f"ì´ì§„ íƒìƒ‰ {iteration}íšŒì°¨: ì„ê³„ê°’ {mid}% í…ŒìŠ¤íŠ¸ ì¤‘... "
                f"(ë²”ìœ„: {left:.1f}% ~ {right:.1f}%)"
            )
        
        if progress_bar:
            # ì „ì²´ ì§„í–‰ë¥ ì˜ 30%ê¹Œì§€ëŠ” ì´ì§„ íƒìƒ‰
            progress_bar.progress((iteration / max_binary_iterations) * 0.3)
        
        # ì¤‘ê°„ê°’ í…ŒìŠ¤íŠ¸
        result = simulate_single_threshold(
            cutoff_id,
            mid,
            window_size=window_size,
            method=method,
            use_threshold=use_threshold,
            main_threshold=main_threshold,
            max_interval=max_interval
        )
        
        if result:
            max_failures = result.get('max_consecutive_failures', 999)
            binary_search_history.append({
                'threshold': mid,
                'max_consecutive_failures': max_failures,
                'range': (left, right)
            })
            
            if max_failures <= target_max_failures:
                # ì¡°ê±´ ë§Œì¡± - ë” ë‚®ì€ ì„ê³„ê°’ ì‹œë„ (ì™¼ìª½ íƒìƒ‰)
                best_threshold = mid
                best_result = result
                right = mid
            else:
                # ì¡°ê±´ ë¶ˆë§Œì¡± - ë” ë†’ì€ ì„ê³„ê°’ ì‹œë„ (ì˜¤ë¥¸ìª½ íƒìƒ‰)
                left = mid
    
    # 2ë‹¨ê³„: ì°¾ì€ ë²”ìœ„ì—ì„œ ìˆœì°¨ ê·¸ë¦¬ë“œ ì„œì¹˜
    if best_threshold is not None:
        # best_threshold ì£¼ë³€ìœ¼ë¡œ íƒìƒ‰ ë²”ìœ„ ì„¤ì •
        fine_min = max(min_skip_threshold, best_threshold - tolerance)
        fine_max = min(max_skip_threshold, best_threshold + tolerance)
        
        # ë²”ìœ„ë¥¼ step ë‹¨ìœ„ë¡œ ì •ë ¬
        fine_min = round((fine_min // step) * step, 1)
        fine_max = round((fine_max // step) * step, 1)
    else:
        # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì„ê³„ê°’ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, ì „ì²´ ë²”ìœ„ì—ì„œ ìˆœì°¨ íƒìƒ‰
        fine_min = min_skip_threshold
        fine_max = max_skip_threshold
        if status_text:
            status_text.text("âš ï¸ ì´ì§„ íƒìƒ‰ì—ì„œ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì„ê³„ê°’ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²´ ë²”ìœ„ì—ì„œ ìˆœì°¨ íƒìƒ‰í•©ë‹ˆë‹¤.")
    
    if status_text:
        status_text.text(
            f"2ë‹¨ê³„: ìˆœì°¨ ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹œì‘ ({fine_min:.1f}% ~ {fine_max:.1f}%)"
        )
    
    # ìˆœì°¨ ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰
    thresholds = []
    current = fine_min
    while current <= fine_max + 0.001:  # ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ ê³ ë ¤
        thresholds.append(round(current, 1))
        current += step
    
    results = []
    total = len(thresholds)
    start_time = time.time()
    binary_steps = iteration
    
    for idx, threshold in enumerate(thresholds):
        threshold_start = time.time()
        
        if status_text:
            status_text.text(
                f"ìˆœì°¨ íƒìƒ‰: ì„ê³„ê°’ {threshold}% í…ŒìŠ¤íŠ¸ ì¤‘... "
                f"({idx+1}/{total})"
            )
        
        result = simulate_single_threshold(
            cutoff_id,
            threshold,
            window_size=window_size,
            method=method,
            use_threshold=use_threshold,
            main_threshold=main_threshold,
            max_interval=max_interval
        )
        
        threshold_elapsed = time.time() - threshold_start
        
        if result is not None:
            results.append(result)
        
        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì—…ë°ì´íŠ¸ (30% ~ 100%)
        if progress_bar:
            progress = 0.3 + ((idx + 1) / total) * 0.7
            progress_bar.progress(progress)
        
        # ì˜ˆìƒ ì‹œê°„ ê³„ì‚° ë° í‘œì‹œ
        if status_text and idx >= 0:
            elapsed = time.time() - start_time
            if idx > 0:
                avg_time_per_threshold = elapsed / (idx + 1)
                remaining = (total - idx - 1) * avg_time_per_threshold
                
                elapsed_min = int(elapsed // 60)
                elapsed_sec = int(elapsed % 60)
                remaining_min = int(remaining // 60)
                remaining_sec = int(remaining % 60)
                
                if elapsed_min > 0:
                    elapsed_str = f"{elapsed_min}ë¶„ {elapsed_sec}ì´ˆ"
                else:
                    elapsed_str = f"{elapsed_sec}ì´ˆ"
                
                if remaining_min > 0:
                    remaining_str = f"{remaining_min}ë¶„ {remaining_sec}ì´ˆ"
                else:
                    remaining_str = f"{remaining_sec}ì´ˆ"
                
                status_text.text(
                    f"ìˆœì°¨ íƒìƒ‰: {threshold}% ì™„ë£Œ ({idx+1}/{total}) | "
                    f"ê²½ê³¼: {elapsed_str} | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining_str} | "
                    f"ì´ì§„ íƒìƒ‰: {binary_steps}íšŒ"
                )
        
        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        if 'simulation_progress' not in st.session_state:
            st.session_state.simulation_progress = {}
        st.session_state.simulation_progress[threshold] = {
            'completed': True,
            'result': result is not None
        }
    
    return {
        'results': results,
        'thresholds_tested': thresholds,
        'total_tested': total,
        'successful': len(results),
        'failed': total - len(results),
        'binary_search_steps': binary_steps,
        'binary_search_history': binary_search_history,
        'search_method': 'hybrid'
    }

def find_optimal_threshold(simulation_results):
    """
    ìµœì  ì„ê³„ê°’ ì„ ì • ì•Œê³ ë¦¬ì¦˜
    - 1ì°¨ í•„í„°ë§: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 5 ì´í•˜ì¸ ì„ê³„ê°’ë§Œ ì„ ë³„
    - 2ì°¨ ì •ë ¬: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ ê°€ì¥ ë‚®ì€ ìˆœ, ë™ì¼í•˜ë©´ ìŠ¤í‚µ íšŸìˆ˜ê°€ ì ì€ ìˆœ
    
    Args:
        simulation_results: batch_simulate_threshold_range()ì˜ ë°˜í™˜ê°’
    
    Returns:
        dict: ìµœì  ì„ê³„ê°’ ì •ë³´ ë° ì¶”ì²œ ê²°ê³¼
    """
    if not simulation_results or len(simulation_results.get('results', [])) == 0:
        return {
            'optimal_threshold': None,
            'optimal_result': None,
            'candidates': [],
            'all_results': []
        }
    
    all_results = simulation_results['results']
    
    # 1ì°¨ í•„í„°ë§: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 5 ì´í•˜ì¸ ì„ê³„ê°’ë§Œ ì„ ë³„
    candidates = [
        r for r in all_results 
        if r.get('max_consecutive_failures', 999) <= 5
    ]
    
    if len(candidates) == 0:
        # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì„ê³„ê°’ì´ ì—†ìœ¼ë©´ ì „ì²´ ê²°ê³¼ ë°˜í™˜
        # ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ ê°€ì¥ ë‚®ì€ ê²ƒì„ ì„ íƒ
        all_results_sorted = sorted(
            all_results,
            key=lambda x: (
                x.get('max_consecutive_failures', 999),
                x.get('total_skipped_predictions', 999999),
                -x.get('avg_accuracy', 0.0)
            )
        )
        optimal_result = all_results_sorted[0] if all_results_sorted else None
        return {
            'optimal_threshold': optimal_result.get('confidence_skip_threshold') if optimal_result else None,
            'optimal_result': optimal_result,
            'candidates': [],
            'all_results': all_results,
            'warning': 'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ 5 ì´í•˜ë¥¼ ë§Œì¡±í•˜ëŠ” ì„ê³„ê°’ì´ ì—†ìŠµë‹ˆë‹¤.'
        }
    
    # 2ì°¨ ì •ë ¬: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ ê°€ì¥ ë‚®ì€ ìˆœ, ë™ì¼í•˜ë©´ ìŠ¤í‚µ íšŸìˆ˜ê°€ ì ì€ ìˆœ, ë™ì¼í•˜ë©´ ì •í™•ë„ê°€ ë†’ì€ ìˆœ
    candidates_sorted = sorted(
        candidates,
        key=lambda x: (
            x.get('max_consecutive_failures', 999),
            x.get('total_skipped_predictions', 999999),
            -x.get('avg_accuracy', 0.0)
        )
    )
    
    optimal_result = candidates_sorted[0]
    optimal_threshold = optimal_result.get('confidence_skip_threshold')
    
    return {
        'optimal_threshold': optimal_threshold,
        'optimal_result': optimal_result,
        'candidates': candidates_sorted,
        'all_results': all_results,
        'candidate_count': len(candidates)
    }

def find_optimal_multi_dimensional(simulation_results):
    """
    ë‹¤ì°¨ì› ìµœì í™” ê²°ê³¼ì—ì„œ ìµœì  ì¡°í•© ì„ ì • ì•Œê³ ë¦¬ì¦˜
    - 1ì°¨ í•„í„°ë§: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 5 ì´í•˜ì¸ ì¡°í•©ë§Œ ì„ ë³„
    - 2ì°¨ ì •ë ¬: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ ê°€ì¥ ë‚®ì€ ìˆœ, ë™ì¼í•˜ë©´ ìŠ¤í‚µ íšŸìˆ˜ê°€ ì ì€ ìˆœ
    
    Args:
        simulation_results: random_search_multi_dimensional()ì˜ ë°˜í™˜ê°’
    
    Returns:
        dict: ìµœì  ì¡°í•© ì •ë³´ ë° ì¶”ì²œ ê²°ê³¼
    """
    if not simulation_results or len(simulation_results.get('results', [])) == 0:
        return {
            'optimal_combination': None,
            'candidates': [],
            'all_results': []
        }
    
    all_results = simulation_results['results']
    
    # 1ì°¨ í•„í„°ë§: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 5 ì´í•˜ì¸ ì¡°í•©ë§Œ ì„ ë³„ (ìµœìš°ì„  ì¡°ê±´)
    candidates = [
        r for r in all_results
        if r.get('max_consecutive_failures', 999) <= 5
    ]
    
    if len(candidates) == 0:
        # ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ 5 ì´í•˜ì¸ ì¡°í•©ì´ ì—†ìœ¼ë©´ ì „ì²´ ê²°ê³¼ì—ì„œ ì„ íƒ
        all_results_sorted = sorted(
            all_results,
            key=lambda x: (
                x.get('max_consecutive_failures', 999),
                x.get('total_skipped_predictions', 999999),
                -x.get('avg_accuracy', 0.0)
            )
        )
        optimal_result = all_results_sorted[0] if all_results_sorted else None
        warning_msg = 'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ 5 ì´í•˜ë¥¼ ë§Œì¡±í•˜ëŠ” ì¡°í•©ì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ê²°ê³¼ ì¤‘ ìµœì„ ì˜ ì¡°í•©ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.'
        
        if optimal_result:
            optimal_combination = {
                'window_size': optimal_result.get('window_size'),
                'max_interval': optimal_result.get('max_interval'),
                'confidence_skip_threshold': optimal_result.get('confidence_skip_threshold'),
                'result': optimal_result
            }
        else:
            optimal_combination = None
        
        return {
            'optimal_combination': optimal_combination,
            'candidates': [],
            'all_results': all_results,
            'warning': warning_msg
        }
    
    # 2ì°¨ í•„í„°ë§: ìœ ì˜ë¯¸í•œ ê²°ê³¼ ìš°ì„  ì„ íƒ (ì„ íƒì )
    # ìœ ì˜ë¯¸í•œ ê²°ê³¼ ì¡°ê±´:
    # - ì˜ˆì¸¡ë¥  >= 10% (ë„ˆë¬´ ì ê²Œ ì˜ˆì¸¡í•œ ê²½ìš° ì œì™¸)
    # - ìŠ¤í‚µ ë¹„ìœ¨ <= 90% (ë„ˆë¬´ ë§ì´ ìŠ¤í‚µí•œ ê²½ìš° ì œì™¸)
    # - ì´ ì˜ˆì¸¡ íšŸìˆ˜ >= 10íšŒ (í†µê³„ì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ìµœì†Œ ì˜ˆì¸¡ íšŸìˆ˜)
    meaningful_candidates = [
        r for r in candidates
        if r.get('prediction_rate', 0.0) >= 10.0
        and r.get('avg_skip_rate', 100.0) <= 90.0
        and r.get('total_predictions', 0) >= 10
    ]
    
    # ìœ ì˜ë¯¸í•œ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê·¸ ì¤‘ì—ì„œ ì„ íƒ, ì—†ìœ¼ë©´ ì „ì²´ í›„ë³´ì—ì„œ ì„ íƒ
    final_candidates = meaningful_candidates if len(meaningful_candidates) > 0 else candidates
    
    # 3ì°¨ ì •ë ¬: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ ê°€ì¥ ë‚®ì€ ìˆœ, ë™ì¼í•˜ë©´ ìŠ¤í‚µ íšŸìˆ˜ê°€ ì ì€ ìˆœ, ë™ì¼í•˜ë©´ ì •í™•ë„ê°€ ë†’ì€ ìˆœ
    candidates_sorted = sorted(
        final_candidates,
        key=lambda x: (
            x.get('max_consecutive_failures', 999),
            x.get('total_skipped_predictions', 999999),
            -x.get('avg_accuracy', 0.0)
        )
    )
    
    optimal_result = candidates_sorted[0]
    optimal_combination = {
        'window_size': optimal_result.get('window_size'),
        'max_interval': optimal_result.get('max_interval'),
        'confidence_skip_threshold': optimal_result.get('confidence_skip_threshold'),
        'result': optimal_result
    }
    
    # ìœ ì˜ë¯¸í•œ ê²°ê³¼ê°€ ì—†ì—ˆëŠ”ì§€ í™•ì¸ (ê²½ê³  ë©”ì‹œì§€ìš©)
    warning_msg = None
    if len(meaningful_candidates) == 0 and len(candidates) > 0:
        warning_msg = 'âš ï¸ ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ 5 ì´í•˜ ì¡°ê±´ì€ ë§Œì¡±í•˜ì§€ë§Œ, ìœ ì˜ë¯¸í•œ ê²°ê³¼ ì¡°ê±´(ì˜ˆì¸¡ë¥  â‰¥10%, ìŠ¤í‚µ ë¹„ìœ¨ â‰¤90%, ìµœì†Œ 10íšŒ ì˜ˆì¸¡)ì„ ë§Œì¡±í•˜ì§€ ì•Šì•„ ì „ì²´ í›„ë³´ ì¤‘ì—ì„œ ì„ íƒí–ˆìŠµë‹ˆë‹¤.'
    
    return {
        'optimal_combination': optimal_combination,
        'candidates': candidates_sorted,
        'all_results': all_results,
        'candidate_count': len(candidates),
        'warning': warning_msg
    }

def save_multi_dimensional_simulation_results(
    cutoff_id,
    window_size_range,
    max_interval_range,
    confidence_skip_range,
    num_samples,
    method,
    use_threshold,
    main_threshold,
    simulation_results,
    optimal_result
):
    """
    ë‹¤ì°¨ì› ìµœì í™” ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ DB ì €ì¥
    
    Args:
        cutoff_id: ê¸°ì¤€ grid_string ID
        window_size_range: (min, max) íŠœí”Œ
        max_interval_range: (min, max) íŠœí”Œ
        confidence_skip_range: (min, max, step) íŠœí”Œ
        num_samples: ìƒ˜í”Œë§ ê°œìˆ˜
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        main_threshold: ë©”ì¸ ì„ê³„ê°’
        simulation_results: random_search_multi_dimensional()ì˜ ë°˜í™˜ê°’
        optimal_result: find_optimal_multi_dimensional()ì˜ ë°˜í™˜ê°’
    
    Returns:
        str: validation_id (ì €ì¥ ì„±ê³µ ì‹œ), None (ì‹¤íŒ¨ ì‹œ)
    """
    if not create_simulation_tables():
        return None
    
    conn = get_db_connection()
    if conn is None:
        return None
    
    cursor = conn.cursor()
    
    try:
        validation_id = str(uuid.uuid4())
        window_size_min, window_size_max = window_size_range
        max_interval_min, max_interval_max = max_interval_range
        skip_min, skip_max, skip_step = confidence_skip_range
        
        # ì„¸ì…˜ ì €ì¥
        # ë‹¤ì°¨ì› ëª¨ë“œì—ì„œëŠ” window_sizeê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ìœ¼ë¡œ ë²”ìœ„ì˜ ì¤‘ê°„ê°’ ì‚¬ìš© (ì œì•½ ì¡°ê±´ ìš°íšŒ)
        default_window_size = (window_size_min + window_size_max) // 2 if window_size_max > window_size_min else window_size_min
        default_max_interval = (max_interval_min + max_interval_max) // 2 if max_interval_max > max_interval_min else max_interval_min
        
        cursor.execute('''
            INSERT INTO optimal_threshold_simulation_sessions (
                validation_id, cutoff_grid_string_id, window_size, method,
                use_threshold, threshold, max_interval,
                search_method, window_size_min, window_size_max,
                max_interval_min, max_interval_max,
                min_skip_threshold, max_skip_threshold, step, num_samples,
                created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, 'multi_dimensional', ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
        ''', (
            validation_id, cutoff_id, default_window_size, method, use_threshold,
            main_threshold if use_threshold else None, default_max_interval,
            window_size_min, window_size_max,
            max_interval_min, max_interval_max,
            skip_min, skip_max, skip_step, num_samples
        ))
        
        # ê° ì¡°í•©ë³„ ê²°ê³¼ ì €ì¥
        # ë‹¤ì°¨ì› ì‹œë®¬ë ˆì´ì…˜ì—ì„œëŠ” ê°™ì€ validation_idì™€ confidence_skip_thresholdê°€ 
        # ë‹¤ë¥¸ window_size, max_interval ì¡°í•©ì—ì„œ ë°˜ë³µë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
        # ê¸°ì¡´ validation_idì˜ ëª¨ë“  ë ˆì½”ë“œë¥¼ ë¨¼ì € ì‚­ì œí•˜ê³  ìƒˆë¡œ ì €ì¥
        cursor.execute('DELETE FROM optimal_threshold_simulation_results WHERE validation_id = ?', (validation_id,))
        
        for result in simulation_results.get('results', []):
            # ìƒˆ ë ˆì½”ë“œ ì‚½ì… (ì¤‘ë³µ ì²´í¬ ë¶ˆí•„ìš”, ìœ„ì—ì„œ ì´ë¯¸ ì‚­ì œí–ˆìœ¼ë¯€ë¡œ)
            cursor.execute('''
                INSERT INTO optimal_threshold_simulation_results (
                    validation_id, confidence_skip_threshold, window_size, max_interval,
                    max_consecutive_failures, avg_max_consecutive_failures,
                    total_skipped_predictions, avg_skip_rate,
                    below_5_ratio, avg_accuracy, prediction_rate,
                    total_grid_strings, total_steps, total_failures, total_predictions,
                    created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                result.get('confidence_skip_threshold'),
                result.get('window_size'),
                result.get('max_interval'),
                result.get('max_consecutive_failures', 0),
                result.get('avg_max_consecutive_failures', 0.0),
                result.get('total_skipped_predictions', 0),
                result.get('avg_skip_rate', 0.0),
                result.get('below_5_ratio', 0.0),
                result.get('avg_accuracy', 0.0),
                result.get('prediction_rate', 0.0),
                result.get('total_grid_strings', 0),
                result.get('total_steps', 0),
                result.get('total_failures', 0),
                result.get('total_predictions', 0)
            ))
        
        conn.commit()
        return validation_id
        
    except Exception as e:
        conn.rollback()
        st.error(f"ë‹¤ì°¨ì› ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def save_simulation_results(
    cutoff_id,
    window_size,
    method,
    use_threshold,
    main_threshold,
    max_interval,
    min_skip_threshold,
    max_skip_threshold,
    step,
    simulation_results,
    optimal_result
):
    """
    ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ DB ì €ì¥
    
    Args:
        cutoff_id: ê¸°ì¤€ grid_string ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        main_threshold: ë©”ì¸ ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
        min_skip_threshold: ìµœì†Œ ìŠ¤í‚µ ì„ê³„ê°’
        max_skip_threshold: ìµœëŒ€ ìŠ¤í‚µ ì„ê³„ê°’
        step: ì„ê³„ê°’ ê°„ê²©
        simulation_results: batch_simulate_threshold_range()ì˜ ë°˜í™˜ê°’
        optimal_result: find_optimal_threshold()ì˜ ë°˜í™˜ê°’
    
    Returns:
        str: validation_id (ì €ì¥ ì„±ê³µ ì‹œ), None (ì‹¤íŒ¨ ì‹œ)
    """
    if not create_simulation_tables():
        return None
    
    conn = get_db_connection()
    if conn is None:
        return None
    
    cursor = conn.cursor()
    
    try:
        # validation_id ìƒì„± (UUID)
        validation_id = str(uuid.uuid4())
        
        # 1. ì‹œë®¬ë ˆì´ì…˜ ì„¸ì…˜ ì €ì¥
        cursor.execute('''
            INSERT INTO optimal_threshold_simulation_sessions (
                validation_id, cutoff_grid_string_id, window_size, method,
                use_threshold, threshold, max_interval,
                min_skip_threshold, max_skip_threshold, step,
                search_method, created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'single', datetime('now', '+9 hours'))
        ''', (
            validation_id,
            cutoff_id,
            window_size,
            method,
            use_threshold,
            main_threshold if use_threshold else None,
            max_interval,
            min_skip_threshold,
            max_skip_threshold,
            step
        ))
        
        # 2. ê° ì„ê³„ê°’ë³„ ê²°ê³¼ ì €ì¥
        for result in simulation_results.get('results', []):
            cursor.execute('''
                INSERT INTO optimal_threshold_simulation_results (
                    validation_id, confidence_skip_threshold,
                    max_consecutive_failures, avg_max_consecutive_failures,
                    total_skipped_predictions, avg_skip_rate,
                    below_5_ratio, avg_accuracy, prediction_rate,
                    total_grid_strings, total_steps, total_failures, total_predictions,
                    created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                validation_id,
                result.get('confidence_skip_threshold'),
                result.get('max_consecutive_failures', 0),
                result.get('avg_max_consecutive_failures', 0.0),
                result.get('total_skipped_predictions', 0),
                result.get('avg_skip_rate', 0.0),
                result.get('below_5_ratio', 0.0),
                result.get('avg_accuracy', 0.0),
                result.get('prediction_rate', 0.0),
                result.get('total_grid_strings', 0),
                result.get('total_steps', 0),
                result.get('total_failures', 0),
                result.get('total_predictions', 0)
            ))
            
            # 3. Grid Stringë³„ ìƒì„¸ ê²°ê³¼ ì €ì¥ (ì„ íƒì  - ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì œí•œ)
            batch_results = result.get('batch_results')
            if batch_results and 'results' in batch_results:
                # ìµœëŒ€ 100ê°œë§Œ ì €ì¥ (ëŒ€ìš©ëŸ‰ ë°©ì§€)
                grid_results = batch_results['results'][:100]
                for grid_result in grid_results:
                    cursor.execute('''
                        INSERT OR REPLACE INTO optimal_threshold_simulation_grid_results (
                            validation_id, confidence_skip_threshold, grid_string_id,
                            max_consecutive_failures, total_skipped_predictions,
                            accuracy, total_steps, total_predictions,
                            created_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                    ''', (
                        validation_id,
                        result.get('confidence_skip_threshold'),
                        grid_result.get('grid_string_id'),
                        grid_result.get('max_consecutive_failures', 0),
                        grid_result.get('total_skipped_predictions', 0),
                        grid_result.get('accuracy', 0.0),
                        grid_result.get('total_steps', 0),
                        grid_result.get('total_predictions', 0)
                    ))
        
        conn.commit()
        return validation_id
        
    except Exception as e:
        conn.rollback()
        st.error(f"ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def load_simulation_sessions():
    """
    ì €ì¥ëœ ì‹œë®¬ë ˆì´ì…˜ ì„¸ì…˜ ëª©ë¡ ë¡œë“œ
    
    Returns:
        pd.DataFrame: ì‹œë®¬ë ˆì´ì…˜ ì„¸ì…˜ ëª©ë¡ (validation_id, cutoff_id, window_size, method, ìµœì  ì„ê³„ê°’ ë“±)
    """
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    try:
        # ë¨¼ì € í…Œì´ë¸” ìƒì„± ë° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        create_simulation_tables()
        
        # ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        cursor = conn.cursor()
        cursor.execute("PRAGMA table_info(optimal_threshold_simulation_sessions)")
        columns_info = cursor.fetchall()
        existing_columns = [row[1] for row in columns_info]
        
        # search_method ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¡°íšŒ
        if 'search_method' not in existing_columns:
            # ì»¬ëŸ¼ì´ ì—†ì„ ë•ŒëŠ” search_methodë¥¼ ì„ íƒí•˜ì§€ ì•ŠìŒ
            query = """
                SELECT 
                    s.validation_id,
                    s.cutoff_grid_string_id,
                    s.window_size,
                    s.method,
                    s.use_threshold,
                    s.threshold,
                    s.max_interval,
                    s.min_skip_threshold,
                    s.max_skip_threshold,
                    s.step,
                    'single' as search_method,
                    s.created_at,
                    r.confidence_skip_threshold as optimal_threshold,
                    r.max_consecutive_failures,
                    r.below_5_ratio,
                    r.avg_accuracy
                FROM optimal_threshold_simulation_sessions s
                LEFT JOIN (
                    SELECT 
                        validation_id,
                        confidence_skip_threshold,
                        max_consecutive_failures,
                        below_5_ratio,
                        avg_accuracy,
                        ROW_NUMBER() OVER (PARTITION BY validation_id ORDER BY max_consecutive_failures ASC, total_skipped_predictions ASC) as rn
                    FROM optimal_threshold_simulation_results
                    WHERE max_consecutive_failures <= 5
                ) r ON s.validation_id = r.validation_id AND r.rn = 1
                ORDER BY s.created_at DESC
            """
        else:
            query = """
                SELECT 
                    s.validation_id,
                    s.cutoff_grid_string_id,
                    s.window_size,
                    s.method,
                    s.use_threshold,
                    s.threshold,
                    s.max_interval,
                    s.min_skip_threshold,
                    s.max_skip_threshold,
                    s.step,
                    s.search_method,
                    s.created_at,
                    r.confidence_skip_threshold as optimal_threshold,
                    r.max_consecutive_failures,
                    r.below_5_ratio,
                    r.avg_accuracy
                FROM optimal_threshold_simulation_sessions s
                LEFT JOIN (
                    SELECT 
                        validation_id,
                        confidence_skip_threshold,
                        max_consecutive_failures,
                        below_5_ratio,
                        avg_accuracy,
                        ROW_NUMBER() OVER (PARTITION BY validation_id ORDER BY max_consecutive_failures ASC, total_skipped_predictions ASC) as rn
                    FROM optimal_threshold_simulation_results
                    WHERE max_consecutive_failures <= 5
                ) r ON s.validation_id = r.validation_id AND r.rn = 1
                ORDER BY s.created_at DESC
            """
        
        df = pd.read_sql_query(query, conn)
        return df
    except Exception as e:
        st.error(f"ì‹œë®¬ë ˆì´ì…˜ ì„¸ì…˜ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return pd.DataFrame()
    finally:
        conn.close()

def load_latest_multi_dimensional_result(cutoff_id=None):
    """
    ìµœê·¼ ë‹¤ì°¨ì› ìµœì í™” ê²°ê³¼ 1ê°œ ë¡œë“œ
    
    Args:
        cutoff_id: ê¸°ì¤€ grid_string ID (Noneì´ë©´ ì „ì²´ì—ì„œ ìµœê·¼ ê²°ê³¼)
    
    Returns:
        dict: ìµœê·¼ ê²°ê³¼ ì •ë³´ ë˜ëŠ” None
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        if cutoff_id is None:
            query = """
                SELECT validation_id
                FROM optimal_threshold_simulation_sessions
                WHERE search_method = 'multi_dimensional'
                ORDER BY created_at DESC
                LIMIT 1
            """
            params = []
        else:
            query = """
                SELECT validation_id
                FROM optimal_threshold_simulation_sessions
                WHERE search_method = 'multi_dimensional'
                  AND cutoff_grid_string_id = ?
                ORDER BY created_at DESC
                LIMIT 1
            """
            params = [cutoff_id]
        
        df = pd.read_sql_query(query, conn, params=params)
        
        if len(df) == 0:
            return None
        
        validation_id = df.iloc[0]['validation_id']
        
        # ì„¸ì…˜ ì •ë³´ ë¡œë“œ
        session_query = """
            SELECT *
            FROM optimal_threshold_simulation_sessions
            WHERE validation_id = ?
        """
        session_df = pd.read_sql_query(session_query, conn, params=[validation_id])
        
        if len(session_df) == 0:
            return None
        
        session_info = session_df.iloc[0].to_dict()
        
        # ìµœì  ê²°ê³¼ ë¡œë“œ
        optimal_query = """
            SELECT *
            FROM optimal_threshold_simulation_results
            WHERE validation_id = ?
            ORDER BY max_consecutive_failures ASC, total_skipped_predictions ASC
            LIMIT 1
        """
        optimal_df = pd.read_sql_query(optimal_query, conn, params=[validation_id])
        
        if len(optimal_df) > 0:
            session_info['optimal_result'] = optimal_df.iloc[0].to_dict()
        
        # ì „ì²´ ê²°ê³¼ ê°œìˆ˜
        count_query = "SELECT COUNT(*) as count FROM optimal_threshold_simulation_results WHERE validation_id = ?"
        count_df = pd.read_sql_query(count_query, conn, params=[validation_id])
        session_info['total_results'] = count_df.iloc[0]['count'] if len(count_df) > 0 else 0
        
        return session_info
        
    except Exception as e:
        st.error(f"ìµœê·¼ ë‹¤ì°¨ì› ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None
    finally:
        conn.close()

def load_simulation_session(validation_id):
    """
    íŠ¹ì • ì‹œë®¬ë ˆì´ì…˜ ì„¸ì…˜ì˜ ìƒì„¸ ì •ë³´ ë¡œë“œ
    
    Args:
        validation_id: ì‹œë®¬ë ˆì´ì…˜ ì„¸ì…˜ ID
    
    Returns:
        dict: ì„¸ì…˜ ì •ë³´ ë° ìµœì  ì„ê³„ê°’
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # ì„¸ì…˜ ì •ë³´ ë¡œë“œ
        session_query = """
            SELECT 
                validation_id,
                cutoff_grid_string_id,
                window_size,
                method,
                use_threshold,
                threshold,
                max_interval,
                min_skip_threshold,
                max_skip_threshold,
                step,
                created_at
            FROM optimal_threshold_simulation_sessions
            WHERE validation_id = ?
        """
        session_df = pd.read_sql_query(session_query, conn, params=[validation_id])
        
        if len(session_df) == 0:
            return None
        
        session_info = session_df.iloc[0].to_dict()
        
        # ìµœì  ì„ê³„ê°’ ì°¾ê¸° (5 ì´í•˜ì¸ ê²ƒ ì¤‘ ê°€ì¥ ì¢‹ì€ ê²ƒ)
        optimal_query = """
            SELECT 
                confidence_skip_threshold,
                max_consecutive_failures,
                below_5_ratio,
                avg_accuracy,
                total_skipped_predictions
            FROM optimal_threshold_simulation_results
            WHERE validation_id = ?
            ORDER BY max_consecutive_failures ASC, total_skipped_predictions ASC, avg_accuracy DESC
            LIMIT 1
        """
        optimal_df = pd.read_sql_query(optimal_query, conn, params=[validation_id])
        
        if len(optimal_df) > 0:
            session_info['optimal_confidence_skip_threshold'] = optimal_df.iloc[0]['confidence_skip_threshold']
            session_info['optimal_max_consecutive_failures'] = optimal_df.iloc[0]['max_consecutive_failures']
            session_info['optimal_below_5_ratio'] = optimal_df.iloc[0]['below_5_ratio']
            session_info['optimal_avg_accuracy'] = optimal_df.iloc[0]['avg_accuracy']
        else:
            session_info['optimal_confidence_skip_threshold'] = None
        
        return session_info
    except Exception as e:
        st.error(f"ì‹œë®¬ë ˆì´ì…˜ ì„¸ì…˜ ìƒì„¸ ì •ë³´ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None
    finally:
        conn.close()

def get_multi_window_prediction(
    grid_string,
    position,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0
):
    """
    ì—¬ëŸ¬ ìœˆë„ìš° í¬ê¸° ì¤‘ ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ì˜ˆì¸¡ê°’ ì„ íƒ
    
    Args:
        grid_string: ì „ì²´ ë¬¸ìì—´
        position: ì˜ˆì¸¡í•  ìœ„ì¹˜ (0-based index)
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
    
    Returns:
        dict: {
            'predicted': 'b' ë˜ëŠ” 'p',
            'confidence': ìµœê³  ì‹ ë¢°ë„,
            'window_size': ì„ íƒëœ ìœˆë„ìš° í¬ê¸°,
            'prefix': ì‚¬ìš©ëœ prefix,
            'all_predictions': ëª¨ë“  ìœˆë„ìš° í¬ê¸°ë³„ ì˜ˆì¸¡ ê²°ê³¼
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        all_predictions = []
        
        # ê° ìœˆë„ìš° í¬ê¸°ë³„ë¡œ ì˜ˆì¸¡ ì¡°íšŒ
        for window_size in window_sizes:
            prefix_length = window_size - 1
            
            # prefix ìƒì„± (í˜„ì¬ ìœ„ì¹˜ ì´ì „ì˜ ë¬¸ìì—´ì—ì„œ)
            if position < prefix_length:
                # prefixê°€ ë¶€ì¡±í•˜ë©´ None
                continue
            
            prefix = grid_string[position - prefix_length:position]
            
            # stored_predictionsì—ì„œ ì¡°íšŒ
            query = """
                SELECT predicted_value, confidence, b_ratio, p_ratio
                FROM stored_predictions
                WHERE window_size = ?
                  AND prefix = ?
                  AND method = ?
                  AND threshold = ?
                LIMIT 1
            """
            
            df = pd.read_sql_query(
                query, 
                conn, 
                params=[window_size, prefix, method, threshold]
            )
            
            if len(df) > 0:
                row = df.iloc[0]
                all_predictions.append({
                    'window_size': window_size,
                    'prefix': prefix,
                    'predicted': row['predicted_value'],
                    'confidence': row['confidence'],
                    'b_ratio': row['b_ratio'],
                    'p_ratio': row['p_ratio']
                })
        
        if len(all_predictions) == 0:
            return {
                'predicted': None,
                'confidence': 0.0,
                'window_size': None,
                'prefix': None,
                'all_predictions': []
            }
        
        # ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ ì˜ˆì¸¡ ì„ íƒ
        best_prediction = max(all_predictions, key=lambda x: x['confidence'])
        
        return {
            'predicted': best_prediction['predicted'],
            'confidence': best_prediction['confidence'],
            'window_size': best_prediction['window_size'],
            'prefix': best_prediction['prefix'],
            'all_predictions': all_predictions
        }
        
    except Exception as e:
        st.error(f"ë‹¤ì¤‘ ìœˆë„ìš° ì˜ˆì¸¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return None
    finally:
        conn.close()

def validate_multi_window_scenario(
    grid_string_id,
    cutoff_grid_string_id,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0
):
    """
    ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° ì „ëµìœ¼ë¡œ ê²€ì¦
    
    ê° ìœ„ì¹˜ì—ì„œ ì—¬ëŸ¬ ìœˆë„ìš° í¬ê¸° ì¤‘ ìµœê³  ì‹ ë¢°ë„ ì˜ˆì¸¡ê°’ ì„ íƒ
    
    Args:
        grid_string_id: ê²€ì¦í•  grid_string ID
        cutoff_grid_string_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string ë¡œë“œ
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        max_window_size = max(window_sizes)
        
        if len(grid_string) < max_window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'accuracy': 0.0,
                'history': []
            }
        
        # ê²€ì¦ ì‹œì‘
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        
        # ê° ìœ„ì¹˜ì—ì„œ ì˜ˆì¸¡
        for position in range(max_window_size - 1, len(grid_string)):
            total_steps += 1
            actual_value = grid_string[position]
            
            # ë‹¤ì¤‘ ìœˆë„ìš° ì˜ˆì¸¡ ìˆ˜í–‰
            prediction_result = get_multi_window_prediction(
                grid_string,
                position,
                window_sizes=window_sizes,
                method=method,
                threshold=threshold
            )
            
            predicted_value = prediction_result.get('predicted') if prediction_result else None
            confidence = prediction_result.get('confidence', 0.0) if prediction_result else 0.0
            selected_window_size = prediction_result.get('window_size') if prediction_result else None
            prefix = prediction_result.get('prefix') if prediction_result else None
            all_predictions = prediction_result.get('all_predictions', []) if prediction_result else []
            
            # ì˜ˆì¸¡ê°’ì´ ìˆìœ¼ë©´ ê²€ì¦
            if predicted_value is not None:
                is_correct = predicted_value == actual_value
                total_predictions += 1
                
                if not is_correct:
                    consecutive_failures += 1
                    total_failures += 1
                    if consecutive_failures > max_consecutive_failures:
                        max_consecutive_failures = consecutive_failures
                else:
                    consecutive_failures = 0
                
                history.append({
                    'step': total_steps,
                    'position': position,
                    'prefix': prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'selected_window_size': selected_window_size,
                    'all_predictions': all_predictions
                })
            else:
                # ì˜ˆì¸¡ê°’ì´ ì—†ìŒ
                history.append({
                    'step': total_steps,
                    'position': position,
                    'prefix': None,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': 0.0,
                    'selected_window_size': None,
                    'all_predictions': []
                })
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'accuracy': accuracy,
            'history': history
        }
        
    except Exception as e:
        st.error(f"ë‹¤ì¤‘ ìœˆë„ìš° ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_multi_window_scenario(
    cutoff_grid_string_id,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0
):
    """
    ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° ì „ëµìœ¼ë¡œ ë°°ì¹˜ ê²€ì¦
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
    
    Returns:
        dict: ë°°ì¹˜ ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff ì´í›„ì˜ ëª¨ë“  grid_string ë¡œë“œ
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0
                }
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        
        # ê° grid_stringì— ëŒ€í•´ ê²€ì¦
        for grid_string_id in grid_string_ids:
            result = validate_multi_window_scenario(
                grid_string_id,
                cutoff_grid_string_id,
                window_sizes=window_sizes,
                method=method,
                threshold=threshold
            )
            
            if result is not None:
                results.append(result)
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            total_steps = sum(r['total_steps'] for r in results)
            total_failures = sum(r['total_failures'] for r in results)
            total_predictions = sum(r['total_predictions'] for r in results)
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': total_steps,
                'total_failures': total_failures,
                'total_predictions': total_predictions
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0
            }
        
        return {
            'results': results,
            'summary': summary,
            'grid_string_ids': grid_string_ids
        }
        
    except Exception as e:
        st.error(f"ë°°ì¹˜ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
        return None
    finally:
        conn.close()

def get_multi_window_prediction_with_exclusion(
    grid_string,
    position,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0,
    excluded_window_sizes=[]
):
    """
    ì œì™¸ëœ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸í•˜ê³  ìµœê³  ì‹ ë¢°ë„ ì˜ˆì¸¡ê°’ ì„ íƒ
    
    Args:
        grid_string: ì „ì²´ ë¬¸ìì—´
        position: ì˜ˆì¸¡í•  ìœ„ì¹˜ (0-based index)
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
        excluded_window_sizes: ì œì™¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
    
    Returns:
        dict: {
            'predicted': 'b' ë˜ëŠ” 'p',
            'confidence': ìµœê³  ì‹ ë¢°ë„,
            'window_size': ì„ íƒëœ ìœˆë„ìš° í¬ê¸°,
            'prefix': ì‚¬ìš©ëœ prefix,
            'all_predictions': ëª¨ë“  ìœˆë„ìš° í¬ê¸°ë³„ ì˜ˆì¸¡ ê²°ê³¼
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        all_predictions = []
        
        # ì œì™¸ëœ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸í•œ ì‚¬ìš© ê°€ëŠ¥í•œ ìœˆë„ìš° í¬ê¸°
        available_window_sizes = [ws for ws in window_sizes if ws not in excluded_window_sizes]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ìœˆë„ìš° í¬ê¸°ê°€ ì—†ìœ¼ë©´ ì œì™¸ ë¦¬ìŠ¤íŠ¸ ë¬´ì‹œ
        if len(available_window_sizes) == 0:
            available_window_sizes = window_sizes
        
        # ê° ìœˆë„ìš° í¬ê¸°ë³„ë¡œ ì˜ˆì¸¡ ì¡°íšŒ
        for window_size in available_window_sizes:
            prefix_length = window_size - 1
            
            # prefix ìƒì„± (í˜„ì¬ ìœ„ì¹˜ ì´ì „ì˜ ë¬¸ìì—´ì—ì„œ)
            if position < prefix_length:
                # prefixê°€ ë¶€ì¡±í•˜ë©´ None
                continue
            
            prefix = grid_string[position - prefix_length:position]
            
            # stored_predictionsì—ì„œ ì¡°íšŒ
            query = """
                SELECT predicted_value, confidence, b_ratio, p_ratio
                FROM stored_predictions
                WHERE window_size = ?
                  AND prefix = ?
                  AND method = ?
                  AND threshold = ?
                LIMIT 1
            """
            
            df = pd.read_sql_query(
                query, 
                conn, 
                params=[window_size, prefix, method, threshold]
            )
            
            if len(df) > 0:
                row = df.iloc[0]
                all_predictions.append({
                    'window_size': window_size,
                    'prefix': prefix,
                    'predicted': row['predicted_value'],
                    'confidence': row['confidence'],
                    'b_ratio': row['b_ratio'],
                    'p_ratio': row['p_ratio']
                })
        
        if len(all_predictions) == 0:
            return {
                'predicted': None,
                'confidence': 0.0,
                'window_size': None,
                'prefix': None,
                'all_predictions': []
            }
        
        # ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ ì˜ˆì¸¡ ì„ íƒ
        best_prediction = max(all_predictions, key=lambda x: x['confidence'])
        
        return {
            'predicted': best_prediction['predicted'],
            'confidence': best_prediction['confidence'],
            'window_size': best_prediction['window_size'],
            'prefix': best_prediction['prefix'],
            'all_predictions': all_predictions
        }
        
    except Exception as e:
        st.error(f"ë‹¤ì¤‘ ìœˆë„ìš° ì˜ˆì¸¡ ì¡°íšŒ ì˜¤ë¥˜ (ì œì™¸ ì „ëµ): {str(e)}")
        return None
    finally:
        conn.close()

def get_multi_window_prediction_with_exclusion_and_confidence_skip(
    grid_string,
    position,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0,
    excluded_window_sizes=[],
    confidence_skip_threshold=None
):
    """
    ì œì™¸ëœ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸í•˜ê³  ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ì„ ì ìš©í•˜ì—¬ ìµœê³  ì‹ ë¢°ë„ ì˜ˆì¸¡ê°’ ì„ íƒ
    
    Args:
        grid_string: ì „ì²´ ë¬¸ìì—´
        position: ì˜ˆì¸¡í•  ìœ„ì¹˜ (0-based index)
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
        excluded_window_sizes: ì œì™¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        confidence_skip_threshold: ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ (Noneì´ë©´ ìŠ¤í‚µ ì—†ìŒ)
    
    Returns:
        dict: {
            'predicted': 'b' ë˜ëŠ” 'p',
            'confidence': ìµœê³  ì‹ ë¢°ë„,
            'window_size': ì„ íƒëœ ìœˆë„ìš° í¬ê¸°,
            'prefix': ì‚¬ìš©ëœ prefix,
            'all_predictions': ëª¨ë“  ìœˆë„ìš° í¬ê¸°ë³„ ì˜ˆì¸¡ ê²°ê³¼,
            'skipped': ìŠ¤í‚µ ì—¬ë¶€
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        all_predictions = []
        
        # ì œì™¸ëœ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸í•œ ì‚¬ìš© ê°€ëŠ¥í•œ ìœˆë„ìš° í¬ê¸°
        available_window_sizes = [ws for ws in window_sizes if ws not in excluded_window_sizes]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ìœˆë„ìš° í¬ê¸°ê°€ ì—†ìœ¼ë©´ ì œì™¸ ë¦¬ìŠ¤íŠ¸ ë¬´ì‹œ
        if len(available_window_sizes) == 0:
            available_window_sizes = window_sizes
        
        # ê° ìœˆë„ìš° í¬ê¸°ë³„ë¡œ ì˜ˆì¸¡ ì¡°íšŒ
        for window_size in available_window_sizes:
            prefix_length = window_size - 1
            
            # prefix ìƒì„± (í˜„ì¬ ìœ„ì¹˜ ì´ì „ì˜ ë¬¸ìì—´ì—ì„œ)
            if position < prefix_length:
                # prefixê°€ ë¶€ì¡±í•˜ë©´ None
                continue
            
            prefix = grid_string[position - prefix_length:position]
            
            # stored_predictionsì—ì„œ ì¡°íšŒ
            query = """
                SELECT predicted_value, confidence, b_ratio, p_ratio
                FROM stored_predictions
                WHERE window_size = ?
                  AND prefix = ?
                  AND method = ?
                  AND threshold = ?
                LIMIT 1
            """
            
            df = pd.read_sql_query(
                query, 
                conn, 
                params=[window_size, prefix, method, threshold]
            )
            
            if len(df) > 0:
                row = df.iloc[0]
                confidence = row['confidence']
                
                # ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ì²´í¬ (ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ í¬í•¨)
                if confidence_skip_threshold is None or confidence >= confidence_skip_threshold:
                    all_predictions.append({
                        'window_size': window_size,
                        'prefix': prefix,
                        'predicted': row['predicted_value'],
                        'confidence': confidence,
                        'b_ratio': row['b_ratio'],
                        'p_ratio': row['p_ratio']
                    })
        
        if len(all_predictions) == 0:
            return {
                'predicted': None,
                'confidence': 0.0,
                'window_size': None,
                'prefix': None,
                'all_predictions': [],
                'skipped': True
            }
        
        # ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ ì˜ˆì¸¡ ì„ íƒ
        best_prediction = max(all_predictions, key=lambda x: x['confidence'])
        
        return {
            'predicted': best_prediction['predicted'],
            'confidence': best_prediction['confidence'],
            'window_size': best_prediction['window_size'],
            'prefix': best_prediction['prefix'],
            'all_predictions': all_predictions,
            'skipped': False
        }
        
    except Exception as e:
        st.error(f"ë‹¤ì¤‘ ìœˆë„ìš° ì˜ˆì¸¡ ì¡°íšŒ ì˜¤ë¥˜ (ì œì™¸ ì „ëµ + ì‹ ë¢°ë„ ìŠ¤í‚µ): {str(e)}")
        return None
    finally:
        conn.close()

def validate_multi_window_scenario_with_exclusion(
    grid_string_id,
    cutoff_grid_string_id,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0
):
    """
    ì‹¤íŒ¨í•œ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸í•˜ëŠ” ì „ëµìœ¼ë¡œ ê²€ì¦
    - ì‹¤íŒ¨í•œ ìœˆë„ìš° í¬ê¸°ëŠ” ì¦‰ì‹œ ì œì™¸
    - ì„±ê³µí•˜ë©´ í•´ë‹¹ ìœˆë„ìš° í¬ê¸° ì¦‰ì‹œ ë³µêµ¬
    - ë¶ˆì¼ì¹˜ êµ¬ê°„ ì¢…ë£Œ ì‹œ (ì„±ê³µ ë°œìƒ ì‹œ) ëª¨ë“  ì œì™¸ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    
    Args:
        grid_string_id: ê²€ì¦í•  grid_string ID
        cutoff_grid_string_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string ë¡œë“œ
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        max_window_size = max(window_sizes)
        
        if len(grid_string) < max_window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'accuracy': 0.0,
                'history': []
            }
        
        # ê²€ì¦ ì‹œì‘
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        
        # ì œì™¸ëœ ìœˆë„ìš° í¬ê¸° ê´€ë¦¬
        excluded_window_sizes = set()  # ì‹¤íŒ¨í•œ ìœˆë„ìš° í¬ê¸° ì§‘í•©
        
        # ê° ìœ„ì¹˜ì—ì„œ ì˜ˆì¸¡
        for position in range(max_window_size - 1, len(grid_string)):
            total_steps += 1
            actual_value = grid_string[position]
            
            # ì˜ˆì¸¡ ì „ ì œì™¸ ë¦¬ìŠ¤íŠ¸ ìƒíƒœ ì €ì¥ (íˆìŠ¤í† ë¦¬ ê¸°ë¡ìš©)
            excluded_before_prediction = list(excluded_window_sizes.copy())
            
            # ì œì™¸ëœ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸í•˜ê³  ì˜ˆì¸¡ ìˆ˜í–‰
            prediction_result = get_multi_window_prediction_with_exclusion(
                grid_string,
                position,
                window_sizes=window_sizes,
                method=method,
                threshold=threshold,
                excluded_window_sizes=excluded_before_prediction
            )
            
            predicted_value = prediction_result.get('predicted') if prediction_result else None
            confidence = prediction_result.get('confidence', 0.0) if prediction_result else 0.0
            selected_window_size = prediction_result.get('window_size') if prediction_result else None
            prefix = prediction_result.get('prefix') if prediction_result else None
            all_predictions = prediction_result.get('all_predictions', []) if prediction_result else []
            
            # ì˜ˆì¸¡ê°’ì´ ìˆìœ¼ë©´ ê²€ì¦
            if predicted_value is not None:
                is_correct = predicted_value == actual_value
                total_predictions += 1
                
                if not is_correct:
                    consecutive_failures += 1
                    total_failures += 1
                    if consecutive_failures > max_consecutive_failures:
                        max_consecutive_failures = consecutive_failures
                    
                    # ì‹¤íŒ¨í•œ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    if selected_window_size:
                        excluded_window_sizes.add(selected_window_size)
                else:
                    # ì„±ê³µí•œ ê²½ìš°
                    consecutive_failures = 0
                    
                    # ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ 1: ì„±ê³µí•œ ìœˆë„ìš° í¬ê¸°ëŠ” ì¦‰ì‹œ ë³µêµ¬
                    if selected_window_size and selected_window_size in excluded_window_sizes:
                        excluded_window_sizes.remove(selected_window_size)
                    
                    # ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ 2: ë¶ˆì¼ì¹˜ êµ¬ê°„ ì¢…ë£Œ ì‹œ ëª¨ë“  ì œì™¸ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
                    # (ì´ì „ ìŠ¤í…ì´ ì‹¤íŒ¨ì˜€ê³  í˜„ì¬ ìŠ¤í…ì´ ì„±ê³µì´ë©´ êµ¬ê°„ ì¢…ë£Œ)
                    if len(history) > 0 and history[-1].get('is_correct') is False:
                        # ë¶ˆì¼ì¹˜ êµ¬ê°„ì´ ì¢…ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ëª¨ë“  ì œì™¸ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
                        excluded_window_sizes.clear()
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡ (ì˜ˆì¸¡ ì „ ì œì™¸ ë¦¬ìŠ¤íŠ¸ ìƒíƒœ ê¸°ë¡)
                history.append({
                    'step': total_steps,
                    'position': position,
                    'prefix': prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'selected_window_size': selected_window_size,
                    'excluded_window_sizes': excluded_before_prediction,  # ì˜ˆì¸¡ ì‹œ ì‚¬ìš©ëœ ì œì™¸ ë¦¬ìŠ¤íŠ¸ (ì˜ˆì¸¡ ì „ ìƒíƒœ)
                    'all_predictions': all_predictions
                })
            else:
                # ì˜ˆì¸¡ê°’ì´ ì—†ìŒ
                history.append({
                    'step': total_steps,
                    'position': position,
                    'prefix': None,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': 0.0,
                    'selected_window_size': None,
                    'excluded_window_sizes': excluded_before_prediction,  # ì˜ˆì¸¡ ì‹œ ì‚¬ìš©ëœ ì œì™¸ ë¦¬ìŠ¤íŠ¸
                    'all_predictions': []
                })
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'accuracy': accuracy,
            'history': history
        }
        
    except Exception as e:
        st.error(f"ë‹¤ì¤‘ ìœˆë„ìš° ê²€ì¦ ì˜¤ë¥˜ (ì œì™¸ ì „ëµ): {str(e)}")
        return None
    finally:
        conn.close()

def validate_multi_window_scenario_with_exclusion_and_confidence_skip(
    grid_string_id,
    cutoff_grid_string_id,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0,
    confidence_skip_threshold=None
):
    """
    ì œì™¸ ì „ëµ + ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµìœ¼ë¡œ ê²€ì¦
    - ì‹¤íŒ¨í•œ ìœˆë„ìš° í¬ê¸°ëŠ” ì¦‰ì‹œ ì œì™¸
    - ì„±ê³µí•˜ë©´ í•´ë‹¹ ìœˆë„ìš° í¬ê¸° ì¦‰ì‹œ ë³µêµ¬
    - ë¶ˆì¼ì¹˜ êµ¬ê°„ ì¢…ë£Œ ì‹œ (ì„±ê³µ ë°œìƒ ì‹œ) ëª¨ë“  ì œì™¸ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    - ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ë¯¸ë§Œì¸ ì˜ˆì¸¡ì€ ìŠ¤í‚µ
    
    Args:
        grid_string_id: ê²€ì¦í•  grid_string ID
        cutoff_grid_string_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
        confidence_skip_threshold: ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ (Noneì´ë©´ ìŠ¤í‚µ ì—†ìŒ)
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string ë¡œë“œ
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        max_window_size = max(window_sizes)
        
        if len(grid_string) < max_window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_skipped': 0,
                'accuracy': 0.0,
                'history': []
            }
        
        # ê²€ì¦ ì‹œì‘
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        total_skipped = 0
        
        # ì œì™¸ëœ ìœˆë„ìš° í¬ê¸° ê´€ë¦¬
        excluded_window_sizes = set()  # ì‹¤íŒ¨í•œ ìœˆë„ìš° í¬ê¸° ì§‘í•©
        
        # ê° ìœ„ì¹˜ì—ì„œ ì˜ˆì¸¡
        for position in range(max_window_size - 1, len(grid_string)):
            total_steps += 1
            actual_value = grid_string[position]
            
            # ì˜ˆì¸¡ ì „ ì œì™¸ ë¦¬ìŠ¤íŠ¸ ìƒíƒœ ì €ì¥ (íˆìŠ¤í† ë¦¬ ê¸°ë¡ìš©)
            excluded_before_prediction = list(excluded_window_sizes.copy())
            
            # ì œì™¸ëœ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸í•˜ê³  ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ë„ ì ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
            prediction_result = get_multi_window_prediction_with_exclusion_and_confidence_skip(
                grid_string,
                position,
                window_sizes=window_sizes,
                method=method,
                threshold=threshold,
                excluded_window_sizes=excluded_before_prediction,
                confidence_skip_threshold=confidence_skip_threshold
            )
            
            predicted_value = prediction_result.get('predicted') if prediction_result else None
            confidence = prediction_result.get('confidence', 0.0) if prediction_result else 0.0
            selected_window_size = prediction_result.get('window_size') if prediction_result else None
            prefix = prediction_result.get('prefix') if prediction_result else None
            all_predictions = prediction_result.get('all_predictions', []) if prediction_result else []
            skipped = prediction_result.get('skipped', False) if prediction_result else False
            
            # ì˜ˆì¸¡ê°’ì´ ìˆìœ¼ë©´ ê²€ì¦
            if predicted_value is not None:
                is_correct = predicted_value == actual_value
                total_predictions += 1
                
                if not is_correct:
                    consecutive_failures += 1
                    total_failures += 1
                    if consecutive_failures > max_consecutive_failures:
                        max_consecutive_failures = consecutive_failures
                    
                    # ì‹¤íŒ¨í•œ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    if selected_window_size:
                        excluded_window_sizes.add(selected_window_size)
                else:
                    # ì„±ê³µí•œ ê²½ìš°
                    consecutive_failures = 0
                    
                    # ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ 1: ì„±ê³µí•œ ìœˆë„ìš° í¬ê¸°ëŠ” ì¦‰ì‹œ ë³µêµ¬
                    if selected_window_size and selected_window_size in excluded_window_sizes:
                        excluded_window_sizes.remove(selected_window_size)
                    
                    # ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ 2: ë¶ˆì¼ì¹˜ êµ¬ê°„ ì¢…ë£Œ ì‹œ ëª¨ë“  ì œì™¸ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
                    # (ì´ì „ ìŠ¤í…ì´ ì‹¤íŒ¨ì˜€ê³  í˜„ì¬ ìŠ¤í…ì´ ì„±ê³µì´ë©´ êµ¬ê°„ ì¢…ë£Œ)
                    if len(history) > 0 and history[-1].get('is_correct') is False:
                        # ë¶ˆì¼ì¹˜ êµ¬ê°„ì´ ì¢…ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ëª¨ë“  ì œì™¸ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
                        excluded_window_sizes.clear()
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡ (ì˜ˆì¸¡ ì „ ì œì™¸ ë¦¬ìŠ¤íŠ¸ ìƒíƒœ ê¸°ë¡)
                history.append({
                    'step': total_steps,
                    'position': position,
                    'prefix': prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'selected_window_size': selected_window_size,
                    'excluded_window_sizes': excluded_before_prediction,  # ì˜ˆì¸¡ ì‹œ ì‚¬ìš©ëœ ì œì™¸ ë¦¬ìŠ¤íŠ¸ (ì˜ˆì¸¡ ì „ ìƒíƒœ)
                    'all_predictions': all_predictions,
                    'skipped': False
                })
            else:
                # ì˜ˆì¸¡ê°’ì´ ì—†ìŒ (ìŠ¤í‚µë¨)
                if skipped:
                    total_skipped += 1
                
                history.append({
                    'step': total_steps,
                    'position': position,
                    'prefix': None,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': 0.0,
                    'selected_window_size': None,
                    'excluded_window_sizes': excluded_before_prediction,  # ì˜ˆì¸¡ ì‹œ ì‚¬ìš©ëœ ì œì™¸ ë¦¬ìŠ¤íŠ¸
                    'all_predictions': [],
                    'skipped': skipped
                })
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'total_skipped': total_skipped,
            'accuracy': accuracy,
            'history': history
        }
        
    except Exception as e:
        st.error(f"ë‹¤ì¤‘ ìœˆë„ìš° ê²€ì¦ ì˜¤ë¥˜ (ì œì™¸ ì „ëµ + ì‹ ë¢°ë„ ìŠ¤í‚µ): {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_multi_window_scenario_with_exclusion(
    cutoff_grid_string_id,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0
):
    """
    ì œì™¸ ì „ëµì„ ì‚¬ìš©í•œ ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° ë°°ì¹˜ ê²€ì¦
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
    
    Returns:
        dict: ë°°ì¹˜ ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff ì´í›„ì˜ ëª¨ë“  grid_string ë¡œë“œ
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0
                }
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        
        # ê° grid_stringì— ëŒ€í•´ ê²€ì¦
        for grid_string_id in grid_string_ids:
            result = validate_multi_window_scenario_with_exclusion(
                grid_string_id,
                cutoff_grid_string_id,
                window_sizes=window_sizes,
                method=method,
                threshold=threshold
            )
            
            if result is not None:
                results.append(result)
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            total_steps = sum(r['total_steps'] for r in results)
            total_failures = sum(r['total_failures'] for r in results)
            total_predictions = sum(r['total_predictions'] for r in results)
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': total_steps,
                'total_failures': total_failures,
                'total_predictions': total_predictions
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0
            }
        
        return {
            'results': results,
            'summary': summary,
            'grid_string_ids': grid_string_ids
        }
        
    except Exception as e:
        st.error(f"ë°°ì¹˜ ê²€ì¦ ì˜¤ë¥˜ (ì œì™¸ ì „ëµ): {str(e)}")
        return None
    finally:
        conn.close()

def get_multi_window_prediction_with_confidence_skip(
    grid_string,
    position,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0,
    confidence_skip_threshold=None
):
    """
    ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° ì˜ˆì¸¡ + ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ì ìš©
    
    Args:
        grid_string: ì „ì²´ ë¬¸ìì—´
        position: ì˜ˆì¸¡í•  ìœ„ì¹˜ (0-based index)
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
        confidence_skip_threshold: ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ (Noneì´ë©´ ìŠ¤í‚µ ì—†ìŒ)
    
    Returns:
        dict: {
            'predicted': 'b' ë˜ëŠ” 'p',
            'confidence': ìµœê³  ì‹ ë¢°ë„,
            'window_size': ì„ íƒëœ ìœˆë„ìš° í¬ê¸°,
            'prefix': ì‚¬ìš©ëœ prefix,
            'all_predictions': ëª¨ë“  ìœˆë„ìš° í¬ê¸°ë³„ ì˜ˆì¸¡ ê²°ê³¼,
            'skipped': ìŠ¤í‚µ ì—¬ë¶€
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        all_predictions = []
        
        # ê° ìœˆë„ìš° í¬ê¸°ë³„ë¡œ ì˜ˆì¸¡ ì¡°íšŒ
        for window_size in window_sizes:
            prefix_length = window_size - 1
            
            # prefix ìƒì„± (í˜„ì¬ ìœ„ì¹˜ ì´ì „ì˜ ë¬¸ìì—´ì—ì„œ)
            if position < prefix_length:
                # prefixê°€ ë¶€ì¡±í•˜ë©´ None
                continue
            
            prefix = grid_string[position - prefix_length:position]
            
            # stored_predictionsì—ì„œ ì¡°íšŒ
            query = """
                SELECT predicted_value, confidence, b_ratio, p_ratio
                FROM stored_predictions
                WHERE window_size = ?
                  AND prefix = ?
                  AND method = ?
                  AND threshold = ?
                LIMIT 1
            """
            
            df = pd.read_sql_query(
                query, 
                conn, 
                params=[window_size, prefix, method, threshold]
            )
            
            if len(df) > 0:
                row = df.iloc[0]
                confidence = row['confidence']
                
                # ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ì²´í¬
                if confidence_skip_threshold is None or confidence >= confidence_skip_threshold:
                    all_predictions.append({
                        'window_size': window_size,
                        'prefix': prefix,
                        'predicted': row['predicted_value'],
                        'confidence': confidence,
                        'b_ratio': row['b_ratio'],
                        'p_ratio': row['p_ratio']
                    })
        
        if len(all_predictions) == 0:
            return {
                'predicted': None,
                'confidence': 0.0,
                'window_size': None,
                'prefix': None,
                'all_predictions': [],
                'skipped': True
            }
        
        # ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ ì˜ˆì¸¡ ì„ íƒ
        best_prediction = max(all_predictions, key=lambda x: x['confidence'])
        
        return {
            'predicted': best_prediction['predicted'],
            'confidence': best_prediction['confidence'],
            'window_size': best_prediction['window_size'],
            'prefix': best_prediction['prefix'],
            'all_predictions': all_predictions,
            'skipped': False
        }
        
    except Exception as e:
        st.error(f"ë‹¤ì¤‘ ìœˆë„ìš° ì˜ˆì¸¡ ì¡°íšŒ ì˜¤ë¥˜ (ì‹ ë¢°ë„ ìŠ¤í‚µ): {str(e)}")
        return None
    finally:
        conn.close()

def validate_multi_window_with_confidence_skip(
    grid_string_id,
    cutoff_grid_string_id,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0,
    confidence_skip_threshold=None
):
    """
    ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° + ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµìœ¼ë¡œ ê²€ì¦
    
    Args:
        grid_string_id: ê²€ì¦í•  grid_string ID
        cutoff_grid_string_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
        confidence_skip_threshold: ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ (Noneì´ë©´ ìŠ¤í‚µ ì—†ìŒ)
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string ë¡œë“œ
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        max_window_size = max(window_sizes)
        
        if len(grid_string) < max_window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_skipped': 0,
                'accuracy': 0.0,
                'history': []
            }
        
        # ê²€ì¦ ì‹œì‘
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        total_skipped = 0
        
        # ê° ìœ„ì¹˜ì—ì„œ ì˜ˆì¸¡
        for position in range(max_window_size - 1, len(grid_string)):
            total_steps += 1
            actual_value = grid_string[position]
            
            # ë‹¤ì¤‘ ìœˆë„ìš° ì˜ˆì¸¡ ìˆ˜í–‰ (ì‹ ë¢°ë„ ìŠ¤í‚µ ì ìš©)
            prediction_result = get_multi_window_prediction_with_confidence_skip(
                grid_string,
                position,
                window_sizes=window_sizes,
                method=method,
                threshold=threshold,
                confidence_skip_threshold=confidence_skip_threshold
            )
            
            predicted_value = prediction_result.get('predicted') if prediction_result else None
            confidence = prediction_result.get('confidence', 0.0) if prediction_result else 0.0
            selected_window_size = prediction_result.get('window_size') if prediction_result else None
            prefix = prediction_result.get('prefix') if prediction_result else None
            all_predictions = prediction_result.get('all_predictions', []) if prediction_result else []
            skipped = prediction_result.get('skipped', False) if prediction_result else False
            
            # ì˜ˆì¸¡ê°’ì´ ìˆìœ¼ë©´ ê²€ì¦
            if predicted_value is not None:
                is_correct = predicted_value == actual_value
                total_predictions += 1
                
                if not is_correct:
                    consecutive_failures += 1
                    total_failures += 1
                    if consecutive_failures > max_consecutive_failures:
                        max_consecutive_failures = consecutive_failures
                else:
                    consecutive_failures = 0
                
                history.append({
                    'step': total_steps,
                    'position': position,
                    'prefix': prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'selected_window_size': selected_window_size,
                    'all_predictions': all_predictions,
                    'skipped': False
                })
            else:
                # ì˜ˆì¸¡ê°’ì´ ì—†ìŒ (ìŠ¤í‚µë¨)
                if skipped:
                    total_skipped += 1
                
                history.append({
                    'step': total_steps,
                    'position': position,
                    'prefix': None,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': 0.0,
                    'selected_window_size': None,
                    'all_predictions': [],
                    'skipped': skipped
                })
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'total_skipped': total_skipped,
            'accuracy': accuracy,
            'history': history
        }
        
    except Exception as e:
        st.error(f"ë‹¤ì¤‘ ìœˆë„ìš° ê²€ì¦ ì˜¤ë¥˜ (ì‹ ë¢°ë„ ìŠ¤í‚µ): {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_multi_window_scenario_with_exclusion_and_confidence_skip(
    cutoff_grid_string_id,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0,
    confidence_skip_threshold=None
):
    """
    ì œì™¸ ì „ëµ + ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµì„ ì‚¬ìš©í•œ ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° ë°°ì¹˜ ê²€ì¦
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
        confidence_skip_threshold: ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ (Noneì´ë©´ ìŠ¤í‚µ ì—†ìŒ)
    
    Returns:
        dict: ë°°ì¹˜ ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff ì´í›„ì˜ ëª¨ë“  grid_string ë¡œë“œ
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0,
                    'total_skipped': 0
                }
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        
        # ê° grid_stringì— ëŒ€í•´ ê²€ì¦
        for grid_string_id in grid_string_ids:
            result = validate_multi_window_scenario_with_exclusion_and_confidence_skip(
                grid_string_id,
                cutoff_grid_string_id,
                window_sizes=window_sizes,
                method=method,
                threshold=threshold,
                confidence_skip_threshold=confidence_skip_threshold
            )
            
            if result is not None:
                results.append(result)
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            total_steps = sum(r['total_steps'] for r in results)
            total_failures = sum(r['total_failures'] for r in results)
            total_predictions = sum(r['total_predictions'] for r in results)
            total_skipped = sum(r['total_skipped'] for r in results)
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': total_steps,
                'total_failures': total_failures,
                'total_predictions': total_predictions,
                'total_skipped': total_skipped
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_skipped': 0
            }
        
        return {
            'results': results,
            'summary': summary,
            'grid_string_ids': grid_string_ids
        }
        
    except Exception as e:
        st.error(f"ë‹¤ì¤‘ ìœˆë„ìš° ë°°ì¹˜ ê²€ì¦ ì˜¤ë¥˜ (ì œì™¸ ì „ëµ + ì‹ ë¢°ë„ ìŠ¤í‚µ): {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_multi_window_with_confidence_skip(
    cutoff_grid_string_id,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0,
    confidence_skip_threshold=None
):
    """
    ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° + ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµìœ¼ë¡œ ë°°ì¹˜ ê²€ì¦
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
        confidence_skip_threshold: ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ (Noneì´ë©´ ìŠ¤í‚µ ì—†ìŒ)
    
    Returns:
        dict: ë°°ì¹˜ ê²€ì¦ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff ì´í›„ì˜ ëª¨ë“  grid_string ë¡œë“œ
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0,
                    'total_skipped': 0
                }
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        
        # ê° grid_stringì— ëŒ€í•´ ê²€ì¦
        for grid_string_id in grid_string_ids:
            result = validate_multi_window_with_confidence_skip(
                grid_string_id,
                cutoff_grid_string_id,
                window_sizes=window_sizes,
                method=method,
                threshold=threshold,
                confidence_skip_threshold=confidence_skip_threshold
            )
            
            if result is not None:
                results.append(result)
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            total_steps = sum(r['total_steps'] for r in results)
            total_failures = sum(r['total_failures'] for r in results)
            total_predictions = sum(r['total_predictions'] for r in results)
            total_skipped = sum(r['total_skipped'] for r in results)
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': total_steps,
                'total_failures': total_failures,
                'total_predictions': total_predictions,
                'total_skipped': total_skipped
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_skipped': 0
            }
        
        return {
            'results': results,
            'summary': summary,
            'grid_string_ids': grid_string_ids
        }
        
    except Exception as e:
        st.error(f"ë°°ì¹˜ ê²€ì¦ ì˜¤ë¥˜ (ì‹ ë¢°ë„ ìŠ¤í‚µ): {str(e)}")
        return None
    finally:
        conn.close()

def binary_search_optimal_threshold_multi_window(
    cutoff_id,
    window_sizes=[5, 6, 7, 8, 9],
    method="ë¹ˆë„ ê¸°ë°˜",
    threshold=0,
    min_range=50.5,
    max_range=59.0,
    target_max_failures=5,
    tolerance=0.5,
    max_iterations=10,
    progress_bar=None,
    status_text=None
):
    """
    ì´ì§„ íƒìƒ‰ìœ¼ë¡œ ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° ì „ëµì˜ ìµœì  ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ì°¾ê¸°
    
    Args:
        cutoff_id: ê¸°ì¤€ grid_string ID
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
        min_range: ìµœì†Œ ì„ê³„ê°’ ë²”ìœ„
        max_range: ìµœëŒ€ ì„ê³„ê°’ ë²”ìœ„
        target_max_failures: ëª©í‘œ ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜
        tolerance: ìµœì¢… ì •ë°€ë„
        max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
        progress_bar: Streamlit progress bar ê°ì²´ (ì„ íƒì )
        status_text: Streamlit status text ê°ì²´ (ì„ íƒì )
    
    Returns:
        tuple: (ìµœì  ì„ê³„ê°’, ìµœì  ê²°ê³¼, íƒìƒ‰ íˆìŠ¤í† ë¦¬)
    """
    best_threshold = None
    best_result = None
    left = min_range
    right = max_range
    iteration = 0
    search_history = []
    
    # 1ë‹¨ê³„: í° ê°„ê²©ìœ¼ë¡œ ì´ì§„ íƒìƒ‰
    while (right - left) > tolerance and iteration < max_iterations:
        iteration += 1
        mid = round((left + right) / 2, 1)
        
        if status_text:
            status_text.text(f"ì´ì§„ íƒìƒ‰ {iteration}íšŒì°¨: ì„ê³„ê°’ {mid}% í…ŒìŠ¤íŠ¸ ì¤‘... (ë²”ìœ„: {left:.1f} ~ {right:.1f})")
        
        # ì¤‘ê°„ê°’ í…ŒìŠ¤íŠ¸
        result = batch_validate_multi_window_with_confidence_skip(
            cutoff_id,
            window_sizes=window_sizes,
            method=method,
            threshold=threshold,
            confidence_skip_threshold=mid
        )
        
        if result:
            summary = result.get('summary', {})
            max_failures = summary.get('max_consecutive_failures', 999)
            
            search_history.append({
                'iteration': iteration,
                'threshold': mid,
                'max_consecutive_failures': max_failures,
                'avg_accuracy': summary.get('avg_accuracy', 0.0),
                'total_skipped': summary.get('total_skipped', 0),
                'range': (left, right)
            })
            
            if max_failures <= target_max_failures:
                # ì¡°ê±´ ë§Œì¡± - ë” ë‚®ì€ ì„ê³„ê°’ ì‹œë„ (ì™¼ìª½ íƒìƒ‰)
                best_threshold = mid
                best_result = result
                right = mid
            else:
                # ì¡°ê±´ ë¶ˆë§Œì¡± - ë” ë†’ì€ ì„ê³„ê°’ ì‹œë„ (ì˜¤ë¥¸ìª½ íƒìƒ‰)
                left = mid
        
        if progress_bar:
            progress_bar.progress(iteration / max_iterations * 0.7)  # 70%ê¹Œì§€ëŠ” ì´ì§„ íƒìƒ‰
    
    # 2ë‹¨ê³„: ì°¾ì€ ë²”ìœ„ì—ì„œ ì„¸ë°€í•˜ê²Œ ê·¸ë¦¬ë“œ ì„œì¹˜
    if best_threshold:
        fine_min = max(min_range, best_threshold - tolerance)
        fine_max = min(max_range, best_threshold + tolerance)
        fine_step = 0.1
        
        if status_text:
            status_text.text(f"ì„¸ë°€ íƒìƒ‰: {fine_min:.1f} ~ {fine_max:.1f} ë²”ìœ„ì—ì„œ 0.1 ê°„ê²©ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        fine_thresholds = []
        current = fine_min
        while current <= fine_max + 0.001:
            fine_thresholds.append(round(current, 1))
            current += fine_step
        
        fine_results = []
        for idx, thresh in enumerate(fine_thresholds):
            if status_text:
                status_text.text(f"ì„¸ë°€ íƒìƒ‰: {thresh}% í…ŒìŠ¤íŠ¸ ì¤‘... ({idx+1}/{len(fine_thresholds)})")
            
            result = batch_validate_multi_window_with_confidence_skip(
                cutoff_id,
                window_sizes=window_sizes,
                method=method,
                threshold=threshold,
                confidence_skip_threshold=thresh
            )
            
            if result:
                summary = result.get('summary', {})
                fine_results.append({
                    'threshold': thresh,
                    'result': result,
                    'max_consecutive_failures': summary.get('max_consecutive_failures', 999),
                    'avg_accuracy': summary.get('avg_accuracy', 0.0),
                    'total_skipped': summary.get('total_skipped', 0)
                })
            
            if progress_bar:
                progress = 0.7 + (idx + 1) / len(fine_thresholds) * 0.3
                progress_bar.progress(progress)
        
        # ìµœì ê°’ ì„ íƒ
        candidates = [
            r for r in fine_results
            if r['max_consecutive_failures'] <= target_max_failures
        ]
        
        if candidates:
            optimal = min(candidates, key=lambda x: (
                x['max_consecutive_failures'],
                x['result'].get('summary', {}).get('total_failures', 999999)
            ))
            return optimal['threshold'], optimal['result'], search_history
    
    return best_threshold, best_result, search_history

def format_datetime_for_dropdown(datetime_str):
    """
    ë“œë¡­ë‹¤ìš´ìš© ë‚ ì§œ í¬ë§·: MM-DD HH:MM (ì—°ë„ ì œì™¸)
    
    Args:
        datetime_str: ë‚ ì§œ ì‹œê°„ ë¬¸ìì—´
    
    Returns:
        str: "MM-DD HH:MM" í˜•ì‹ì˜ ë¬¸ìì—´
    """
    if datetime_str is None:
        return ""
    
    try:
        # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ íŒŒì‹± ì‹œë„
        from datetime import datetime
        
        # SQLite datetime í˜•ì‹: "YYYY-MM-DD HH:MM:SS"
        if isinstance(datetime_str, str):
            # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë‚ ì§œì™€ ì‹œê°„ ì¶”ì¶œ
            parts = datetime_str.split()
            if len(parts) >= 2:
                date_part = parts[0]
                time_part = parts[1]
                
                # ë‚ ì§œ íŒŒì‹± (YYYY-MM-DD)
                date_parts = date_part.split('-')
                if len(date_parts) >= 3:
                    month = date_parts[1]
                    day = date_parts[2]
                    
                    # ì‹œê°„ íŒŒì‹± (HH:MM:SS ë˜ëŠ” HH:MM)
                    time_parts = time_part.split(':')
                    if len(time_parts) >= 2:
                        hour = time_parts[0]
                        minute = time_parts[1]
                        
                        return f"{month}-{day} {hour}:{minute}"
        
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
        return str(datetime_str)
    except Exception as e:
        return str(datetime_str)

def analyze_failure_patterns(simulation_results, min_failures=6):
    """
    ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ min_failures ì´ìƒì¸ grid_string ë¶„ì„
    
    Args:
        simulation_results: batch_validate_multi_window_scenario()ì˜ ë°˜í™˜ê°’
        min_failures: ìµœì†Œ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜ (ê¸°ë³¸ê°’: 6)
    
    Returns:
        dict: {
            'failure_grid_strings': ì‹¤íŒ¨í•œ grid_string ë¦¬ìŠ¤íŠ¸,
            'common_failure_prefixes': ê³µí†µ ì‹¤íŒ¨ prefix íŒ¨í„´,
            'failure_positions': ì‹¤íŒ¨ ìœ„ì¹˜ ë¶„ì„,
            'confidence_analysis': ì‹ ë¢°ë„ ë¶„ì„,
            'window_size_analysis': ìœˆë„ìš° í¬ê¸°ë³„ ë¶„ì„,
            'failure_statistics': ì‹¤íŒ¨ í†µê³„
        }
    """
    if not simulation_results or len(simulation_results.get('results', [])) == 0:
        return {
            'failure_grid_strings': [],
            'common_failure_prefixes': {},
            'failure_positions': {},
            'confidence_analysis': {},
            'window_size_analysis': {},
            'failure_statistics': {}
        }
    
    results = simulation_results.get('results', [])
    
    # ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ min_failures ì´ìƒì¸ grid_string í•„í„°ë§
    failure_grid_strings = [
        r for r in results 
        if r.get('max_consecutive_failures', 0) >= min_failures
    ]
    
    if len(failure_grid_strings) == 0:
        return {
            'failure_grid_strings': [],
            'common_failure_prefixes': {},
            'failure_positions': {},
            'confidence_analysis': {},
            'window_size_analysis': {},
            'failure_statistics': {
                'total_failures': 0,
                'failure_rate': 0.0
            }
        }
    
    # ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
    common_failure_prefixes = defaultdict(int)
    failure_positions = defaultdict(int)
    confidence_before_failure = []
    confidence_during_failure = []
    window_size_usage = defaultdict(lambda: {'total': 0, 'failures': 0})
    
    for result in failure_grid_strings:
        history = result.get('history', [])
        consecutive_failures = 0
        max_consecutive = result.get('max_consecutive_failures', 0)
        
        for i, h in enumerate(history):
            is_correct = h.get('is_correct')
            prefix = h.get('prefix')
            position = h.get('position')
            confidence = h.get('confidence', 0.0)
            selected_window_size = h.get('selected_window_size')
            
            if is_correct is False:
                consecutive_failures += 1
                
                # ì‹¤íŒ¨ prefix ê¸°ë¡
                if prefix:
                    common_failure_prefixes[prefix] += 1
                
                # ì‹¤íŒ¨ ìœ„ì¹˜ ê¸°ë¡
                if position is not None:
                    failure_positions[position] += 1
                
                # ì‹¤íŒ¨ ì¤‘ ì‹ ë¢°ë„ ê¸°ë¡
                confidence_during_failure.append(confidence)
                
                # ìœˆë„ìš° í¬ê¸°ë³„ ì‹¤íŒ¨ ê¸°ë¡
                if selected_window_size:
                    window_size_usage[selected_window_size]['failures'] += 1
                    window_size_usage[selected_window_size]['total'] += 1  # ì‹¤íŒ¨ë„ ì˜ˆì¸¡ì´ë¯€ë¡œ total ì¦ê°€
                
                # ì‹¤íŒ¨ ì „ ì‹ ë¢°ë„ ê¸°ë¡ (ì´ì „ ìŠ¤í…)
                if i > 0:
                    prev_confidence = history[i-1].get('confidence', 0.0)
                    if history[i-1].get('is_correct') is True:
                        confidence_before_failure.append(prev_confidence)
            elif is_correct is True:
                consecutive_failures = 0
                
                # ìœˆë„ìš° í¬ê¸°ë³„ ì‚¬ìš© ê¸°ë¡
                if selected_window_size:
                    window_size_usage[selected_window_size]['total'] += 1
            # is_correct is Noneì¼ ë•ŒëŠ” ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ (ì˜ˆì¸¡ê°’ì´ ì—†ì—ˆë˜ ê²½ìš°)
    
    # í†µê³„ ê³„ì‚°
    total_grid_strings = len(results)
    failure_count = len(failure_grid_strings)
    failure_rate = (failure_count / total_grid_strings * 100) if total_grid_strings > 0 else 0.0
    
    # ì‹ ë¢°ë„ ë¶„ì„
    avg_confidence_before = sum(confidence_before_failure) / len(confidence_before_failure) if confidence_before_failure else 0.0
    avg_confidence_during = sum(confidence_during_failure) / len(confidence_during_failure) if confidence_during_failure else 0.0
    
    # ìœˆë„ìš° í¬ê¸°ë³„ ì‹¤íŒ¨ìœ¨ ê³„ì‚°
    window_size_failure_rates = {}
    for window_size, stats in window_size_usage.items():
        if stats['total'] > 0:
            failure_rate_ws = (stats['failures'] / stats['total'] * 100)
            window_size_failure_rates[window_size] = {
                'failure_rate': failure_rate_ws,
                'total_usage': stats['total'],
                'failures': stats['failures']
            }
    
    # ê³µí†µ ì‹¤íŒ¨ prefix ì •ë ¬ (ë¹ˆë„ìˆœ)
    sorted_failure_prefixes = sorted(
        common_failure_prefixes.items(),
        key=lambda x: x[1],
        reverse=True
    )[:20]  # ìƒìœ„ 20ê°œë§Œ
    
    return {
        'failure_grid_strings': failure_grid_strings,
        'common_failure_prefixes': dict(sorted_failure_prefixes),
        'failure_positions': dict(failure_positions),
        'confidence_analysis': {
            'avg_before_failure': avg_confidence_before,
            'avg_during_failure': avg_confidence_during,
            'confidence_drop': avg_confidence_before - avg_confidence_during
        },
        'window_size_analysis': window_size_failure_rates,
        'failure_statistics': {
            'total_failures': failure_count,
            'total_grid_strings': total_grid_strings,
            'failure_rate': failure_rate,
            'avg_max_consecutive_failures': sum(r.get('max_consecutive_failures', 0) for r in failure_grid_strings) / failure_count if failure_count > 0 else 0.0
        }
    }

def display_multi_dimensional_results(simulation_results, optimal_result, cutoff_id, method, use_threshold, main_threshold):
    """ë‹¤ì°¨ì› ìµœì í™” ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜"""
    st.markdown("---")
    st.markdown("### ğŸ“Š ë‹¤ì°¨ì› ìµœì í™” ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")
    
    # ìµœì  ì¡°í•© ì¶”ì²œ
    optimal_combination = optimal_result.get('optimal_combination')
    
    if optimal_combination is not None:
        opt_result = optimal_combination.get('result')
        
        st.success(
            f"âœ… **ì¶”ì²œ ìµœì  ì¡°í•©**: "
            f"ìœˆë„ìš° í¬ê¸°={optimal_combination['window_size']}, "
            f"ìµœëŒ€ ê°„ê²©={optimal_combination['max_interval']}, "
            f"ì„ê³„ê°’={optimal_combination['confidence_skip_threshold']}%"
        )
        
        col_opt1, col_opt2, col_opt3, col_opt4 = st.columns(4)
        with col_opt1:
            st.metric("ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", f"{opt_result.get('max_consecutive_failures', 0)}íšŒ")
        with col_opt2:
            st.metric("5 ì´í•˜ ë¹„ìœ¨", f"{opt_result.get('below_5_ratio', 0):.2f}%")
        with col_opt3:
            st.metric("ì´ ìŠ¤í‚µ íšŸìˆ˜", f"{opt_result.get('total_skipped_predictions', 0):,}íšŒ")
        with col_opt4:
            st.metric("í‰ê·  ì •í™•ë„", f"{opt_result.get('avg_accuracy', 0):.2f}%")
        
        if optimal_result.get('warning'):
            st.warning(optimal_result['warning'])
        
        # ì¡°ê±´ ë§Œì¡±í•˜ëŠ” í›„ë³´ ê°œìˆ˜
        candidate_count = optimal_result.get('candidate_count', 0)
        if candidate_count > 0:
            st.info(f"ğŸ’¡ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¡°í•©: {candidate_count}ê°œ (ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ â‰¤ 5)")
    else:
        st.error("âŒ ìµœì  ì¡°í•©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìƒìœ„ ì¡°í•© ë¹„êµ í…Œì´ë¸” (ìµœëŒ€ 20ê°œ)
    st.markdown("---")
    st.markdown("### ğŸ“‹ ì¡°í•© ë¹„êµ (ìƒìœ„ 20ê°œ)")
    
    all_results = simulation_results.get('results', [])
    
    # ì •ë ¬: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ ê¸°ì¤€
    sorted_results = sorted(
        all_results,
        key=lambda x: (
            x.get('max_consecutive_failures', 999),
            x.get('total_skipped_predictions', 999999),
            -x.get('avg_accuracy', 0.0)
        )
    )[:20]
    
    comparison_data = []
    for result in sorted_results:
        is_optimal = (
            optimal_combination is not None and
            result.get('window_size') == optimal_combination['window_size'] and
            result.get('max_interval') == optimal_combination['max_interval'] and
            result.get('confidence_skip_threshold') == optimal_combination['confidence_skip_threshold']
        )
        
        comparison_data.append({
            'ìœˆë„ìš° í¬ê¸°': result.get('window_size'),
            'ìµœëŒ€ ê°„ê²©': result.get('max_interval'),
            'ì„ê³„ê°’ (%)': f"{result.get('confidence_skip_threshold', 0):.1f}",
            'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': result.get('max_consecutive_failures', 0),
            'í‰ê·  ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': f"{result.get('avg_max_consecutive_failures', 0):.2f}",
            '5 ì´í•˜ ë¹„ìœ¨ (%)': f"{result.get('below_5_ratio', 0):.2f}",
            'ì´ ìŠ¤í‚µ íšŸìˆ˜': result.get('total_skipped_predictions', 0),
            'í‰ê·  ì •í™•ë„ (%)': f"{result.get('avg_accuracy', 0):.2f}",
            'ìµœì ': 'âœ…' if is_optimal else ''
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    st.dataframe(comparison_df, use_container_width=True, hide_index=True)
    
    # íŒŒë¼ë¯¸í„°ë³„ íš¨ê³¼ ë¶„ì„
    st.markdown("---")
    st.markdown("### ğŸ“ˆ íŒŒë¼ë¯¸í„°ë³„ íš¨ê³¼ ë¶„ì„")
    
    # ìœˆë„ìš° í¬ê¸°ë³„ í‰ê·  ì„±ëŠ¥
    window_size_stats = defaultdict(lambda: {'total': 0, 'failures_sum': 0, 'count': 0})
    for result in all_results:
        ws = result.get('window_size')
        failures = result.get('max_consecutive_failures', 0)
        window_size_stats[ws]['total'] += failures
        window_size_stats[ws]['count'] += 1
    
    ws_data = []
    for ws in sorted(window_size_stats.keys()):
        stats = window_size_stats[ws]
        avg_failures = stats['total'] / stats['count'] if stats['count'] > 0 else 0
        ws_data.append({
            'ìœˆë„ìš° í¬ê¸°': ws,
            'í…ŒìŠ¤íŠ¸ íšŸìˆ˜': stats['count'],
            'í‰ê·  ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': f"{avg_failures:.2f}"
        })
    
    if ws_data:
        col_analysis1, col_analysis2 = st.columns(2)
        with col_analysis1:
            st.markdown("#### ìœˆë„ìš° í¬ê¸°ë³„ ì„±ëŠ¥")
            ws_df = pd.DataFrame(ws_data)
            st.dataframe(ws_df, use_container_width=True, hide_index=True)
    
    # ìµœëŒ€ ê°„ê²©ë³„ í‰ê·  ì„±ëŠ¥
    interval_stats = defaultdict(lambda: {'total': 0, 'count': 0})
    for result in all_results:
        mi = result.get('max_interval')
        failures = result.get('max_consecutive_failures', 0)
        interval_stats[mi]['total'] += failures
        interval_stats[mi]['count'] += 1
    
    interval_data = []
    for mi in sorted(interval_stats.keys()):
        stats = interval_stats[mi]
        avg_failures = stats['total'] / stats['count'] if stats['count'] > 0 else 0
        interval_data.append({
            'ìµœëŒ€ ê°„ê²©': mi,
            'í…ŒìŠ¤íŠ¸ íšŸìˆ˜': stats['count'],
            'í‰ê·  ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': f"{avg_failures:.2f}"
        })
    
    if interval_data:
        with col_analysis2:
            st.markdown("#### ìµœëŒ€ ê°„ê²©ë³„ ì„±ëŠ¥")
            interval_df = pd.DataFrame(interval_data)
            st.dataframe(interval_df, use_container_width=True, hide_index=True)
    
    # ì‹œë®¬ë ˆì´ì…˜ í†µê³„
    st.markdown("---")
    st.markdown("### ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ í†µê³„")
    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
    with col_stat1:
        total_tested = simulation_results.get('total_tested', 0)
        total_planned = simulation_results.get('total_planned', total_tested)
        if total_planned > total_tested:
            st.metric("í…ŒìŠ¤íŠ¸í•œ ì¡°í•© ìˆ˜", f"{total_tested}ê°œ", f"ê³„íš: {total_planned}ê°œ (ì¡°ê¸° ì¢…ë£Œ)")
        else:
            st.metric("í…ŒìŠ¤íŠ¸í•œ ì¡°í•© ìˆ˜", f"{total_tested}ê°œ")
    with col_stat2:
        st.metric("ê°€ëŠ¥í•œ ì¡°í•© ìˆ˜", f"{simulation_results.get('total_combinations_possible', 0):,}ê°œ")
    with col_stat3:
        meaningful_count = simulation_results.get('meaningful_count', 0)
        st.metric("ìœ ì˜ë¯¸í•œ ê²°ê³¼", f"{meaningful_count}ê°œ", 
                 help="ì˜ˆì¸¡ë¥  â‰¥10%, ìŠ¤í‚µ ë¹„ìœ¨ â‰¤90%, ìµœì†Œ 10íšŒ ì˜ˆì¸¡")
    with col_stat4:
        success_rate = (simulation_results.get('successful', 0) / max(total_tested, 1)) * 100
        st.metric("ì„±ê³µë¥ ", f"{success_rate:.1f}%")
    
    # ì¡°ê¸° ì¢…ë£Œ ì •ë³´
    if simulation_results.get('early_stopped', False):
        st.info(f"âš¡ **ì¡°ê¸° ì¢…ë£Œ**: ì¶©ë¶„í•œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ë¥¼ ì°¾ì•„ {total_planned - total_tested}ê°œ ì¡°í•©ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤. ì‹œê°„ ì ˆì•½: ì•½ {int((total_planned - total_tested) * 0.3)}ë¶„")
    
    # ê²°ê³¼ ì €ì¥ ë²„íŠ¼ (session_stateì—ì„œ í•„ìš”í•œ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°)
    st.markdown("---")
    col_save1, col_save2 = st.columns([1, 4])
    with col_save1:
        if st.button("ğŸ’¾ ê²°ê³¼ ì €ì¥", type="primary", use_container_width=True, key="save_multi_dimensional"):
            # session_stateì—ì„œ ë‹¤ì°¨ì› ì„¤ì • ê°€ì ¸ì˜¤ê¸°
            window_size_min = st.session_state.get('multi_window_size_min', 5)
            window_size_max = st.session_state.get('multi_window_size_max', 9)
            max_interval_min = st.session_state.get('multi_max_interval_min', 1)
            max_interval_max = st.session_state.get('multi_max_interval_max', 20)
            min_skip_threshold = st.session_state.get('multi_min_skip_threshold', 51.0)
            max_skip_threshold = st.session_state.get('multi_max_skip_threshold', 53.5)
            threshold_step = st.session_state.get('multi_threshold_step', 0.1)
            num_samples = st.session_state.get('multi_num_samples', 100)
            
            validation_id = save_multi_dimensional_simulation_results(
                cutoff_id,
                (window_size_min, window_size_max),
                (max_interval_min, max_interval_max),
                (min_skip_threshold, max_skip_threshold, threshold_step),
                num_samples,
                method,
                use_threshold,
                main_threshold if use_threshold else 56,
                simulation_results,
                optimal_result
            )
            
            if validation_id:
                st.session_state.multi_dimensional_saved_id = validation_id
                st.success(f"âœ… ë‹¤ì°¨ì› ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {validation_id[:8]}...)")
            else:
                st.warning("âš ï¸ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    with col_save2:
        if 'multi_dimensional_saved_id' in st.session_state:
            st.info(f"ğŸ’¾ ë§ˆì§€ë§‰ ì €ì¥ ID: {st.session_state.multi_dimensional_saved_id[:8]}...")

def display_results(simulation_results, optimal_result, cutoff_id, window_size, method, use_threshold, main_threshold, max_interval):
    """ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜"""
    st.markdown("---")
    st.markdown("### ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")
    
    # ìµœì  ì„ê³„ê°’ ì¶”ì²œ
    optimal_threshold = optimal_result.get('optimal_threshold')
    optimal_data = optimal_result.get('optimal_result')
    
    if optimal_threshold is not None and optimal_data:
        st.success(f"âœ… **ì¶”ì²œ ìµœì  ì„ê³„ê°’: {optimal_threshold}%**")
        
        col_opt1, col_opt2, col_opt3, col_opt4 = st.columns(4)
        with col_opt1:
            st.metric("ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", f"{optimal_data.get('max_consecutive_failures', 0)}íšŒ")
        with col_opt2:
            st.metric("5 ì´í•˜ ë¹„ìœ¨", f"{optimal_data.get('below_5_ratio', 0):.2f}%")
        with col_opt3:
            st.metric("ì´ ìŠ¤í‚µ íšŸìˆ˜", f"{optimal_data.get('total_skipped_predictions', 0):,}íšŒ")
        with col_opt4:
            st.metric("í‰ê·  ì •í™•ë„", f"{optimal_data.get('avg_accuracy', 0):.2f}%")
        
        if optimal_result.get('warning'):
            st.warning(optimal_result['warning'])
    else:
        st.error("âŒ ìµœì  ì„ê³„ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëª¨ë“  ì„ê³„ê°’ ë¹„êµ í…Œì´ë¸”
    st.markdown("---")
    st.markdown("### ğŸ“‹ ëª¨ë“  ì„ê³„ê°’ ë¹„êµ")
    
    comparison_data = []
    for result in simulation_results.get('results', []):
        threshold = result.get('confidence_skip_threshold')
        is_optimal = (threshold == optimal_threshold)
        
        comparison_data.append({
            'ì„ê³„ê°’ (%)': f"{threshold:.1f}",
            'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': result.get('max_consecutive_failures', 0),
            'í‰ê·  ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': f"{result.get('avg_max_consecutive_failures', 0):.2f}",
            '5 ì´í•˜ ë¹„ìœ¨ (%)': f"{result.get('below_5_ratio', 0):.2f}",
            'ì´ ìŠ¤í‚µ íšŸìˆ˜': result.get('total_skipped_predictions', 0),
            'í‰ê·  ìŠ¤í‚µ ë¹„ìœ¨': f"{result.get('avg_skip_rate', 0):.2f}",
            'í‰ê·  ì •í™•ë„ (%)': f"{result.get('avg_accuracy', 0):.2f}",
            'ì˜ˆì¸¡ë¥  (%)': f"{result.get('prediction_rate', 0):.2f}",
            'ìµœì ': 'âœ…' if is_optimal else ''
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    st.dataframe(comparison_df, use_container_width=True, hide_index=True)
    
    # ê²°ê³¼ ì €ì¥ ë²„íŠ¼
    st.markdown("---")
    col_save1, col_save2 = st.columns([1, 4])
    with col_save1:
        if st.button("ğŸ’¾ ê²°ê³¼ ì €ì¥", type="primary", use_container_width=True):
            validation_id = save_simulation_results(
                cutoff_id,
                window_size,
                method,
                use_threshold,
                main_threshold if use_threshold else 56,
                max_interval,
                50.5,
                51.5,
                0.1,
                simulation_results,
                optimal_result
            )
            
            if validation_id:
                st.session_state.simulation_saved_id = validation_id
                st.success(f"âœ… ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {validation_id[:8]}...)")
            else:
                st.warning("âš ï¸ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    with col_save2:
        if 'simulation_saved_id' in st.session_state:
            st.info(f"ğŸ’¾ ë§ˆì§€ë§‰ ì €ì¥ ID: {st.session_state.simulation_saved_id[:8]}...")

def main():
    st.title("ğŸ¯ ìµœì  ìŠ¤í‚µ ì„ê³„ê°’ íƒìƒ‰ ì‹œë®¬ë ˆì´ì…˜")
    st.markdown("""
    **ëª©í‘œ**: ì§€ì •í•œ ë²”ìœ„ì—ì„œ ì„¤ì •í•œ ë‹¨ìœ„ë¡œ ìŠ¤í‚µ ì„ê³„ê°’ì„ í…ŒìŠ¤íŠ¸í•˜ì—¬
    ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ 5 ì´í•˜ë¥¼ ë§Œì¡±í•˜ëŠ” ìµœì  ì„ê³„ê°’ì„ ì°¾ìŠµë‹ˆë‹¤.
    """)
    
    # í…Œì´ë¸” ìƒì„± í™•ì¸
    if 'simulation_tables_created' not in st.session_state:
        if create_simulation_tables():
            st.session_state.simulation_tables_created = True
        else:
            st.error("í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨")
            return
    
    # ìµœê·¼ ê²°ê³¼ í‘œì‹œ (ì´ì „ì— ì €ì¥ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ)
    st.markdown("---")
    st.markdown("### ğŸ“‹ ìµœê·¼ ì €ì¥ëœ ê²°ê³¼")
    
    latest_result = load_latest_multi_dimensional_result()
    if latest_result and 'optimal_result' in latest_result:
        opt_result = latest_result['optimal_result']
        
        col_recent1, col_recent2, col_recent3 = st.columns(3)
        with col_recent1:
            st.metric("ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", f"{opt_result.get('max_consecutive_failures', 0)}íšŒ")
        with col_recent2:
            st.metric("í‰ê·  ì •í™•ë„", f"{opt_result.get('avg_accuracy', 0):.2f}%")
        with col_recent3:
            st.metric("ì´ í…ŒìŠ¤íŠ¸ ì¡°í•©", f"{latest_result.get('total_results', 0)}ê°œ")
        
        if opt_result.get('window_size') and opt_result.get('max_interval'):
            st.info(
                f"**ìµœê·¼ ì €ì¥ëœ ìµœì  ì¡°í•©** (ì €ì¥ ì‹œê°„: {latest_result.get('created_at', 'N/A')}): "
                f"ìœˆë„ìš° í¬ê¸°={opt_result.get('window_size')}, "
                f"ìµœëŒ€ ê°„ê²©={opt_result.get('max_interval')}, "
                f"ì„ê³„ê°’={opt_result.get('confidence_skip_threshold', 0):.1f}%"
            )
    else:
        st.info("ğŸ’¡ ì €ì¥ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•˜ë©´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
    
    # ìµœì í™” ëª¨ë“œ ì„ íƒ (form ì™¸ë¶€ì— ë°°ì¹˜í•˜ì—¬ ì¦‰ì‹œ ë°˜ì˜ë˜ë„ë¡ í•¨)
    st.markdown("### âš™ï¸ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •")
    
    # ë°ì´í„° ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    col_refresh1, col_refresh2 = st.columns([1, 4])
    with col_refresh1:
        refresh_clicked = st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", key="simulation_refresh_data", use_container_width=True)
    with col_refresh2:
        auto_refresh = st.checkbox(
            "ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì‹œ ìë™ ìƒˆë¡œê³ ì¹¨",
            value=st.session_state.get('simulation_auto_refresh', False),
            key="simulation_auto_refresh_checkbox",
            help="ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì „ì— ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤"
        )
    
    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ í´ë¦­ ì‹œ ìºì‹œ ì œê±° ë° ìƒˆë¡œê³ ì¹¨
    if refresh_clicked:
        # ìºì‹œëœ ë°ì´í„° ì œê±°
        if 'preprocessed_data_cache' in st.session_state:
            del st.session_state.preprocessed_data_cache
        # ì €ì¥ëœ ì‹œë®¬ë ˆì´ì…˜ ì„¸ì…˜ ê´€ë ¨ ìºì‹œ ì œê±°
        cache_keys_to_remove = [key for key in st.session_state.keys() if 'simulation' in key.lower() and 'cache' in key.lower()]
        for key in cache_keys_to_remove:
            del st.session_state[key]
        
        st.session_state.simulation_auto_refresh = auto_refresh
        st.success("âœ… ë°ì´í„°ê°€ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun()
    
    # ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì • ì €ì¥
    if auto_refresh != st.session_state.get('simulation_auto_refresh', False):
        st.session_state.simulation_auto_refresh = auto_refresh
    
    optimization_mode = st.radio(
        "ìµœì í™” ëª¨ë“œ",
        options=["ë‹¨ì¼ íŒŒë¼ë¯¸í„° ìµœì í™”", "ë‹¤ì°¨ì› ìµœì í™”"],
        index=0,
        key="simulation_optimization_mode",
        help="ë‹¨ì¼ íŒŒë¼ë¯¸í„°: ê¸°ì¡´ ë°©ì‹ (ì„ê³„ê°’ë§Œ ìµœì í™”) | ë‹¤ì°¨ì›: ìœˆë„ìš° í¬ê¸°, ê°„ê²©, ì„ê³„ê°’ ë™ì‹œ ìµœì í™”",
        horizontal=True
    )
    
    # ëª¨ë“œ í™•ì¸
    is_multi_dimensional = optimization_mode == "ë‹¤ì°¨ì› ìµœì í™”"
    
    # ì„¤ì • ì„¹ì…˜
    with st.form("simulation_settings_form", clear_on_submit=False):
        
        # ë‹¤ì°¨ì› ëª¨ë“œì¼ ë•ŒëŠ” ë‹¨ì¼ íŒŒë¼ë¯¸í„° ì„¤ì • ìˆ¨ê¸°ê¸°
        if not is_multi_dimensional:
            col_setting1, col_setting2, col_setting3 = st.columns(3)
            
            with col_setting1:
                window_size = st.selectbox(
                    "ìœˆë„ìš° í¬ê¸°",
                    options=[5, 6, 7, 8, 9],
                    index=2,  # 7ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
                    key="simulation_window_size",
                    help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ìœˆë„ìš° í¬ê¸°"
                )
            
            with col_setting2:
                method = st.selectbox(
                    "ì˜ˆì¸¡ ë°©ë²•",
                    options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
                    index=0,
                    key="simulation_method",
                    help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ë°©ë²•"
                )
            
            with col_setting3:
                use_threshold = st.checkbox(
                    "ì„ê³„ê°’ ì „ëµ ì‚¬ìš©",
                    value=True,
                    key="simulation_use_threshold",
                    help="ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•˜ë„ë¡ ì„¤ì •"
                )
                main_threshold = None
                if use_threshold:
                    main_threshold = st.number_input(
                        "ì„ê³„ê°’ (%)",
                        min_value=0,
                        max_value=100,
                        value=56,
                        step=1,
                        key="simulation_main_threshold",
                        help="ì´ ì‹ ë¢°ë„ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤"
                    )
            
            col_setting4, col_setting5 = st.columns(2)
            with col_setting4:
                max_interval = st.number_input(
                    "ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© (ìŠ¤í…)",
                    min_value=1,
                    max_value=20,
                    value=5,
                    step=1,
                    key="simulation_max_interval",
                    help="ì´ ê°„ê²©ì„ ë„˜ê¸°ë©´ ì„ê³„ê°’ ë¬´ì‹œí•˜ê³  ê°•ì œ ì˜ˆì¸¡í•©ë‹ˆë‹¤"
                )
            
            with col_setting5:
                # ê¸°ì¤€ Grid String ID ì„ íƒ
                df_all_strings = load_preprocessed_data()
                if len(df_all_strings) > 0:
                    grid_string_options = []
                    for _, row in df_all_strings.iterrows():
                        grid_string_options.append((row['id'], row['created_at']))
                    
                    grid_string_options.sort(key=lambda x: x[0], reverse=True)
                    
                    current_selected = st.session_state.get('simulation_cutoff_id', None)
                    default_index = 0
                    if current_selected is not None:
                        option_ids = [None] + [opt[0] for opt in grid_string_options]
                        if current_selected in option_ids:
                            default_index = option_ids.index(current_selected)
                    
                    selected_cutoff_id = st.selectbox(
                        "ê¸°ì¤€ Grid String ID (ì´ ID ì´í›„ì˜ ë°ì´í„° ê²€ì¦)",
                        options=[None] + [opt[0] for opt in grid_string_options],
                        format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else next((f"ID {opt[0]} - {format_datetime_for_dropdown(opt[1])}" for opt in grid_string_options if opt[0] == x), f"ID {x} ì´í›„"),
                        index=default_index,
                        key="simulation_cutoff_id_select"
                    )
                    
                    if selected_cutoff_id is not None:
                        selected_info = df_all_strings[df_all_strings['id'] == selected_cutoff_id].iloc[0]
                        st.info(f"ì„ íƒëœ ê¸°ì¤€: ID {selected_cutoff_id} (ê¸¸ì´: {selected_info['string_length']}, ìƒì„±ì¼: {selected_info['created_at']})")
                        
                        # ì´í›„ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                        conn = get_db_connection()
                        if conn is not None:
                            try:
                                count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings WHERE id > ?"
                                count_df = pd.read_sql_query(count_query, conn, params=[selected_cutoff_id])
                                after_count = count_df.iloc[0]['count']
                                st.caption(f"ê²€ì¦ ëŒ€ìƒ: {after_count}ê°œì˜ grid_string")
                            except:
                                pass
                            finally:
                                conn.close()
                else:
                    selected_cutoff_id = None
                    st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ë‹¤ì°¨ì› ëª¨ë“œ: ê¸°ì¤€ Grid String IDë§Œ ì„ íƒ
            df_all_strings = load_preprocessed_data()
            if len(df_all_strings) > 0:
                grid_string_options = []
                for _, row in df_all_strings.iterrows():
                    grid_string_options.append((row['id'], row['created_at']))
                
                grid_string_options.sort(key=lambda x: x[0], reverse=True)
                
                current_selected = st.session_state.get('simulation_cutoff_id', None)
                default_index = 0
                if current_selected is not None:
                    option_ids = [None] + [opt[0] for opt in grid_string_options]
                    if current_selected in option_ids:
                        default_index = option_ids.index(current_selected)
                
                selected_cutoff_id = st.selectbox(
                    "ê¸°ì¤€ Grid String ID (ì´ ID ì´í›„ì˜ ë°ì´í„° ê²€ì¦)",
                    options=[None] + [opt[0] for opt in grid_string_options],
                    format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else next((f"ID {opt[0]} - {format_datetime_for_dropdown(opt[1])}" for opt in grid_string_options if opt[0] == x), f"ID {x} ì´í›„"),
                    index=default_index,
                    key="simulation_cutoff_id_select"
                )
                
                if selected_cutoff_id is not None:
                    selected_info = df_all_strings[df_all_strings['id'] == selected_cutoff_id].iloc[0]
                    st.info(f"ì„ íƒëœ ê¸°ì¤€: ID {selected_cutoff_id} (ê¸¸ì´: {selected_info['string_length']}, ìƒì„±ì¼: {selected_info['created_at']})")
                    
                    # ì´í›„ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                    conn = get_db_connection()
                    if conn is not None:
                        try:
                            count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings WHERE id > ?"
                            count_df = pd.read_sql_query(count_query, conn, params=[selected_cutoff_id])
                            after_count = count_df.iloc[0]['count']
                            st.caption(f"ê²€ì¦ ëŒ€ìƒ: {after_count}ê°œì˜ grid_string")
                        except:
                            pass
                        finally:
                            conn.close()
            else:
                selected_cutoff_id = None
                st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë‹¤ì°¨ì› ëª¨ë“œë¥¼ ìœ„í•œ ê¸°ë³¸ê°’ ì„¤ì •
            method = st.session_state.get('simulation_method', 'ë¹ˆë„ ê¸°ë°˜')
            use_threshold = st.session_state.get('simulation_use_threshold', True)
            main_threshold = st.session_state.get('simulation_main_threshold', 56) if use_threshold else None
        
        # ì‹œë®¬ë ˆì´ì…˜ ë²”ìœ„ ì„¤ì •
        st.markdown("---")
        
        if is_multi_dimensional:
            # ë‹¤ì°¨ì› ìµœì í™” ëª¨ë“œ
            st.markdown("### ğŸ“Š ë‹¤ì°¨ì› ìµœì í™” ë²”ìœ„ ì„¤ì •")
            
            # ìœˆë„ìš° í¬ê¸° ë²”ìœ„
            st.markdown("#### ìœˆë„ìš° í¬ê¸° ë²”ìœ„")
            col_ws1, col_ws2 = st.columns(2)
            with col_ws1:
                window_size_min = st.number_input(
                    "ìµœì†Œ ìœˆë„ìš° í¬ê¸°",
                    min_value=5,
                    max_value=9,
                    value=5,
                    step=1,
                    key="multi_window_size_min",
                    help="í…ŒìŠ¤íŠ¸í•  ìµœì†Œ ìœˆë„ìš° í¬ê¸°"
                )
            with col_ws2:
                window_size_max = st.number_input(
                    "ìµœëŒ€ ìœˆë„ìš° í¬ê¸°",
                    min_value=5,
                    max_value=9,
                    value=9,
                    step=1,
                    key="multi_window_size_max",
                    help="í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ìœˆë„ìš° í¬ê¸°"
                )
            
            # ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© ë²”ìœ„
            st.markdown("#### ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© ë²”ìœ„")
            col_interval1, col_interval2 = st.columns(2)
            with col_interval1:
                max_interval_min = st.number_input(
                    "ìµœì†Œ ê°„ê²©",
                    min_value=1,
                    max_value=20,
                    value=1,
                    step=1,
                    key="multi_max_interval_min",
                    help="í…ŒìŠ¤íŠ¸í•  ìµœì†Œ ê°„ê²©"
                )
            with col_interval2:
                max_interval_max = st.number_input(
                    "ìµœëŒ€ ê°„ê²©",
                    min_value=1,
                    max_value=20,
                    value=20,
                    step=1,
                    key="multi_max_interval_max",
                    help="í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ê°„ê²©"
                )
            
            # ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ë²”ìœ„
            st.markdown("#### ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ë²”ìœ„")
            col_thresh1, col_thresh2, col_thresh3 = st.columns(3)
            with col_thresh1:
                min_skip_threshold = st.number_input(
                    "ìµœì†Œ ì„ê³„ê°’ (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=51.0,
                    step=0.1,
                    key="multi_min_skip_threshold",
                    help="í…ŒìŠ¤íŠ¸í•  ìµœì†Œ ìŠ¤í‚µ ì„ê³„ê°’"
                )
            with col_thresh2:
                max_skip_threshold = st.number_input(
                    "ìµœëŒ€ ì„ê³„ê°’ (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=53.5,
                    step=0.1,
                    key="multi_max_skip_threshold",
                    help="í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ìŠ¤í‚µ ì„ê³„ê°’"
                )
            with col_thresh3:
                threshold_step = st.number_input(
                    "ë‹¨ìœ„",
                    min_value=0.1,
                    max_value=10.0,
                    value=0.1,
                    step=0.1,
                    key="multi_threshold_step",
                    help="ì„ê³„ê°’ í…ŒìŠ¤íŠ¸ ê°„ê²©"
                )
            
            # ëœë¤ ìƒ˜í”Œë§ ì„¤ì •
            st.markdown("#### ëœë¤ ìƒ˜í”Œë§ ì„¤ì •")
            num_samples = st.number_input(
                "ìƒ˜í”Œë§ ê°œìˆ˜",
                min_value=10,
                max_value=1000,
                value=100,
                step=10,
                key="multi_num_samples",
                help="í…ŒìŠ¤íŠ¸í•  ë¬´ì‘ìœ„ ì¡°í•© ê°œìˆ˜ (10-1000)"
            )
            
            # ì¡°ê¸° ì¢…ë£Œ ì˜µì…˜
            enable_early_stop = st.checkbox(
                "ì¡°ê¸° ì¢…ë£Œ í™œì„±í™”",
                value=False,
                key="multi_enable_early_stop",
                help="ì¶©ë¶„í•œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ë¥¼ ì°¾ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œí•˜ì—¬ ì‹œê°„ ì ˆì•½ (ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ â‰¤ 5ì¸ ìœ ì˜ë¯¸í•œ ê²°ê³¼ 5ê°œ ì´ìƒ ë°œê²¬ ì‹œ)"
            )
            
            if enable_early_stop:
                min_meaningful_results = st.number_input(
                    "ìµœì†Œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ ê°œìˆ˜",
                    min_value=3,
                    max_value=20,
                    value=5,
                    step=1,
                    key="multi_min_meaningful_results",
                    help="ì¡°ê¸° ì¢…ë£Œë¥¼ ìœ„í•œ ìµœì†Œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ ê°œìˆ˜ (3-20)"
                )
            else:
                min_meaningful_results = 5  # ê¸°ë³¸ê°’
            
            # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
            st.markdown("#### ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •")
            col_parallel1, col_parallel2 = st.columns(2)
            with col_parallel1:
                use_threading = st.checkbox(
                    "ìŠ¤ë ˆë“œ í’€ ì‚¬ìš© (I/O ë°”ìš´ë“œ ì‘ì—…ì— ìœ ë¦¬)",
                    value=False,
                    key="multi_use_threading",
                    help="ì²´í¬ ì‹œ ThreadPoolExecutor ì‚¬ìš© (DB ì½ê¸° ë§ì„ ë•Œ ìœ ë¦¬), ì²´í¬ í•´ì œ ì‹œ ProcessPoolExecutor ì‚¬ìš© (CPU ì‘ì—… ë§ì„ ë•Œ ìœ ë¦¬)"
                )
            
            with col_parallel2:
                max_workers_manual = st.number_input(
                    "ì‘ì—…ì ìˆ˜ (Noneì´ë©´ ìë™)",
                    min_value=1,
                    max_value=mp.cpu_count(),
                    value=None,
                    step=1,
                    key="multi_max_workers",
                    help=f"ë³‘ë ¬ ì‘ì—…ì ìˆ˜ (1-{mp.cpu_count()}ê°œ). Noneì´ë©´ ìë™ ê³„ì‚° (CPUì˜ 50%ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹¤ë¥¸ ì‘ì—… ì—¬ìœ  í™•ë³´)"
                )
            
            # CPU ì •ë³´ í‘œì‹œ
            cpu_count = mp.cpu_count()
            if max_workers_manual is None:
                auto_workers = max(2, min(int(cpu_count * 0.5), 4))
                expected_cpu_usage = (auto_workers / cpu_count) * 100
                st.info(
                    f"ğŸ’¡ **CPU ì •ë³´**: {cpu_count}ê°œ ìŠ¤ë ˆë“œ ê°ì§€ | "
                    f"ìë™ ì‘ì—…ì ìˆ˜: {auto_workers}ê°œ | "
                    f"ì˜ˆìƒ CPU ì‚¬ìš©ë¥ : {expected_cpu_usage:.0f}% | "
                    f"ë‹¤ë¥¸ ì‘ì—…ì„ ìœ„í•œ ì—¬ìœ : {100 - expected_cpu_usage:.0f}%"
                )
            else:
                expected_cpu_usage = (max_workers_manual / cpu_count) * 100
                st.info(
                    f"ğŸ’¡ **ìˆ˜ë™ ì„¤ì •**: {max_workers_manual}ê°œ ì‘ì—…ì ì‚¬ìš© | "
                    f"ì˜ˆìƒ CPU ì‚¬ìš©ë¥ : {expected_cpu_usage:.0f}% | "
                    f"ë‹¤ë¥¸ ì‘ì—…ì„ ìœ„í•œ ì—¬ìœ : {100 - expected_cpu_usage:.0f}%"
                )
            
            # ë²”ìœ„ ê²€ì¦ ë° ì¡°í•© ìˆ˜ ê³„ì‚°
            valid_ranges = True
            if window_size_min > window_size_max:
                st.error("âš ï¸ ìµœì†Œ ìœˆë„ìš° í¬ê¸°ëŠ” ìµœëŒ€ ìœˆë„ìš° í¬ê¸°ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
                valid_ranges = False
            if max_interval_min > max_interval_max:
                st.error("âš ï¸ ìµœì†Œ ê°„ê²©ì€ ìµœëŒ€ ê°„ê²©ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
                valid_ranges = False
            if min_skip_threshold >= max_skip_threshold:
                st.error("âš ï¸ ìµœì†Œ ì„ê³„ê°’ì€ ìµœëŒ€ ì„ê³„ê°’ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
                valid_ranges = False
            
            if valid_ranges:
                # ê°€ëŠ¥í•œ ì¡°í•© ìˆ˜ ê³„ì‚°
                window_size_count = window_size_max - window_size_min + 1
                max_interval_count = max_interval_max - max_interval_min + 1
                threshold_count = int((max_skip_threshold - min_skip_threshold) / threshold_step) + 1
                total_combinations = window_size_count * max_interval_count * threshold_count
                
                col_info1, col_info2 = st.columns(2)
                with col_info1:
                    st.metric("ê°€ëŠ¥í•œ ì¡°í•© ìˆ˜", f"{total_combinations:,}ê°œ")
                with col_info2:
                    actual_samples = min(num_samples, total_combinations)
                    st.metric("ì‹¤ì œ í…ŒìŠ¤íŠ¸í•  ì¡°í•©", f"{actual_samples}ê°œ")
                    
                    if num_samples > total_combinations:
                        st.warning(f"âš ï¸ ìƒ˜í”Œë§ ê°œìˆ˜({num_samples}ê°œ)ê°€ ê°€ëŠ¥í•œ ì¡°í•© ìˆ˜({total_combinations}ê°œ)ë³´ë‹¤ í½ë‹ˆë‹¤. ì „ì²´ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
        else:
            # ë‹¨ì¼ íŒŒë¼ë¯¸í„° ìµœì í™” ëª¨ë“œ (ê¸°ì¡´ UI)
            st.markdown("### ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ë²”ìœ„")
            col_range1, col_range2, col_range3 = st.columns(3)
            with col_range1:
                min_skip_threshold = st.number_input(
                    "ìµœì†Œ ì„ê³„ê°’ (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=51.0,
                    step=0.1,
                    key="simulation_min_skip_threshold",
                    help="í…ŒìŠ¤íŠ¸í•  ìµœì†Œ ìŠ¤í‚µ ì„ê³„ê°’"
                )
            with col_range2:
                max_skip_threshold = st.number_input(
                    "ìµœëŒ€ ì„ê³„ê°’ (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=53.5,
                    step=0.1,
                    key="simulation_max_skip_threshold",
                    help="í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ìŠ¤í‚µ ì„ê³„ê°’"
                )
            with col_range3:
                threshold_step = st.number_input(
                    "ë‹¨ìœ„",
                    min_value=0.1,
                    max_value=10.0,
                    value=0.1,
                    step=0.1,
                    key="simulation_threshold_step",
                    help="ì„ê³„ê°’ í…ŒìŠ¤íŠ¸ ê°„ê²©"
                )
            
            # ë²”ìœ„ ê²€ì¦ ë° ì •ë³´ í‘œì‹œ
            if min_skip_threshold >= max_skip_threshold:
                st.error("âš ï¸ ìµœì†Œ ì„ê³„ê°’ì€ ìµœëŒ€ ì„ê³„ê°’ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
            else:
                # í…ŒìŠ¤íŠ¸ ê°œìˆ˜ ê³„ì‚°
                test_count = int((max_skip_threshold - min_skip_threshold) / threshold_step) + 1
                
                col_info1, col_info2, col_info3 = st.columns(3)
                with col_info1:
                    st.metric("í…ŒìŠ¤íŠ¸ ë²”ìœ„", f"{min_skip_threshold:.1f}% ~ {max_skip_threshold:.1f}%")
                with col_info2:
                    st.metric("í…ŒìŠ¤íŠ¸ ê°œìˆ˜", f"{test_count}ê°œ")
                with col_info3:
                    st.metric("í…ŒìŠ¤íŠ¸ ë‹¨ìœ„", f"{threshold_step:.1f}")
        # ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
        should_calculate_time = selected_cutoff_id is not None
        if is_multi_dimensional:
            should_calculate_time = (should_calculate_time and 
                                   window_size_min <= window_size_max and
                                   max_interval_min <= max_interval_max and
                                   min_skip_threshold < max_skip_threshold)
        else:
            should_calculate_time = should_calculate_time and min_skip_threshold < max_skip_threshold
        
        if should_calculate_time:
            conn = get_db_connection()
            if conn is not None:
                try:
                    count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings WHERE id > ?"
                    count_df = pd.read_sql_query(count_query, conn, params=[selected_cutoff_id])
                    after_count = count_df.iloc[0]['count']
                    
                    # ì˜ˆìƒ ì‹œê°„ ê³„ì‚° (ê²½í—˜ì  ê°’)
                    # grid_string í•˜ë‚˜ë‹¹ ì•½ 0.5~2ì´ˆ ì†Œìš” (ê¸¸ì´ì™€ ë³µì¡ë„ì— ë”°ë¼ ë‹¤ë¦„)
                    # ë³´ìˆ˜ì ìœ¼ë¡œ 1ì´ˆ/grid_stringìœ¼ë¡œ ê³„ì‚°
                    time_per_grid = 1.0  # ì´ˆ
                    time_per_test = after_count * time_per_grid  # ì´ˆ
                    
                    if is_multi_dimensional:
                        # ë‹¤ì°¨ì› ëª¨ë“œ: ìƒ˜í”Œë§ ê°œìˆ˜ ê¸°ì¤€
                        estimated_tests = min(num_samples, total_combinations)
                        estimated_time_seconds = time_per_test * estimated_tests
                    else:
                        # ë‹¨ì¼ íŒŒë¼ë¯¸í„° ëª¨ë“œ
                        test_count_full = int((max_skip_threshold - min_skip_threshold) / threshold_step) + 1
                        use_hybrid_estimate = st.session_state.get('simulation_search_method', 'í•˜ì´ë¸Œë¦¬ë“œ (ì´ì§„ íƒìƒ‰ + ìˆœì°¨ íƒìƒ‰)')
                        if 'í•˜ì´ë¸Œë¦¬ë“œ' in use_hybrid_estimate:
                            # ì´ì§„ íƒìƒ‰ 10íšŒ + ìˆœì°¨ íƒìƒ‰ (ë²”ìœ„ì˜ ì•½ 20-30%)
                            estimated_tests = 10 + max(5, int(test_count_full * 0.25))
                        else:
                            estimated_tests = test_count_full
                        estimated_time_seconds = time_per_test * estimated_tests
                    
                    total_minutes = int(estimated_time_seconds // 60)
                    total_seconds = int(estimated_time_seconds % 60)
                    
                    if total_minutes > 0:
                        estimated_time = f"ì•½ {total_minutes}ë¶„ {total_seconds}ì´ˆ"
                    else:
                        estimated_time = f"ì•½ {total_seconds}ì´ˆ"
                    
                    if is_multi_dimensional:
                        st.info(f"â±ï¸ **ì˜ˆìƒ ì†Œìš” ì‹œê°„**: {estimated_time} (ê²€ì¦ ëŒ€ìƒ: {after_count}ê°œ grid_string Ã— {estimated_tests}ê°œ ì¡°í•©, ë‹¤ì°¨ì› ìµœì í™”)")
                    else:
                        test_count_display = f"{estimated_tests}ê°œ" if 'í•˜ì´ë¸Œë¦¬ë“œ' in use_hybrid_estimate else f"{test_count_full}ê°œ"
                        method_note = " (í•˜ì´ë¸Œë¦¬ë“œ)" if 'í•˜ì´ë¸Œë¦¬ë“œ' in use_hybrid_estimate else " (ìˆœì°¨ ì „ì²´)"
                        st.info(f"â±ï¸ **ì˜ˆìƒ ì†Œìš” ì‹œê°„**: {estimated_time}{method_note} (ê²€ì¦ ëŒ€ìƒ: {after_count}ê°œ grid_string Ã— {test_count_display} ì„ê³„ê°’)")
                except:
                    st.info("â±ï¸ **ì˜ˆìƒ ì†Œìš” ì‹œê°„**: ê³„ì‚° ì¤‘...")
                finally:
                    conn.close()
            else:
                st.info("â±ï¸ **ì˜ˆìƒ ì†Œìš” ì‹œê°„**: ê³„ì‚° ë¶ˆê°€")
        elif selected_cutoff_id is None:
            st.info("ğŸ’¡ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•˜ë©´ ì˜ˆìƒ ì†Œìš” ì‹œê°„ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # íƒìƒ‰ ë°©ì‹ ì„ íƒ (ë‹¨ì¼ íŒŒë¼ë¯¸í„° ëª¨ë“œì—ì„œë§Œ í‘œì‹œ)
        if not is_multi_dimensional:
            search_method = st.radio(
                "íƒìƒ‰ ë°©ì‹",
                options=["í•˜ì´ë¸Œë¦¬ë“œ (ì´ì§„ íƒìƒ‰ + ìˆœì°¨ íƒìƒ‰)", "ìˆœì°¨ ê·¸ë¦¬ë“œ ì„œì¹˜ (ì „ì²´ ë²”ìœ„)"],
                index=0,
                key="simulation_search_method",
                help="í•˜ì´ë¸Œë¦¬ë“œ: ë¹ ë¥¸ ì´ì§„ íƒìƒ‰ í›„ ì •ë°€ íƒìƒ‰ | ìˆœì°¨: ëª¨ë“  ì„ê³„ê°’ ìˆœì°¨ í…ŒìŠ¤íŠ¸"
            )
        else:
            # ë‹¤ì°¨ì› ëª¨ë“œëŠ” í•­ìƒ ëœë¤ ì„œì¹˜ ì‚¬ìš©
            search_method = "ëœë¤ ì„œì¹˜ (ë‹¤ì°¨ì›)"
            st.session_state.simulation_search_method = search_method
        
        # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ë²„íŠ¼
        if st.form_submit_button("ğŸš€ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰", type="primary", use_container_width=True):
            if selected_cutoff_id is None:
                st.warning("âš ï¸ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            elif is_multi_dimensional:
                # ë‹¤ì°¨ì› ëª¨ë“œ ê²€ì¦
                if window_size_min > window_size_max:
                    st.warning("âš ï¸ ìµœì†Œ ìœˆë„ìš° í¬ê¸°ëŠ” ìµœëŒ€ ìœˆë„ìš° í¬ê¸°ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
                elif max_interval_min > max_interval_max:
                    st.warning("âš ï¸ ìµœì†Œ ê°„ê²©ì€ ìµœëŒ€ ê°„ê²©ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
                elif min_skip_threshold >= max_skip_threshold:
                    st.warning("âš ï¸ ìµœì†Œ ì„ê³„ê°’ì€ ìµœëŒ€ ì„ê³„ê°’ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    st.session_state.simulation_cutoff_id = selected_cutoff_id
                    st.session_state.simulation_results = None
                    st.session_state.simulation_optimal = None
                    st.session_state.simulation_progress = {}
                    st.rerun()
            else:
                # ë‹¨ì¼ íŒŒë¼ë¯¸í„° ëª¨ë“œ ê²€ì¦
                if min_skip_threshold >= max_skip_threshold:
                    st.warning("âš ï¸ ìµœì†Œ ì„ê³„ê°’ì€ ìµœëŒ€ ì„ê³„ê°’ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    st.session_state.simulation_cutoff_id = selected_cutoff_id
                    st.session_state.simulation_results = None
                    st.session_state.simulation_optimal = None
                    st.session_state.simulation_progress = {}
                    st.rerun()
    
    # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œ
    if 'simulation_cutoff_id' in st.session_state and st.session_state.simulation_cutoff_id is not None:
        cutoff_id = st.session_state.simulation_cutoff_id
        
        # í˜„ì¬ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (form ë‚´ë¶€ ìœ„ì ¯ ê°’ë“¤ì€ ìë™ìœ¼ë¡œ session_stateì— ì €ì¥ë¨)
        optimization_mode = st.session_state.get('simulation_optimization_mode', 'ë‹¨ì¼ íŒŒë¼ë¯¸í„° ìµœì í™”')
        is_multi_dimensional = optimization_mode == "ë‹¤ì°¨ì› ìµœì í™”"
        
        window_size = st.session_state.get('simulation_window_size', 7)
        method = st.session_state.get('simulation_method', 'ë¹ˆë„ ê¸°ë°˜')
        use_threshold = st.session_state.get('simulation_use_threshold', True)
        main_threshold = st.session_state.get('simulation_main_threshold', 56) if use_threshold else None
        max_interval = st.session_state.get('simulation_max_interval', 5)
        min_skip_threshold = st.session_state.get('simulation_min_skip_threshold', 51.0)
        max_skip_threshold = st.session_state.get('simulation_max_skip_threshold', 53.5)
        threshold_step = st.session_state.get('simulation_threshold_step', 0.1)
        search_method = st.session_state.get('simulation_search_method', 'í•˜ì´ë¸Œë¦¬ë“œ (ì´ì§„ íƒìƒ‰ + ìˆœì°¨ íƒìƒ‰)')
        
        # ë‹¤ì°¨ì› ëª¨ë“œ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
        if is_multi_dimensional:
            window_size_min = st.session_state.get('multi_window_size_min', 5)
            window_size_max = st.session_state.get('multi_window_size_max', 9)
            max_interval_min = st.session_state.get('multi_max_interval_min', 1)
            max_interval_max = st.session_state.get('multi_max_interval_max', 20)
            min_skip_threshold = st.session_state.get('multi_min_skip_threshold', 51.0)
            max_skip_threshold = st.session_state.get('multi_max_skip_threshold', 53.5)
            threshold_step = st.session_state.get('multi_threshold_step', 0.1)
            num_samples = st.session_state.get('multi_num_samples', 100)
        
        # í…ŒìŠ¤íŠ¸ ê°œìˆ˜ ê³„ì‚°
        if is_multi_dimensional:
            window_size_count = window_size_max - window_size_min + 1
            max_interval_count = max_interval_max - max_interval_min + 1
            threshold_count = int((max_skip_threshold - min_skip_threshold) / threshold_step) + 1
            total_combinations = window_size_count * max_interval_count * threshold_count
            test_count = min(num_samples, total_combinations)
        else:
            test_count_full = int((max_skip_threshold - min_skip_threshold) / threshold_step) + 1
            test_count = test_count_full if 'ìˆœì°¨' in search_method else f"~{max(10, int(test_count_full * 0.3))}ê°œ (ì´ì§„ íƒìƒ‰ + ìˆœì°¨ íƒìƒ‰)"
        
        # ê²°ê³¼ê°€ ìºì‹œë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‹¤í–‰
        if 'simulation_results' in st.session_state and st.session_state.simulation_results is not None:
            simulation_results = st.session_state.simulation_results
            optimal_result = st.session_state.get('simulation_optimal')
        else:
            with st.spinner(f"ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘... ({test_count}ê°œ ì„ê³„ê°’ í…ŒìŠ¤íŠ¸)"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    # ë°°ì¹˜ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
                    status_text.text("ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘... (ì˜ˆìƒ ì‹œê°„: ê³„ì‚° ì¤‘)")
                    progress_bar.progress(0.0)
                    
                    # ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ í•¨ìˆ˜ í˜¸ì¶œ
                    if is_multi_dimensional:
                        # ë‹¤ì°¨ì› ìµœì í™” ëª¨ë“œ
                        enable_early_stop = st.session_state.get('multi_enable_early_stop', False)
                        min_meaningful_results = st.session_state.get('multi_min_meaningful_results', 5)
                        use_threading = st.session_state.get('multi_use_threading', False)
                        max_workers = st.session_state.get('multi_max_workers', None)
                        # Noneì´ê±°ë‚˜ 0ì´ë©´ ìë™ ê³„ì‚°
                        if max_workers is not None and max_workers <= 0:
                            max_workers = None
                        
                        simulation_results = random_search_multi_dimensional(
                            cutoff_id,
                            window_size_range=(window_size_min, window_size_max),
                            max_interval_range=(max_interval_min, max_interval_max),
                            confidence_skip_range=(min_skip_threshold, max_skip_threshold, threshold_step),
                            num_samples=num_samples,
                            method=method,
                            use_threshold=use_threshold,
                            main_threshold=main_threshold if use_threshold else 56,
                            progress_bar=progress_bar,
                            status_text=status_text,
                            enable_early_stop=enable_early_stop,
                            min_meaningful_results=min_meaningful_results,
                            max_workers=max_workers,
                            use_threading=use_threading
                        )
                    else:
                        # ë‹¨ì¼ íŒŒë¼ë¯¸í„° ìµœì í™” ëª¨ë“œ
                        use_hybrid = 'í•˜ì´ë¸Œë¦¬ë“œ' in search_method
                        
                        if use_hybrid:
                            simulation_results = hybrid_search_optimal_threshold(
                                cutoff_id,
                                window_size=window_size,
                                method=method,
                                use_threshold=use_threshold,
                                main_threshold=main_threshold if use_threshold else 56,
                                max_interval=max_interval,
                                min_skip_threshold=min_skip_threshold,
                                max_skip_threshold=max_skip_threshold,
                                step=threshold_step,
                                target_max_failures=5,
                                tolerance=1.0,
                                max_binary_iterations=10,
                                progress_bar=progress_bar,
                                status_text=status_text
                            )
                        else:
                            simulation_results = batch_simulate_threshold_range(
                                cutoff_id,
                                window_size=window_size,
                                method=method,
                                use_threshold=use_threshold,
                                main_threshold=main_threshold if use_threshold else 56,
                                max_interval=max_interval,
                                min_skip_threshold=min_skip_threshold,
                                max_skip_threshold=max_skip_threshold,
                                step=threshold_step,
                                progress_bar=progress_bar,
                                status_text=status_text
                            )
                    
                    if simulation_results and len(simulation_results.get('results', [])) > 0:
                        # ìµœì ê°’ ì°¾ê¸° (ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ í•¨ìˆ˜ ì‚¬ìš©)
                        status_text.text("ìµœì  ì¡°í•© ë¶„ì„ ì¤‘...")
                        progress_bar.progress(0.95)
                        
                        if is_multi_dimensional:
                            optimal_result = find_optimal_multi_dimensional(simulation_results)
                        else:
                            optimal_result = find_optimal_threshold(simulation_results)
                        
                        st.session_state.simulation_results = simulation_results
                        st.session_state.simulation_optimal = optimal_result
                        
                        progress_bar.progress(1.0)
                        status_text.text("ì™„ë£Œ!")
                    else:
                        st.error("ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨")
                        simulation_results = None
                        optimal_result = None
                        
                except Exception as e:
                    st.error(f"ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    import traceback
                    st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                    simulation_results = None
                    optimal_result = None
                finally:
                    progress_bar.empty()
                    status_text.empty()
        
        # ê²°ê³¼ í‘œì‹œ
        if simulation_results and optimal_result:
            if is_multi_dimensional:
                display_multi_dimensional_results(simulation_results, optimal_result, cutoff_id, method, use_threshold, main_threshold)
            else:
                display_results(simulation_results, optimal_result, cutoff_id, window_size, method, use_threshold, main_threshold, max_interval)
        elif simulation_results:
            st.warning("âš ï¸ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ëŠ” ìˆì§€ë§Œ ìµœì ê°’ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ’¡ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    else:
        st.info("ğŸ’¡ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•˜ê³  ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    # êµ¬ë¶„ì„ 
    st.markdown("---")
    
    # ì˜ˆì¸¡ê°’ í…Œì´ë¸” ê´€ë¦¬ ì„¹ì…˜
    st.markdown("## ğŸ“Š ì˜ˆì¸¡ê°’ í…Œì´ë¸” ê´€ë¦¬")
    
    col_table1, col_table2 = st.columns(2)
    
    with col_table1:
        if st.button("ğŸ”§ ì˜ˆì¸¡ê°’ í…Œì´ë¸” ìƒì„±", use_container_width=True):
            with st.spinner("í…Œì´ë¸” ìƒì„± ì¤‘..."):
                if create_stored_predictions_table():
                    st.success("âœ… ì˜ˆì¸¡ê°’ í…Œì´ë¸”ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("âŒ í…Œì´ë¸” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    with col_table2:
        # í…Œì´ë¸” ìƒíƒœ í™•ì¸
        conn = get_db_connection()
        if conn is not None:
            try:
                count_query = "SELECT COUNT(*) as count FROM stored_predictions"
                count_df = pd.read_sql_query(count_query, conn)
                stored_count = count_df.iloc[0]['count'] if len(count_df) > 0 else 0
                st.metric("ì €ì¥ëœ ì˜ˆì¸¡ê°’ ê°œìˆ˜", f"{stored_count:,}ê°œ")
            except:
                st.metric("ì €ì¥ëœ ì˜ˆì¸¡ê°’ ê°œìˆ˜", "0ê°œ")
            finally:
                conn.close()
        else:
            st.metric("ì €ì¥ëœ ì˜ˆì¸¡ê°’ ê°œìˆ˜", "0ê°œ")
    
    # ì˜ˆì¸¡ê°’ ìƒì„± ì„¹ì…˜
    with st.form("prediction_generation_form", clear_on_submit=False):
        st.markdown("### ì˜ˆì¸¡ê°’ ìƒì„±")
        
        col_pred1, col_pred2, col_pred3 = st.columns(3)
        
        with col_pred1:
            # ê¸°ì¤€ Grid String ID ì„ íƒ
            df_all_strings = load_preprocessed_data()
            if len(df_all_strings) > 0:
                grid_string_options = []
                for _, row in df_all_strings.iterrows():
                    grid_string_options.append((row['id'], row['created_at']))
                
                grid_string_options.sort(key=lambda x: x[0], reverse=True)
                
                selected_cutoff_id_pred = st.selectbox(
                    "ê¸°ì¤€ Grid String ID (ì´ ID ì´í•˜ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©)",
                    options=[None] + [opt[0] for opt in grid_string_options],
                    format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else next((f"ID {opt[0]} - {format_datetime_for_dropdown(opt[1])}" for opt in grid_string_options if opt[0] == x), f"ID {x}"),
                    key="prediction_cutoff_id"
                )
            else:
                selected_cutoff_id_pred = None
                st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
        
        with col_pred2:
            prediction_methods = st.multiselect(
                "ì˜ˆì¸¡ ë°©ë²• (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
                options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
                default=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜"],
                key="prediction_methods",
                help="ì„ íƒí•œ ëª¨ë“  ë°©ë²•ì— ëŒ€í•´ ì˜ˆì¸¡ê°’ì´ ë³„ë„ë¡œ ì €ì¥ë©ë‹ˆë‹¤"
            )
        
        with col_pred3:
            prediction_threshold = st.number_input(
                "ì„ê³„ê°’",
                min_value=0,
                max_value=100,
                value=0,
                step=1,
                key="prediction_threshold",
                help="0ì€ ì„ê³„ê°’ ì—†ì´ ëª¨ë“  ì˜ˆì¸¡ í¬í•¨"
            )
        
        if st.form_submit_button("ğŸš€ ì˜ˆì¸¡ê°’ ìƒì„± ì‹œì‘", type="primary", use_container_width=True):
            if selected_cutoff_id_pred is None:
                st.warning("âš ï¸ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            elif len(prediction_methods) == 0:
                st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ ì˜ˆì¸¡ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ì˜ˆì¸¡ê°’ ìƒì„± ì¤‘... (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    status_text.text("ì˜ˆì¸¡ê°’ ìƒì„± ì‹œì‘...")
                    progress_bar.progress(0.1)
                    
                    result = save_or_update_predictions_for_historical_data(
                        cutoff_grid_string_id=selected_cutoff_id_pred,
                        window_sizes=[5, 6, 7, 8, 9],
                        methods=prediction_methods,
                        thresholds=[prediction_threshold],
                        batch_size=1000
                    )
                    
                    if result:
                        progress_bar.progress(1.0)
                        status_text.text("ì™„ë£Œ!")
                        st.success(f"âœ… ì˜ˆì¸¡ê°’ ìƒì„± ì™„ë£Œ!")
                        methods_str = ", ".join(prediction_methods)
                        st.info(f"""
                        - ìƒì„±ëœ ì˜ˆì¸¡ ë°©ë²•: {methods_str}
                        - ì´ ì €ì¥/ì—…ë°ì´íŠ¸: {result.get('total_saved', 0):,}ê°œ
                        - ìƒˆ ë ˆì½”ë“œ: {result.get('new_records', 0):,}ê°œ
                        - ì—…ë°ì´íŠ¸: {result.get('updated_records', 0):,}ê°œ
                        - ê³ ìœ  prefix: {result.get('unique_prefixes', 0):,}ê°œ
                        """)
                    else:
                        st.error("âŒ ì˜ˆì¸¡ê°’ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    
                    progress_bar.empty()
                    status_text.empty()
    
    # ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° ì‹œë®¬ë ˆì´ì…˜ ì„¹ì…˜
    st.markdown("---")
    st.markdown("## ğŸ¯ ë‹¤ì¤‘ ìœˆë„ìš° í¬ê¸° ì‹œë®¬ë ˆì´ì…˜")
    st.markdown("""
    **ì „ëµ**: ê° ìœ„ì¹˜ì—ì„œ ì—¬ëŸ¬ ìœˆë„ìš° í¬ê¸°(5, 6, 7, 8, 9) ì¤‘ ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ì˜ˆì¸¡ê°’ì„ ì„ íƒí•©ë‹ˆë‹¤.
    """)
    
    # stored_predictions í…Œì´ë¸” í™•ì¸
    conn = get_db_connection()
    if conn is not None:
        try:
            count_query = "SELECT COUNT(*) as count FROM stored_predictions"
            count_df = pd.read_sql_query(count_query, conn)
            stored_count = count_df.iloc[0]['count'] if len(count_df) > 0 else 0
            
            if stored_count == 0:
                st.warning("âš ï¸ stored_predictions í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ìœ„ì˜ 'ì˜ˆì¸¡ê°’ ìƒì„±' ì„¹ì…˜ì—ì„œ ì˜ˆì¸¡ê°’ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
        except:
            stored_count = 0
            st.warning("âš ï¸ stored_predictions í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ 'ì˜ˆì¸¡ê°’ í…Œì´ë¸” ìƒì„±' ë²„íŠ¼ì„ ë¨¼ì € í´ë¦­í•´ì£¼ì„¸ìš”.")
        finally:
            conn.close()
    else:
        stored_count = 0
    
    # ë°ì´í„° ìƒˆë¡œê³ ì¹¨ ì„¤ì • ì´ˆê¸°í™”
    if 'multi_window_auto_refresh' not in st.session_state:
        st.session_state.multi_window_auto_refresh = False
    
    # ë°ì´í„° ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ (form ë°–ì— ìœ„ì¹˜)
    st.markdown("### âš™ï¸ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •")
    col_refresh_mw1, col_refresh_mw2 = st.columns([1, 4])
    with col_refresh_mw1:
        refresh_clicked_mw = st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", key="multi_window_refresh_data", use_container_width=True)
    with col_refresh_mw2:
        auto_refresh_mw = st.checkbox(
            "ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì‹œ ìë™ ìƒˆë¡œê³ ì¹¨",
            value=st.session_state.multi_window_auto_refresh,
            key="multi_window_auto_refresh_checkbox",
            help="ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì „ì— ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤"
        )
    
    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ í´ë¦­ ì‹œ ìºì‹œ ì œê±°
    if refresh_clicked_mw:
        if 'preprocessed_data_cache' in st.session_state:
            del st.session_state.preprocessed_data_cache
        st.session_state.multi_window_auto_refresh = auto_refresh_mw
        st.rerun()
    
    # ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì • ì €ì¥
    if auto_refresh_mw != st.session_state.multi_window_auto_refresh:
        st.session_state.multi_window_auto_refresh = auto_refresh_mw
    
    # ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • í¼
    with st.form("multi_window_simulation_form", clear_on_submit=False):
        col_mw1, col_mw2, col_mw3 = st.columns(3)
        
        with col_mw1:
            # ê¸°ì¤€ Grid String ID ì„ íƒ
            df_all_strings_mw = load_preprocessed_data()
            if len(df_all_strings_mw) > 0:
                grid_string_options_mw = []
                for _, row in df_all_strings_mw.iterrows():
                    grid_string_options_mw.append((row['id'], row['created_at']))
                
                grid_string_options_mw.sort(key=lambda x: x[0], reverse=True)
                
                current_selected_mw = st.session_state.get('multi_window_cutoff_id', None)
                default_index_mw = 0
                if current_selected_mw is not None:
                    option_ids_mw = [None] + [opt[0] for opt in grid_string_options_mw]
                    if current_selected_mw in option_ids_mw:
                        default_index_mw = option_ids_mw.index(current_selected_mw)
                
                selected_cutoff_id_mw = st.selectbox(
                    "ê¸°ì¤€ Grid String ID (ì´ ID ì´í›„ì˜ ë°ì´í„° ê²€ì¦)",
                    options=[None] + [opt[0] for opt in grid_string_options_mw],
                    format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else next((f"ID {opt[0]} - {format_datetime_for_dropdown(opt[1])}" for opt in grid_string_options_mw if opt[0] == x), f"ID {x} ì´í›„"),
                    index=default_index_mw,
                    key="multi_window_cutoff_id_select"
                )
            else:
                selected_cutoff_id_mw = None
                st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
        
        with col_mw2:
            multi_window_method = st.selectbox(
                "ì˜ˆì¸¡ ë°©ë²•",
                options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
                index=0,
                key="multi_window_method"
            )
        
        with col_mw3:
            multi_window_threshold = st.number_input(
                "ì„ê³„ê°’",
                min_value=0,
                max_value=100,
                value=0,
                step=1,
                key="multi_window_threshold",
                help="0ì€ ì„ê³„ê°’ ì—†ì´ ëª¨ë“  ì˜ˆì¸¡ í¬í•¨"
            )
        
        # ì „ëµ ì„ íƒ
        st.markdown("#### ì „ëµ ì„ íƒ")
        use_exclusion_strategy = st.checkbox(
            "ì œì™¸ ì „ëµ ì‚¬ìš©",
            value=False,
            key="use_exclusion_strategy",
            help="ì‹¤íŒ¨í•œ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸í•˜ëŠ” ì „ëµ ì‚¬ìš© (ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)"
        )
        
        # ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ì„¤ì •
        st.markdown("#### ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ ì„¤ì •")
        skip_mode = st.radio(
            "ì„ê³„ê°’ ì„¤ì • ë°©ì‹",
            ["ìˆ˜ë™ ì„¤ì •", "ìë™ ìµœì í™” (ì´ì§„ íƒìƒ‰)"],
            key="multi_window_skip_mode",
            help="ìˆ˜ë™ ì„¤ì •: ì§ì ‘ ì„ê³„ê°’ ì…ë ¥, ìë™ ìµœì í™”: ì´ì§„ íƒìƒ‰ìœ¼ë¡œ ìµœì ê°’ ìë™ ì°¾ê¸°"
        )
        
        confidence_skip_threshold = None
        use_confidence_skip = False
        min_skip = None
        max_skip = None
        tolerance_skip = None
        
        if skip_mode == "ìˆ˜ë™ ì„¤ì •":
            confidence_skip_threshold = st.number_input(
                "ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’ (%)",
                min_value=0.0,
                max_value=100.0,
                value=None,
                step=0.1,
                key="multi_window_confidence_skip_manual",
                help="ì´ ì‹ ë¢°ë„ ë¯¸ë§Œì¸ ì˜ˆì¸¡ì€ ì œì™¸ë©ë‹ˆë‹¤. Noneì´ë©´ ìŠ¤í‚µ ì—†ìŒ"
            )
            use_confidence_skip = confidence_skip_threshold is not None
        else:
            # ìë™ ìµœì í™” ëª¨ë“œ
            col_opt1, col_opt2, col_opt3 = st.columns(3)
            with col_opt1:
                min_skip = st.number_input(
                    "ìµœì†Œ ì„ê³„ê°’",
                    0.0, 100.0, 50.5, 0.5,
                    key="multi_window_min_skip"
                )
            with col_opt2:
                max_skip = st.number_input(
                    "ìµœëŒ€ ì„ê³„ê°’",
                    0.0, 100.0, 59.0, 0.5,
                    key="multi_window_max_skip"
                )
            with col_opt3:
                tolerance_skip = st.number_input(
                    "ìµœì¢… ì •ë°€ë„",
                    0.1, 2.0, 0.5, 0.1,
                    key="multi_window_tolerance_skip",
                    help="ì´ì§„ íƒìƒ‰ í›„ ì„¸ë°€ íƒìƒ‰í•  ë²”ìœ„"
                )
            
            use_confidence_skip = True
            # ìë™ ìµœì í™” ì‹œì—ëŠ” ì„ê³„ê°’ì„ Noneìœ¼ë¡œ ì„¤ì • (ë‚˜ì¤‘ì— ì°¾ì„ ê²ƒ)
            confidence_skip_threshold = None
        
        # ìœˆë„ìš° í¬ê¸° ì„ íƒ
        st.markdown("#### ìœˆë„ìš° í¬ê¸° ì„ íƒ")
        col_ws1, col_ws2, col_ws3, col_ws4, col_ws5 = st.columns(5)
        
        with col_ws1:
            use_window_5 = st.checkbox("5", value=True, key="use_window_5")
        with col_ws2:
            use_window_6 = st.checkbox("6", value=True, key="use_window_6")
        with col_ws3:
            use_window_7 = st.checkbox("7", value=True, key="use_window_7")
        with col_ws4:
            use_window_8 = st.checkbox("8", value=True, key="use_window_8")
        with col_ws5:
            use_window_9 = st.checkbox("9", value=True, key="use_window_9")
        
        selected_window_sizes = []
        if use_window_5:
            selected_window_sizes.append(5)
        if use_window_6:
            selected_window_sizes.append(6)
        if use_window_7:
            selected_window_sizes.append(7)
        if use_window_8:
            selected_window_sizes.append(8)
        if use_window_9:
            selected_window_sizes.append(9)
        
        if len(selected_window_sizes) == 0:
            st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ ìœˆë„ìš° í¬ê¸°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ë²„íŠ¼
        if st.form_submit_button("ğŸš€ ë‹¤ì¤‘ ìœˆë„ìš° ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰", type="primary", use_container_width=True):
            if selected_cutoff_id_mw is None:
                st.warning("âš ï¸ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            elif len(selected_window_sizes) == 0:
                st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ ìœˆë„ìš° í¬ê¸°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            elif stored_count == 0:
                st.warning("âš ï¸ stored_predictions í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ìœ„ì˜ 'ì˜ˆì¸¡ê°’ ìƒì„±' ì„¹ì…˜ì—ì„œ ì˜ˆì¸¡ê°’ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
            else:
                # ìë™ ìƒˆë¡œê³ ì¹¨ì´ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ìºì‹œ ì œê±°
                if st.session_state.multi_window_auto_refresh:
                    if 'preprocessed_data_cache' in st.session_state:
                        del st.session_state.preprocessed_data_cache
                
                st.session_state.multi_window_cutoff_id = selected_cutoff_id_mw
                st.session_state.multi_window_use_exclusion = use_exclusion_strategy
                # skip_modeëŠ” ìœ„ì ¯ì´ ì´ë¯¸ session_stateë¥¼ ê´€ë¦¬í•˜ë¯€ë¡œ ì €ì¥í•˜ì§€ ì•ŠìŒ
                # st.session_state.multi_window_skip_modeëŠ” ìœ„ì ¯ì´ ìë™ìœ¼ë¡œ ê´€ë¦¬
                st.session_state.multi_window_confidence_skip = confidence_skip_threshold
                st.session_state.multi_window_use_confidence_skip = use_confidence_skip
                if skip_mode == "ìë™ ìµœì í™” (ì´ì§„ íƒìƒ‰)":
                    # min_skip, max_skip, tolerance_skipë„ ìœ„ì ¯ì´ ì´ë¯¸ session_stateë¥¼ ê´€ë¦¬
                    # st.session_state.multi_window_min_skip ë“±ì€ ìœ„ì ¯ì´ ìë™ìœ¼ë¡œ ê´€ë¦¬
                    pass
                st.session_state.multi_window_results = None
                st.session_state.multi_window_optimal_result = None
                st.rerun()
    
    # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ í‘œì‹œ
    if 'multi_window_cutoff_id' in st.session_state and st.session_state.multi_window_cutoff_id is not None:
        cutoff_id_mw = st.session_state.multi_window_cutoff_id
        
        # í˜„ì¬ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        selected_window_sizes_state = []
        if st.session_state.get('use_window_5', True):
            selected_window_sizes_state.append(5)
        if st.session_state.get('use_window_6', True):
            selected_window_sizes_state.append(6)
        if st.session_state.get('use_window_7', True):
            selected_window_sizes_state.append(7)
        if st.session_state.get('use_window_8', True):
            selected_window_sizes_state.append(8)
        if st.session_state.get('use_window_9', True):
            selected_window_sizes_state.append(9)
        
        multi_window_method_state = st.session_state.get('multi_window_method', 'ë¹ˆë„ ê¸°ë°˜')
        multi_window_threshold_state = st.session_state.get('multi_window_threshold', 0)
        
        # ì „ëµ ê°€ì ¸ì˜¤ê¸°
        use_exclusion_strategy_state = st.session_state.get('multi_window_use_exclusion', False)
        skip_mode_state = st.session_state.get('multi_window_skip_mode', 'ìˆ˜ë™ ì„¤ì •')
        confidence_skip_threshold_state = st.session_state.get('multi_window_confidence_skip', None)
        use_confidence_skip_state = st.session_state.get('multi_window_use_confidence_skip', False)
        
        # ê²°ê³¼ê°€ ìºì‹œë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‹¤í–‰
        if 'multi_window_results' in st.session_state and st.session_state.multi_window_results is not None:
            multi_window_results = st.session_state.multi_window_results
            multi_window_optimal_result = st.session_state.get('multi_window_optimal_result')
        else:
            with st.spinner("ë‹¤ì¤‘ ìœˆë„ìš° ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘..."):
                progress_bar_mw = st.progress(0)
                status_text_mw = st.empty()
                
                strategy_name = "ì œì™¸ ì „ëµ" if use_exclusion_strategy_state else "ê¸°ë³¸ ì „ëµ"
                if use_confidence_skip_state:
                    if skip_mode_state == "ìë™ ìµœì í™” (ì´ì§„ íƒìƒ‰)":
                        strategy_name += " + ì‹ ë¢°ë„ ìŠ¤í‚µ (ìë™ ìµœì í™”)"
                    else:
                        strategy_name += f" + ì‹ ë¢°ë„ ìŠ¤í‚µ ({confidence_skip_threshold_state}%)"
                
                status_text_mw.text(f"ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘... ({strategy_name})")
                progress_bar_mw.progress(0.1)
                
                multi_window_optimal_result = None
                
                # ë””ë²„ê¹…: í˜„ì¬ ìƒíƒœ í™•ì¸
                # st.info(f"ğŸ” ë””ë²„ê¹… ì •ë³´:\n- skip_mode_state: {skip_mode_state}\n- use_confidence_skip_state: {use_confidence_skip_state}\n- skip_mode íƒ€ì…: {type(skip_mode_state)}")
                
                # ìë™ ìµœì í™” ëª¨ë“œì¸ ê²½ìš°
                if skip_mode_state == "ìë™ ìµœì í™” (ì´ì§„ íƒìƒ‰)" and use_confidence_skip_state:
                    min_skip_state = st.session_state.get('multi_window_min_skip', 50.5)
                    max_skip_state = st.session_state.get('multi_window_max_skip', 59.0)
                    tolerance_skip_state = st.session_state.get('multi_window_tolerance_skip', 0.5)
                    
                    optimal_threshold, optimal_result, search_history = binary_search_optimal_threshold_multi_window(
                        cutoff_id_mw,
                        window_sizes=selected_window_sizes_state,
                        method=multi_window_method_state,
                        threshold=multi_window_threshold_state,
                        min_range=min_skip_state,
                        max_range=max_skip_state,
                        target_max_failures=5,
                        tolerance=tolerance_skip_state,
                        progress_bar=progress_bar_mw,
                        status_text=status_text_mw
                    )
                    
                    if optimal_result:
                        multi_window_results = optimal_result
                        multi_window_optimal_result = {
                            'optimal_threshold': optimal_threshold,
                            'search_history': search_history
                        }
                        st.session_state.multi_window_optimal_result = multi_window_optimal_result
                    else:
                        st.warning("âš ï¸ ìµœì  ì„ê³„ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        multi_window_results = None
                else:
                    # ìˆ˜ë™ ì„¤ì • ëª¨ë“œ ë˜ëŠ” ì‹ ë¢°ë„ ìŠ¤í‚µ ë¯¸ì‚¬ìš©
                    # ë””ë²„ê¹…: ì™œ ìë™ ìµœì í™”ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
                    if skip_mode_state != "ìë™ ìµœì í™” (ì´ì§„ íƒìƒ‰)":
                        # st.warning(f"âš ï¸ ìë™ ìµœì í™” ëª¨ë“œê°€ ì•„ë‹™ë‹ˆë‹¤. í˜„ì¬ ëª¨ë“œ: {skip_mode_state}")
                        pass
                    if not use_confidence_skip_state:
                        # st.warning(f"âš ï¸ ì‹ ë¢°ë„ ìŠ¤í‚µì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        pass
                    
                    if use_exclusion_strategy_state:
                        if use_confidence_skip_state:
                            # ì œì™¸ ì „ëµ + ì‹ ë¢°ë„ ìŠ¤í‚µ (ìˆ˜ë™)
                            multi_window_results = batch_validate_multi_window_scenario_with_exclusion_and_confidence_skip(
                                cutoff_id_mw,
                                window_sizes=selected_window_sizes_state,
                                method=multi_window_method_state,
                                threshold=multi_window_threshold_state,
                                confidence_skip_threshold=confidence_skip_threshold_state
                            )
                        else:
                            multi_window_results = batch_validate_multi_window_scenario_with_exclusion(
                                cutoff_id_mw,
                                window_sizes=selected_window_sizes_state,
                                method=multi_window_method_state,
                                threshold=multi_window_threshold_state
                            )
                    else:
                        if use_confidence_skip_state:
                            # ê¸°ë³¸ ì „ëµ + ì‹ ë¢°ë„ ìŠ¤í‚µ (ìˆ˜ë™)
                            multi_window_results = batch_validate_multi_window_with_confidence_skip(
                                cutoff_id_mw,
                                window_sizes=selected_window_sizes_state,
                                method=multi_window_method_state,
                                threshold=multi_window_threshold_state,
                                confidence_skip_threshold=confidence_skip_threshold_state
                            )
                        else:
                            # ê¸°ë³¸ ì „ëµë§Œ
                            multi_window_results = batch_validate_multi_window_scenario(
                                cutoff_id_mw,
                                window_sizes=selected_window_sizes_state,
                                method=multi_window_method_state,
                                threshold=multi_window_threshold_state
                            )
                
                if multi_window_results:
                    st.session_state.multi_window_results = multi_window_results
                    progress_bar_mw.progress(1.0)
                    status_text_mw.text("ì™„ë£Œ!")
                else:
                    st.error("ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨")
                
                progress_bar_mw.empty()
                status_text_mw.empty()
        
        # ê²°ê³¼ í‘œì‹œ
        if multi_window_results and len(multi_window_results.get('results', [])) > 0:
            st.markdown("---")
            strategy_label = "ì œì™¸ ì „ëµ" if use_exclusion_strategy_state else "ê¸°ë³¸ ì „ëµ"
            if use_confidence_skip_state:
                if skip_mode_state == "ìë™ ìµœì í™” (ì´ì§„ íƒìƒ‰)":
                    optimal_thresh = multi_window_optimal_result.get('optimal_threshold') if multi_window_optimal_result else None
                    if optimal_thresh:
                        strategy_label += f" + ì‹ ë¢°ë„ ìŠ¤í‚µ (ìµœì : {optimal_thresh}%)"
                    else:
                        strategy_label += " + ì‹ ë¢°ë„ ìŠ¤í‚µ (ìµœì í™” ì‹¤íŒ¨)"
                else:
                    strategy_label += f" + ì‹ ë¢°ë„ ìŠ¤í‚µ ({confidence_skip_threshold_state}%)"
            st.markdown(f"### ğŸ“Š ë‹¤ì¤‘ ìœˆë„ìš° ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ({strategy_label})")
            
            # ìë™ ìµœì í™” ê²°ê³¼ í‘œì‹œ
            if skip_mode_state == "ìë™ ìµœì í™” (ì´ì§„ íƒìƒ‰)" and multi_window_optimal_result:
                optimal_thresh = multi_window_optimal_result.get('optimal_threshold')
                search_history = multi_window_optimal_result.get('search_history', [])
                
                if optimal_thresh:
                    st.success(f"âœ… **ìµœì  ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’: {optimal_thresh}%**")
                    
                    if search_history:
                        st.markdown("#### ğŸ” ì´ì§„ íƒìƒ‰ íˆìŠ¤í† ë¦¬")
                        history_data = []
                        for h in search_history:
                            history_data.append({
                                'íšŒì°¨': h['iteration'],
                                'ì„ê³„ê°’ (%)': f"{h['threshold']:.1f}",
                                'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': h['max_consecutive_failures'],
                                'í‰ê·  ì •í™•ë„ (%)': f"{h['avg_accuracy']:.2f}",
                                'ìŠ¤í‚µ íšŸìˆ˜': h['total_skipped'],
                                'ë²”ìœ„': f"{h['range'][0]:.1f} ~ {h['range'][1]:.1f}"
                            })
                        history_df = pd.DataFrame(history_data)
                        st.dataframe(history_df, use_container_width=True, hide_index=True)
                else:
                    st.warning("âš ï¸ ìµœì  ì„ê³„ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            summary = multi_window_results.get('summary', {})
            
            col_result1, col_result2, col_result3, col_result4 = st.columns(4)
            with col_result1:
                st.metric("ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", f"{summary.get('max_consecutive_failures', 0)}íšŒ")
            with col_result2:
                st.metric("í‰ê·  ì •í™•ë„", f"{summary.get('avg_accuracy', 0):.2f}%")
            with col_result3:
                st.metric("ì´ ì˜ˆì¸¡ íšŸìˆ˜", f"{summary.get('total_predictions', 0):,}íšŒ")
            with col_result4:
                st.metric("ê²€ì¦ ëŒ€ìƒ", f"{summary.get('total_grid_strings', 0):,}ê°œ")
            
            # ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
            st.markdown("#### ìƒì„¸ ê²°ê³¼")
            results_data = []
            for result in multi_window_results.get('results', []):
                results_data.append({
                    'Grid String ID': result.get('grid_string_id'),
                    'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': result.get('max_consecutive_failures', 0),
                    'ì •í™•ë„ (%)': f"{result.get('accuracy', 0):.2f}",
                    'ì´ ìŠ¤í…': result.get('total_steps', 0),
                    'ì´ ì˜ˆì¸¡': result.get('total_predictions', 0),
                    'ì´ ì‹¤íŒ¨': result.get('total_failures', 0)
                })
            
            if results_data:
                results_df = pd.DataFrame(results_data)
                st.dataframe(results_df, use_container_width=True, hide_index=True)
                
                # Grid String ì„ íƒ ë“œë¡­ë‹¤ìš´
                st.markdown("#### ìƒì„¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ")
                grid_string_ids_list = [r.get('grid_string_id') for r in multi_window_results.get('results', [])]
                
                if len(grid_string_ids_list) > 0:
                    selected_grid_id = st.selectbox(
                        "Grid String ID ì„ íƒ",
                        options=grid_string_ids_list,
                        key="selected_grid_string_id_mw",
                        format_func=lambda x: f"ID {x}"
                    )
                    
                    # ì„ íƒëœ grid_stringì˜ íˆìŠ¤í† ë¦¬ í‘œì‹œ
                    selected_result = next(
                        (r for r in multi_window_results.get('results', []) if r.get('grid_string_id') == selected_grid_id),
                        None
                    )
                    
                    if selected_result and len(selected_result.get('history', [])) > 0:
                        history = selected_result.get('history', [])
                        
                        # ì‹¤íŒ¨ êµ¬ê°„ ê°•ì¡°ë¥¼ ìœ„í•œ ì •ë³´
                        consecutive_failures = 0
                        max_consecutive = 0
                        failure_ranges = []
                        current_range_start = None
                        
                        for i, h in enumerate(history):
                            is_correct = h.get('is_correct')
                            if is_correct is False:
                                consecutive_failures += 1
                                if current_range_start is None:
                                    current_range_start = i
                                if consecutive_failures > max_consecutive:
                                    max_consecutive = consecutive_failures
                            else:
                                if current_range_start is not None:
                                    failure_ranges.append((current_range_start, i - 1))
                                    current_range_start = None
                                consecutive_failures = 0
                        
                        if current_range_start is not None:
                            failure_ranges.append((current_range_start, len(history) - 1))
                        
                        col_hist1, col_hist2 = st.columns(2)
                        with col_hist1:
                            st.metric("ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", f"{selected_result.get('max_consecutive_failures', 0)}íšŒ")
                        with col_hist2:
                            st.metric("ì •í™•ë„", f"{selected_result.get('accuracy', 0):.2f}%")
                        
                        if failure_ranges:
                            st.info(f"âš ï¸ ì‹¤íŒ¨ êµ¬ê°„: {len(failure_ranges)}ê°œ (ìŠ¤í… {', '.join([f'{r[0]+1}-{r[1]+1}' for r in failure_ranges[:5]])}{'...' if len(failure_ranges) > 5 else ''})")
                        
                        # íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
                        history_data = []
                        for i, h in enumerate(history):
                            is_failure_range = any(start <= i <= end for start, end in failure_ranges)
                            
                            # ì œì™¸ ì „ëµ ì‚¬ìš© ì‹œ ì œì™¸ëœ ìœˆë„ìš° í¬ê¸° ì •ë³´ ì¶”ê°€
                            excluded_info = ""
                            if use_exclusion_strategy_state and h.get('excluded_window_sizes'):
                                excluded_info = f"ì œì™¸: {', '.join(map(str, h.get('excluded_window_sizes', [])))}"
                            
                            history_data.append({
                                'ìŠ¤í…': h.get('step'),
                                'ìœ„ì¹˜': h.get('position'),
                                'Prefix': h.get('prefix', ''),
                                'ì˜ˆì¸¡ê°’': h.get('predicted', ''),
                                'ì‹¤ì œê°’': h.get('actual', ''),
                                'ì •í™•': 'âœ…' if h.get('is_correct') else 'âŒ' if h.get('is_correct') is False else '-',
                                'ì‹ ë¢°ë„': f"{h.get('confidence', 0):.2f}%",
                                'ì„ íƒëœ ìœˆë„ìš°': h.get('selected_window_size', ''),
                                'ì œì™¸ëœ ìœˆë„ìš°': excluded_info if use_exclusion_strategy_state else '',
                                'ì‹¤íŒ¨ êµ¬ê°„': 'ğŸ”´' if is_failure_range else ''
                            })
                        
                        if history_data:
                            history_df = pd.DataFrame(history_data)
                            st.dataframe(history_df, use_container_width=True, hide_index=True)
            
            # ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ì„¹ì…˜
            st.markdown("---")
            st.markdown("### ğŸ” ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ (ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ 6 ì´ìƒ)")
            
            failure_analysis = analyze_failure_patterns(multi_window_results, min_failures=6)
            
            if len(failure_analysis.get('failure_grid_strings', [])) > 0:
                failure_stats = failure_analysis.get('failure_statistics', {})
                
                col_fail1, col_fail2, col_fail3 = st.columns(3)
                with col_fail1:
                    st.metric("ì‹¤íŒ¨ Grid String ìˆ˜", f"{failure_stats.get('total_failures', 0)}ê°œ")
                with col_fail2:
                    st.metric("ì‹¤íŒ¨ìœ¨", f"{failure_stats.get('failure_rate', 0):.2f}%")
                with col_fail3:
                    st.metric("í‰ê·  ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", f"{failure_stats.get('avg_max_consecutive_failures', 0):.2f}íšŒ")
                
                # ì‹ ë¢°ë„ ë¶„ì„
                confidence_analysis = failure_analysis.get('confidence_analysis', {})
                if confidence_analysis:
                    st.markdown("#### ì‹ ë¢°ë„ ë¶„ì„")
                    col_conf1, col_conf2, col_conf3 = st.columns(3)
                    with col_conf1:
                        st.metric("ì‹¤íŒ¨ ì „ í‰ê·  ì‹ ë¢°ë„", f"{confidence_analysis.get('avg_before_failure', 0):.2f}%")
                    with col_conf2:
                        st.metric("ì‹¤íŒ¨ ì¤‘ í‰ê·  ì‹ ë¢°ë„", f"{confidence_analysis.get('avg_during_failure', 0):.2f}%")
                    with col_conf3:
                        confidence_drop = confidence_analysis.get('confidence_drop', 0)
                        st.metric("ì‹ ë¢°ë„ í•˜ë½", f"{confidence_drop:.2f}%", delta=f"{confidence_drop:.2f}%")
                
                # ê³µí†µ ì‹¤íŒ¨ prefix íŒ¨í„´
                common_prefixes = failure_analysis.get('common_failure_prefixes', {})
                if common_prefixes:
                    st.markdown("#### ê³µí†µ ì‹¤íŒ¨ Prefix íŒ¨í„´ (ìƒìœ„ 10ê°œ)")
                    prefix_data = []
                    for prefix, count in list(common_prefixes.items())[:10]:
                        prefix_data.append({
                            'Prefix': prefix,
                            'ì‹¤íŒ¨ íšŸìˆ˜': count
                        })
                    
                    if prefix_data:
                        prefix_df = pd.DataFrame(prefix_data)
                        st.dataframe(prefix_df, use_container_width=True, hide_index=True)
                
                # ìœˆë„ìš° í¬ê¸°ë³„ ë¶„ì„
                window_analysis = failure_analysis.get('window_size_analysis', {})
                if window_analysis:
                    st.markdown("#### ìœˆë„ìš° í¬ê¸°ë³„ ì‹¤íŒ¨ìœ¨")
                    window_data = []
                    for window_size, stats in sorted(window_analysis.items()):
                        window_data.append({
                            'ìœˆë„ìš° í¬ê¸°': window_size,
                            'ì‹¤íŒ¨ìœ¨ (%)': f"{stats.get('failure_rate', 0):.2f}",
                            'ì´ ì‚¬ìš©': stats.get('total_usage', 0),
                            'ì‹¤íŒ¨ íšŸìˆ˜': stats.get('failures', 0)
                        })
                    
                    if window_data:
                        window_df = pd.DataFrame(window_data)
                        st.dataframe(window_df, use_container_width=True, hide_index=True)
                
                # íšŒí”¼ ì „ëµ ì œì•ˆ
                st.markdown("#### ğŸ’¡ íšŒí”¼ ì „ëµ ì œì•ˆ")
                suggestions = []
                
                if confidence_analysis.get('confidence_drop', 0) > 10:
                    suggestions.append("ì‹¤íŒ¨ ì „ ì‹ ë¢°ë„ê°€ í¬ê²Œ í•˜ë½í•˜ë¯€ë¡œ, ì‹ ë¢°ë„ê°€ ê¸‰ê²©íˆ ë–¨ì–´ì§ˆ ë•Œ ì˜ˆì¸¡ì„ ìŠ¤í‚µí•˜ëŠ” ì „ëµì„ ê³ ë ¤í•˜ì„¸ìš”.")
                
                if window_analysis:
                    worst_window = min(window_analysis.items(), key=lambda x: x[1].get('failure_rate', 0))
                    if worst_window[1].get('failure_rate', 0) > 50:
                        suggestions.append(f"ìœˆë„ìš° í¬ê¸° {worst_window[0]}ì˜ ì‹¤íŒ¨ìœ¨ì´ ë†’ìœ¼ë¯€ë¡œ, í•´ë‹¹ ìœˆë„ìš° í¬ê¸°ë¥¼ ì œì™¸í•˜ê±°ë‚˜ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì¶”ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")
                
                if common_prefixes:
                    top_failure_prefix = list(common_prefixes.items())[0][0]
                    suggestions.append(f"Prefix '{top_failure_prefix}'ì—ì„œ ìì£¼ ì‹¤íŒ¨í•˜ë¯€ë¡œ, í•´ë‹¹ íŒ¨í„´ì´ ë‚˜íƒ€ë‚  ë•Œ íŠ¹ë³„í•œ ì²˜ë¦¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
                
                if suggestions:
                    for i, suggestion in enumerate(suggestions, 1):
                        st.info(f"{i}. {suggestion}")
                else:
                    st.info("ì¶”ê°€ì ì¸ íšŒí”¼ ì „ëµì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.")
            else:
                st.success("âœ… ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ 6 ì´ìƒì¸ grid_stringì´ ì—†ìŠµë‹ˆë‹¤!")
        elif multi_window_results:
            st.warning("âš ï¸ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ’¡ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    else:
        st.info("ğŸ’¡ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•˜ê³  ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    # ìœˆë„ìš° í¬ê¸°ë³„ ì‹ ë¢°ë„ ëª©ë¡ ì„¹ì…˜
    st.markdown("---")
    st.markdown("## ğŸ“Š ìœˆë„ìš° í¬ê¸°ë³„ Prefix ì‹ ë¢°ë„ ëª©ë¡")
    st.markdown("**stored_predictions í…Œì´ë¸”ì˜ ê° ìœˆë„ìš° í¬ê¸°ë³„ ëª¨ë“  prefixì™€ ì‹ ë¢°ë„ (ë†’ì€ ìˆœì„œ)**")
    
    conn = get_db_connection()
    if conn is not None:
        try:
            # ìœˆë„ìš° í¬ê¸°ë³„ë¡œ íƒ­ ìƒì„±
            tab5, tab6, tab7, tab8 = st.tabs(["ìœˆë„ìš° í¬ê¸° 5", "ìœˆë„ìš° í¬ê¸° 6", "ìœˆë„ìš° í¬ê¸° 7", "ìœˆë„ìš° í¬ê¸° 8"])
            
            for tab, window_size in [(tab5, 5), (tab6, 6), (tab7, 7), (tab8, 8)]:
                with tab:
                    # í•´ë‹¹ ìœˆë„ìš° í¬ê¸°ì˜ ëª¨ë“  prefixì™€ ì‹ ë¢°ë„ë¥¼ ì‹ ë¢°ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì¡°íšŒ
                    # ngram_chunks í…Œì´ë¸”ê³¼ JOINí•˜ì—¬ ë¹ˆë„ìˆ˜ë„ í•¨ê»˜ ê°€ì ¸ì˜¤ê¸°
                    query = """
                        SELECT 
                            sp.prefix,
                            sp.confidence,
                            sp.predicted_value,
                            sp.b_ratio,
                            sp.p_ratio,
                            COUNT(nc.id) as frequency
                        FROM stored_predictions sp
                        LEFT JOIN ngram_chunks nc 
                            ON sp.window_size = nc.window_size 
                            AND sp.prefix = nc.prefix
                        WHERE sp.window_size = ?
                        GROUP BY sp.prefix, sp.confidence, sp.predicted_value, sp.b_ratio, sp.p_ratio
                        ORDER BY sp.confidence DESC
                    """
                    
                    df = pd.read_sql_query(query, conn, params=[window_size])
                    
                    if len(df) > 0:
                        # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
                        result_data = []
                        for idx, row in df.iterrows():
                            result_data.append({
                                'ìˆœìœ„': idx + 1,
                                'Prefix': row['prefix'],
                                'ì‹ ë¢°ë„ (%)': f"{row['confidence']:.2f}",
                                'ë¹ˆë„ìˆ˜': int(row['frequency']) if row['frequency'] is not None else 0,
                                'ì˜ˆì¸¡ê°’': row['predicted_value'],
                                'B ë¹„ìœ¨': f"{row['b_ratio']:.2f}" if row['b_ratio'] is not None else "N/A",
                                'P ë¹„ìœ¨': f"{row['p_ratio']:.2f}" if row['p_ratio'] is not None else "N/A"
                            })
                        
                        result_df = pd.DataFrame(result_data)
                        
                        # ì´ ê°œìˆ˜ í‘œì‹œ
                        st.markdown(f"**ì´ {len(df)}ê°œ prefix**")
                        
                        # í…Œì´ë¸” í‘œì‹œ
                        st.dataframe(result_df, use_container_width=True, hide_index=True)
                    else:
                        st.warning(f"âš ï¸ ìœˆë„ìš° í¬ê¸° {window_size}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
        except Exception as e:
            st.error(f"ì‹ ë¢°ë„ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        finally:
            conn.close()
    else:
        st.error("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ì˜ˆì¸¡ ë°©ë²•ë³„ ì˜ˆì¸¡ê°’ ë¶„í¬ ë¹„êµ ë¶„ì„ ì„¹ì…˜
    st.markdown("---")
    st.markdown("## ğŸ“ˆ ì˜ˆì¸¡ ë°©ë²•ë³„ ì˜ˆì¸¡ê°’ ë¶„í¬ ë¹„êµ")
    st.markdown("**ë¹ˆë„ ê¸°ë°˜ vs ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì˜ˆì¸¡ê°’ ë¶„í¬ ë¹„êµ (ìœˆë„ìš° í¬ê¸° 5, 6, 7, 8)**")
    
    conn = get_db_connection()
    if conn is not None:
        try:
            # ìœˆë„ìš° í¬ê¸°ë³„, ë°©ë²•ë³„ ì˜ˆì¸¡ê°’ ë¶„í¬ ì§‘ê³„
            comparison_data = []
            
            for window_size in [5, 6, 7, 8]:
                for method in ["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜"]:
                    # í•´ë‹¹ ìœˆë„ìš° í¬ê¸°ì™€ ë°©ë²•ì˜ ì „ì²´ ì˜ˆì¸¡ ê°œìˆ˜ ë° B/P ë¶„í¬
                    query = """
                        SELECT 
                            predicted_value,
                            COUNT(*) as count,
                            AVG(confidence) as avg_confidence,
                            AVG(b_ratio) as avg_b_ratio,
                            AVG(p_ratio) as avg_p_ratio
                        FROM stored_predictions
                        WHERE window_size = ? 
                          AND method = ?
                          AND threshold = 0
                        GROUP BY predicted_value
                    """
                    
                    df = pd.read_sql_query(query, conn, params=[window_size, method])
                    
                    total_count = 0
                    b_count = 0
                    p_count = 0
                    b_avg_confidence = 0.0
                    p_avg_confidence = 0.0
                    b_avg_b_ratio = 0.0
                    b_avg_p_ratio = 0.0
                    p_avg_b_ratio = 0.0
                    p_avg_p_ratio = 0.0
                    
                    for _, row in df.iterrows():
                        count = int(row['count'])
                        total_count += count
                        
                        if row['predicted_value'] == 'b':
                            b_count = count
                            b_avg_confidence = row['avg_confidence'] if row['avg_confidence'] is not None else 0.0
                            b_avg_b_ratio = row['avg_b_ratio'] if row['avg_b_ratio'] is not None else 0.0
                            b_avg_p_ratio = row['avg_p_ratio'] if row['avg_p_ratio'] is not None else 0.0
                        elif row['predicted_value'] == 'p':
                            p_count = count
                            p_avg_confidence = row['avg_confidence'] if row['avg_confidence'] is not None else 0.0
                            p_avg_b_ratio = row['avg_b_ratio'] if row['avg_b_ratio'] is not None else 0.0
                            p_avg_p_ratio = row['avg_p_ratio'] if row['avg_p_ratio'] is not None else 0.0
                    
                    if total_count > 0:
                        b_ratio = (b_count / total_count) * 100
                        p_ratio = (p_count / total_count) * 100
                        
                        comparison_data.append({
                            'ìœˆë„ìš° í¬ê¸°': window_size,
                            'ì˜ˆì¸¡ ë°©ë²•': method,
                            'ì´ ì˜ˆì¸¡ ìˆ˜': total_count,
                            'B ì˜ˆì¸¡ ìˆ˜': b_count,
                            'P ì˜ˆì¸¡ ìˆ˜': p_count,
                            'B ë¹„ìœ¨ (%)': f"{b_ratio:.2f}",
                            'P ë¹„ìœ¨ (%)': f"{p_ratio:.2f}",
                            'B í‰ê·  ì‹ ë¢°ë„ (%)': f"{b_avg_confidence:.2f}" if b_count > 0 else "N/A",
                            'P í‰ê·  ì‹ ë¢°ë„ (%)': f"{p_avg_confidence:.2f}" if p_count > 0 else "N/A",
                            'B ì˜ˆì¸¡ í‰ê·  B ë¹„ìœ¨ (%)': f"{b_avg_b_ratio:.2f}" if b_count > 0 else "N/A",
                            'B ì˜ˆì¸¡ í‰ê·  P ë¹„ìœ¨ (%)': f"{b_avg_p_ratio:.2f}" if b_count > 0 else "N/A",
                            'P ì˜ˆì¸¡ í‰ê·  B ë¹„ìœ¨ (%)': f"{p_avg_b_ratio:.2f}" if p_count > 0 else "N/A",
                            'P ì˜ˆì¸¡ í‰ê·  P ë¹„ìœ¨ (%)': f"{p_avg_p_ratio:.2f}" if p_count > 0 else "N/A"
                        })
            
            if comparison_data:
                comparison_df = pd.DataFrame(comparison_data)
                
                # ìš”ì•½ í†µê³„ í‘œì‹œ
                st.markdown("### ì „ì²´ ìš”ì•½")
                summary_cols = st.columns(2)
                
                with summary_cols[0]:
                    st.markdown("#### ë¹ˆë„ ê¸°ë°˜")
                    freq_df = comparison_df[comparison_df['ì˜ˆì¸¡ ë°©ë²•'] == 'ë¹ˆë„ ê¸°ë°˜']
                    if len(freq_df) > 0:
                        total_freq = freq_df['ì´ ì˜ˆì¸¡ ìˆ˜'].sum()
                        b_total_freq = freq_df['B ì˜ˆì¸¡ ìˆ˜'].sum()
                        p_total_freq = freq_df['P ì˜ˆì¸¡ ìˆ˜'].sum()
                        b_ratio_freq = (b_total_freq / total_freq * 100) if total_freq > 0 else 0
                        p_ratio_freq = (p_total_freq / total_freq * 100) if total_freq > 0 else 0
                        
                        st.metric("ì´ ì˜ˆì¸¡ ìˆ˜", f"{total_freq:,}")
                        st.metric("B ì˜ˆì¸¡ ë¹„ìœ¨", f"{b_ratio_freq:.2f}%")
                        st.metric("P ì˜ˆì¸¡ ë¹„ìœ¨", f"{p_ratio_freq:.2f}%")
                
                with summary_cols[1]:
                    st.markdown("#### ê°€ì¤‘ì¹˜ ê¸°ë°˜")
                    weighted_df = comparison_df[comparison_df['ì˜ˆì¸¡ ë°©ë²•'] == 'ê°€ì¤‘ì¹˜ ê¸°ë°˜']
                    if len(weighted_df) > 0:
                        total_weighted = weighted_df['ì´ ì˜ˆì¸¡ ìˆ˜'].sum()
                        b_total_weighted = weighted_df['B ì˜ˆì¸¡ ìˆ˜'].sum()
                        p_total_weighted = weighted_df['P ì˜ˆì¸¡ ìˆ˜'].sum()
                        b_ratio_weighted = (b_total_weighted / total_weighted * 100) if total_weighted > 0 else 0
                        p_ratio_weighted = (p_total_weighted / total_weighted * 100) if total_weighted > 0 else 0
                        
                        st.metric("ì´ ì˜ˆì¸¡ ìˆ˜", f"{total_weighted:,}")
                        st.metric("B ì˜ˆì¸¡ ë¹„ìœ¨", f"{b_ratio_weighted:.2f}%")
                        st.metric("P ì˜ˆì¸¡ ë¹„ìœ¨", f"{p_ratio_weighted:.2f}%")
                
                # ìƒì„¸ ë¹„êµ í…Œì´ë¸”
                st.markdown("### ìœˆë„ìš° í¬ê¸°ë³„ ìƒì„¸ ë¹„êµ")
                st.dataframe(comparison_df, use_container_width=True, hide_index=True)
                
                # ì°¨ì´ ë¶„ì„
                st.markdown("### ì°¨ì´ ë¶„ì„")
                if len(freq_df) > 0 and len(weighted_df) > 0:
                    # ìœˆë„ìš° í¬ê¸°ë³„ë¡œ ë¹„êµ
                    diff_data = []
                    for window_size in [5, 6, 7, 8]:
                        freq_row = freq_df[freq_df['ìœˆë„ìš° í¬ê¸°'] == window_size]
                        weighted_row = weighted_df[weighted_df['ìœˆë„ìš° í¬ê¸°'] == window_size]
                        
                        if len(freq_row) > 0 and len(weighted_row) > 0:
                            freq_b_ratio = float(freq_row.iloc[0]['B ë¹„ìœ¨ (%)'].replace('%', ''))
                            weighted_b_ratio = float(weighted_row.iloc[0]['B ë¹„ìœ¨ (%)'].replace('%', ''))
                            diff = weighted_b_ratio - freq_b_ratio
                            
                            diff_data.append({
                                'ìœˆë„ìš° í¬ê¸°': window_size,
                                'ë¹ˆë„ ê¸°ë°˜ B ë¹„ìœ¨ (%)': f"{freq_b_ratio:.2f}",
                                'ê°€ì¤‘ì¹˜ ê¸°ë°˜ B ë¹„ìœ¨ (%)': f"{weighted_b_ratio:.2f}",
                                'ì°¨ì´ (ê°€ì¤‘ì¹˜ - ë¹ˆë„) (%)': f"{diff:+.2f}",
                                'ë³€í™”': "ì¦ê°€" if diff > 0 else "ê°ì†Œ" if diff < 0 else "ë™ì¼"
                            })
                    
                    if diff_data:
                        diff_df = pd.DataFrame(diff_data)
                        st.dataframe(diff_df, use_container_width=True, hide_index=True)
            else:
                st.warning("âš ï¸ ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. stored_predictions í…Œì´ë¸”ì— ë¹ˆë„ ê¸°ë°˜ê³¼ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë°ì´í„°ê°€ ëª¨ë‘ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ê°’ ë¶„í¬ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        finally:
            conn.close()
    else:
        st.error("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ì‹¤ì‹œê°„ ëª¨ë¸ vs stored_predictions ë¹„êµ ì„¹ì…˜
    st.markdown("---")
    st.markdown("## ğŸ” ì‹¤ì‹œê°„ ëª¨ë¸ vs stored_predictions í…Œì´ë¸” ë¹„êµ")
    st.markdown("**ì‹¤ì‹œê°„ ëª¨ë¸ë¡œ ìƒì„±í•œ ì˜ˆì¸¡ê°’ê³¼ stored_predictions í…Œì´ë¸”ì˜ ì˜ˆì¸¡ê°’ì„ ë¹„êµí•©ë‹ˆë‹¤.**")
    
    def generate_realtime_predictions_table(cutoff_grid_string_id, window_sizes=[5, 6, 7, 8, 9], methods=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜"], threshold=0):
        """
        ì‹¤ì‹œê°„ ëª¨ë¸ë¡œ ì˜ˆì¸¡ í…Œì´ë¸” ìƒì„± (stored_predictionsì™€ ë™ì¼í•œ í˜•ì‹)
        
        Args:
            cutoff_grid_string_id: ê¸°ì¤€ grid_string_id (ì´ ID ì´í•˜ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©)
            window_sizes: ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
            methods: ì˜ˆì¸¡ ë°©ë²• ë¦¬ìŠ¤íŠ¸
            threshold: ì„ê³„ê°’ (0ì€ ì„ê³„ê°’ ì—†ìŒ)
        
        Returns:
            list: [{window_size, prefix, predicted_value, confidence, b_ratio, p_ratio, method, threshold}, ...]
        """
        conn = get_db_connection()
        if conn is None:
            return []
        
        try:
            # í•™ìŠµ ë°ì´í„° ì„ íƒ
            if cutoff_grid_string_id is None:
                query = "SELECT id FROM preprocessed_grid_strings ORDER BY id"
                params = []
            else:
                query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
                params = [cutoff_grid_string_id]
            
            df_historical = pd.read_sql_query(query, conn, params=params)
            
            if len(df_historical) == 0:
                return []
            
            historical_ids = df_historical['id'].tolist()
            predictions = []
            
            for window_size in window_sizes:
                # í•´ë‹¹ ìœˆë„ìš° í¬ê¸°ì˜ ngram_chunks ë¡œë“œ
                train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=historical_ids)
                
                if len(train_ngrams) == 0:
                    continue
                
                # ëª¨ë“  ê°€ëŠ¥í•œ prefix ì¶”ì¶œ
                all_prefixes = set()
                for _, row in train_ngrams.iterrows():
                    all_prefixes.add(row['prefix'])
                
                # ê° ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ êµ¬ì¶• ë° ì˜ˆì¸¡
                for method in methods:
                    # ëª¨ë¸ êµ¬ì¶•
                    if method == "ë¹ˆë„ ê¸°ë°˜":
                        model = build_frequency_model(train_ngrams)
                    elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                        model = build_weighted_model(train_ngrams)
                    else:
                        model = build_frequency_model(train_ngrams)
                    
                    # ê° prefixì— ëŒ€í•´ ì˜ˆì¸¡ê°’ ê³„ì‚°
                    for prefix in all_prefixes:
                        prediction_result = predict_for_prefix(model, prefix, method)
                        
                        predicted = prediction_result.get('predicted')
                        ratios = prediction_result.get('ratios', {})
                        confidence = prediction_result.get('confidence', 0.0)
                        
                        b_ratio = ratios.get('b', 0.0)
                        p_ratio = ratios.get('p', 0.0)
                        
                        predictions.append({
                            'window_size': window_size,
                            'prefix': prefix,
                            'predicted_value': predicted,
                            'confidence': confidence,
                            'b_ratio': b_ratio,
                            'p_ratio': p_ratio,
                            'method': method,
                            'threshold': threshold
                        })
            
            return predictions
            
        except Exception as e:
            st.error(f"ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
        finally:
            conn.close()
    
    # ë¹„êµ ì„¹ì…˜ UI
    with st.form("realtime_vs_stored_comparison_form", clear_on_submit=False):
        st.markdown("### ë¹„êµ ì„¤ì •")
        
        col_comp1, col_comp2, col_comp3 = st.columns(3)
        
        with col_comp1:
            # ê¸°ì¤€ Grid String ID ì„ íƒ
            df_all_strings_comp = load_preprocessed_data()
            if len(df_all_strings_comp) > 0:
                grid_string_options_comp = []
                for _, row in df_all_strings_comp.iterrows():
                    grid_string_options_comp.append((row['id'], row['created_at']))
                
                grid_string_options_comp.sort(key=lambda x: x[0], reverse=True)
                
                selected_cutoff_id_comp = st.selectbox(
                    "ê¸°ì¤€ Grid String ID (ì´ ID ì´í•˜ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©)",
                    options=[None] + [opt[0] for opt in grid_string_options_comp],
                    format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else next((f"ID {opt[0]} - {format_datetime_for_dropdown(opt[1])}" for opt in grid_string_options_comp if opt[0] == x), f"ID {x}"),
                    key="comparison_cutoff_id"
                )
            else:
                selected_cutoff_id_comp = None
                st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
        
        with col_comp2:
            comparison_methods = st.multiselect(
                "ë¹„êµí•  ì˜ˆì¸¡ ë°©ë²•",
                options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜"],
                default=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜"],
                key="comparison_methods"
            )
        
        with col_comp3:
            comparison_threshold = st.number_input(
                "ì„ê³„ê°’",
                min_value=0,
                max_value=100,
                value=0,
                step=1,
                key="comparison_threshold",
                help="stored_predictionsì—ì„œ ì¡°íšŒí•  ì„ê³„ê°’"
            )
        
        if st.form_submit_button("ğŸ” ë¹„êµ ì‹¤í–‰", type="primary", use_container_width=True):
            if selected_cutoff_id_comp is None:
                st.warning("âš ï¸ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            elif len(comparison_methods) == 0:
                st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ ì˜ˆì¸¡ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ì‹¤ì‹œê°„ ëª¨ë¸ë¡œ ì˜ˆì¸¡ í…Œì´ë¸” ìƒì„± ì¤‘..."):
                    # ì‹¤ì‹œê°„ ëª¨ë¸ë¡œ ì˜ˆì¸¡ í…Œì´ë¸” ìƒì„±
                    realtime_predictions = generate_realtime_predictions_table(
                        cutoff_grid_string_id=selected_cutoff_id_comp,
                        window_sizes=[5, 6, 7, 8, 9],
                        methods=comparison_methods,
                        threshold=0
                    )
                    
                    st.session_state.realtime_predictions = realtime_predictions
                    st.session_state.comparison_cutoff_id_saved = selected_cutoff_id_comp
                    st.session_state.comparison_methods_saved = comparison_methods
                    st.session_state.comparison_threshold_saved = comparison_threshold
                    st.rerun()
    
    # ë¹„êµ ê²°ê³¼ í‘œì‹œ
    if 'realtime_predictions' in st.session_state and st.session_state.realtime_predictions:
        realtime_predictions = st.session_state.realtime_predictions
        comparison_cutoff_id = st.session_state.get('comparison_cutoff_id_saved')
        comparison_methods = st.session_state.get('comparison_methods_saved', [])
        comparison_threshold = st.session_state.get('comparison_threshold_saved', 0)
        
        # stored_predictions í…Œì´ë¸”ì—ì„œ ë°ì´í„° ë¡œë“œ
        conn = get_db_connection()
        if conn is not None:
            try:
                # ìœˆë„ìš° í¬ê¸°ë³„, ë°©ë²•ë³„ë¡œ ë¹„êµ
                for window_size in [5, 6, 7, 8, 9]:
                    for method in comparison_methods:
                        st.markdown(f"### ìœˆë„ìš° í¬ê¸° {window_size} - {method}")
                        
                        # ì‹¤ì‹œê°„ ëª¨ë¸ ë°ì´í„° í•„í„°ë§
                        realtime_data = [
                            p for p in realtime_predictions 
                            if p['window_size'] == window_size and p['method'] == method
                        ]
                        
                        if len(realtime_data) == 0:
                            st.info(f"ì‹¤ì‹œê°„ ëª¨ë¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            continue
                        
                        # stored_predictions ë°ì´í„° ë¡œë“œ
                        stored_query = """
                            SELECT 
                                prefix,
                                predicted_value,
                                confidence,
                                b_ratio,
                                p_ratio
                            FROM stored_predictions
                            WHERE window_size = ?
                              AND method = ?
                              AND threshold = ?
                        """
                        stored_df = pd.read_sql_query(stored_query, conn, params=[window_size, method, comparison_threshold])
                        
                        if len(stored_df) == 0:
                            st.warning(f"stored_predictionsì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì„ê³„ê°’: {comparison_threshold})")
                            continue
                        
                        # ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                        realtime_df = pd.DataFrame(realtime_data)
                        
                        # ë¹„êµ ë°ì´í„° ìƒì„±
                        comparison_data = []
                        
                        # ì‹¤ì‹œê°„ ëª¨ë¸ì˜ ëª¨ë“  prefixì— ëŒ€í•´ ë¹„êµ
                        for _, realtime_row in realtime_df.iterrows():
                            prefix = realtime_row['prefix']
                            stored_row = stored_df[stored_df['prefix'] == prefix]
                            
                            if len(stored_row) > 0:
                                stored_row = stored_row.iloc[0]
                                
                                # ì‹ ë¢°ë„ ì°¨ì´ ê³„ì‚°
                                confidence_diff = realtime_row['confidence'] - stored_row['confidence']
                                
                                # ì˜ˆì¸¡ê°’ ì¼ì¹˜ ì—¬ë¶€
                                predicted_match = (realtime_row['predicted_value'] == stored_row['predicted_value'])
                                
                                comparison_data.append({
                                    'Prefix': prefix,
                                    'ì‹¤ì‹œê°„ ì˜ˆì¸¡ê°’': realtime_row['predicted_value'],
                                    'ì €ì¥ëœ ì˜ˆì¸¡ê°’': stored_row['predicted_value'],
                                    'ì˜ˆì¸¡ê°’ ì¼ì¹˜': 'âœ…' if predicted_match else 'âŒ',
                                    'ì‹¤ì‹œê°„ ì‹ ë¢°ë„ (%)': f"{realtime_row['confidence']:.2f}",
                                    'ì €ì¥ëœ ì‹ ë¢°ë„ (%)': f"{stored_row['confidence']:.2f}",
                                    'ì‹ ë¢°ë„ ì°¨ì´': f"{confidence_diff:+.2f}",
                                    'ì‹¤ì‹œê°„ B ë¹„ìœ¨ (%)': f"{realtime_row['b_ratio']:.2f}",
                                    'ì €ì¥ëœ B ë¹„ìœ¨ (%)': f"{stored_row['b_ratio']:.2f}" if pd.notna(stored_row['b_ratio']) else "N/A",
                                    'ì‹¤ì‹œê°„ P ë¹„ìœ¨ (%)': f"{realtime_row['p_ratio']:.2f}",
                                    'ì €ì¥ëœ P ë¹„ìœ¨ (%)': f"{stored_row['p_ratio']:.2f}" if pd.notna(stored_row['p_ratio']) else "N/A"
                                })
                        
                        # ì €ì¥ëœ í…Œì´ë¸”ì—ëŠ” ìˆì§€ë§Œ ì‹¤ì‹œê°„ ëª¨ë¸ì—ëŠ” ì—†ëŠ” prefix
                        realtime_prefixes = set(realtime_df['prefix'].tolist())
                        stored_prefixes = set(stored_df['prefix'].tolist())
                        only_in_stored = stored_prefixes - realtime_prefixes
                        
                        for prefix in only_in_stored:
                            stored_row = stored_df[stored_df['prefix'] == prefix].iloc[0]
                            comparison_data.append({
                                'Prefix': prefix,
                                'ì‹¤ì‹œê°„ ì˜ˆì¸¡ê°’': 'N/A',
                                'ì €ì¥ëœ ì˜ˆì¸¡ê°’': stored_row['predicted_value'],
                                'ì˜ˆì¸¡ê°’ ì¼ì¹˜': '-',
                                'ì‹¤ì‹œê°„ ì‹ ë¢°ë„ (%)': 'N/A',
                                'ì €ì¥ëœ ì‹ ë¢°ë„ (%)': f"{stored_row['confidence']:.2f}",
                                'ì‹ ë¢°ë„ ì°¨ì´': 'N/A',
                                'ì‹¤ì‹œê°„ B ë¹„ìœ¨ (%)': 'N/A',
                                'ì €ì¥ëœ B ë¹„ìœ¨ (%)': f"{stored_row['b_ratio']:.2f}" if pd.notna(stored_row['b_ratio']) else "N/A",
                                'ì‹¤ì‹œê°„ P ë¹„ìœ¨ (%)': 'N/A',
                                'ì €ì¥ëœ P ë¹„ìœ¨ (%)': f"{stored_row['p_ratio']:.2f}" if pd.notna(stored_row['p_ratio']) else "N/A"
                            })
                        
                        if comparison_data:
                            comparison_df = pd.DataFrame(comparison_data)
                            
                            # í†µê³„ ìš”ì•½
                            matched_count = sum(1 for d in comparison_data if d['ì˜ˆì¸¡ê°’ ì¼ì¹˜'] == 'âœ…')
                            total_count = len([d for d in comparison_data if d['ì‹ ë¢°ë„ ì°¨ì´'] != 'N/A'])
                            
                            col_stat1, col_stat2, col_stat3 = st.columns(3)
                            with col_stat1:
                                st.metric("ì´ Prefix ìˆ˜", len(comparison_data))
                            with col_stat2:
                                st.metric("ì˜ˆì¸¡ê°’ ì¼ì¹˜", f"{matched_count}/{total_count}", f"{matched_count/total_count*100:.1f}%" if total_count > 0 else "0%")
                            with col_stat3:
                                if total_count > 0:
                                    confidence_diffs = [float(d['ì‹ ë¢°ë„ ì°¨ì´'].replace('+', '')) for d in comparison_data if d['ì‹ ë¢°ë„ ì°¨ì´'] != 'N/A']
                                    avg_diff = sum(confidence_diffs) / len(confidence_diffs)
                                    st.metric("í‰ê·  ì‹ ë¢°ë„ ì°¨ì´", f"{avg_diff:+.2f}%")
                            
                            # ì‹ ë¢°ë„ ì°¨ì´ ìˆœìœ¼ë¡œ ì •ë ¬ (í° ì°¨ì´ë¶€í„°)
                            comparison_df_sorted = comparison_df.copy()
                            comparison_df_sorted['ì‹ ë¢°ë„_ì°¨ì´_ìˆ«ì'] = comparison_df_sorted['ì‹ ë¢°ë„ ì°¨ì´'].apply(
                                lambda x: float(x.replace('+', '')) if x != 'N/A' else 0
                            )
                            comparison_df_sorted = comparison_df_sorted.sort_values('ì‹ ë¢°ë„_ì°¨ì´_ìˆ«ì', key=abs, ascending=False)
                            comparison_df_sorted = comparison_df_sorted.drop('ì‹ ë¢°ë„_ì°¨ì´_ìˆ«ì', axis=1)
                            
                            st.dataframe(comparison_df_sorted, use_container_width=True, hide_index=True)
                        else:
                            st.info("ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                        st.markdown("---")
                
            except Exception as e:
                st.error(f"ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                import traceback
                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            finally:
                conn.close()

if __name__ == "__main__":
    main()
