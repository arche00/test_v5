import streamlit as st
import sqlite3
import pandas as pd
import os
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Game Outcome Summary V2 Viewer",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
def get_db_connection():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        if not os.path.exists(db_path):
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
            return None
        return sqlite3.connect(db_path)
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return None

# ë°ì´í„° ë¡œë“œ (ìºì‹œ ì—†ì´ ë§¤ë²ˆ ìµœì‹  ë°ì´í„° ë¡œë“œ)
def load_game_outcome_v2_data():
    """game_outcome_summary_v2 í…Œì´ë¸”ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    try:
        conn = get_db_connection()
        if conn is None:
            return pd.DataFrame()
        
        query = """
            SELECT 
                id,
                session_id,
                sequence_prediction_results,
                reconstructed_sequence_prediction_results,
                reconstructed_gap_results,
                converted_grid,
                reconstructed_grid,
                created_at
            FROM game_outcome_summary_v2
            ORDER BY created_at DESC
        """
        df = pd.read_sql_query(query, conn)
        conn.close()
        return df
    except sqlite3.OperationalError as e:
        if "no such table" in str(e).lower():
            st.error("í…Œì´ë¸” 'game_outcome_summary_v2'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()

# ë¶„ì„ í•¨ìˆ˜ë“¤
def analyze_prediction_comparison(df):
    """
    ë‘ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ë¶„ì„
    sequence_prediction_resultsì™€ reconstructed_sequence_prediction_results ë¹„êµ
    """
    analysis_results = {
        'first_match_position': [],  # ì²« ë²ˆì§¸ë¡œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜
        'max_match_position': [],  # ìµœëŒ€ ëª‡ ë²ˆì§¸ ìœ„ì¹˜ê¹Œì§€ ê°™ì€ ë¬¸ìê°€ ë‚˜ì™”ëŠ”ì§€
        'position_match': {1: [], 2: [], 3: []},  # ìœ„ì¹˜ë³„ë¡œ ê°™ì€ ë¬¸ìì¸ì§€ (True/False)
        'first_different_match_position': []  # ì²« ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš°, ëª‡ ë²ˆì§¸ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
    }
    
    valid_comparisons = 0
    session_info_list = []  # ì„¸ì…˜ ì •ë³´ ì €ì¥ (ìˆœì„œ ìœ ì§€)
    
    for idx, row in df.iterrows():
        seq1 = str(row.get('sequence_prediction_results', '')) if pd.notna(row.get('sequence_prediction_results')) else ''
        seq2 = str(row.get('reconstructed_sequence_prediction_results', '')) if pd.notna(row.get('reconstructed_sequence_prediction_results')) else ''
        
        # ë¹ˆ ë¬¸ìì—´ì´ë©´ ìŠ¤í‚µ
        if not seq1 or not seq2:
            continue
        
        # ë¬¸ìì—´ ê¸¸ì´ ë§ì¶”ê¸° (ì§§ì€ ê¸¸ì´ ê¸°ì¤€)
        min_len = min(len(seq1), len(seq2))
        seq1 = seq1[:min_len]
        seq2 = seq2[:min_len]
        
        # ê²°ê³¼ ê¸¸ì´ê°€ 2ë¯¸ë§Œì¸ ê²ƒì€ ìœ íš¨í•˜ì§€ ì•Šì•„ì„œ ì œê±°
        if min_len < 2:
            continue
        
        valid_comparisons += 1
        
        # 1. ì²« ë²ˆì§¸ë¡œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ì°¾ê¸°
        first_match_pos = None
        for i in range(min_len):
            if seq1[i] == seq2[i]:
                first_match_pos = i + 1  # 1-based index
                break
        analysis_results['first_match_position'].append(first_match_pos if first_match_pos else None)
        
        # 2. ìµœëŒ€ ëª‡ ë²ˆì§¸ ìœ„ì¹˜ê¹Œì§€ ê°™ì€ ë¬¸ìê°€ ë‚˜ì™”ëŠ”ì§€
        max_match_pos = 0
        for i in range(min_len):
            if seq1[i] == seq2[i]:
                max_match_pos = i + 1  # 1-based index
            else:
                break  # ì—°ì†ëœ ë§¤ì¹­ë§Œ ì¹´ìš´íŠ¸
        analysis_results['max_match_position'].append(max_match_pos)
        
        # 3. ìœ„ì¹˜ë³„ë¡œ ê°™ì€ ë¬¸ìì¸ì§€ (ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸, ì„¸ ë²ˆì§¸)
        for pos in [1, 2, 3]:
            if pos <= min_len:
                is_match = (seq1[pos-1] == seq2[pos-1])
                analysis_results['position_match'][pos].append(is_match)
        
        # 4. ì²« ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš°, ëª‡ ë²ˆì§¸ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
        if seq1[0] != seq2[0]:
            match_pos = None
            for i in range(1, min_len):  # ë‘ ë²ˆì§¸ ë¬¸ìë¶€í„° ì‹œì‘
                if seq1[i] == seq2[i]:
                    match_pos = i + 1  # 1-based index
                    break
            analysis_results['first_different_match_position'].append(match_pos)
        
        # 5. êµì°¨ íŒ¨í„´ ë¶„ì„ (ì²« ë²ˆì§¸ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ íŒ¨í„´ì´ ë°”ë€ŒëŠ” ìœ„ì¹˜ ì¶”ì )
        # min_len >= 2ì´ë¯€ë¡œ ë°”ë¡œ ì§„í–‰
        first_same = (seq1[0] == seq2[0])
        converted_within_3 = False  # 3ë²ˆì§¸ê¹Œì§€ ì „í™˜ ì—¬ë¶€
        
        # ì²« ë²ˆì§¸ê°€ ê°™ì„ ë•Œ â†’ ë‹¤ìŒì— ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ì°¾ê¸°
        if first_same:
            different_pos = None
            for i in range(1, min_len):
                if seq1[i] != seq2[i]:  # ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜
                    different_pos = i + 1  # 1-based index
                    break
            analysis_results.setdefault('first_same_next_different_position', []).append(different_pos)
            
            # 3ë²ˆì§¸ê¹Œì§€ ì „í™˜ ì—¬ë¶€ í™•ì¸ (2, 3ë²ˆì§¸ ì¤‘ í•˜ë‚˜ë¼ë„ ë‹¤ë¥´ë©´ ì „í™˜ ì„±ê³µ)
            if min_len >= 2 and seq1[1] != seq2[1]:
                converted_within_3 = True
            elif min_len >= 3 and seq1[2] != seq2[2]:
                converted_within_3 = True
        else:
            # ì²« ë²ˆì§¸ê°€ ë‹¤ë¥¼ ë•Œ â†’ ë‹¤ìŒì— ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ì°¾ê¸°
            same_pos = None
            for i in range(1, min_len):
                if seq1[i] == seq2[i]:  # ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜
                    same_pos = i + 1  # 1-based index
                    break
            analysis_results.setdefault('first_different_next_same_position', []).append(same_pos)
            
            # 3ë²ˆì§¸ê¹Œì§€ ì „í™˜ ì—¬ë¶€ í™•ì¸ (2, 3ë²ˆì§¸ ì¤‘ í•˜ë‚˜ë¼ë„ ê°™ìœ¼ë©´ ì „í™˜ ì„±ê³µ)
            if min_len >= 2 and seq1[1] == seq2[1]:
                converted_within_3 = True
            elif min_len >= 3 and seq1[2] == seq2[2]:
                converted_within_3 = True
        
        # ì„¸ì…˜ë³„ 3ë²ˆì§¸ê¹Œì§€ ì „í™˜ ì—¬ë¶€ ì €ì¥ (ìˆœì„œ ìœ ì§€)
        # ìµœëŒ€ì—°ì†ì‹¤íŒ¨ ë¶„ì„ì—ëŠ” ê¸¸ì´ 3 ì´ìƒì¸ ê²ƒë§Œ í¬í•¨
        if min_len >= 3:
            analysis_results.setdefault('converted_within_3_by_session', []).append(converted_within_3)
        else:
            # ê¸¸ì´ 3 ë¯¸ë§Œì¸ ê²½ìš° ìµœëŒ€ì—°ì†ì‹¤íŒ¨ ë¶„ì„ì—ì„œ ì œì™¸ (ì „í™˜ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ)
            # ì¦‰, ì´ ê²½ìš°ëŠ” ìµœëŒ€ì—°ì†ì‹¤íŒ¨ ë¶„ì„ì— í¬í•¨ë˜ì§€ ì•ŠìŒ
            pass
        
        # ì„¸ì…˜ ì •ë³´ ì €ì¥ (ìˆœì„œ ìœ ì§€) - ìƒì„±ì‹œê°„ í¬í•¨, ê¸¸ì´ ì •ë³´ë„ ì €ì¥
        session_info_list.append({
            'id': row.get('id'),
            'session_id': row.get('session_id'),
            'created_at': row.get('created_at'),
            'sequence_prediction_results': seq1,
            'reconstructed_sequence_prediction_results': seq2,
            'converted_within_3': converted_within_3,
            'min_len': min_len  # ê¸¸ì´ ì •ë³´ ì €ì¥
        })
    
    # ì„¸ì…˜ ì •ë³´ë¥¼ ë¶„ì„ ê²°ê³¼ì— ì €ì¥
    analysis_results['session_info_list'] = session_info_list
    
    return analysis_results, valid_comparisons

def calculate_statistics(analysis_results, valid_comparisons):
    """ë¶„ì„ ê²°ê³¼ë¡œë¶€í„° í†µê³„ ê³„ì‚°"""
    stats = {}
    
    # 1. ì²« ë²ˆì§¸ë¡œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ í†µê³„
    first_match_positions = [pos for pos in analysis_results['first_match_position'] if pos is not None]
    if first_match_positions:
        stats['first_match'] = {
            'mean': sum(first_match_positions) / len(first_match_positions),
            'min': min(first_match_positions),
            'max': max(first_match_positions),
            'distribution': {i: first_match_positions.count(i) for i in range(1, max(first_match_positions) + 1) if i in first_match_positions}
        }
    else:
        stats['first_match'] = None
    
    # 2. ìµœëŒ€ ëª‡ ë²ˆì§¸ ìœ„ì¹˜ê¹Œì§€ ê°™ì€ ë¬¸ìê°€ ë‚˜ì™”ëŠ”ì§€
    max_match_positions = analysis_results['max_match_position']
    if max_match_positions:
        stats['max_match'] = {
            'mean': sum(max_match_positions) / len(max_match_positions),
            'min': min(max_match_positions),
            'max': max(max_match_positions),
            'distribution': {i: max_match_positions.count(i) for i in range(1, max(max_match_positions) + 1) if i in max_match_positions}
        }
    else:
        stats['max_match'] = None
    
    # 3. ìœ„ì¹˜ë³„ë¡œ ê°™ì€ ë¬¸ìì¸ì§€ ë¹„ìœ¨
    stats['position_match_rate'] = {}
    for pos in [1, 2, 3]:
        matches = analysis_results['position_match'][pos]
        if matches:
            match_count = sum(matches)
            total_count = len(matches)
            stats['position_match_rate'][pos] = {
                'match_count': match_count,
                'total_count': total_count,
                'rate': (match_count / total_count * 100) if total_count > 0 else 0
            }
        else:
            stats['position_match_rate'][pos] = None
    
    # 4. ì²« ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš°, ëª‡ ë²ˆì§¸ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
    first_different_matches = [pos for pos in analysis_results['first_different_match_position'] if pos is not None]
    if first_different_matches:
        stats['first_different_match'] = {
            'mean': sum(first_different_matches) / len(first_different_matches),
            'min': min(first_different_matches),
            'max': max(first_different_matches),
            'distribution': {i: first_different_matches.count(i) for i in range(1, max(first_different_matches) + 1) if i in first_different_matches},
            'no_match_count': analysis_results['first_different_match_position'].count(None)
        }
    else:
        stats['first_different_match'] = {
            'no_match_count': len(analysis_results['first_different_match_position'])
        }
    
    stats['valid_comparisons'] = valid_comparisons
    
    return stats

def analyze_max_position_strategy(stats, analysis_results):
    """
    ìµœëŒ€ ìœ„ì¹˜ ë¶„ì„ì„ í†µí•œ ì „ëµ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
    """
    insights = {
        'strategy_type': None,  # 'same' or 'different'
        'confidence_level': None,  # 'high', 'medium', 'low'
        'recommended_approach': [],
        'risk_assessment': [],
        'detailed_analysis': {}
    }
    
    if not stats['max_match'] or not stats['position_match_rate']:
        return insights
    
    max_match_stats = stats['max_match']
    position_rates = stats['position_match_rate']
    
    # í‰ê·  ìµœëŒ€ ìœ„ì¹˜
    avg_max_pos = max_match_stats['mean']
    max_max_pos = max_match_stats['max']
    
    # ìœ„ì¹˜ë³„ ì¼ì¹˜ìœ¨
    pos1_rate = position_rates[1]['rate'] if position_rates[1] else 0
    pos2_rate = position_rates[2]['rate'] if position_rates[2] else 0
    pos3_rate = position_rates[3]['rate'] if position_rates[3] else 0
    
    # ìµœëŒ€ ìœ„ì¹˜ ë¶„í¬ ë¶„ì„
    max_pos_distribution = max_match_stats.get('distribution', {})
    pos3_count = max_pos_distribution.get(3, 0)
    pos2_count = max_pos_distribution.get(2, 0)
    pos1_count = max_pos_distribution.get(1, 0)
    pos0_count = max_pos_distribution.get(0, 0) if 0 in max_pos_distribution else 0
    total_count = len(analysis_results['max_match_position'])
    
    # ìƒì„¸ ë¶„ì„ ì €ì¥
    insights['detailed_analysis'] = {
        'avg_max_position': avg_max_pos,
        'max_max_position': max_max_pos,
        'position_rates': {
            1: pos1_rate,
            2: pos2_rate,
            3: pos3_rate
        },
        'max_position_distribution': max_pos_distribution,
        'pos3_ratio': (pos3_count / total_count * 100) if total_count > 0 else 0,
        'pos2_or_below_ratio': ((pos2_count + pos1_count + pos0_count) / total_count * 100) if total_count > 0 else 0
    }
    
    # ì „ëµ ê²°ì • ë¡œì§
    # 1. ìµœëŒ€ ìœ„ì¹˜ê°€ 3ì¼ ë•Œì˜ ì˜ë¯¸ ë¶„ì„
    if max_max_pos == 3:
        pos3_ratio = (pos3_count / total_count * 100) if total_count > 0 else 0
        
        # ìµœëŒ€ ìœ„ì¹˜ê°€ 3ì¸ ê²½ìš°ê°€ ë§ê³ , ìœ„ì¹˜ë³„ ì¼ì¹˜ìœ¨ì´ ë†’ìœ¼ë©´ -> ê°™ì€ ë¬¸ì ì „ëµ
        if pos3_ratio >= 30 and pos1_rate >= 50:
            insights['strategy_type'] = 'same'
            insights['confidence_level'] = 'high' if pos3_ratio >= 50 else 'medium'
            insights['recommended_approach'].append(
                f"âœ… **ê°™ì€ ë¬¸ì ì ‘ê·¼ ì „ëµ ì¶”ì²œ**: ìµœëŒ€ ìœ„ì¹˜ 3ì¸ ê²½ìš°ê°€ {pos3_ratio:.1f}%ë¡œ ë†’ê³ , "
                f"1ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨ì´ {pos1_rate:.1f}%ì…ë‹ˆë‹¤. ì²˜ìŒë¶€í„° ê°™ì€ ë¬¸ìë¡œ ì˜ˆì¸¡í•˜ëŠ” ì „ëµì´ ìœ íš¨í•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
            )
        # ìµœëŒ€ ìœ„ì¹˜ê°€ 3ì´ì§€ë§Œ ì „ì²´ì ìœ¼ë¡œ ì¼ì¹˜ìœ¨ì´ ë‚®ìœ¼ë©´ -> ì£¼ì˜ í•„ìš”
        elif pos3_ratio < 30 or pos1_rate < 50:
            insights['strategy_type'] = 'mixed'
            insights['confidence_level'] = 'medium' if pos1_rate >= 40 else 'low'
            insights['recommended_approach'].append(
                f"âš ï¸ **í˜¼í•© ì „ëµ ê¶Œì¥**: ìµœëŒ€ ìœ„ì¹˜ê°€ 3ì´ì§€ë§Œ ì „ì²´ ì¼ì¹˜ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. "
                f"1ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨ {pos1_rate:.1f}%, ìµœëŒ€ ìœ„ì¹˜ 3ì¸ ê²½ìš° {pos3_ratio:.1f}%. "
                f"ë³´ìˆ˜ì ì¸ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
    
    # 2. í‰ê·  ìµœëŒ€ ìœ„ì¹˜ ë¶„ì„
    if avg_max_pos >= 2.5:
        insights['recommended_approach'].append(
            f"ğŸ’¡ í‰ê·  ìµœëŒ€ ìœ„ì¹˜ê°€ {avg_max_pos:.2f}ë¡œ ë†’ìŠµë‹ˆë‹¤. ì²˜ìŒ 2-3ê°œ ì˜ˆì¸¡ì— ì‹ ë¢°ë¥¼ ë‘˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        if insights['strategy_type'] is None:
            insights['strategy_type'] = 'same'
            insights['confidence_level'] = 'high'
    elif avg_max_pos >= 1.5:
        insights['recommended_approach'].append(
            f"ğŸ“Š í‰ê·  ìµœëŒ€ ìœ„ì¹˜ê°€ {avg_max_pos:.2f}ì…ë‹ˆë‹¤. ì²« 1-2ê°œ ì˜ˆì¸¡ì—ë§Œ ì‹ ë¢°ë¥¼ ë‘ê³  ì´í›„ëŠ” ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤."
        )
    else:
        insights['recommended_approach'].append(
            f"âš ï¸ í‰ê·  ìµœëŒ€ ìœ„ì¹˜ê°€ {avg_max_pos:.2f}ë¡œ ë‚®ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        if insights['strategy_type'] is None:
            insights['strategy_type'] = 'different'
            insights['confidence_level'] = 'low'
    
    # 3. ìœ„ì¹˜ë³„ ì¼ì¹˜ìœ¨ ì¢…í•© ë¶„ì„
    avg_position_rate = (pos1_rate + pos2_rate + pos3_rate) / 3
    if avg_position_rate >= 60:
        insights['recommended_approach'].append(
            f"ğŸ¯ ì „ì²´ í‰ê·  ì¼ì¹˜ìœ¨ì´ {avg_position_rate:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ê°™ì€ ë¬¸ì ì ‘ê·¼ ì „ëµì´ ìœ íš¨í•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
        )
    elif avg_position_rate >= 40:
        insights['recommended_approach'].append(
            f"ğŸ“ˆ ì „ì²´ í‰ê·  ì¼ì¹˜ìœ¨ì´ {avg_position_rate:.1f}%ì…ë‹ˆë‹¤. ì¡°ê±´ë¶€ë¡œ ê°™ì€ ë¬¸ì ì ‘ê·¼ì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
    else:
        insights['recommended_approach'].append(
            f"âš ï¸ ì „ì²´ í‰ê·  ì¼ì¹˜ìœ¨ì´ {avg_position_rate:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë¬¸ì ì ‘ê·¼ì„ ê³ ë ¤í•˜ê±°ë‚˜ ë§¤ìš° ë³´ìˆ˜ì ì¸ ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤."
        )
    
    # 4. ë¦¬ìŠ¤í¬ í‰ê°€
    if pos1_rate < 50:
        insights['risk_assessment'].append(
            f"ğŸ”´ **ê³ ìœ„í—˜**: 1ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨ì´ {pos1_rate:.1f}%ë¡œ 50% ë¯¸ë§Œì…ë‹ˆë‹¤. ì²« ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤."
        )
    elif pos1_rate < 60:
        insights['risk_assessment'].append(
            f"ğŸŸ¡ **ì¤‘ìœ„í—˜**: 1ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨ì´ {pos1_rate:.1f}%ì…ë‹ˆë‹¤. ì²« ì˜ˆì¸¡ì— ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        )
    else:
        insights['risk_assessment'].append(
            f"ğŸŸ¢ **ì €ìœ„í—˜**: 1ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨ì´ {pos1_rate:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì²« ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë†’ìŠµë‹ˆë‹¤."
        )
    
    # ìµœëŒ€ ìœ„ì¹˜ 3ì¸ ê²½ìš°ì˜ íŠ¹ë³„ ë¶„ì„
    if max_max_pos == 3:
        pos2_or_below = pos2_count + pos1_count + pos0_count
        pos2_or_below_ratio = (pos2_or_below / total_count * 100) if total_count > 0 else 0
        
        if pos2_or_below_ratio > 50:
            insights['recommended_approach'].append(
                f"âš ï¸ ìµœëŒ€ ìœ„ì¹˜ê°€ 2 ì´í•˜ì¸ ê²½ìš°ê°€ {pos2_or_below_ratio:.1f}%ë¡œ ë§ìŠµë‹ˆë‹¤. "
                f"ìµœëŒ€ ìœ„ì¹˜ 3ì´ë¼ê³  í•´ë„ ì‹¤ì œë¡œëŠ” 2ë²ˆì§¸ ìœ„ì¹˜ê¹Œì§€ë§Œ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ, "
                f"3ë²ˆì§¸ ìœ„ì¹˜ ì´í›„ì˜ ì˜ˆì¸¡ì€ ì‹ ë¢°í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
            )
        else:
            insights['recommended_approach'].append(
                f"âœ… ìµœëŒ€ ìœ„ì¹˜ê°€ 3ì¸ ê²½ìš°ê°€ {pos3_ratio:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤. "
                f"ì²˜ìŒ 3ê°œ ìœ„ì¹˜ê¹Œì§€ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ, 3ë²ˆì§¸ ìœ„ì¹˜ê¹Œì§€ëŠ” ê°™ì€ ë¬¸ì ì „ëµì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
    
    return insights

def analyze_cross_pattern_strategy(analysis_results, stats, df_filtered=None):
    """
    êµì°¨ íŒ¨í„´ ì „ëµ ë¶„ì„
    ì „ëµ: ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³ , ê°™ìœ¼ë©´ ë‹¤ìŒì€ ë‹¤ë¥¼ ê²ƒìœ¼ë¡œ, ë‹¤ë¥´ë©´ ë‹¤ìŒì€ ê°™ì„ ê²ƒìœ¼ë¡œ ì ‘ê·¼
    ìœ„ì¹˜ ì •ë³´ë¥¼ í¬í•¨í•œ ìƒì„¸ ë¶„ì„
    """
    strategy_analysis = {
        'strategy_name': 'êµì°¨ íŒ¨í„´ ì „ëµ',
        'description': 'ì²« ë²ˆì§¸ ê²°ê³¼ê°€ ê°™ìœ¼ë©´ â†’ ë‹¤ìŒì— ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜\nì²« ë²ˆì§¸ ê²°ê³¼ê°€ ë‹¤ë¥´ë©´ â†’ ë‹¤ìŒì— ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜',
        'first_same_next_different': None,  # ì²« ë²ˆì§¸ê°€ ê°™ì„ ë•Œ ë‹¤ìŒì— ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ë¶„ì„
        'first_different_next_same': None,  # ì²« ë²ˆì§¸ê°€ ë‹¤ë¥¼ ë•Œ ë‹¤ìŒì— ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ë¶„ì„
        'recommendation': None,
        'comparison_with_same_strategy': None
    }
    
    # ì²« ë²ˆì§¸ê°€ ê°™ì„ ë•Œ â†’ ë‹¤ìŒì— ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ë¶„ì„
    first_same_positions = [pos for pos in analysis_results.get('first_same_next_different_position', []) if pos is not None]
    if first_same_positions:
        total_count = len(analysis_results.get('first_same_next_different_position', []))
        no_change_count = analysis_results.get('first_same_next_different_position', []).count(None)
        
        strategy_analysis['first_same_next_different'] = {
            'total_count': total_count,
            'found_count': len(first_same_positions),
            'no_change_count': no_change_count,
            'no_change_rate': (no_change_count / total_count * 100) if total_count > 0 else 0,
            'mean_position': sum(first_same_positions) / len(first_same_positions) if first_same_positions else None,
            'min_position': min(first_same_positions) if first_same_positions else None,
            'max_position': max(first_same_positions) if first_same_positions else None,
            'distribution': {i: first_same_positions.count(i) for i in sorted(set(first_same_positions))}
        }
    else:
        first_same_all = analysis_results.get('first_same_next_different_position', [])
        if first_same_all:
            strategy_analysis['first_same_next_different'] = {
                'total_count': len(first_same_all),
                'found_count': 0,
                'no_change_count': first_same_all.count(None),
                'no_change_rate': 100.0,
                'mean_position': None,
                'min_position': None,
                'max_position': None,
                'distribution': {}
            }
    
    # ì²« ë²ˆì§¸ê°€ ë‹¤ë¥¼ ë•Œ â†’ ë‹¤ìŒì— ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ë¶„ì„
    first_different_positions = [pos for pos in analysis_results.get('first_different_next_same_position', []) if pos is not None]
    if first_different_positions:
        total_count = len(analysis_results.get('first_different_next_same_position', []))
        no_change_count = analysis_results.get('first_different_next_same_position', []).count(None)
        
        strategy_analysis['first_different_next_same'] = {
            'total_count': total_count,
            'found_count': len(first_different_positions),
            'no_change_count': no_change_count,
            'no_change_rate': (no_change_count / total_count * 100) if total_count > 0 else 0,
            'mean_position': sum(first_different_positions) / len(first_different_positions) if first_different_positions else None,
            'min_position': min(first_different_positions) if first_different_positions else None,
            'max_position': max(first_different_positions) if first_different_positions else None,
            'distribution': {i: first_different_positions.count(i) for i in sorted(set(first_different_positions))}
        }
    else:
        first_different_all = analysis_results.get('first_different_next_same_position', [])
        if first_different_all:
            strategy_analysis['first_different_next_same'] = {
                'total_count': len(first_different_all),
                'found_count': 0,
                'no_change_count': first_different_all.count(None),
                'no_change_rate': 100.0,
                'mean_position': None,
                'min_position': None,
                'max_position': None,
                'distribution': {}
            }
    
    # ì¶”ì²œ í‰ê°€
    recommendations = []
    
    if strategy_analysis['first_same_next_different']:
        data = strategy_analysis['first_same_next_different']
        if data['mean_position']:
            recommendations.append(
                f"âœ… **ì²« ë²ˆì§¸ê°€ ê°™ì„ ë•Œ**: í‰ê·  {data['mean_position']:.1f}ë²ˆì§¸ ìœ„ì¹˜ì—ì„œ ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜µë‹ˆë‹¤. "
                f"(ì´ {data['found_count']}ê±´ ì¤‘ í‰ê·  ìœ„ì¹˜ {data['mean_position']:.1f})"
            )
            if data['mean_position'] <= 2:
                recommendations.append(
                    f"ğŸ’¡ ì²« ë²ˆì§¸ê°€ ê°™ìœ¼ë©´, 2ë²ˆì§¸ ìœ„ì¹˜ì—ì„œ ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ë¹ ë¥´ê²Œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
        if data['no_change_rate'] > 50:
            recommendations.append(
                f"âš ï¸ ì²« ë²ˆì§¸ê°€ ê°™ì„ ë•Œ íŒ¨í„´ì´ ë°”ë€Œì§€ ì•ŠëŠ” ê²½ìš°ê°€ {data['no_change_rate']:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤."
            )
    
    if strategy_analysis['first_different_next_same']:
        data = strategy_analysis['first_different_next_same']
        if data['mean_position']:
            recommendations.append(
                f"âœ… **ì²« ë²ˆì§¸ê°€ ë‹¤ë¥¼ ë•Œ**: í‰ê·  {data['mean_position']:.1f}ë²ˆì§¸ ìœ„ì¹˜ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜µë‹ˆë‹¤. "
                f"(ì´ {data['found_count']}ê±´ ì¤‘ í‰ê·  ìœ„ì¹˜ {data['mean_position']:.1f})"
            )
            if data['mean_position'] <= 2:
                recommendations.append(
                    f"ğŸ’¡ ì²« ë²ˆì§¸ê°€ ë‹¤ë¥´ë©´, 2ë²ˆì§¸ ìœ„ì¹˜ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ë¹ ë¥´ê²Œ ì¼ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
        if data['no_change_rate'] > 50:
            recommendations.append(
                f"âš ï¸ ì²« ë²ˆì§¸ê°€ ë‹¤ë¥¼ ë•Œ íŒ¨í„´ì´ ë°”ë€Œì§€ ì•ŠëŠ” ê²½ìš°ê°€ {data['no_change_rate']:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤."
            )
    
    if recommendations:
        strategy_analysis['recommendation'] = {
            'level': 'medium',
            'messages': recommendations,
            'confidence': 'ì¤‘ê°„'
        }
    
    # 3ë²ˆì§¸ê¹Œì§€ ì „í™˜ë˜ì§€ ì•ŠëŠ” ì—°ì† ì„¸ì…˜ ë¶„ì„
    # ëª¨ë“  ì„¸ì…˜ì˜ 3ë²ˆì§¸ê¹Œì§€ ì „í™˜ ì—¬ë¶€ í™•ì¸ (ìˆœì„œ ìœ ì§€)
    all_converted_within_3 = analysis_results.get('converted_within_3_by_session', [])
    
    if all_converted_within_3:
        # ì—°ì† ì‹¤íŒ¨ ì¶”ì 
        max_consecutive_failures = 0
        current_consecutive_failures = 0
        consecutive_failure_sequences = []
        current_sequence = 0
        
        for converted in all_converted_within_3:
            if not converted:  # ì „í™˜ ì‹¤íŒ¨
                current_consecutive_failures += 1
                current_sequence += 1
            else:  # ì „í™˜ ì„±ê³µ
                if current_consecutive_failures > 0:
                    consecutive_failure_sequences.append(current_consecutive_failures)
                max_consecutive_failures = max(max_consecutive_failures, current_consecutive_failures)
                current_consecutive_failures = 0
                current_sequence = 0
        
        # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ì¶”ê°€
        if current_consecutive_failures > 0:
            consecutive_failure_sequences.append(current_consecutive_failures)
            max_consecutive_failures = max(max_consecutive_failures, current_consecutive_failures)
        
        # í†µê³„ ê³„ì‚°
        total_failures = sum([1 for x in all_converted_within_3 if not x])
        total_successes = sum([1 for x in all_converted_within_3 if x])
        total_count = len(all_converted_within_3)
        success_rate = (total_successes / total_count * 100) if total_count > 0 else 0
        
        avg_consecutive_failures = (sum(consecutive_failure_sequences) / len(consecutive_failure_sequences)) if consecutive_failure_sequences else 0
        
        # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ì„¸ì…˜ ì°¾ê¸° (max_consecutive_failures ê³„ì‚° í›„)
        # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ ì—¬ëŸ¬ê°œì¸ ê²½ìš°, ê°€ì¥ ìµœê·¼ ê²ƒë§Œ í‘œì‹œ
        # ë°ì´í„°ëŠ” ORDER BY created_at DESCë¡œ ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¸ë±ìŠ¤ 0ì´ ê°€ì¥ ìµœì‹ 
        max_consecutive_failure_sessions = []
        session_info_list = analysis_results.get('session_info_list', [])
        
        # ê¸¸ì´ 3 ì´ìƒì¸ ì„¸ì…˜ë§Œ í•„í„°ë§ (ìµœëŒ€ì—°ì†ì‹¤íŒ¨ ë¶„ì„ìš©)
        # all_converted_within_3ì™€ ì¸ë±ìŠ¤ê°€ ì¼ì¹˜í•˜ë„ë¡ ê¸¸ì´ 3 ì´ìƒì¸ ê²ƒë§Œ ì¶”ì¶œ
        valid_session_info_list = [s for s in session_info_list if s.get('min_len', 0) >= 3]
        
        # all_converted_within_3ì™€ valid_session_info_listëŠ” ì¸ë±ìŠ¤ê°€ ì¼ì¹˜í•´ì•¼ í•¨
        if len(valid_session_info_list) == len(all_converted_within_3) and valid_session_info_list and all_converted_within_3 and max_consecutive_failures > 0:
            # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ ë°œìƒí•œ ìœ„ì¹˜ ì°¾ê¸° (ê°€ì¥ ìµœê·¼ ê²ƒë¶€í„° ì°¾ê¸°)
            # ë°ì´í„°ê°€ ORDER BY created_at DESCë¡œ ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ
            # ì¸ë±ìŠ¤ 0ì´ ê°€ì¥ ìµœì‹ ì´ê³ , ë’¤ë¡œ ê°ˆìˆ˜ë¡ ì˜¤ë˜ëœ ë°ì´í„°
            # ê°€ì¥ ìµœê·¼ ë°œìƒí•œ ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ë¥¼ ì°¾ê¸° ìœ„í•´ ì•ì—ì„œë¶€í„° ìˆœíšŒí•˜ë©´ì„œ ì²« ë²ˆì§¸ ë°œê²¬ ì‹œì  ì €ì¥
            max_start_idx = -1
            max_end_idx = -1
            current_failures = 0
            current_start_idx = -1
            
            for idx, converted in enumerate(all_converted_within_3):
                if not converted:  # ì „í™˜ ì‹¤íŒ¨
                    if current_failures == 0:
                        current_start_idx = idx
                    current_failures += 1
                    
                    # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ë¥¼ ë°œê²¬í•œ ê²½ìš° (ê°€ì¥ ìµœê·¼ ê²ƒ, ì¦‰ ì²« ë²ˆì§¸ ë°œê²¬ë§Œ ì €ì¥)
                    if current_failures == max_consecutive_failures and max_start_idx == -1:
                        max_start_idx = current_start_idx
                        max_end_idx = idx
                        # ê°€ì¥ ìµœê·¼ ê²ƒì„ ì°¾ì•˜ìœ¼ë¯€ë¡œ ë” ì´ìƒ ê°±ì‹ í•˜ì§€ ì•ŠìŒ
                else:  # ì „í™˜ ì„±ê³µ
                    current_failures = 0
                    current_start_idx = -1
            
            # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ì„¸ì…˜ ì •ë³´ ì¶”ì¶œ (ê¸¸ì´ 3 ì´ìƒì¸ ì„¸ì…˜ë§Œ)
            # ì¸ë±ìŠ¤ê°€ ì¼ì¹˜í•˜ë¯€ë¡œ valid_session_info_listì—ì„œ ì§ì ‘ ì¶”ì¶œ
            if max_start_idx >= 0 and max_end_idx >= max_start_idx:
                for idx in range(max_start_idx, max_end_idx + 1):
                    if idx < len(valid_session_info_list):
                        max_consecutive_failure_sessions.append(valid_session_info_list[idx])
        
        strategy_analysis['conversion_within_3_analysis'] = {
            'total_sessions': total_count,
            'success_count': total_successes,
            'failure_count': total_failures,
            'success_rate': success_rate,
            'max_consecutive_failures': max_consecutive_failures,
            'avg_consecutive_failures': avg_consecutive_failures,
            'consecutive_failure_sequences': consecutive_failure_sequences,
            'failure_distribution': {i: consecutive_failure_sequences.count(i) for i in sorted(set(consecutive_failure_sequences))} if consecutive_failure_sequences else {},
            'max_consecutive_failure_sessions': max_consecutive_failure_sessions  # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ì„¸ì…˜ ì •ë³´
        }
    
    return strategy_analysis

def analyze_next_session_match_strategy(analysis_results):
    """
    ìƒˆë¡œìš´ ì „ëµ ë¶„ì„: ë‹¨ì¼ ì„¸ì…˜ ë‚´ì—ì„œ ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¨ ê²½ìš° ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸
    1. ì²«ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš° â†’ ê·¸ ì„¸ì…˜ ë‚´ì—ì„œ ë‹¤ìŒ ìœ„ì¹˜(ë‘ë²ˆì§¸, ì„¸ë²ˆì§¸ ë“±)ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
    2. ì²«ë²ˆì§¸ê°€ ê°™ê³  ë‘ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš° â†’ ê·¸ ì„¸ì…˜ ë‚´ì—ì„œ ë‹¤ìŒ ìœ„ì¹˜(ì„¸ë²ˆì§¸ ë“±)ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
    """
    strategy_analysis = {
        'strategy_name': 'ë‹¤ìŒ ìœ„ì¹˜ ì¼ì¹˜ ì „ëµ',
        'description': 'ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¨ ê²½ìš° ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¬ ê²ƒìœ¼ë¡œ ì˜ˆìƒ',
        'first_different_next_match': None,  # ì²«ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš°
        'first_same_second_different_next_match': None,  # ì²«ë²ˆì§¸ê°€ ê°™ê³  ë‘ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš°
    }
    
    session_info_list = analysis_results.get('session_info_list', [])
    
    if not session_info_list:
        return strategy_analysis
    
    # 1. ì²«ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš° â†’ ê·¸ ì„¸ì…˜ ë‚´ì—ì„œ ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
    first_different_cases = []
    
    # 2. ì²«ë²ˆì§¸ê°€ ê°™ê³  ë‘ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš° â†’ ê·¸ ì„¸ì…˜ ë‚´ì—ì„œ ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
    first_same_second_different_cases = []
    
    # ê° ì„¸ì…˜ ë‚´ì—ì„œ íŒ¨í„´ ë¶„ì„
    for session_info in session_info_list:
        seq1 = session_info.get('sequence_prediction_results', '')
        seq2 = session_info.get('reconstructed_sequence_prediction_results', '')
        
        if not seq1 or not seq2:
            continue
        
        min_len = min(len(seq1), len(seq2))
        if min_len < 2:
            continue
        
        # 1. ì²«ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš°
        if seq1[0] != seq2[0]:
            # ì²«ë²ˆì§¸ê°€ ë‹¤ë¥¸ ìƒíƒœì—ì„œ, ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ì°¾ê¸°
            # ì˜ˆ: WWLWWLLW vs LWWLWWLW
            # - ì²«ë²ˆì§¸: W != L (ë‹¤ë¦„)
            # - ë‘ë²ˆì§¸: W == W (ê°™ìŒ) â†’ ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ = 2
            # - ìµœëŒ€ ìœ„ì¹˜ = 2 (ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜)
            next_match_position = None
            next_match_found = False
            for i in range(1, min_len):
                if seq1[i] == seq2[i]:
                    next_match_found = True
                    next_match_position = i + 1  # 1-based index (ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜)
                    break
            
            # ìµœëŒ€ ìœ„ì¹˜ = ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜
            max_match_pos = next_match_position if next_match_position is not None else 0
            
            first_different_cases.append({
                'session': session_info,
                'next_match_found': next_match_found,
                'next_match_position': next_match_position,
                'max_position': max_match_pos,  # ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜
                'current_pattern': 'ì²«ë²ˆì§¸ ë‹¤ë¦„'
            })
        
        # 2. ì²«ë²ˆì§¸ê°€ ê°™ê³  ë‘ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš°
        elif min_len >= 2 and seq1[0] == seq2[0] and seq1[1] != seq2[1]:
            # ì²«ë²ˆì§¸ê°€ ê°™ê³  ë‘ë²ˆì§¸ê°€ ë‹¤ë¥¸ ìƒíƒœì—ì„œ, ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ì°¾ê¸°
            # ì˜ˆ: WLLLL vs WWWWL
            # - ì²«ë²ˆì§¸: W == W (ê°™ìŒ)
            # - ë‘ë²ˆì§¸: L != W (ë‹¤ë¦„)
            # - ì„¸ë²ˆì§¸: L != W (ë‹¤ë¦„)
            # - ë„¤ë²ˆì§¸: L != W (ë‹¤ë¦„)
            # - ë‹¤ì„¯ë²ˆì§¸: L == L (ê°™ìŒ) â†’ ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ = 5
            # - ìµœëŒ€ ìœ„ì¹˜ = 5 (ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜)
            next_match_position = None
            next_match_found = False
            for i in range(2, min_len):  # ì„¸ë²ˆì§¸ ìœ„ì¹˜ë¶€í„° í™•ì¸
                if seq1[i] == seq2[i]:
                    next_match_found = True
                    next_match_position = i + 1  # 1-based index (ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜)
                    break
            
            # ìµœëŒ€ ìœ„ì¹˜ = ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜
            max_match_pos = next_match_position if next_match_position is not None else 0
            
            first_same_second_different_cases.append({
                'session': session_info,
                'next_match_found': next_match_found,
                'next_match_position': next_match_position,
                'max_position': max_match_pos,  # ë‹¤ìŒ ê°™ì€ ë¬¸ìê°€ ì²˜ìŒ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜
                'current_pattern': 'ì²«ë²ˆì§¸ ê°™ìŒ, ë‘ë²ˆì§¸ ë‹¤ë¦„'
            })
    
    # 1. ì²«ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš° ë¶„ì„
    if first_different_cases:
        # ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ í†µê³„ ê³„ì‚°
        next_match_positions = [case['next_match_position'] for case in first_different_cases if case['next_match_found']]
        no_match_count = len([case for case in first_different_cases if not case['next_match_found']])
        
        # í†µê³„ ê³„ì‚°
        avg_position = sum(next_match_positions) / len(next_match_positions) if next_match_positions else 0
        min_position = min(next_match_positions) if next_match_positions else None
        max_position = max([case['max_position'] for case in first_different_cases], default=0)
        
        # ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ ë¶„í¬ ê³„ì‚°
        position_distribution = {}
        for pos in next_match_positions:
            position_distribution[pos] = position_distribution.get(pos, 0) + 1
        
        # ì¤‘ì•™ê°’ ê³„ì‚°
        sorted_positions = sorted(next_match_positions) if next_match_positions else []
        median_position = sorted_positions[len(sorted_positions) // 2] if sorted_positions else None
        
        # ìµœì‹  ìµœëŒ€ ìœ„ì¹˜ ì„¸ì…˜ ì°¾ê¸° (ë°ì´í„°ëŠ” ìµœì‹ ìˆœì´ë¯€ë¡œ ì²« ë²ˆì§¸ê°€ ìµœì‹ )
        max_position_case = None
        for case in first_different_cases:
            if case['max_position'] == max_position:
                max_position_case = case
                break  # ì²« ë²ˆì§¸ê°€ ìµœì‹ ì´ë¯€ë¡œ ë°”ë¡œ ì°¾ìœ¼ë©´ ì¤‘ë‹¨
        
        strategy_analysis['first_different_next_match'] = {
            'total_cases': len(first_different_cases),
            'max_position': max_position,  # ìµœëŒ€ ìœ„ì¹˜
            'avg_position': avg_position,  # í‰ê·  ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜
            'min_position': min_position,  # ìµœì†Œ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜
            'median_position': median_position,  # ì¤‘ì•™ê°’ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜
            'no_match_count': no_match_count,  # ë‹¤ìŒ ì¼ì¹˜ê°€ ì—†ëŠ” ì¼€ì´ìŠ¤ ìˆ˜
            'position_distribution': position_distribution,  # ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ ë¶„í¬
            'max_position_case': max_position_case,  # ìµœì‹  ìµœëŒ€ ìœ„ì¹˜ ì„¸ì…˜
            'cases': first_different_cases
        }
    
    # 2. ì²«ë²ˆì§¸ê°€ ê°™ê³  ë‘ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš° ë¶„ì„
    if first_same_second_different_cases:
        # ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ í†µê³„ ê³„ì‚°
        next_match_positions = [case['next_match_position'] for case in first_same_second_different_cases if case['next_match_found']]
        no_match_count = len([case for case in first_same_second_different_cases if not case['next_match_found']])
        
        # í†µê³„ ê³„ì‚°
        avg_position = sum(next_match_positions) / len(next_match_positions) if next_match_positions else 0
        min_position = min(next_match_positions) if next_match_positions else None
        max_position = max([case['max_position'] for case in first_same_second_different_cases], default=0)
        
        # ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ ë¶„í¬ ê³„ì‚°
        position_distribution = {}
        for pos in next_match_positions:
            position_distribution[pos] = position_distribution.get(pos, 0) + 1
        
        # ì¤‘ì•™ê°’ ê³„ì‚°
        sorted_positions = sorted(next_match_positions) if next_match_positions else []
        median_position = sorted_positions[len(sorted_positions) // 2] if sorted_positions else None
        
        # ìµœì‹  ìµœëŒ€ ìœ„ì¹˜ ì„¸ì…˜ ì°¾ê¸° (ë°ì´í„°ëŠ” ìµœì‹ ìˆœì´ë¯€ë¡œ ì²« ë²ˆì§¸ê°€ ìµœì‹ )
        max_position_case = None
        for case in first_same_second_different_cases:
            if case['max_position'] == max_position:
                max_position_case = case
                break  # ì²« ë²ˆì§¸ê°€ ìµœì‹ ì´ë¯€ë¡œ ë°”ë¡œ ì°¾ìœ¼ë©´ ì¤‘ë‹¨
        
        strategy_analysis['first_same_second_different_next_match'] = {
            'total_cases': len(first_same_second_different_cases),
            'max_position': max_position,  # ìµœëŒ€ ìœ„ì¹˜
            'avg_position': avg_position,  # í‰ê·  ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜
            'min_position': min_position,  # ìµœì†Œ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜
            'median_position': median_position,  # ì¤‘ì•™ê°’ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜
            'no_match_count': no_match_count,  # ë‹¤ìŒ ì¼ì¹˜ê°€ ì—†ëŠ” ì¼€ì´ìŠ¤ ìˆ˜
            'position_distribution': position_distribution,  # ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ ë¶„í¬
            'max_position_case': max_position_case,  # ìµœì‹  ìµœëŒ€ ìœ„ì¹˜ ì„¸ì…˜
            'cases': first_same_second_different_cases
        }
    
    return strategy_analysis

# ë©”ì¸ ì•±
def main():
    st.title("Game Outcome Summary V2 Viewer")
    st.markdown("---")
    
    # ë°ì´í„° ë¡œë“œ
    df_all = load_game_outcome_v2_data()
    
    if len(df_all) == 0:
        st.warning("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê²Œì„ í…Œì´ë¸” ëª©ë¡ ì •ì˜
    game_tables = {
        'K': ['K1', 'K2', 'K3', 'K5'],
        'C': ['C1', 'C2', 'C3'],
        'J': ['J1', 'J2', 'J3'],
        'T': ['T1', 'T2', 'T3'],
        'V': ['V1', 'V2'],
        'S': ['S1', 'S2', 'S3', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S15', 'S16', 'S17', 'S18']
    }
    
    # ëª¨ë“  ê²Œì„ í…Œì´ë¸” ëª©ë¡ ìˆ˜ì§‘
    all_table_names = []
    for tables in game_tables.values():
        all_table_names.extend(tables)
    
    # ê²Œì„ í…Œì´ë¸” ì²´í¬ë¦¬ìŠ¤íŠ¸ ì„¹ì…˜
    header_col1, header_col2 = st.columns([4, 1])
    with header_col1:
        st.markdown("### ğŸ® ê²Œì„ í…Œì´ë¸” ì²´í¬ë¦¬ìŠ¤íŠ¸")
        st.caption("ê²Œì„ì´ ì™„ë£Œëœ í…Œì´ë¸”ì€ ì²´í¬í•˜ì„¸ìš”.")
    with header_col2:
        st.markdown("<br>", unsafe_allow_html=True)  # ì •ë ¬ì„ ìœ„í•œ ê³µê°„
        if st.button("ğŸ”„ ë¦¬ì…‹", use_container_width=True, key="reset_checkboxes"):
            # ëª¨ë“  ì²´í¬ë°•ìŠ¤ í‚¤ë¥¼ Falseë¡œ ë¦¬ì…‹
            for table_name in all_table_names:
                checkbox_key = f"checkbox_{table_name}"
                st.session_state[checkbox_key] = False
            st.rerun()
    
    # ì²´í¬ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì ìš© (ì „ì—­) - ë” ì»´íŒ©íŠ¸í•˜ê²Œ
    st.markdown("""
        <style>
        .stCheckbox {
            margin-bottom: 0 !important;
            padding: 0 !important;
        }
        .stCheckbox label {
            padding-left: 0.5rem !important;
        }
        .stCheckbox label p {
            margin: 0 !important;
            font-size: 0.95em !important;
            line-height: 1.3 !important;
            white-space: nowrap !important;
        }
        .game-group-container {
            margin-bottom: 0.3rem !important;
        }
        .game-group-title {
            display: inline-block;
            margin-right: 0.5rem;
            font-size: 0.85em !important;
            font-weight: bold;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # ëª¨ë“  ê·¸ë£¹ì„ ìˆ˜í‰ìœ¼ë¡œ ë°°ì¹˜
    for group_name, tables in game_tables.items():
        # S ê·¸ë£¹ì€ 3ì¤„ë¡œ ë°°ì¹˜ (6, 6, 6ê°œì”©)
        if group_name == 'S':
            items_per_row = [6, 6, 6]
        else:
            # ë‹¤ë¥¸ ê·¸ë£¹ì€ í•œ ì¤„ì— ëª¨ë‘ ë°°ì¹˜
            items_per_row = [len(tables)]
        
        row_start = 0
        for row_idx, items_in_row in enumerate(items_per_row):
            if row_start >= len(tables):
                break
            
            row_tables = tables[row_start:row_start + items_in_row]
            cols = st.columns([0.8] + [1] * len(row_tables))
            
            # ì²« ë²ˆì§¸ í–‰ì—ë§Œ ê·¸ë£¹ ì œëª© í‘œì‹œ
            if row_idx == 0:
                with cols[0]:
                    st.markdown(f"<div class='game-group-title'>{group_name}:</div>", unsafe_allow_html=True)
            else:
                with cols[0]:
                    st.markdown("", unsafe_allow_html=True)  # ë¹ˆ ê³µê°„ (ì œëª© ìœ„ì¹˜)
            
            # ì•„ì´í…œë“¤ í‘œì‹œ
            for idx, table_name in enumerate(row_tables):
                with cols[idx + 1]:
                    checkbox_key = f"checkbox_{table_name}"
                    st.checkbox(
                        table_name,
                        value=st.session_state.get(checkbox_key, False),
                        key=checkbox_key
                    )
            
            row_start += items_in_row
    
    st.markdown("---")
    
    # ê²€ìƒ‰ ì„¹ì…˜
    st.markdown("### ğŸ” ê²€ìƒ‰")
    
    search_col1, search_col2 = st.columns([3, 1])
    
    with search_col1:
        search_term = st.text_input(
            "ê²€ìƒ‰ì–´ ì…ë ¥",
            placeholder="session_id, id ë“±ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
            key="search_input"
        )
    
    with search_col2:
        search_button = st.button("ê²€ìƒ‰", type="primary", use_container_width=True)
    
    # ê²€ìƒ‰ í•„í„°ë§
    if search_term:
        # ë¬¸ìì—´ ê²€ìƒ‰ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        search_term_lower = search_term.lower()
        
        # ëª¨ë“  ì»¬ëŸ¼ì—ì„œ ê²€ìƒ‰
        mask = pd.Series([False] * len(df_all))
        
        for col in df_all.columns:
            if df_all[col].dtype == 'object':  # ë¬¸ìì—´ ì»¬ëŸ¼ë§Œ ê²€ìƒ‰
                mask |= df_all[col].astype(str).str.lower().str.contains(search_term_lower, na=False)
            else:  # ìˆ«ì ì»¬ëŸ¼
                mask |= df_all[col].astype(str).str.contains(search_term_lower, na=False)
        
        df_filtered = df_all[mask].copy()
    else:
        df_filtered = df_all.copy()
    
    # í•„í„°ë§ í›„ì—ë„ ìµœì‹  ìˆœì„œ ìœ ì§€ (created_at DESC)
    df_filtered = df_filtered.sort_values('created_at', ascending=False).reset_index(drop=True)
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if search_term:
        st.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(df_filtered)}ê°œ (ì „ì²´: {len(df_all)}ê°œ)")
    
    st.markdown("---")
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ë¶„ì„
    st.markdown("### ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ ë¶„ì„")
    
    # ë¶„ì„ ì‹¤í–‰
    if len(df_filtered) > 0:
        analysis_results, valid_comparisons = analyze_prediction_comparison(df_filtered)
        stats = calculate_statistics(analysis_results, valid_comparisons)
        
        if valid_comparisons > 0:
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ: {valid_comparisons}ê°œì˜ ìœ íš¨í•œ ë¹„êµ ë°ì´í„°")
            
            # 1. ì²« ë²ˆì§¸ë¡œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜
            st.markdown("#### 1ï¸âƒ£ ì²« ë²ˆì§¸ë¡œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜")
            if stats['first_match']:
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í‰ê·  ìœ„ì¹˜", f"{stats['first_match']['mean']:.2f}")
                with col2:
                    st.metric("ìµœì†Œ ìœ„ì¹˜", stats['first_match']['min'])
                with col3:
                    st.metric("ìµœëŒ€ ìœ„ì¹˜", stats['first_match']['max'])
                with col4:
                    st.metric("ë¶„ì„ ë°ì´í„° ìˆ˜", len(analysis_results['first_match_position']))
                
                # ë¶„í¬ í‘œì‹œ
                if stats['first_match']['distribution']:
                    st.markdown("**ìœ„ì¹˜ë³„ ë¶„í¬:**")
                    dist_df = pd.DataFrame([
                        {'ìœ„ì¹˜': k, 'íšŸìˆ˜': v, 'ë¹„ìœ¨(%)': (v / len(analysis_results['first_match_position']) * 100)} 
                        for k, v in sorted(stats['first_match']['distribution'].items())
                    ])
                    st.dataframe(dist_df, use_container_width=True, hide_index=True)
            else:
                st.warning("ì²« ë²ˆì§¸ë¡œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ê²½ìš°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            st.markdown("---")
            
            # 2. ìµœëŒ€ ëª‡ ë²ˆì§¸ ìœ„ì¹˜ê¹Œì§€ ê°™ì€ ë¬¸ìê°€ ë‚˜ì™”ëŠ”ì§€
            st.markdown("#### 2ï¸âƒ£ ìµœëŒ€ ëª‡ ë²ˆì§¸ ìœ„ì¹˜ê¹Œì§€ ê°™ì€ ë¬¸ìê°€ ë‚˜ì™”ëŠ”ì§€")
            if stats['max_match']:
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í‰ê·  ìµœëŒ€ ìœ„ì¹˜", f"{stats['max_match']['mean']:.2f}")
                with col2:
                    st.metric("ìµœì†Œ ìµœëŒ€ ìœ„ì¹˜", stats['max_match']['min'])
                with col3:
                    st.metric("ìµœëŒ€ ìœ„ì¹˜", stats['max_match']['max'])
                with col4:
                    st.metric("ë¶„ì„ ë°ì´í„° ìˆ˜", len(analysis_results['max_match_position']))
                
                # ë¶„í¬ í‘œì‹œ
                if stats['max_match']['distribution']:
                    st.markdown("**ìœ„ì¹˜ë³„ ë¶„í¬:**")
                    dist_df = pd.DataFrame([
                        {'ìµœëŒ€ ìœ„ì¹˜': k, 'íšŸìˆ˜': v, 'ë¹„ìœ¨(%)': (v / len(analysis_results['max_match_position']) * 100)} 
                        for k, v in sorted(stats['max_match']['distribution'].items())
                    ])
                    st.dataframe(dist_df, use_container_width=True, hide_index=True)
            else:
                st.warning("ìµœëŒ€ ìœ„ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            st.markdown("---")
            
            # 3. ìœ„ì¹˜ë³„ë¡œ ê°™ì€ ë¬¸ìì¸ì§€ ë¹„ìœ¨
            st.markdown("#### 3ï¸âƒ£ ìœ„ì¹˜ë³„ ë¬¸ì ì¼ì¹˜ ë¹„ìœ¨")
            position_cols = st.columns(3)
            for idx, pos in enumerate([1, 2, 3]):
                with position_cols[idx]:
                    if stats['position_match_rate'][pos]:
                        rate_info = stats['position_match_rate'][pos]
                        st.metric(
                            f"{pos}ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨",
                            f"{rate_info['rate']:.2f}%",
                            f"{rate_info['match_count']}/{rate_info['total_count']}"
                        )
                    else:
                        st.metric(f"{pos}ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨", "N/A")
            
            st.markdown("---")
            
            # 4. ì²« ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš°, ëª‡ ë²ˆì§¸ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
            st.markdown("#### 4ï¸âƒ£ ì²« ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš°, ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜")
            if stats['first_different_match']:
                if 'mean' in stats['first_different_match']:
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("í‰ê·  ìœ„ì¹˜", f"{stats['first_different_match']['mean']:.2f}")
                    with col2:
                        st.metric("ìµœì†Œ ìœ„ì¹˜", stats['first_different_match']['min'])
                    with col3:
                        st.metric("ìµœëŒ€ ìœ„ì¹˜", stats['first_different_match']['max'])
                    with col4:
                        no_match = stats['first_different_match'].get('no_match_count', 0)
                        total_first_different = len(analysis_results['first_different_match_position'])
                        st.metric("ì¼ì¹˜í•˜ì§€ ì•Šì€ ê²½ìš°", f"{no_match}/{total_first_different}")
                    
                    # ë¶„í¬ í‘œì‹œ
                    if stats['first_different_match']['distribution']:
                        st.markdown("**ìœ„ì¹˜ë³„ ë¶„í¬:**")
                        dist_df = pd.DataFrame([
                            {'ìœ„ì¹˜': k, 'íšŸìˆ˜': v, 'ë¹„ìœ¨(%)': (v / (total_first_different - no_match) * 100) if (total_first_different - no_match) > 0 else 0} 
                            for k, v in sorted(stats['first_different_match']['distribution'].items())
                        ])
                        st.dataframe(dist_df, use_container_width=True, hide_index=True)
                else:
                    st.info(f"ì²« ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš°: {stats['first_different_match'].get('no_match_count', 0)}ê°œ (ëª¨ë‘ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ)")
            else:
                st.warning("ì²« ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš°ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            st.markdown("---")
            
            # ìµœëŒ€ ìœ„ì¹˜ ë¶„ì„ ì¸ì‚¬ì´íŠ¸
            st.markdown("#### ğŸ” ìµœëŒ€ ìœ„ì¹˜ ë¶„ì„ ì¸ì‚¬ì´íŠ¸")
            strategy_insights = analyze_max_position_strategy(stats, analysis_results)
            
            if strategy_insights['detailed_analysis']:
                detail = strategy_insights['detailed_analysis']
                
                # í•µì‹¬ ì§€í‘œ í‘œì‹œ
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("í‰ê·  ìµœëŒ€ ìœ„ì¹˜", f"{detail['avg_max_position']:.2f}")
                with col2:
                    st.metric("ìµœëŒ€ ìœ„ì¹˜ 3ì¸ ë¹„ìœ¨", f"{detail['pos3_ratio']:.1f}%")
                with col3:
                    st.metric("ìœ„ì¹˜ 2 ì´í•˜ ë¹„ìœ¨", f"{detail['pos2_or_below_ratio']:.1f}%")
                
                # ì „ëµ ìœ í˜• í‘œì‹œ
                if strategy_insights['strategy_type']:
                    strategy_type_label = {
                        'same': 'âœ… ê°™ì€ ë¬¸ì ì ‘ê·¼ ì „ëµ',
                        'different': 'âš ï¸ ë‹¤ë¥¸ ë¬¸ì ì ‘ê·¼ ì „ëµ',
                        'mixed': 'ğŸ“Š í˜¼í•© ì „ëµ'
                    }
                    confidence_label = {
                        'high': 'ğŸŸ¢ ë†’ìŒ',
                        'medium': 'ğŸŸ¡ ì¤‘ê°„',
                        'low': 'ğŸ”´ ë‚®ìŒ'
                    }
                    
                    st.markdown(f"**ê¶Œì¥ ì „ëµ ìœ í˜•**: {strategy_type_label.get(strategy_insights['strategy_type'], 'ë¯¸ì •')}")
                    if strategy_insights['confidence_level']:
                        st.markdown(f"**ì‹ ë¢°ë„**: {confidence_label.get(strategy_insights['confidence_level'], 'ë¯¸ì •')}")
                
                st.markdown("---")
                
                # ê¶Œì¥ ì ‘ê·¼ ë°©ë²•
                if strategy_insights['recommended_approach']:
                    st.markdown("**ğŸ’¡ ê¶Œì¥ ì ‘ê·¼ ë°©ë²•:**")
                    for approach in strategy_insights['recommended_approach']:
                        st.markdown(approach)
                
                # ë¦¬ìŠ¤í¬ í‰ê°€
                if strategy_insights['risk_assessment']:
                    st.markdown("**âš ï¸ ë¦¬ìŠ¤í¬ í‰ê°€:**")
                    for risk in strategy_insights['risk_assessment']:
                        st.markdown(risk)
            
            st.markdown("---")
            
            # êµì°¨ íŒ¨í„´ ì „ëµ ë¶„ì„
            st.markdown("#### ğŸ”„ êµì°¨ íŒ¨í„´ ì „ëµ í‰ê°€")
            cross_strategy = analyze_cross_pattern_strategy(analysis_results, stats, df_filtered)
            
            st.markdown(f"**ì „ëµ ì„¤ëª…**: {cross_strategy['description']}")
            st.markdown("---")
            
            # ì²« ë²ˆì§¸ê°€ ê°™ì„ ë•Œ â†’ ë‹¤ìŒì— ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ë¶„ì„
            if cross_strategy['first_same_next_different']:
                data1 = cross_strategy['first_same_next_different']
                st.markdown("#### ì²« ë²ˆì§¸ê°€ ê°™ì„ ë•Œ â†’ ë‹¤ìŒì— ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í‰ê·  ìœ„ì¹˜", f"{data1['mean_position']:.2f}" if data1['mean_position'] else "N/A")
                with col2:
                    st.metric("ìµœì†Œ ìœ„ì¹˜", data1['min_position'] if data1['min_position'] else "N/A")
                with col3:
                    st.metric("ìµœëŒ€ ìœ„ì¹˜", data1['max_position'] if data1['max_position'] else "N/A")
                with col4:
                    # 2-3ë²ˆì§¸ ìœ„ì¹˜ì—ì„œ ë¹ ë¥¸ ì „í™˜ ë¹„ìœ¨
                    if data1['distribution'] and data1['found_count'] > 0:
                        quick_change_count = sum([data1['distribution'].get(i, 0) for i in [2, 3]])
                        quick_change_rate = (quick_change_count / data1['found_count'] * 100) if data1['found_count'] > 0 else 0
                        st.metric("ë¹ ë¥¸ ì „í™˜ ë¹„ìœ¨", f"{quick_change_rate:.1f}%", f"2-3ë²ˆì§¸: {quick_change_count}ê±´")
                    else:
                        st.metric("ë¹ ë¥¸ ì „í™˜ ë¹„ìœ¨", "N/A")
                
                if data1['distribution']:
                    st.markdown("**ìœ„ì¹˜ë³„ ë¶„í¬:**")
                    dist_df = pd.DataFrame([
                        {'ìœ„ì¹˜': k, 'íšŸìˆ˜': v, 'ë¹„ìœ¨(%)': (v / data1['found_count'] * 100) if data1['found_count'] > 0 else 0} 
                        for k, v in sorted(data1['distribution'].items())
                    ])
                    st.dataframe(dist_df, use_container_width=True, hide_index=True)
                
                if data1['no_change_count'] > 0:
                    st.info(f"íŒ¨í„´ì´ ë³€ê²½ë˜ì§€ ì•Šì€ ê²½ìš°: {data1['no_change_count']}ê±´ ({data1['no_change_rate']:.1f}%)")
            
            # ì²« ë²ˆì§¸ê°€ ë‹¤ë¥¼ ë•Œ â†’ ë‹¤ìŒì— ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜ ë¶„ì„
            if cross_strategy['first_different_next_same']:
                st.markdown("---")
                data2 = cross_strategy['first_different_next_same']
                st.markdown("#### ì²« ë²ˆì§¸ê°€ ë‹¤ë¥¼ ë•Œ â†’ ë‹¤ìŒì— ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ” ìœ„ì¹˜")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í‰ê·  ìœ„ì¹˜", f"{data2['mean_position']:.2f}" if data2['mean_position'] else "N/A")
                with col2:
                    st.metric("ìµœì†Œ ìœ„ì¹˜", data2['min_position'] if data2['min_position'] else "N/A")
                with col3:
                    st.metric("ìµœëŒ€ ìœ„ì¹˜", data2['max_position'] if data2['max_position'] else "N/A")
                with col4:
                    # 2-3ë²ˆì§¸ ìœ„ì¹˜ì—ì„œ ë¹ ë¥¸ ì „í™˜ ë¹„ìœ¨
                    if data2['distribution'] and data2['found_count'] > 0:
                        quick_change_count = sum([data2['distribution'].get(i, 0) for i in [2, 3]])
                        quick_change_rate = (quick_change_count / data2['found_count'] * 100) if data2['found_count'] > 0 else 0
                        st.metric("ë¹ ë¥¸ ì „í™˜ ë¹„ìœ¨", f"{quick_change_rate:.1f}%", f"2-3ë²ˆì§¸: {quick_change_count}ê±´")
                    else:
                        st.metric("ë¹ ë¥¸ ì „í™˜ ë¹„ìœ¨", "N/A")
                
                if data2['distribution']:
                    st.markdown("**ìœ„ì¹˜ë³„ ë¶„í¬:**")
                    dist_df = pd.DataFrame([
                        {'ìœ„ì¹˜': k, 'íšŸìˆ˜': v, 'ë¹„ìœ¨(%)': (v / data2['found_count'] * 100) if data2['found_count'] > 0 else 0} 
                        for k, v in sorted(data2['distribution'].items())
                    ])
                    st.dataframe(dist_df, use_container_width=True, hide_index=True)
                
                if data2['no_change_count'] > 0:
                    st.info(f"íŒ¨í„´ì´ ë³€ê²½ë˜ì§€ ì•Šì€ ê²½ìš°: {data2['no_change_count']}ê±´ ({data2['no_change_rate']:.1f}%)")
            
            # ì¶”ì²œ í‰ê°€
            if cross_strategy['recommendation']:
                st.markdown("---")
                st.markdown("**ğŸ’¡ ì „ëµ ì¸ì‚¬ì´íŠ¸**")
                rec = cross_strategy['recommendation']
                
                for message in rec['messages']:
                    st.markdown(message)
            
            st.markdown("---")
            
            # ìƒˆë¡œìš´ ì „ëµ ë¶„ì„: ë‹¤ìŒ ìœ„ì¹˜ ì¼ì¹˜ ì „ëµ
            st.markdown("#### ğŸ”® ë‹¤ìŒ ìœ„ì¹˜ ì¼ì¹˜ ì „ëµ í‰ê°€")
            next_match_strategy = analyze_next_session_match_strategy(analysis_results)
            
            st.markdown(f"**ì „ëµ ì„¤ëª…**: {next_match_strategy['description']}")
            st.markdown("---")
            
            # 1. ì²«ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš° â†’ ê·¸ ì„¸ì…˜ ë‚´ì—ì„œ ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
            if next_match_strategy.get('first_different_next_match'):
                data = next_match_strategy['first_different_next_match']
                st.markdown("##### 1ï¸âƒ£ ì²«ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš°")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì´ ì¼€ì´ìŠ¤", f"{data['total_cases']}ê±´")
                with col2:
                    st.metric("ìµœëŒ€ ìœ„ì¹˜", f"{data.get('max_position', 0)}ë²ˆì§¸")
                with col3:
                    if data.get('avg_position'):
                        st.metric("í‰ê·  ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜", f"{data['avg_position']:.1f}ë²ˆì§¸")
                    else:
                        st.metric("í‰ê·  ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜", "N/A")
                with col4:
                    if data.get('min_position'):
                        st.metric("ìµœì†Œ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜", f"{data['min_position']}ë²ˆì§¸")
                    else:
                        st.metric("ìµœì†Œ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜", "N/A")
                
                # ì¶”ê°€ í†µê³„ í‘œì‹œ
                if data.get('median_position'):
                    st.info(f"ğŸ’¡ ì¤‘ì•™ê°’ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜: {data['median_position']}ë²ˆì§¸")
                
                if data.get('no_match_count', 0) > 0:
                    st.warning(f"âš ï¸ ë‹¤ìŒ ì¼ì¹˜ê°€ ì—†ëŠ” ì¼€ì´ìŠ¤: {data['no_match_count']}ê±´")
                
                # ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ ë¶„í¬ í‘œì‹œ
                if data.get('position_distribution'):
                    st.markdown("**ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ ë¶„í¬:**")
                    dist_df = pd.DataFrame([
                        {'ìœ„ì¹˜': k, 'íšŸìˆ˜': v, 'ë¹„ìœ¨(%)': (v / sum(data['position_distribution'].values()) * 100)} 
                        for k, v in sorted(data['position_distribution'].items())
                    ])
                    st.dataframe(dist_df, use_container_width=True, hide_index=True)
                
                # ìµœëŒ€ ìœ„ì¹˜ ì„¸ì…˜ í…Œì´ë¸” í‘œì‹œ
                if data.get('max_position_case') and data.get('max_position', 0) > 0:
                    st.markdown("**ğŸ“Š ìµœëŒ€ ìœ„ì¹˜ ì„¸ì…˜ (ìµœì‹  1ê°œ):**")
                    max_case = data['max_position_case']
                    session = max_case['session']
                    
                    max_session_df = pd.DataFrame([{
                        'ID': session.get('id', 'N/A'),
                        'ì„¸ì…˜ ID': session.get('session_id', 'N/A'),
                        'ìƒì„±ì¼ì‹œ': session.get('created_at', 'N/A'),
                        'Sequence ì˜ˆì¸¡': session.get('sequence_prediction_results', 'N/A'),
                        'ì¬êµ¬ì„± Sequence': session.get('reconstructed_sequence_prediction_results', 'N/A'),
                        'ìµœëŒ€ ìœ„ì¹˜': f"{max_case['max_position']}ë²ˆì§¸"
                    }])
                    st.dataframe(max_session_df, use_container_width=True, hide_index=True)
                
                st.markdown("---")
            
            # 2. ì²«ë²ˆì§¸ê°€ ê°™ê³  ë‘ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš° â†’ ê·¸ ì„¸ì…˜ ë‚´ì—ì„œ ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ ê°™ì€ ë¬¸ìê°€ ë‚˜ì˜¤ëŠ”ì§€
            if next_match_strategy.get('first_same_second_different_next_match'):
                data = next_match_strategy['first_same_second_different_next_match']
                st.markdown("##### 2ï¸âƒ£ ì²«ë²ˆì§¸ê°€ ê°™ê³  ë‘ë²ˆì§¸ê°€ ë‹¤ë¥¸ ê²½ìš°")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì´ ì¼€ì´ìŠ¤", f"{data['total_cases']}ê±´")
                with col2:
                    st.metric("ìµœëŒ€ ìœ„ì¹˜", f"{data.get('max_position', 0)}ë²ˆì§¸")
                with col3:
                    if data.get('avg_position'):
                        st.metric("í‰ê·  ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜", f"{data['avg_position']:.1f}ë²ˆì§¸")
                    else:
                        st.metric("í‰ê·  ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜", "N/A")
                with col4:
                    if data.get('min_position'):
                        st.metric("ìµœì†Œ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜", f"{data['min_position']}ë²ˆì§¸")
                    else:
                        st.metric("ìµœì†Œ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜", "N/A")
                
                # ì¶”ê°€ í†µê³„ í‘œì‹œ
                if data.get('median_position'):
                    st.info(f"ğŸ’¡ ì¤‘ì•™ê°’ ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜: {data['median_position']}ë²ˆì§¸")
                
                if data.get('no_match_count', 0) > 0:
                    st.warning(f"âš ï¸ ë‹¤ìŒ ì¼ì¹˜ê°€ ì—†ëŠ” ì¼€ì´ìŠ¤: {data['no_match_count']}ê±´")
                
                # ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ ë¶„í¬ í‘œì‹œ
                if data.get('position_distribution'):
                    st.markdown("**ë‹¤ìŒ ì¼ì¹˜ ìœ„ì¹˜ ë¶„í¬:**")
                    dist_df = pd.DataFrame([
                        {'ìœ„ì¹˜': k, 'íšŸìˆ˜': v, 'ë¹„ìœ¨(%)': (v / sum(data['position_distribution'].values()) * 100)} 
                        for k, v in sorted(data['position_distribution'].items())
                    ])
                    st.dataframe(dist_df, use_container_width=True, hide_index=True)
                
                # ìµœëŒ€ ìœ„ì¹˜ ì„¸ì…˜ í…Œì´ë¸” í‘œì‹œ
                if data.get('max_position_case') and data.get('max_position', 0) > 0:
                    st.markdown("**ğŸ“Š ìµœëŒ€ ìœ„ì¹˜ ì„¸ì…˜ (ìµœì‹  1ê°œ):**")
                    max_case = data['max_position_case']
                    session = max_case['session']
                    
                    max_session_df = pd.DataFrame([{
                        'ID': session.get('id', 'N/A'),
                        'ì„¸ì…˜ ID': session.get('session_id', 'N/A'),
                        'ìƒì„±ì¼ì‹œ': session.get('created_at', 'N/A'),
                        'Sequence ì˜ˆì¸¡': session.get('sequence_prediction_results', 'N/A'),
                        'ì¬êµ¬ì„± Sequence': session.get('reconstructed_sequence_prediction_results', 'N/A'),
                        'ìµœëŒ€ ìœ„ì¹˜': f"{max_case['max_position']}ë²ˆì§¸"
                    }])
                    st.dataframe(max_session_df, use_container_width=True, hide_index=True)
                
                st.markdown("---")
            
            # ì „ëµ ì œì•ˆ
            st.markdown("#### ğŸ¯ ì¢…í•© ìŠ¹ë¦¬ ì „ëµ ì œì•ˆ")
            strategy_suggestions = []
            
            # ìœ„ì¹˜ë³„ ì¼ì¹˜ìœ¨ ê¸°ë°˜ ì „ëµ
            if stats['position_match_rate'][1]:
                first_match_rate = stats['position_match_rate'][1]['rate']
                if first_match_rate >= 50:
                    strategy_suggestions.append(f"âœ… 1ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨ì´ {first_match_rate:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ë¬¸ìì— ì§‘ì¤‘í•˜ëŠ” ì „ëµì„ ê³ ë ¤í•˜ì„¸ìš”.")
                else:
                    strategy_suggestions.append(f"âš ï¸ 1ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨ì´ {first_match_rate:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ë¬¸ìë§Œìœ¼ë¡œëŠ” ì˜ˆì¸¡í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.")
            
            if stats['position_match_rate'][2]:
                second_match_rate = stats['position_match_rate'][2]['rate']
                strategy_suggestions.append(f"ğŸ“Š 2ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨: {second_match_rate:.1f}%")
            
            if stats['position_match_rate'][3]:
                third_match_rate = stats['position_match_rate'][3]['rate']
                strategy_suggestions.append(f"ğŸ“Š 3ë²ˆì§¸ ìœ„ì¹˜ ì¼ì¹˜ìœ¨: {third_match_rate:.1f}%")
            
            # ìµœëŒ€ ìœ„ì¹˜ ê¸°ë°˜ ì „ëµ
            if stats['max_match']:
                avg_max_pos = stats['max_match']['mean']
                if avg_max_pos >= 2:
                    strategy_suggestions.append(f"ğŸ’¡ í‰ê· ì ìœ¼ë¡œ {avg_max_pos:.1f}ë²ˆì§¸ ìœ„ì¹˜ê¹Œì§€ ì¼ì¹˜í•©ë‹ˆë‹¤. ì—°ì†ëœ ë¬¸ì ë§¤ì¹­ì„ í™œìš©í•˜ì„¸ìš”.")
            
            # ì²« ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš° ì „ëµ
            if stats['first_different_match'] and 'mean' in stats['first_different_match']:
                avg_match_pos = stats['first_different_match']['mean']
                strategy_suggestions.append(f"ğŸ”„ ì²« ë¬¸ìê°€ ë‹¤ë¥¸ ê²½ìš°, í‰ê·  {avg_match_pos:.1f}ë²ˆì§¸ ìœ„ì¹˜ì—ì„œ ì¼ì¹˜í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ê°€ ë‹¤ë¥´ë”ë¼ë„ í¬ê¸°í•˜ì§€ ë§ˆì„¸ìš”.")
            
            for suggestion in strategy_suggestions:
                st.write(suggestion)
            
        else:
            st.warning("âš ï¸ ë¹„êµí•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ì¡°ê±´ì„ ë³€ê²½í•´ë³´ì„¸ìš”.")
    
    st.markdown("---")
    
    # í…Œì´ë¸” í‘œì‹œ
    st.markdown("### ğŸ“‹ ë°ì´í„° í…Œì´ë¸”")
    
    # ì»¬ëŸ¼ëª… í•œê¸€í™”
    display_df = df_filtered.copy()
    
    # ì»¬ëŸ¼ëª… ë§¤í•‘
    column_mapping = {
        'id': 'ID',
        'session_id': 'ì„¸ì…˜ ID',
        'converted_grid': 'ë³€í™˜ëœ ê·¸ë¦¬ë“œ',
        'reconstructed_grid': 'ì¬êµ¬ì„±ëœ ê·¸ë¦¬ë“œ',
        'sequence_prediction_results': 'Sequence ì˜ˆì¸¡ ê²°ê³¼',
        'reconstructed_sequence_prediction_results': 'ì¬êµ¬ì„± Sequence ì˜ˆì¸¡ ê²°ê³¼',
        'reconstructed_gap_results': 'ì¬êµ¬ì„± Gap ê²°ê³¼',
        'created_at': 'ìƒì„±ì¼ì‹œ'
    }
    
    # ì»¬ëŸ¼ëª… ë³€ê²½
    display_df = display_df.rename(columns=column_mapping)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì§€ì • (ì˜ˆì¸¡ ê²°ê³¼ê°€ ê·¸ë¦¬ë“œë³´ë‹¤ ì™¼ìª½ì— ì˜¤ë„ë¡)
    column_order = [
        'ID',
        'ì„¸ì…˜ ID',
        'Sequence ì˜ˆì¸¡ ê²°ê³¼',
        'ì¬êµ¬ì„± Sequence ì˜ˆì¸¡ ê²°ê³¼',
        'ì¬êµ¬ì„± Gap ê²°ê³¼',
        'ë³€í™˜ëœ ê·¸ë¦¬ë“œ',
        'ì¬êµ¬ì„±ëœ ê·¸ë¦¬ë“œ',
        'ìƒì„±ì¼ì‹œ'
    ]
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    available_columns = [col for col in column_order if col in display_df.columns]
    display_df = display_df[available_columns]
    
    # ë°ì´í„° í‘œì‹œ
    if len(display_df) > 0:
        st.dataframe(display_df, use_container_width=True, height=600)
        
        # ë°ì´í„° ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
            load_game_outcome_v2_data.clear()
            st.rerun()
    else:
        st.warning("âš ï¸ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        if search_term:
            st.info("ê²€ìƒ‰ì–´ë¥¼ ë³€ê²½í•˜ê±°ë‚˜ ê²€ìƒ‰ì–´ë¥¼ ì§€ì›Œì„œ ì „ì²´ ë°ì´í„°ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")

if __name__ == "__main__":
    main()

