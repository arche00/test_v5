"""
ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê°€ì„¤ ê²€ì¦ ë¶„ì„ ì•±
ì²« ë²ˆì§¸ ì¼ì¹˜ ì˜ˆì¸¡ ì´í›„ ì—°ì† ë¶ˆì¼ì¹˜ íŒ¨í„´ ë¶„ì„
"""

import streamlit as st

# í˜ì´ì§€ ì„¤ì • (ëª¨ë“  import ì „ì— ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
st.set_page_config(
    page_title="Confidence Skip Hypothesis Analysis",
    page_icon="ğŸ“Š",
    layout="wide"
)

import pandas as pd
import sqlite3
from collections import defaultdict
from datetime import datetime
import uuid

# ê¸°ì¡´ ì•±ì˜ í•¨ìˆ˜ë“¤ import
from hypothesis_validation_app import get_db_connection

# interactive_multi_step_validation_appì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ import
from interactive_multi_step_validation_app import (
    load_ngram_chunks,
    build_frequency_model,
    build_weighted_model,
    predict_for_prefix,
    predict_with_fallback_interval,
    get_next_prefix
)

# DB ê²½ë¡œ
DB_PATH = 'hypothesis_validation.db'

def load_validation_sessions():
    """
    ì €ì¥ëœ ê²€ì¦ ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ
    
    Returns:
        DataFrame: ê²€ì¦ ì„¸ì…˜ ëª©ë¡
    """
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    try:
        query = """
            SELECT 
                validation_id,
                cutoff_grid_string_id,
                window_size,
                method,
                use_threshold,
                threshold,
                max_interval,
                confidence_skip_threshold_1,
                confidence_skip_threshold_2,
                created_at
            FROM confidence_skip_validation_sessions
            ORDER BY created_at DESC
        """
        df = pd.read_sql_query(query, conn)
        return df
    except Exception as e:
        st.error(f"ê²€ì¦ ì„¸ì…˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()
    finally:
        conn.close()

def load_validation_session_steps(validation_id, confidence_skip_threshold):
    """
    íŠ¹ì • ê²€ì¦ ì„¸ì…˜ì˜ ëª¨ë“  ìŠ¤í… ë°ì´í„° ì¡°íšŒ
    
    Args:
        validation_id: ê²€ì¦ ì„¸ì…˜ ID
        confidence_skip_threshold: ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’
    
    Returns:
        DataFrame: ìŠ¤í… ë°ì´í„°
    """
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    try:
        query = """
            SELECT 
                id,
                validation_id,
                confidence_skip_threshold,
                grid_string_id,
                step,
                prefix,
                predicted,
                actual,
                is_correct,
                confidence,
                is_forced,
                current_interval,
                has_prediction,
                validated,
                skipped,
                created_at
            FROM confidence_skip_validation_steps
            WHERE validation_id = ? AND confidence_skip_threshold = ?
            ORDER BY grid_string_id, step
        """
        df = pd.read_sql_query(query, conn, params=[validation_id, confidence_skip_threshold])
        return df
    except Exception as e:
        st.error(f"ìŠ¤í… ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()
    finally:
        conn.close()

def load_live_game_sessions():
    """
    ì €ì¥ëœ ë¼ì´ë¸Œ ê²Œì„ ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ
    
    Returns:
        DataFrame: ë¼ì´ë¸Œ ê²Œì„ ì„¸ì…˜ ëª©ë¡
    """
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    try:
        query = """
            SELECT 
                session_id,
                grid_string,
                window_size,
                method,
                use_threshold,
                threshold,
                max_interval,
                confidence_skip_threshold,
                total_steps,
                total_predictions,
                total_failures,
                max_consecutive_failures,
                accuracy,
                started_at,
                auto_executed
            FROM live_game_sessions
            ORDER BY started_at DESC
        """
        df = pd.read_sql_query(query, conn)
        return df
    except Exception as e:
        st.error(f"ë¼ì´ë¸Œ ê²Œì„ ì„¸ì…˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()
    finally:
        conn.close()

def load_live_game_steps(session_id):
    """
    íŠ¹ì • ë¼ì´ë¸Œ ê²Œì„ ì„¸ì…˜ì˜ ëª¨ë“  ìŠ¤í… ë°ì´í„° ì¡°íšŒ
    
    Args:
        session_id: ë¼ì´ë¸Œ ê²Œì„ ì„¸ì…˜ ID
    
    Returns:
        DataFrame: ìŠ¤í… ë°ì´í„°
    """
    conn = get_db_connection()
    if conn is None:
        return pd.DataFrame()
    
    try:
        query = """
            SELECT 
                id,
                session_id,
                step,
                prefix,
                predicted_value,
                actual_value,
                is_correct,
                confidence,
                is_forced,
                current_interval,
                has_prediction,
                validated,
                skipped,
                created_at
            FROM live_game_steps
            WHERE session_id = ?
            ORDER BY step
        """
        df = pd.read_sql_query(query, conn, params=[session_id])
        return df
    except Exception as e:
        st.error(f"ë¼ì´ë¸Œ ê²Œì„ ìŠ¤í… ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return pd.DataFrame()
    finally:
        conn.close()

def analyze_live_game_first_match_hypothesis(session_id):
    """
    ë¼ì´ë¸Œ ê²Œì„ ë°ì´í„°ì— ëŒ€í•œ ì²« ì¼ì¹˜ í›„ ì—°ì† ë¶ˆì¼ì¹˜ ë¶„ì„ ë¡œì§ ì‹¤í–‰
    
    ê°€ì„¤: ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
    ë‹¤ìŒ ê²Œì„ë¶€í„° ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 6ê°œ ë¯¸ë§Œì¼ ê²ƒì´ë‹¤.
    
    Args:
        session_id: ë¼ì´ë¸Œ ê²Œì„ ì„¸ì…˜ ID
    
    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    # ìŠ¤í… ë°ì´í„° ë¡œë“œ
    steps_df = load_live_game_steps(session_id)
    
    if len(steps_df) == 0:
        return {
            'session_id': session_id,
            'has_first_match': False,
            'first_match_step': None,
            'max_consecutive_mismatches_after_first': None,
            'is_below_6': None,
            'total_steps': 0
        }
    
    steps_df = steps_df.sort_values('step').reset_index(drop=True)
    
    # ë””ë²„ê¹…: ë°ì´í„° í™•ì¸
    if len(steps_df) > 0:
        # skipped ê°’ ë¶„í¬ í™•ì¸
        skipped_counts = steps_df['skipped'].value_counts()
        validated_counts = steps_df['validated'].value_counts()
        has_prediction_counts = steps_df['has_prediction'].value_counts()
        
        # ë””ë²„ê·¸ ì •ë³´ (í•„ìš”ì‹œ ì‚¬ìš©)
        # st.write(f"Session {session_id} - Skipped ë¶„í¬: {dict(skipped_counts)}")
        # st.write(f"Session {session_id} - Validated ë¶„í¬: {dict(validated_counts)}")
        # st.write(f"Session {session_id} - Has Prediction ë¶„í¬: {dict(has_prediction_counts)}")
    
    # ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ ì°¾ê¸° (skipped=0 ë˜ëŠ” False)
    first_non_skipped_idx = None
    for idx, row in steps_df.iterrows():
        skipped_val = row['skipped']
        # 0 ë˜ëŠ” False ëª¨ë‘ ì²˜ë¦¬
        if skipped_val == 0 or skipped_val is False or skipped_val == '0':
            first_non_skipped_idx = idx
            break
    
    if first_non_skipped_idx is None:
        # ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì—†ëŠ” ê²½ìš°
        return {
            'session_id': session_id,
            'has_first_match': False,
            'first_match_step': None,
            'max_consecutive_mismatches_after_first': None,
            'is_below_6': None,
            'total_steps': len(steps_df)
        }
    
    first_non_skipped = steps_df.iloc[first_non_skipped_idx]
    
    # ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì¼ì¹˜ì¸ì§€ í™•ì¸
    # is_correct: 1=True, 0=False, None=None
    is_correct_val = first_non_skipped['is_correct']
    # 1 ë˜ëŠ” Trueì¸ ê²½ìš°ë§Œ ì¼ì¹˜ë¡œ ì²˜ë¦¬
    is_match = (is_correct_val == 1 or is_correct_val is True or is_correct_val == '1')
    if not is_match:  # ì¼ì¹˜ê°€ ì•„ë‹˜
        return {
            'session_id': session_id,
            'has_first_match': False,
            'first_match_step': None,
            'max_consecutive_mismatches_after_first': None,
            'is_below_6': None,
            'total_steps': len(steps_df)
        }
    
    # ì²« ì¼ì¹˜ ìŠ¤í… ê¸°ë¡
    first_match_step = first_non_skipped['step']
    
    # ì²« ì¼ì¹˜ ì´í›„ ì²« ë²ˆì§¸ ê²€ì¦ëœ ìŠ¤í… ì°¾ê¸° (ë‘ ë²ˆì§¸)
    second_validated_idx = None
    for idx in range(first_non_skipped_idx + 1, len(steps_df)):
        row = steps_df.iloc[idx]
        validated_val = row['validated']
        skipped_val = row['skipped']
        is_validated = (validated_val == 1 or validated_val is True or validated_val == '1')
        is_skipped = (skipped_val == 1 or skipped_val is True or skipped_val == '1')
        
        if is_validated and not is_skipped:
            second_validated_idx = idx
            break
    
    # ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
    if second_validated_idx is None:
        return {
            'session_id': session_id,
            'has_first_match': True,
            'first_match_step': first_match_step,
            'second_is_mismatch': False,
            'second_mismatch_step': None,
            'max_consecutive_mismatches_after_first': None,
            'is_below_6': None,
            'is_6_or_more': False,
            'has_complete_data': False,
            'ended_with_mismatch': False,
            'total_steps': len(steps_df)
        }
    
    second_validated = steps_df.iloc[second_validated_idx]
    is_correct_val = second_validated['is_correct']
    is_second_mismatch = (is_correct_val == 0 or is_correct_val is False or is_correct_val == '0')
    
    if not is_second_mismatch:
        return {
            'session_id': session_id,
            'has_first_match': True,
            'first_match_step': first_match_step,
            'second_is_mismatch': False,
            'second_mismatch_step': None,
            'max_consecutive_mismatches_after_first': None,
            'is_below_6': None,
            'is_6_or_more': False,
            'has_complete_data': False,
            'ended_with_mismatch': False,
            'total_steps': len(steps_df)
        }
    
    # ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•¨ -> ì—°ì† ë¶ˆì¼ì¹˜ ê³„ì‚°
    max_consecutive_mismatches = 0
    current_consecutive = 0
    has_complete_data = False
    second_mismatch_step = second_validated['step']
    
    # ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ìŠ¤í…ë¶€í„° ì‹œì‘í•˜ì—¬ ì—°ì† ë¶ˆì¼ì¹˜ ê³„ì‚°
    for idx in range(second_validated_idx, len(steps_df)):
        row = steps_df.iloc[idx]
        
        validated_val = row['validated']
        skipped_val = row['skipped']
        is_validated = (validated_val == 1 or validated_val is True or validated_val == '1')
        is_skipped = (skipped_val == 1 or skipped_val is True or skipped_val == '1')
        
        if is_validated and not is_skipped:
            is_correct_val = row['is_correct']
            is_match = (is_correct_val == 1 or is_correct_val is True or is_correct_val == '1')
            
            if is_match:
                # ì¼ì¹˜ë¥¼ ë§Œë‚¨ -> ì™„ì „í•œ ë°ì´í„°
                has_complete_data = True
                if current_consecutive > max_consecutive_mismatches:
                    max_consecutive_mismatches = current_consecutive
                break
            else:
                # ë¶ˆì¼ì¹˜ ê³„ì†
                current_consecutive += 1
                if current_consecutive > max_consecutive_mismatches:
                    max_consecutive_mismatches = current_consecutive
    
    return {
        'session_id': session_id,
        'has_first_match': True,
        'first_match_step': first_match_step,
        'second_is_mismatch': True,
        'second_mismatch_step': second_mismatch_step,
        'max_consecutive_mismatches_after_first': max_consecutive_mismatches,
        'is_below_6': max_consecutive_mismatches < 6,
        'is_6_or_more': max_consecutive_mismatches >= 6,
        'has_complete_data': has_complete_data,
        'ended_with_mismatch': not has_complete_data,
        'total_steps': len(steps_df)
    }

def analyze_all_live_games_first_match_hypothesis():
    """
    ëª¨ë“  ë¼ì´ë¸Œ ê²Œì„ ì„¸ì…˜ì˜ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ì„œ ë¶„ì„
    ì„¸ì…˜ êµ¬ë¶„ ì—†ì´ ëª¨ë“  ìŠ¤í…ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
    
    Returns:
        dict: ë¶„ì„ ê²°ê³¼ ë° í†µê³„
    """
    conn = get_db_connection()
    if conn is None:
        return {
            'has_first_match': False,
            'first_match_step': None,
            'max_consecutive_mismatches_after_first': None,
            'is_below_6': None,
            'total_steps': 0,
            'all_steps': []
        }
    
    try:
        # ëª¨ë“  ë¼ì´ë¸Œ ê²Œì„ ìŠ¤í…ì„ ì„¸ì…˜ ID, ìŠ¤í… ìˆœì„œëŒ€ë¡œ ì¡°íšŒ
        query = """
            SELECT 
                st.session_id,
                st.step,
                st.prefix,
                st.predicted_value,
                st.actual_value,
                st.is_correct,
                st.confidence,
                st.is_forced,
                st.current_interval,
                st.has_prediction,
                st.validated,
                st.skipped,
                s.started_at
            FROM live_game_steps st
            JOIN live_game_sessions s ON st.session_id = s.session_id
            ORDER BY s.started_at ASC, st.step ASC
        """
        all_steps_df = pd.read_sql_query(query, conn)
        
        if len(all_steps_df) == 0:
            return {
                'has_first_match': False,
                'first_match_step': None,
                'max_consecutive_mismatches_after_first': None,
                'is_below_6': None,
                'total_steps': 0,
                'all_steps': []
            }
        
        all_steps_df = all_steps_df.reset_index(drop=True)
        
        # ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ ì°¾ê¸° (skipped=0 ë˜ëŠ” False)
        first_non_skipped_idx = None
        for idx, row in all_steps_df.iterrows():
            skipped_val = row['skipped']
            # 0 ë˜ëŠ” False ëª¨ë‘ ì²˜ë¦¬
            if skipped_val == 0 or skipped_val is False or skipped_val == '0':
                first_non_skipped_idx = idx
                break
        
        if first_non_skipped_idx is None:
            # ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì—†ëŠ” ê²½ìš°
            return {
                'has_first_match': False,
                'first_match_step': None,
                'max_consecutive_mismatches_after_first': None,
                'is_below_6': None,
                'total_steps': len(all_steps_df),
                'all_steps': all_steps_df.to_dict('records')
            }
        
        first_non_skipped = all_steps_df.iloc[first_non_skipped_idx]
        
        # ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì¼ì¹˜ì¸ì§€ í™•ì¸
        is_correct_val = first_non_skipped['is_correct']
        is_match = (is_correct_val == 1 or is_correct_val is True or is_correct_val == '1')
        if not is_match:  # ì¼ì¹˜ê°€ ì•„ë‹˜
            return {
                'has_first_match': False,
                'first_match_step': None,
                'max_consecutive_mismatches_after_first': None,
                'is_below_6': None,
                'total_steps': len(all_steps_df),
                'all_steps': all_steps_df.to_dict('records')
            }
        
        # ì²« ì¼ì¹˜ ìŠ¤í… ê¸°ë¡ (ì „ì²´ ì¸ë±ìŠ¤ë¡œ í‘œì‹œ)
        first_match_idx = first_non_skipped_idx
        first_match_step = first_non_skipped['step']
        
        # ì²« ì¼ì¹˜ ì´í›„ ì²« ë²ˆì§¸ ê²€ì¦ëœ ìŠ¤í… ì°¾ê¸° (ë‘ ë²ˆì§¸)
        second_validated_idx = None
        for idx in range(first_non_skipped_idx + 1, len(all_steps_df)):
            row = all_steps_df.iloc[idx]
            validated_val = row['validated']
            skipped_val = row['skipped']
            is_validated = (validated_val == 1 or validated_val is True or validated_val == '1')
            is_skipped = (skipped_val == 1 or skipped_val is True or skipped_val == '1')
            
            if is_validated and not is_skipped:
                second_validated_idx = idx
                break
        
        # ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
        if second_validated_idx is None:
            return {
                'has_first_match': True,
                'first_match_idx': first_match_idx,
                'first_match_step': first_match_step,
                'first_match_session_id': first_non_skipped['session_id'],
                'second_is_mismatch': False,
                'second_mismatch_step': None,
                'max_consecutive_mismatches_after_first': None,
                'is_below_6': None,
                'is_6_or_more': False,
                'has_complete_data': False,
                'ended_with_mismatch': False,
                'total_steps': len(all_steps_df),
                'all_steps': all_steps_df.to_dict('records')
            }
        
        second_validated = all_steps_df.iloc[second_validated_idx]
        is_correct_val = second_validated['is_correct']
        is_second_mismatch = (is_correct_val == 0 or is_correct_val is False or is_correct_val == '0')
        
        if not is_second_mismatch:
            return {
                'has_first_match': True,
                'first_match_idx': first_match_idx,
                'first_match_step': first_match_step,
                'first_match_session_id': first_non_skipped['session_id'],
                'second_is_mismatch': False,
                'second_mismatch_step': None,
                'max_consecutive_mismatches_after_first': None,
                'is_below_6': None,
                'is_6_or_more': False,
                'has_complete_data': False,
                'ended_with_mismatch': False,
                'total_steps': len(all_steps_df),
                'all_steps': all_steps_df.to_dict('records')
            }
        
        # ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•¨ -> ì—°ì† ë¶ˆì¼ì¹˜ ê³„ì‚°
        max_consecutive_mismatches = 0
        current_consecutive = 0
        has_complete_data = False
        second_mismatch_step = second_validated['step']
        second_mismatch_session_id = second_validated['session_id']
        
        # ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ìŠ¤í…ë¶€í„° ì‹œì‘í•˜ì—¬ ì—°ì† ë¶ˆì¼ì¹˜ ê³„ì‚°
        for idx in range(second_validated_idx, len(all_steps_df)):
            row = all_steps_df.iloc[idx]
            
            validated_val = row['validated']
            skipped_val = row['skipped']
            is_validated = (validated_val == 1 or validated_val is True or validated_val == '1')
            is_skipped = (skipped_val == 1 or skipped_val is True or skipped_val == '1')
            
            if is_validated and not is_skipped:
                is_correct_val = row['is_correct']
                is_match = (is_correct_val == 1 or is_correct_val is True or is_correct_val == '1')
                
                if is_match:
                    # ì¼ì¹˜ë¥¼ ë§Œë‚¨ -> ì™„ì „í•œ ë°ì´í„°
                    has_complete_data = True
                    if current_consecutive > max_consecutive_mismatches:
                        max_consecutive_mismatches = current_consecutive
                    break
                else:
                    # ë¶ˆì¼ì¹˜ ê³„ì†
                    current_consecutive += 1
                    if current_consecutive > max_consecutive_mismatches:
                        max_consecutive_mismatches = current_consecutive
        
        return {
            'has_first_match': True,
            'first_match_idx': first_match_idx,
            'first_match_step': first_match_step,
            'first_match_session_id': first_non_skipped['session_id'],
            'second_is_mismatch': True,
            'second_mismatch_idx': second_validated_idx,
            'second_mismatch_step': second_mismatch_step,
            'second_mismatch_session_id': second_mismatch_session_id,
            'max_consecutive_mismatches_after_first': max_consecutive_mismatches,
            'is_below_6': max_consecutive_mismatches < 6,
            'is_6_or_more': max_consecutive_mismatches >= 6,
            'has_complete_data': has_complete_data,
            'ended_with_mismatch': not has_complete_data,
            'total_steps': len(all_steps_df),
            'all_steps': all_steps_df.to_dict('records')
        }
        
    except Exception as e:
        st.error(f"ì „ì²´ ë¼ì´ë¸Œ ê²Œì„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return {
            'has_first_match': False,
            'first_match_step': None,
            'max_consecutive_mismatches_after_first': None,
            'is_below_6': None,
            'total_steps': 0,
            'all_steps': []
        }
    finally:
        conn.close()

def analyze_first_match_hypothesis(validation_id, confidence_skip_threshold):
    """
    ì²« ì¼ì¹˜ í›„ ì—°ì† ë¶ˆì¼ì¹˜ ë¶„ì„ ë¡œì§ ì‹¤í–‰
    
    ê°€ì„¤: ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” grid_stringì€
    ë‹¤ìŒ ê²Œì„ë¶€í„° ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 6ê°œ ë¯¸ë§Œì¼ ê²ƒì´ë‹¤.
    
    Args:
        validation_id: ê²€ì¦ ì„¸ì…˜ ID
        confidence_skip_threshold: ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’
    
    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    # ìŠ¤í… ë°ì´í„° ë¡œë“œ
    steps_df = load_validation_session_steps(validation_id, confidence_skip_threshold)
    
    if len(steps_df) == 0:
        return {
            'total_grid_strings': 0,
            'grid_strings_with_first_match': 0,
            'grid_strings_with_second_mismatch': 0,
            'grid_strings_below_6': 0,
            'cases_6_or_more_complete': 0,
            'cases_6_or_more_incomplete': 0,
            'cases_6_or_more_total': 0,
            'incomplete_data_count': 0,
            'below_6_ratio': 0.0,
            'avg_max_consecutive_mismatches': 0.0,
            'max_consecutive_mismatches': 0,
            'results': [],
            'cases_6_or_more_grid_ids': []
        }
    
    # Grid Stringë³„ë¡œ ê·¸ë£¹í™”
    grid_string_ids = steps_df['grid_string_id'].unique()
    results = []
    
    for grid_string_id in grid_string_ids:
        grid_steps = steps_df[steps_df['grid_string_id'] == grid_string_id].copy()
        grid_steps = grid_steps.sort_values('step').reset_index(drop=True)
        
        # ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ ì°¾ê¸° (skipped=0ì´ê³  has_prediction=1ì¸ ê²½ìš°)
        first_non_skipped_idx = None
        for idx, row in grid_steps.iterrows():
            skipped_val = row['skipped']
            has_prediction_val = row['has_prediction']
            # skipped=0ì´ê³  has_prediction=1ì¸ ê²½ìš°ë§Œ ì²« ì˜ˆì¸¡ìœ¼ë¡œ ê°„ì£¼
            is_skipped = (skipped_val == 1 or skipped_val is True)
            has_prediction = (has_prediction_val == 1 or has_prediction_val is True)
            
            if not is_skipped and has_prediction:
                first_non_skipped_idx = idx
                break
        
        if first_non_skipped_idx is None:
            # ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì—†ëŠ” ê²½ìš°
            results.append({
                'grid_string_id': grid_string_id,
                'has_first_match': False,
                'first_match_step': None,
                'max_consecutive_mismatches_after_first': None,
                'is_below_6': None
            })
            continue
        
        first_non_skipped = grid_steps.iloc[first_non_skipped_idx]
        
        # ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì¼ì¹˜ì¸ì§€ í™•ì¸
        # is_correct: 1=True, 0=False, None=None
        is_correct_val = first_non_skipped['is_correct']
        is_match = (is_correct_val == 1 or is_correct_val is True)
        if not is_match:  # ì¼ì¹˜ê°€ ì•„ë‹˜
            results.append({
                'grid_string_id': grid_string_id,
                'has_first_match': False,
                'first_match_step': None,
                'max_consecutive_mismatches_after_first': None,
                'is_below_6': None
            })
            continue
        
        # ì²« ì¼ì¹˜ ìŠ¤í… ê¸°ë¡
        first_match_step = first_non_skipped['step']
        
        # ì²« ì¼ì¹˜ ì´í›„ ì²« ë²ˆì§¸ ê²€ì¦ëœ ìŠ¤í… ì°¾ê¸° (ë‘ ë²ˆì§¸)
        second_validated_idx = None
        for idx in range(first_non_skipped_idx + 1, len(grid_steps)):
            row = grid_steps.iloc[idx]
            validated_val = row['validated']
            skipped_val = row['skipped']
            is_validated = (validated_val == 1 or validated_val is True or validated_val == '1')
            is_skipped = (skipped_val == 1 or skipped_val is True or skipped_val == '1')
            
            if is_validated and not is_skipped:
                second_validated_idx = idx
                break
        
        # ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
        if second_validated_idx is None:
            # ì²« ì¼ì¹˜ ì´í›„ ê²€ì¦ëœ ìŠ¤í…ì´ ì—†ìŒ
            results.append({
                'grid_string_id': grid_string_id,
                'has_first_match': True,
                'first_match_step': first_match_step,
                'second_is_mismatch': False,
                'second_mismatch_step': None,
                'max_consecutive_mismatches_after_first': None,
                'is_below_6': None,
                'is_6_or_more': False,
                'has_complete_data': False,
                'ended_with_mismatch': False
            })
            continue
        
        second_validated = grid_steps.iloc[second_validated_idx]
        is_correct_val = second_validated['is_correct']
        is_second_mismatch = (is_correct_val == 0 or is_correct_val is False or is_correct_val == '0')
        
        if not is_second_mismatch:
            # ë‘ ë²ˆì§¸ê°€ ì¼ì¹˜ì„ -> ë¶„ì„ ëŒ€ìƒ ì•„ë‹˜
            results.append({
                'grid_string_id': grid_string_id,
                'has_first_match': True,
                'first_match_step': first_match_step,
                'second_is_mismatch': False,
                'second_mismatch_step': None,
                'max_consecutive_mismatches_after_first': None,
                'is_below_6': None,
                'is_6_or_more': False,
                'has_complete_data': False,
                'ended_with_mismatch': False
            })
            continue
        
        # ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•¨ -> ì—°ì† ë¶ˆì¼ì¹˜ ê³„ì‚°
        max_consecutive_mismatches = 0
        current_consecutive = 0
        has_complete_data = False  # ë‹¤ìŒ ì¼ì¹˜ê°€ ë‚˜ì™”ëŠ”ì§€ ì—¬ë¶€
        second_mismatch_step = second_validated['step']  # ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ìŠ¤í… ê¸°ë¡
        
        # ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ìŠ¤í…ë¶€í„° ì‹œì‘í•˜ì—¬ ì—°ì† ë¶ˆì¼ì¹˜ ê³„ì‚°
        for idx in range(second_validated_idx, len(grid_steps)):
            row = grid_steps.iloc[idx]
            
            validated_val = row['validated']
            skipped_val = row['skipped']
            is_validated = (validated_val == 1 or validated_val is True or validated_val == '1')
            is_skipped = (skipped_val == 1 or skipped_val is True or skipped_val == '1')
            
            if is_validated and not is_skipped:
                is_correct_val = row['is_correct']
                is_match = (is_correct_val == 1 or is_correct_val is True or is_correct_val == '1')
                
                if is_match:
                    # ì¼ì¹˜ë¥¼ ë§Œë‚¨ -> ì™„ì „í•œ ë°ì´í„°
                    has_complete_data = True
                    # í˜„ì¬ê¹Œì§€ì˜ ì—°ì† ë¶ˆì¼ì¹˜ì™€ ìµœëŒ€ê°’ ë¹„êµ
                    if current_consecutive > max_consecutive_mismatches:
                        max_consecutive_mismatches = current_consecutive
                    break  # ë‹¤ìŒ ì¼ì¹˜ë¥¼ ë§Œë‚¬ìœ¼ë¯€ë¡œ ê³„ì‚° ì¢…ë£Œ
                else:
                    # ë¶ˆì¼ì¹˜ ê³„ì†
                    current_consecutive += 1
                    if current_consecutive > max_consecutive_mismatches:
                        max_consecutive_mismatches = current_consecutive
        
        results.append({
            'grid_string_id': grid_string_id,
            'has_first_match': True,
            'first_match_step': first_match_step,
            'second_is_mismatch': True,
            'second_mismatch_step': second_mismatch_step,
            'max_consecutive_mismatches_after_first': max_consecutive_mismatches,
            'is_below_6': max_consecutive_mismatches < 6,
            'is_6_or_more': max_consecutive_mismatches >= 6,
            'has_complete_data': has_complete_data,
            'ended_with_mismatch': not has_complete_data
        })
    
    # í†µê³„ ê³„ì‚°
    total_grid_strings = len(grid_string_ids)
    grid_strings_with_first_match = sum(1 for r in results if r.get('has_first_match'))
    
    # ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” ì¼€ì´ìŠ¤ë§Œ í•„í„°ë§
    second_mismatch_results = [r for r in results if r.get('has_first_match') and r.get('second_is_mismatch') is True]
    grid_strings_with_second_mismatch = len(second_mismatch_results)
    
    # ì™„ì „í•œ ë°ì´í„°ë§Œ (ë‹¤ìŒ ì¼ì¹˜ë¥¼ ë§Œë‚œ ì¼€ì´ìŠ¤)
    complete_second_mismatch = [r for r in second_mismatch_results if r.get('has_complete_data') is True]
    
    # ë¶ˆì™„ì „í•œ ë°ì´í„° (ë¶ˆì¼ì¹˜ ìƒíƒœë¡œ ëë‚œ ì¼€ì´ìŠ¤)
    incomplete_second_mismatch = [r for r in second_mismatch_results if r.get('has_complete_data') is False]
    
    # 6ê°œ ì´ìƒ ì—°ì† ë¶ˆì¼ì¹˜ ì¼€ì´ìŠ¤ (í•µì‹¬!)
    cases_6_or_more_complete = [r for r in complete_second_mismatch if r.get('is_6_or_more') is True]
    cases_6_or_more_incomplete = [r for r in incomplete_second_mismatch if r.get('is_6_or_more') is True]
    cases_6_or_more_total = len(cases_6_or_more_complete) + len(cases_6_or_more_incomplete)
    
    # 6ê°œ ë¯¸ë§Œ ì¼€ì´ìŠ¤ (ì™„ì „í•œ ë°ì´í„°ë§Œ)
    cases_below_6 = [r for r in complete_second_mismatch if r.get('is_below_6') is True]
    grid_strings_below_6 = len(cases_below_6)
    
    # ë¹„ìœ¨ ê³„ì‚° (ì™„ì „í•œ ë°ì´í„° ê¸°ì¤€)
    below_6_ratio = (grid_strings_below_6 / len(complete_second_mismatch) * 100) if len(complete_second_mismatch) > 0 else 0.0
    
    # í‰ê·  ë° ìµœëŒ€ê°’ ê³„ì‚°
    max_mismatches_list = [r['max_consecutive_mismatches_after_first'] for r in second_mismatch_results if r['max_consecutive_mismatches_after_first'] is not None]
    avg_max_consecutive_mismatches = sum(max_mismatches_list) / len(max_mismatches_list) if len(max_mismatches_list) > 0 else 0.0
    max_consecutive_mismatches = max(max_mismatches_list) if len(max_mismatches_list) > 0 else 0
    
    return {
        'total_grid_strings': total_grid_strings,
        'grid_strings_with_first_match': grid_strings_with_first_match,
        'grid_strings_with_second_mismatch': grid_strings_with_second_mismatch,
        'grid_strings_below_6': grid_strings_below_6,
        'cases_6_or_more_complete': len(cases_6_or_more_complete),
        'cases_6_or_more_incomplete': len(cases_6_or_more_incomplete),
        'cases_6_or_more_total': cases_6_or_more_total,
        'incomplete_data_count': len(incomplete_second_mismatch),
        'below_6_ratio': below_6_ratio,
        'avg_max_consecutive_mismatches': avg_max_consecutive_mismatches,
        'max_consecutive_mismatches': max_consecutive_mismatches,
        'results': results,
        'cases_6_or_more_grid_ids': [r['grid_string_id'] for r in cases_6_or_more_complete + cases_6_or_more_incomplete]
    }

def validate_interactive_multi_step_scenario_with_confidence_skip_first_step_analysis(
    grid_string_id,
    cutoff_grid_string_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False,
    confidence_skip_threshold=51
):
    """
    ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤í‚µ ê·œì¹™ì´ ìˆëŠ” ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ (ì²« ìŠ¤í… ìŠ¤í‚µ ë¶„ì„ìš©)
    
    ê¸°ì¡´ í•¨ìˆ˜ë¥¼ ë³µì œí•˜ì—¬ ì²« ìŠ¤í… ìŠ¤í‚µ ì—¬ë¶€ì™€ ê²Œì„ ì¢…ë£Œ ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” ë…ë¦½ í•¨ìˆ˜
    
    Args:
        grid_string_id: ê²€ì¦í•  grid_stringì˜ ID
        cutoff_grid_string_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        threshold: ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
        reverse_forced_prediction: ë°˜ëŒ€ ì„ íƒ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        confidence_skip_threshold: ìŠ¤í‚µí•  ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 51)
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼ (first_step_skipped, game_end_status, last_validation_result í¬í•¨)
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string ë¡œë“œ
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        
        if len(grid_string) < window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_skipped_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'first_success_step': None,
                'first_step_skipped': False,
                'game_end_status': 'other',
                'last_validation_result': None,
                'history': []
            }
        
        # í•™ìŠµ ë°ì´í„° êµ¬ì¶•
        train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
        train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[cutoff_grid_string_id])
        train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
        
        # N-gram ë¡œë“œ
        train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
        
        if len(train_ngrams) == 0:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_skipped_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'first_success_step': None,
                'first_step_skipped': False,
                'game_end_status': 'other',
                'last_validation_result': None,
                'history': []
            }
        
        # ëª¨ë¸ êµ¬ì¶•
        if method == "ë¹ˆë„ ê¸°ë°˜":
            model = build_frequency_model(train_ngrams)
        elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
            model = build_weighted_model(train_ngrams)
        else:
            model = build_frequency_model(train_ngrams)
        
        # ì‹œë‚˜ë¦¬ì˜¤ ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        prefix_length = window_size - 1
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        consecutive_matches = 0
        max_consecutive_matches = 0
        total_steps = 0
        total_failures = 0
        total_predictions = 0
        total_forced_predictions = 0
        total_skipped_predictions = 0
        total_forced_successes = 0
        current_interval = 0
        first_success_step = None  # ì²« ë²ˆì§¸ ì„±ê³µ ìŠ¤í… ì¶”ì 
        first_step_skipped = False  # ì²« ë²ˆì§¸ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ìŠ¤í…ì—ì„œ ìŠ¤í‚µ ì—¬ë¶€
        first_prediction_encountered = False  # ì²« ë²ˆì§¸ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ìŠ¤í…ì„ ë§Œë‚¬ëŠ”ì§€ ì—¬ë¶€
        last_validation_result = None  # ë§ˆì§€ë§‰ ê²€ì¦ ê²°ê³¼
        
        # ì´ˆê¸° prefix ìƒì„±
        if len(grid_string) < prefix_length:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'max_consecutive_matches': 0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_forced_predictions': 0,
                'total_skipped_predictions': 0,
                'forced_prediction_rate': 0.0,
                'accuracy': 0.0,
                'first_success_step': None,
                'first_step_skipped': False,
                'game_end_status': 'other',
                'last_validation_result': None,
                'history': []
            }
        
        current_prefix = grid_string[:prefix_length]
        
        # ê° ìŠ¤í…ë§ˆë‹¤ ì˜ˆì¸¡
        i = prefix_length
        while i < len(grid_string):
            total_steps += 1
            actual_value = grid_string[i]
            
            # ì˜ˆì¸¡ ìˆ˜í–‰ (ê¸°ë³¸ ê·œì¹™: ëª¨ë“  ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ ì‹œë„)
            if use_threshold:
                # ì„ê³„ê°’ ì „ëµ ì‚¬ìš©: ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡, ì•„ë‹ˆë©´ ê°•ì œ ì˜ˆì¸¡
                prediction_result = predict_with_fallback_interval(
                    model,
                    current_prefix,
                    method=method,
                    threshold=threshold,
                    max_interval=max_interval,
                    current_interval=current_interval
                )
            else:
                # ì„ê³„ê°’ ì „ëµ ë¯¸ì‚¬ìš©: ëª¨ë“  ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ (ê¸°ë³¸ ê·œì¹™)
                prediction_result = predict_for_prefix(model, current_prefix, method)
                # predict_for_prefixëŠ” í•­ìƒ ì˜ˆì¸¡ê°’ì„ ë°˜í™˜í•˜ê±°ë‚˜ Noneì„ ë°˜í™˜
                # Noneì¸ ê²½ìš°ë„ ìˆìœ¼ë¯€ë¡œ is_forcedëŠ” Falseë¡œ ì„¤ì •
                if 'is_forced' not in prediction_result:
                    prediction_result['is_forced'] = False
            
            predicted_value = prediction_result.get('predicted')
            confidence = prediction_result.get('confidence', 0.0)
            is_forced = prediction_result.get('is_forced', False)
            
            # ë°˜ëŒ€ ì„ íƒ ì „ëµ: ê°•ì œ ì˜ˆì¸¡ ì‹œ ë°˜ëŒ€ ê°’ ì„ íƒ
            if is_forced and reverse_forced_prediction and predicted_value is not None:
                predicted_value = 'p' if predicted_value == 'b' else 'b'
            
            has_prediction = predicted_value is not None
            
            # ì²« ë²ˆì§¸ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ìŠ¤í… ê°ì§€ ë° ìŠ¤í‚µ ì—¬ë¶€ ì¶”ì 
            if has_prediction and not first_prediction_encountered:
                first_prediction_encountered = True
                # ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤í‚µ ê·œì¹™ ì²´í¬
                if use_threshold and is_forced and confidence < confidence_skip_threshold:
                    first_step_skipped = True
            
            # ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤í‚µ ê·œì¹™ ì²´í¬
            should_skip = False
            # ê¸°ë³¸ ê·œì¹™: use_threshold=Falseì¼ ë•ŒëŠ” ëª¨ë“  ì˜ˆì¸¡ê°’ì— ëŒ€í•´ ê²€ì¦ ìˆ˜í–‰
            # ìŠ¤í‚µ ê·œì¹™ì€ use_threshold=Trueì´ê³  ê°•ì œ ì˜ˆì¸¡ì¼ ë•Œë§Œ ì ìš©
            if use_threshold and has_prediction and is_forced and confidence < confidence_skip_threshold:
                # ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì¤‘ì´ê³ , ê°•ì œ ì˜ˆì¸¡ì´ê³  ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
                should_skip = True
                total_skipped_predictions += 1
            
            # ê²€ì¦ ìˆ˜í–‰ ì—¬ë¶€ ê²°ì • (ê¸°ë³¸ ê·œì¹™: ì˜ˆì¸¡ê°’ì´ ìˆìœ¼ë©´ í•­ìƒ ê²€ì¦)
            is_correct = None
            should_validate = False
            
            if has_prediction and not should_skip:
                # ê¸°ë³¸ ê·œì¹™: ì˜ˆì¸¡ê°’ì´ ìˆê³  ìŠ¤í‚µí•˜ì§€ ì•Šìœ¼ë©´ í•­ìƒ ê²€ì¦ ìˆ˜í–‰
                should_validate = True
                is_correct = predicted_value == actual_value
                
                if not is_correct:
                    consecutive_failures += 1
                    consecutive_matches = 0
                    total_failures += 1
                    if consecutive_failures > max_consecutive_failures:
                        max_consecutive_failures = consecutive_failures
                else:
                    consecutive_failures = 0
                    consecutive_matches += 1
                    if consecutive_matches > max_consecutive_matches:
                        max_consecutive_matches = consecutive_matches
                    # ì²« ë²ˆì§¸ ì„±ê³µ ìŠ¤í… ê¸°ë¡
                    if first_success_step is None:
                        first_success_step = total_steps
                
                total_predictions += 1
                if is_forced:
                    total_forced_predictions += 1
                    if is_correct:
                        total_forced_successes += 1
                
                # ë§ˆì§€ë§‰ ê²€ì¦ ê²°ê³¼ ì—…ë°ì´íŠ¸
                last_validation_result = 'match' if is_correct else 'mismatch'
                
                # ê²€ì¦ í›„ ê°„ê²© ë¦¬ì…‹
                current_interval = 0
                
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                history.append({
                    'step': total_steps,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': has_prediction,
                    'validated': True,
                    'skipped': False
                })
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰
                i += 1
                current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
            elif has_prediction and should_skip:
                # ìŠ¤í‚µ: ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰í•˜ë˜ ê°„ê²©ì€ ì¦ê°€í•˜ì§€ ì•ŠìŒ (ë©ˆì¶¤)
                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                history.append({
                    'step': total_steps,
                    'prefix': current_prefix,
                    'predicted': predicted_value,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': is_forced,
                    'current_interval': current_interval,
                    'has_prediction': has_prediction,
                    'validated': False,
                    'skipped': True
                })
                
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰ (ê°„ê²©ì€ ì¦ê°€í•˜ì§€ ì•ŠìŒ - ë©ˆì¶¤ ìƒíƒœ)
                i += 1
                current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
                # current_intervalì€ ì¦ê°€í•˜ì§€ ì•ŠìŒ (ë©ˆì¶¤)
            else:
                # ì˜ˆì¸¡ê°’ì´ ì—†ìŒ: ê°„ê²© ì¦ê°€
                history.append({
                    'step': total_steps,
                    'prefix': current_prefix,
                    'predicted': None,
                    'actual': actual_value,
                    'is_correct': None,
                    'confidence': confidence,
                    'is_forced': False,
                    'current_interval': current_interval,
                    'has_prediction': False,
                    'validated': False,
                    'skipped': False
                })
                
                current_interval += 1
                # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰
                i += 1
                current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = ((total_predictions - total_failures) / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ ê³„ì‚°
        forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
        
        # ê°•ì œ ì˜ˆì¸¡ ì„±ê³µ ë¹„ìœ¨ ê³„ì‚°
        forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
        
        # ê²Œì„ ì¢…ë£Œ ìƒíƒœ íŒë‹¨
        if last_validation_result == 'match':
            game_end_status = 'match_end'
        elif max_consecutive_failures >= 6:
            game_end_status = 'mismatch_6plus'
        else:
            game_end_status = 'other'
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'max_consecutive_matches': max_consecutive_matches,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'total_predictions': total_predictions,
            'total_forced_predictions': total_forced_predictions,
            'total_skipped_predictions': total_skipped_predictions,
            'forced_prediction_rate': forced_prediction_rate,
            'forced_success_rate': forced_success_rate,
            'accuracy': accuracy,
            'first_success_step': first_success_step,  # ì²« ë²ˆì§¸ ì„±ê³µ ìŠ¤í…
            'first_step_skipped': first_step_skipped,  # ì²« ìŠ¤í… ìŠ¤í‚µ ì—¬ë¶€
            'game_end_status': game_end_status,  # ê²Œì„ ì¢…ë£Œ ìƒíƒœ
            'last_validation_result': last_validation_result,  # ë§ˆì§€ë§‰ ê²€ì¦ ê²°ê³¼
            'history': history
        }
        
    except Exception as e:
        st.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_with_first_step_skip_analysis(
    cutoff_grid_string_id,
    window_size=7,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_threshold=True,
    threshold=60,
    max_interval=6,
    reverse_forced_prediction=False,
    confidence_skip_threshold=51
):
    """
    ì²« ìŠ¤í… ìŠ¤í‚µ ë¶„ì„ì„ ìœ„í•œ ì‹ ë¢°ë„ ê¸°ë°˜ ìŠ¤í‚µ ê·œì¹™ ë°°ì¹˜ ê²€ì¦ (ë…ë¦½)
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        threshold: ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
        reverse_forced_prediction: ë°˜ëŒ€ ì„ íƒ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        confidence_skip_threshold: ìŠ¤í‚µí•  ì‹ ë¢°ë„ ì„ê³„ê°’
    
    Returns:
        dict: ë°°ì¹˜ ê²€ì¦ ê²°ê³¼ (first_step_skipped, game_end_status í¬í•¨)
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff_grid_string_id ì´í›„ì˜ ëª¨ë“  grid_string ë¡œë“œ
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0,
                    'total_steps': 0,
                    'total_failures': 0,
                    'total_predictions': 0,
                    'total_skipped_predictions': 0,
                    'prediction_rate': 0.0
                },
                'grid_string_ids': []
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        all_history = []  # ì‹ ë¢°ë„ í†µê³„ ìˆ˜ì§‘ìš©
        
        # ê° grid_stringì— ëŒ€í•´ ê²€ì¦ ì‹¤í–‰
        for grid_string_id in grid_string_ids:
            result = validate_interactive_multi_step_scenario_with_confidence_skip_first_step_analysis(
                grid_string_id,
                cutoff_grid_string_id,
                window_size=window_size,
                method=method,
                use_threshold=use_threshold,
                threshold=threshold,
                max_interval=max_interval,
                reverse_forced_prediction=reverse_forced_prediction,
                confidence_skip_threshold=confidence_skip_threshold
            )
            
            if result is not None:
                results.append(result)
                # íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ (ì‹ ë¢°ë„ í†µê³„ìš©)
                all_history.extend(result.get('history', []))
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            total_steps = sum(r['total_steps'] for r in results)
            total_failures = sum(r['total_failures'] for r in results)
            total_predictions = sum(r['total_predictions'] for r in results)
            total_skipped_predictions = sum(r.get('total_skipped_predictions', 0) for r in results)
            total_forced_predictions = sum(r.get('total_forced_predictions', 0) for r in results)
            total_forced_successes = sum(r.get('total_forced_successes', 0) for r in results)
            prediction_rate = (total_predictions / total_steps * 100) if total_steps > 0 else 0.0
            forced_prediction_rate = (total_forced_predictions / total_predictions * 100) if total_predictions > 0 else 0.0
            forced_success_rate = (total_forced_successes / total_forced_predictions * 100) if total_forced_predictions > 0 else 0.0
            
            # ì²« ë²ˆì§¸ ì„±ê³µ ìŠ¤í… í†µê³„
            first_success_steps = [r.get('first_success_step') for r in results if r.get('first_success_step') is not None]
            avg_first_success_step = sum(first_success_steps) / len(first_success_steps) if len(first_success_steps) > 0 else None
            min_first_success_step = min(first_success_steps) if len(first_success_steps) > 0 else None
            max_first_success_step = max(first_success_steps) if len(first_success_steps) > 0 else None
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': total_steps,
                'total_failures': total_failures,
                'total_predictions': total_predictions,
                'total_skipped_predictions': total_skipped_predictions,
                'total_forced_predictions': total_forced_predictions,
                'total_forced_successes': total_forced_successes,
                'prediction_rate': prediction_rate,
                'forced_prediction_rate': forced_prediction_rate,
                'forced_success_rate': forced_success_rate,
                'avg_first_success_step': avg_first_success_step,
                'min_first_success_step': min_first_success_step,
                'max_first_success_step': max_first_success_step,
                'total_with_success': len(first_success_steps)  # ì„±ê³µì´ ìˆì—ˆë˜ grid_string ìˆ˜
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0,
                'total_predictions': 0,
                'total_skipped_predictions': 0,
                'total_forced_predictions': 0,
                'total_forced_successes': 0,
                'prediction_rate': 0.0,
                'forced_prediction_rate': 0.0,
                'forced_success_rate': 0.0
            }
        
        return {
            'results': results,
            'summary': summary,
            'all_history': all_history,  # ì‹ ë¢°ë„ í†µê³„ ìˆ˜ì§‘ìš©
            'grid_string_ids': grid_string_ids  # ê²€ì¦í•œ grid_string_id ë¦¬ìŠ¤íŠ¸
        }
        
    except Exception as e:
        st.error(f"ë°°ì¹˜ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    finally:
        conn.close()

def save_first_step_skip_analysis_results(
    cutoff_grid_string_id,
    window_size,
    method,
    use_threshold,
    threshold,
    max_interval,
    confidence_skip_threshold,
    batch_results,
    grid_string_ids=None
):
    """
    ì²« ìŠ¤í… ìŠ¤í‚µ ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥ (ë…ë¦½)
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        use_threshold: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€
        threshold: ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
        confidence_skip_threshold: ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’
        batch_results: ë°°ì¹˜ ê²€ì¦ ê²°ê³¼
        grid_string_ids: ê²€ì¦í•œ grid_string_id ë¦¬ìŠ¤íŠ¸ (ì„ íƒì )
    
    Returns:
        str: validation_id (ì €ì¥ ì„±ê³µ ì‹œ), None (ì‹¤íŒ¨ ì‹œ)
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    cursor = conn.cursor()
    
    try:
        # validation_id ìƒì„± (UUID)
        validation_id = str(uuid.uuid4())
        
        # 1. ê²€ì¦ ì„¸ì…˜ ì €ì¥
        cursor.execute('''
            INSERT INTO first_step_skip_analysis_sessions (
                validation_id, cutoff_grid_string_id, window_size, method,
                use_threshold, threshold, max_interval,
                confidence_skip_threshold, created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
        ''', (
            validation_id,
            cutoff_grid_string_id,
            window_size,
            method,
            use_threshold,
            threshold if use_threshold else None,
            max_interval,
            confidence_skip_threshold
        ))
        
        # 2. Grid Stringë³„ ê²°ê³¼ ì €ì¥
        if batch_results and 'results' in batch_results:
            for result in batch_results['results']:
                cursor.execute('''
                    INSERT OR REPLACE INTO first_step_skip_analysis_results (
                        validation_id, confidence_skip_threshold, grid_string_id,
                        max_consecutive_failures, total_steps, total_failures,
                        total_predictions, total_skipped_predictions,
                        accuracy, forced_prediction_rate, forced_success_rate,
                        first_success_step, first_step_skipped, game_end_status,
                        last_validation_result, created_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                ''', (
                    validation_id,
                    confidence_skip_threshold,
                    result.get('grid_string_id'),
                    result.get('max_consecutive_failures', 0),
                    result.get('total_steps', 0),
                    result.get('total_failures', 0),
                    result.get('total_predictions', 0),
                    result.get('total_skipped_predictions', 0),
                    result.get('accuracy', 0.0),
                    result.get('forced_prediction_rate', 0.0),
                    result.get('forced_success_rate', 0.0),
                    result.get('first_success_step'),
                    1 if result.get('first_step_skipped', False) else 0,
                    result.get('game_end_status', 'other'),
                    result.get('last_validation_result')
                ))
        
        # 3. ì˜ˆì¸¡ê°’ í…Œì´ë¸” ìŠ¤ëƒ…ìƒ· ì €ì¥ (ê²€ì¦ ì‹œì ì— ì‹¤ì‹œê°„ ê³„ì‚°)
        snapshot_threshold = threshold if use_threshold else 0.0
        
        try:
            # í•™ìŠµ ë°ì´í„° êµ¬ì¶•
            train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
            train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[cutoff_grid_string_id])
            train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
            
            if len(train_ids) > 0:
                # N-gram ë¡œë“œ
                train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
                
                if len(train_ngrams) > 0:
                    # ëª¨ë¸ êµ¬ì¶•
                    if method == "ë¹ˆë„ ê¸°ë°˜":
                        model = build_frequency_model(train_ngrams)
                    elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                        model = build_weighted_model(train_ngrams)
                    else:
                        model = build_frequency_model(train_ngrams)
                    
                    # í•™ìŠµ ë°ì´í„°ì—ì„œ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ëª¨ë“  prefix ì¶”ì¶œ
                    prefixes = set()
                    for ngram in train_ngrams:
                        if len(ngram) >= window_size:
                            prefix = ngram[:window_size-1]
                            prefixes.add(prefix)
                    
                    # ê° prefixì— ëŒ€í•´ ì˜ˆì¸¡ê°’ ê³„ì‚° ë° ì €ì¥
                    snapshot_count = 0
                    for prefix in prefixes:
                        prediction_result = predict_for_prefix(model, prefix, method)
                        predicted_value = prediction_result.get('predicted')
                        confidence = prediction_result.get('confidence', 0.0)
                        ratios = prediction_result.get('ratios', {})
                        b_ratio = ratios.get('b', 0.0) if ratios else 0.0
                        p_ratio = ratios.get('p', 0.0) if ratios else 0.0
                        
                        cursor.execute('''
                            INSERT INTO validation_session_prediction_snapshots (
                                validation_id, window_size, prefix, predicted_value,
                                confidence, b_ratio, p_ratio, method, threshold,
                                snapshot_created_at
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                        ''', (
                            validation_id, window_size, prefix, predicted_value,
                            confidence, b_ratio, p_ratio, method, snapshot_threshold
                        ))
                        snapshot_count += 1
                    
                    if snapshot_count > 0:
                        st.info(f"ì˜ˆì¸¡ê°’ ìŠ¤ëƒ…ìƒ· {snapshot_count}ê°œ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            # ì˜ˆì¸¡ê°’ ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨í•´ë„ ì„¸ì…˜ ì €ì¥ì€ ê³„ì† ì§„í–‰
            st.warning(f"ì˜ˆì¸¡ê°’ ìŠ¤ëƒ…ìƒ· ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì„¸ì…˜ì€ ì €ì¥ë¨): {str(e)}")
        
        # 4. Grid String ID ë¦¬ìŠ¤íŠ¸ ì €ì¥
        if grid_string_ids and len(grid_string_ids) > 0:
            for order, grid_string_id in enumerate(grid_string_ids, start=1):
                cursor.execute('''
                    INSERT OR REPLACE INTO validation_session_grid_strings (
                        validation_id, grid_string_id, sequence_order, created_at
                    ) VALUES (?, ?, ?, datetime('now', '+9 hours'))
                ''', (validation_id, grid_string_id, order))
        
        conn.commit()
        return validation_id
        
    except Exception as e:
        conn.rollback()
        st.error(f"ê²€ì¦ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def analyze_first_step_skip_correlation(validation_id):
    """
    ì²« ìŠ¤í… ìŠ¤í‚µê³¼ ìŠ¹ë¥ ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
    
    Args:
        validation_id: ë¶„ì„í•  validation_id
    
    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # ì™„ì „í•œ ê²Œì„ë§Œ í•„í„°ë§ (game_end_status IN ('match_end', 'mismatch_6plus'))
        query = '''
            SELECT 
                first_step_skipped,
                accuracy,
                max_consecutive_failures,
                game_end_status
            FROM first_step_skip_analysis_results
            WHERE validation_id = ?
              AND game_end_status IN ('match_end', 'mismatch_6plus')
        '''
        df = pd.read_sql_query(query, conn, params=[validation_id])
        
        if len(df) == 0:
            return {
                'total_complete_games': 0,
                'skip_start_count': 0,
                'non_skip_start_count': 0,
                'skip_start_avg_accuracy': None,
                'non_skip_start_avg_accuracy': None,
                'skip_start_outlier_rate': None,
                'non_skip_start_outlier_rate': None,
                'skip_start_outlier_count': 0,
                'non_skip_start_outlier_count': 0
            }
        
        # ìŠ¤í‚µìœ¼ë¡œ ì‹œì‘í•œ ê²Œì„ê³¼ ê·¸ë ‡ì§€ ì•Šì€ ê²Œì„ ë¶„ë¦¬
        skip_start = df[df['first_step_skipped'] == 1]
        non_skip_start = df[df['first_step_skipped'] == 0]
        
        # ì´ìƒì¹˜ (ë¶ˆì¼ì¹˜ 6ê°œ ì´ìƒ) ë°œìƒ ë¹„ìœ¨
        skip_start_outliers = skip_start[skip_start['max_consecutive_failures'] >= 6]
        non_skip_start_outliers = non_skip_start[non_skip_start['max_consecutive_failures'] >= 6]
        
        # í†µê³„ ê³„ì‚°
        total_complete_games = len(df)
        skip_start_count = len(skip_start)
        non_skip_start_count = len(non_skip_start)
        
        skip_start_avg_accuracy = skip_start['accuracy'].mean() if len(skip_start) > 0 else None
        non_skip_start_avg_accuracy = non_skip_start['accuracy'].mean() if len(non_skip_start) > 0 else None
        
        skip_start_outlier_count = len(skip_start_outliers)
        non_skip_start_outlier_count = len(non_skip_start_outliers)
        
        skip_start_outlier_rate = (skip_start_outlier_count / skip_start_count * 100) if skip_start_count > 0 else None
        non_skip_start_outlier_rate = (non_skip_start_outlier_count / non_skip_start_count * 100) if non_skip_start_count > 0 else None
        
        return {
            'total_complete_games': total_complete_games,
            'skip_start_count': skip_start_count,
            'non_skip_start_count': non_skip_start_count,
            'skip_start_avg_accuracy': skip_start_avg_accuracy,
            'non_skip_start_avg_accuracy': non_skip_start_avg_accuracy,
            'skip_start_outlier_rate': skip_start_outlier_rate,
            'non_skip_start_outlier_rate': non_skip_start_outlier_rate,
            'skip_start_outlier_count': skip_start_outlier_count,
            'non_skip_start_outlier_count': non_skip_start_outlier_count,
            'skip_start_df': skip_start,
            'non_skip_start_df': non_skip_start
        }
        
    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def main():
    st.title("ğŸ“Š ì‹ ë¢°ë„ ìŠ¤í‚µ ì „ëµ ê°€ì„¤ ê²€ì¦ ë¶„ì„")
    st.markdown("""
    **ê°€ì„¤**: ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” grid_stringì€
    ë‹¤ìŒ ê²Œì„ë¶€í„° ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 6ê°œ ë¯¸ë§Œì¼ ê²ƒì´ë‹¤.
    """)
    
    # ê²€ì¦ ì„¸ì…˜ ì„ íƒ
    st.markdown("---")
    st.markdown("### ê²€ì¦ ì„¸ì…˜ ì„ íƒ")
    
    sessions_df = load_validation_sessions()
    
    if len(sessions_df) == 0:
        st.warning("âš ï¸ ì €ì¥ëœ ê²€ì¦ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ê²€ì¦ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•´ì£¼ì„¸ìš”.")
        return
    
    # ì„¸ì…˜ ì„ íƒ UI
    session_options = []
    for _, row in sessions_df.iterrows():
        display_text = (
            f"ID: {row['validation_id'][:8]}... | "
            f"ì„ê³„ê°’: {row['confidence_skip_threshold_1']:.1f}% / {row['confidence_skip_threshold_2']:.1f}% | "
            f"ìœˆë„ìš°: {row['window_size']} | "
            f"ìƒì„±ì¼: {row['created_at']}"
        )
        session_options.append((row['validation_id'], display_text))
    
    selected_session_id = st.selectbox(
        "ê²€ì¦ ì„¸ì…˜ ì„ íƒ",
        options=[opt[0] for opt in session_options],
        format_func=lambda x: next((opt[1] for opt in session_options if opt[0] == x), x),
        key="selected_validation_session"
    )
    
    if selected_session_id:
        selected_session = sessions_df[sessions_df['validation_id'] == selected_session_id].iloc[0]
        
        # ì„¸ì…˜ ì •ë³´ í‘œì‹œ
        st.markdown("---")
        st.markdown("### ê²€ì¦ ì„¸ì…˜ ì •ë³´")
        col_info1, col_info2, col_info3, col_info4 = st.columns(4)
        with col_info1:
            st.metric("ìœˆë„ìš° í¬ê¸°", selected_session['window_size'])
        with col_info2:
            st.metric("ì˜ˆì¸¡ ë°©ë²•", selected_session['method'])
        with col_info3:
            st.metric("ì„ê³„ê°’ 1", f"{selected_session['confidence_skip_threshold_1']:.1f}%")
        with col_info4:
            st.metric("ì„ê³„ê°’ 2", f"{selected_session['confidence_skip_threshold_2']:.1f}%")
        
        # ì„ê³„ê°’ ì„ íƒ
        st.markdown("---")
        st.markdown("### ë¶„ì„í•  ì„ê³„ê°’ ì„ íƒ")
        threshold_option = st.radio(
            "ë¶„ì„í•  ì‹ ë¢°ë„ ìŠ¤í‚µ ì„ê³„ê°’",
            options=[selected_session['confidence_skip_threshold_1'], selected_session['confidence_skip_threshold_2']],
            format_func=lambda x: f"{x:.1f}%",
            key="validation_threshold_radio"
        )
        
        # ë¶„ì„ ì‹¤í–‰
        if st.button("ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True):
            st.session_state.analysis_results = analyze_first_match_hypothesis(
                selected_session_id,
                threshold_option
            )
            st.session_state.selected_validation_id = selected_session_id
            st.session_state.selected_validation_threshold = threshold_option
            st.rerun()
        
        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if 'analysis_results' in st.session_state and st.session_state.get('selected_validation_id') == selected_session_id and st.session_state.get('selected_validation_threshold') == threshold_option:
            results = st.session_state.analysis_results
            
            st.markdown("---")
            st.markdown("### ê°€ì„¤ ê²€ì¦ ê²°ê³¼")
            
            # í•µì‹¬ ì§€í‘œ ê°•ì¡°
            col_key1, col_key2, col_key3 = st.columns(3)
            with col_key1:
                st.metric(
                    "ğŸ”¥ 6ê°œ ì´ìƒ ì—°ì† ë¶ˆì¼ì¹˜", 
                    f"{results.get('cases_6_or_more_total', 0)}ê°œ",
                    help="ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•˜ì—¬ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 6ê°œ ì´ìƒì¸ ì¼€ì´ìŠ¤"
                )
            with col_key2:
                st.metric(
                    "ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘", 
                    f"{results.get('grid_strings_with_second_mismatch', 0)}ê°œ"
                )
            with col_key3:
                st.metric(
                    "ì™„ì „í•œ ë°ì´í„° ì¤‘ 6ê°œ ì´ìƒ", 
                    f"{results.get('cases_6_or_more_complete', 0)}ê°œ"
                )
            
            st.markdown("---")
            
            # ì¼ë°˜ í†µê³„
            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
            with col_stat1:
                st.metric("ì²« ì¼ì¹˜ Grid String ìˆ˜", f"{results['grid_strings_with_first_match']}")
            with col_stat2:
                st.metric("6ê°œ ë¯¸ë§Œ ë¹„ìœ¨", f"{results['below_6_ratio']:.2f}%")
            with col_stat3:
                st.metric("í‰ê·  ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", f"{results['avg_max_consecutive_mismatches']:.2f}")
            with col_stat4:
                st.metric("ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", f"{results['max_consecutive_mismatches']}")
            
            # ê°€ì„¤ ê²€ì¦ ê²°ê³¼
            st.markdown("---")
            st.markdown("### ê°€ì„¤ ê²€ì¦ ìš”ì•½")
            
            if results['grid_strings_with_first_match'] > 0:
                below_6_count = results['grid_strings_below_6']
                total_count = results['grid_strings_with_first_match']
                ratio = results['below_6_ratio']
                
                if ratio >= 50:
                    st.success(f"âœ… ê°€ì„¤ ì§€ì§€: {below_6_count}/{total_count} ({ratio:.2f}%)ì˜ grid_stringì´ 6ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
                else:
                    st.warning(f"âš ï¸ ê°€ì„¤ ë°˜ë°•: {below_6_count}/{total_count} ({ratio:.2f}%)ì˜ grid_stringë§Œ 6ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
                
                # ìƒì„¸ í†µê³„
                col_detail1, col_detail2 = st.columns(2)
                with col_detail1:
                    st.metric("6ê°œ ë¯¸ë§Œ", f"{below_6_count}ê°œ")
                with col_detail2:
                    st.metric("6ê°œ ì´ìƒ (ì™„ì „í•œ ë°ì´í„°)", f"{results.get('cases_6_or_more_complete', 0)}ê°œ")
                
                # íˆìŠ¤í† ê·¸ë¨ (ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ì¸ ì¼€ì´ìŠ¤ë§Œ)
                st.markdown("---")
                st.markdown("### ì—°ì† ë¶ˆì¼ì¹˜ ë¶„í¬ (ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•œ ì¼€ì´ìŠ¤)")
                
                # ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ì¸ ì¼€ì´ìŠ¤ë§Œ í•„í„°ë§í•˜ê³  None ì œì™¸
                max_mismatches_list = [
                    r['max_consecutive_mismatches_after_first'] 
                    for r in results['results'] 
                    if r.get('has_first_match') 
                    and r.get('second_is_mismatch') 
                    and r.get('max_consecutive_mismatches_after_first') is not None
                ]
                
                if len(max_mismatches_list) > 0:
                    bins = defaultdict(int)
                    for value in max_mismatches_list:
                        if value < 6:
                            bins['0-5'] += 1
                        elif value < 10:
                            bins['6-9'] += 1
                        elif value < 15:
                            bins['10-14'] += 1
                        else:
                            bins['15+'] += 1
                    
                    # íˆìŠ¤í† ê·¸ë¨ í‘œì‹œ
                    max_count = max(bins.values()) if bins else 1
                    total_count = len(max_mismatches_list)
                    
                    for bin_range in ['0-5', '6-9', '10-14', '15+']:
                        count = bins.get(bin_range, 0)
                        ratio = (count / total_count * 100) if total_count > 0 else 0
                        bar_length = int((count / max_count) * 50) if max_count > 0 else 0
                        bar = 'â–ˆ' * bar_length
                        st.text(f"{bin_range:>8}: {bar} {count:>4}ê°œ ({ratio:>5.2f}%)")
                else:
                    st.info("íˆìŠ¤í† ê·¸ë¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë¶ˆì™„ì „í•œ ë°ì´í„° ì•Œë¦¼
            if results.get('incomplete_data_count', 0) > 0:
                st.info(f"â„¹ï¸ {results['incomplete_data_count']}ê°œì˜ grid_stringì€ ë¶ˆì¼ì¹˜ ìƒíƒœë¡œ ì¢…ë£Œë˜ì–´ í†µê³„ì—ì„œ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. (ì „ì²´ ë°ì´í„° í…Œì´ë¸”ì—ì„œ í™•ì¸ ê°€ëŠ¥)")
            
            # 6ê°œ ì´ìƒ ì¼€ì´ìŠ¤ ê°•ì¡° í‘œì‹œ
            if results.get('cases_6_or_more_total', 0) > 0:
                st.markdown("---")
                st.warning(f"âš ï¸ **ì¤‘ìš”**: {results['cases_6_or_more_total']}ê°œì˜ grid_stringì—ì„œ ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•˜ì—¬ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 6ê°œ ì´ìƒ ë°œìƒí–ˆìŠµë‹ˆë‹¤!")
                
                # 6ê°œ ì´ìƒ ì¼€ì´ìŠ¤ ìƒì„¸ ì •ë³´
                st.markdown("#### ğŸ”¥ 6ê°œ ì´ìƒ ì—°ì† ë¶ˆì¼ì¹˜ ì¼€ì´ìŠ¤")
                cases_6_or_more = [r for r in results['results'] 
                                   if r.get('has_first_match') and r.get('second_is_mismatch') and r.get('is_6_or_more')]
                
                if cases_6_or_more:
                    critical_data = []
                    for r in cases_6_or_more:
                        critical_data.append({
                            'Grid String ID': r['grid_string_id'],
                            'ì²« ì¼ì¹˜ Step': r['first_match_step'],
                            'ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ Step': r.get('second_mismatch_step'),
                            'ì—°ì† ë¶ˆì¼ì¹˜ ê°œìˆ˜': r['max_consecutive_mismatches_after_first'],
                            'ì™„ì „ ì—¬ë¶€': "âœ… ì™„ë£Œ" if r.get('has_complete_data') else "âš ï¸ ë¶ˆì™„ì „",
                            'ìƒíƒœ': "âŒ ê°€ì„¤ ë°˜ë°•" if r.get('is_6_or_more') else "âœ… ê°€ì„¤ ì§€ì§€"
                        })
                    
                    critical_df = pd.DataFrame(critical_data)
                    st.dataframe(critical_df, use_container_width=True, hide_index=True)
            else:
                st.info("ğŸ’¡ ì²« ì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # Grid Stringë³„ ìƒì„¸ ê²°ê³¼
            st.markdown("---")
            st.markdown("### Grid Stringë³„ ìƒì„¸ ê²°ê³¼")
            
            results_df_data = []
            for r in results['results']:
                if r.get('has_first_match'):
                    if r.get('second_is_mismatch'):
                        max_mismatches = r['max_consecutive_mismatches_after_first']
                        below_6_status = 'âœ… ì˜ˆ' if r.get('is_below_6') else 'âŒ ì•„ë‹ˆì˜¤'
                        status = "âœ… ì™„ë£Œ" if r.get('has_complete_data') else "âš ï¸ ë¶ˆì™„ì „"
                        is_critical = "ğŸ”¥" if r.get('is_6_or_more') else ""
                        results_df_data.append({
                            'Grid String ID': r['grid_string_id'],
                            'ì²« ì¼ì¹˜ Step': r['first_match_step'],
                            'ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ Step': r.get('second_mismatch_step'),
                            'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': max_mismatches,
                            '6ê°œ ë¯¸ë§Œ': below_6_status,
                            'ìƒíƒœ': f"{is_critical} {status}"
                        })
                    else:
                        results_df_data.append({
                            'Grid String ID': r['grid_string_id'],
                            'ì²« ì¼ì¹˜ Step': r['first_match_step'],
                            'ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ Step': '-',
                            'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': '-',
                            '6ê°œ ë¯¸ë§Œ': '-',
                            'ìƒíƒœ': '- (ë‘ ë²ˆì§¸ê°€ ì¼ì¹˜)'
                        })
                else:
                    results_df_data.append({
                        'Grid String ID': r['grid_string_id'],
                        'ì²« ì¼ì¹˜ Step': '-',
                        'ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ Step': '-',
                        'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': '-',
                        '6ê°œ ë¯¸ë§Œ': '-',
                        'ìƒíƒœ': '-'
                    })
            
            if len(results_df_data) > 0:
                results_df = pd.DataFrame(results_df_data)
                st.dataframe(results_df, use_container_width=True, hide_index=True)
                
                # ìƒì„¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ëª¨ë“  Grid Stringì— ëŒ€í•´)
                st.markdown("---")
                st.markdown("#### ìƒì„¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ")
                
                # ì²« ì¼ì¹˜ê°€ ìˆëŠ” Grid Stringë§Œ ì„ íƒ ëª©ë¡ì— í¬í•¨
                first_match_grid_ids = [r['grid_string_id'] for r in results['results'] if r['has_first_match']]
                
                if len(first_match_grid_ids) > 0:
                    selected_grid_id = st.selectbox(
                        "Grid String ì„ íƒ (ìƒì„¸ íˆìŠ¤í† ë¦¬ ë³´ê¸°)",
                        options=[None] + first_match_grid_ids,
                        format_func=lambda x: "ì„ íƒ ì•ˆí•¨" if x is None else f"ID {x}",
                        key="selected_grid_id_for_history"
                    )
                    
                    if selected_grid_id:
                        steps_df = load_validation_session_steps(selected_session_id, threshold_option)
                        grid_steps = steps_df[steps_df['grid_string_id'] == selected_grid_id].copy()
                        grid_steps = grid_steps.sort_values('step').reset_index(drop=True)
                        
                        # ì„ íƒëœ Grid Stringì˜ ê²°ê³¼ ì°¾ê¸°
                        selected_result = next((r for r in results['results'] if r['grid_string_id'] == selected_grid_id), None)
                        first_match_step = selected_result['first_match_step'] if selected_result and selected_result.get('has_first_match') else None
                        second_mismatch_step = selected_result.get('second_mismatch_step') if selected_result and selected_result.get('second_is_mismatch') else None
                        max_consecutive_mismatches = selected_result['max_consecutive_mismatches_after_first'] if selected_result and selected_result.get('has_first_match') and selected_result.get('second_is_mismatch') else None
                        
                        st.markdown(f"**Grid String ID: {selected_grid_id}**")
                        if first_match_step:
                            st.markdown(f"- ì²« ì¼ì¹˜ ìŠ¤í…: {first_match_step}")
                        if second_mismatch_step:
                            st.markdown(f"- ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ìŠ¤í…: {second_mismatch_step}")
                        if max_consecutive_mismatches is not None:
                            st.markdown(f"- ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜: {max_consecutive_mismatches}ê°œ")
                            if selected_result.get('is_6_or_more'):
                                st.error(f"ğŸ”¥ **ì¤‘ìš”**: ì—°ì† ë¶ˆì¼ì¹˜ê°€ {max_consecutive_mismatches}ê°œë¡œ 6ê°œ ì´ìƒì…ë‹ˆë‹¤!")
                        if selected_result and selected_result.get('has_complete_data') is False:
                            st.warning("âš ï¸ ì´ ë°ì´í„°ëŠ” ë¶ˆì¼ì¹˜ ìƒíƒœë¡œ ì¢…ë£Œë˜ì–´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.")
                        
                        # ì „ì²´ íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
                        history_data = []
                        for _, row in grid_steps.iterrows():
                            is_correct = row['is_correct']
                            match_status = 'âœ…' if is_correct == 1 else ('âŒ' if is_correct == 0 else '-')
                            is_forced = 'âš¡' if row['is_forced'] == 1 else ''
                            skipped = 'â­ï¸' if row['skipped'] == 1 else ''
                            
                            # ì²« ì¼ì¹˜ ë° ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ìŠ¤í… í•˜ì´ë¼ì´íŠ¸
                            highlight = ''
                            if first_match_step and row['step'] == first_match_step:
                                highlight = ' ğŸ”µ (ì²« ì¼ì¹˜)'
                            # ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ì •ë³´ ì¶”ê°€
                            selected_result = next((r for r in results['results'] if r.get('grid_string_id') == selected_grid_id), None)
                            second_mismatch_step = selected_result.get('second_mismatch_step') if selected_result and selected_result.get('second_is_mismatch') else None
                            if second_mismatch_step and row['step'] == second_mismatch_step:
                                highlight = ' ğŸ”´ (ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ì‹œì‘)'
                            if first_match_step and second_mismatch_step and row['step'] == first_match_step:
                                highlight = ' ğŸ”µ (ì²« ì¼ì¹˜)'
                            
                            has_prediction = (row['has_prediction'] == 1 or row['has_prediction'] is True)
                            
                            history_data.append({
                                'Step': row['step'],
                                'Prefix': row['prefix'],
                                'ì˜ˆì¸¡': f"{row['predicted'] or '-'}{is_forced}{skipped}",
                                'ì‹¤ì œê°’': row['actual'],
                                'ì¼ì¹˜': match_status,
                                'ì‹ ë¢°ë„': f"{row['confidence']:.1f}%" if has_prediction else '-',
                                'ê°„ê²©': row['current_interval'] if not has_prediction else 0,
                                'ê²€ì¦': 'âœ“' if row['validated'] == 1 else '',
                                'ìŠ¤í‚µ': 'â­ï¸' if row['skipped'] == 1 else '',
                                'ë¹„ê³ ': highlight
                            })
                        
                        history_df = pd.DataFrame(history_data)
                        st.dataframe(history_df, use_container_width=True, hide_index=True)
                else:
                    st.info("ğŸ’¡ ìƒì„¸ íˆìŠ¤í† ë¦¬ë¥¼ ì¡°íšŒí•  Grid Stringì´ ì—†ìŠµë‹ˆë‹¤.")
                
                # ì˜ˆì™¸ ì¼€ì´ìŠ¤ (6ê°œ ì´ìƒ)
                st.markdown("---")
                st.markdown("### ì˜ˆì™¸ ì¼€ì´ìŠ¤ (6ê°œ ì´ìƒ ì—°ì† ë¶ˆì¼ì¹˜)")
                
                exception_cases = [r for r in results['results'] 
                                  if r.get('has_first_match') and r.get('second_is_mismatch') and r.get('is_6_or_more')]
                
                if len(exception_cases) > 0:
                    exception_df_data = []
                    for r in exception_cases:
                        exception_df_data.append({
                            'Grid String ID': r['grid_string_id'],
                            'ì²« ì¼ì¹˜ Step': r['first_match_step'],
                            'ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ Step': r.get('second_mismatch_step'),
                            'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': r['max_consecutive_mismatches_after_first'],
                            'ì™„ì „ ì—¬ë¶€': "âœ… ì™„ë£Œ" if r.get('has_complete_data') else "âš ï¸ ë¶ˆì™„ì „"
                        })
                    
                    exception_df = pd.DataFrame(exception_df_data)
                    st.dataframe(exception_df, use_container_width=True, hide_index=True)
                else:
                    st.success("âœ… ì˜ˆì™¸ ì¼€ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  grid_stringì´ 6ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
            else:
                st.info("ğŸ’¡ ì²« ì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë¼ì´ë¸Œ ê²Œì„ ë°ì´í„° ë¶„ì„ ì„¹ì…˜
    st.markdown("---")
    st.markdown("---")
    st.header("ğŸ® ë¼ì´ë¸Œ ê²Œì„ ë°ì´í„° ë¶„ì„")
    st.markdown("""
    **ê°€ì„¤**: ì²« ë²ˆì§¸ ìŠ¤í‚µë˜ì§€ ì•Šì€ ì˜ˆì¸¡ì´ ì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
    ë‹¤ìŒ ê²Œì„ë¶€í„° ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ 6ê°œ ë¯¸ë§Œì¼ ê²ƒì´ë‹¤.
    
    **ë¶„ì„ ë°©ì‹**: ëª¨ë“  ë¼ì´ë¸Œ ê²Œì„ ì„¸ì…˜ì˜ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ì„œ ë¶„ì„í•©ë‹ˆë‹¤.
    """)
    
    # ì „ì²´ ë¶„ì„ ì‹¤í–‰
    if st.button("ì „ì²´ ë¼ì´ë¸Œ ê²Œì„ íˆìŠ¤í† ë¦¬ ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True, key="analyze_all_live_games"):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            st.session_state.all_live_game_analysis_result = analyze_all_live_games_first_match_hypothesis()
        st.rerun()
    
    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if 'all_live_game_analysis_result' in st.session_state:
        result = st.session_state.all_live_game_analysis_result
        
        st.markdown("---")
        st.markdown("### ê°€ì„¤ ê²€ì¦ ê²°ê³¼")
        
        if result.get('has_first_match'):
            # í•µì‹¬ ì§€í‘œ ê°•ì¡°
            col_key1, col_key2, col_key3 = st.columns(3)
            with col_key1:
                is_6_or_more = result.get('is_6_or_more', False)
                display_value = f"{result.get('max_consecutive_mismatches_after_first', 0)}ê°œ"
                st.metric(
                    "ğŸ”¥ ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", 
                    display_value,
                    delta="6ê°œ ì´ìƒ" if is_6_or_more else None,
                    delta_color="inverse" if is_6_or_more else "normal",
                    help="ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•˜ì—¬ ì—°ì† ë¶ˆì¼ì¹˜ ê°œìˆ˜"
                )
            with col_key2:
                second_mismatch = "âœ… ì˜ˆ" if result.get('second_is_mismatch') else "âŒ ì•„ë‹ˆì˜¤"
                st.metric(
                    "ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘", 
                    second_mismatch
                )
            with col_key3:
                complete_status = "âœ… ì™„ë£Œ" if result.get('has_complete_data') else "âš ï¸ ë¶ˆì™„ì „"
                st.metric(
                    "ë°ì´í„° ì™„ì „ ì—¬ë¶€", 
                    complete_status
                )
            
            st.markdown("---")
            
            # ì¼ë°˜ í†µê³„
            col_stat1, col_stat2 = st.columns(2)
            with col_stat1:
                st.metric("ì´ ìŠ¤í… ìˆ˜", f"{result['total_steps']}")
            with col_stat2:
                st.metric("6ê°œ ë¯¸ë§Œ ì—¬ë¶€", "âœ… ì˜ˆ" if result.get('is_below_6') else "âŒ ì•„ë‹ˆì˜¤")
            
            # ê°€ì„¤ ê²€ì¦ ê²°ê³¼
            st.markdown("---")
            st.markdown("### ê°€ì„¤ ê²€ì¦ ìš”ì•½")
            
            max_mismatches = result.get('max_consecutive_mismatches_after_first', 0)
            if result.get('second_is_mismatch'):
                if result.get('is_below_6'):
                    st.success(f"âœ… ê°€ì„¤ ì§€ì§€: ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•˜ì—¬ ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ {max_mismatches}ê°œë¡œ 6ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
                elif result.get('is_6_or_more'):
                    st.error(f"âŒ ê°€ì„¤ ë°˜ë°•: ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ë¡œ ì‹œì‘í•˜ì—¬ ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ {max_mismatches}ê°œë¡œ 6ê°œ ì´ìƒì…ë‹ˆë‹¤.")
                else:
                    st.warning(f"âš ï¸ ê°€ì„¤ ë°˜ë°•: ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ê°€ {max_mismatches}ê°œë¡œ 6ê°œ ì´ìƒì…ë‹ˆë‹¤.")
            else:
                st.info("â„¹ï¸ ë‘ ë²ˆì§¸ê°€ ì¼ì¹˜ë¡œ ì‹œì‘í•˜ì—¬ ë¶„ì„ ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤.")
            
            # ì²« ì¼ì¹˜ ë° ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ì •ë³´
            st.markdown("---")
            st.markdown("### ì²« ì¼ì¹˜ ë° ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ì •ë³´")
            col_match1, col_match2 = st.columns(2)
            with col_match1:
                st.markdown("#### ì²« ì¼ì¹˜")
                st.metric("ì²« ì¼ì¹˜ ì¸ë±ìŠ¤", f"{result.get('first_match_idx', '-')}")
                st.metric("ì²« ì¼ì¹˜ ìŠ¤í…", f"{result.get('first_match_step', '-')}")
                st.metric("ì²« ì¼ì¹˜ ì„¸ì…˜ ID", f"{result.get('first_match_session_id', '-')}")
            with col_match2:
                st.markdown("#### ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜")
                if result.get('second_is_mismatch'):
                    st.metric("ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ì¸ë±ìŠ¤", f"{result.get('second_mismatch_idx', '-')}")
                    st.metric("ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ìŠ¤í…", f"{result.get('second_mismatch_step', '-')}")
                    st.metric("ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ì„¸ì…˜ ID", f"{result.get('second_mismatch_session_id', '-')}")
                else:
                    st.info("ë‘ ë²ˆì§¸ê°€ ë¶ˆì¼ì¹˜ê°€ ì•„ë‹™ë‹ˆë‹¤.")
            
            # ì „ì²´ íˆìŠ¤í† ë¦¬ í‘œì‹œ
            st.markdown("---")
            st.markdown("### ì „ì²´ íˆìŠ¤í† ë¦¬")
            
            if len(result['all_steps']) > 0:
                first_match_idx = result['first_match_idx']
                
                history_data = []
                for idx, entry in enumerate(result['all_steps']):
                    is_correct = entry.get('is_correct')
                    match_status = 'âœ…' if (is_correct == 1 or is_correct is True) else ('âŒ' if (is_correct == 0 or is_correct is False) else '-')
                    is_forced = 'âš¡' if (entry.get('is_forced') == 1 or entry.get('is_forced') is True) else ''
                    skipped_val = entry.get('skipped')
                    skipped = 'â­ï¸' if (skipped_val == 1 or skipped_val is True) else ''
                    
                    # ì²« ì¼ì¹˜ ë° ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ í•˜ì´ë¼ì´íŠ¸
                    highlight = ''
                    if idx == first_match_idx:
                        highlight = ' ğŸ”µ (ì²« ì¼ì¹˜)'
                    second_mismatch_idx = result.get('second_mismatch_idx')
                    if second_mismatch_idx is not None and idx == second_mismatch_idx:
                        highlight = ' ğŸ”´ (ë‘ ë²ˆì§¸ ë¶ˆì¼ì¹˜ ì‹œì‘)'
                    if idx == first_match_idx and second_mismatch_idx is not None and idx == second_mismatch_idx:
                        highlight = ' ğŸ”µ (ì²« ì¼ì¹˜)'
                    
                    has_prediction_val = entry.get('has_prediction')
                    has_prediction = (has_prediction_val == 1 or has_prediction_val is True)
                    
                    history_data.append({
                        'ì¸ë±ìŠ¤': idx,
                        'ì„¸ì…˜ ID': entry.get('session_id'),
                        'ìŠ¤í…': entry.get('step'),
                        'Prefix': entry.get('prefix', ''),
                        'ì˜ˆì¸¡': f"{entry.get('predicted_value') or '-'}{is_forced}{skipped}",
                        'ì‹¤ì œê°’': entry.get('actual_value', ''),
                        'ì¼ì¹˜': match_status,
                        'ì‹ ë¢°ë„': f"{entry.get('confidence', 0):.1f}%" if has_prediction else '-',
                        'ë¹„ê³ ': highlight
                    })
                
                history_df = pd.DataFrame(history_data)
                st.dataframe(history_df, use_container_width=True, hide_index=True)
                
                # ì²« ì¼ì¹˜ ì´í›„ ì—°ì† ë¶ˆì¼ì¹˜ êµ¬ê°„ í‘œì‹œ
                if max_mismatches > 0:
                    st.markdown("---")
                    st.markdown("### ì²« ì¼ì¹˜ ì´í›„ ì—°ì† ë¶ˆì¼ì¹˜ êµ¬ê°„")
                    
                    # ì—°ì† ë¶ˆì¼ì¹˜ êµ¬ê°„ ì°¾ê¸°
                    consecutive_runs = []
                    current_run_start = None
                    current_run_length = 0
                    
                    for idx in range(result['first_match_idx'] + 1, len(result['all_steps'])):
                        entry = result['all_steps'][idx]
                        validated_val = entry.get('validated')
                        is_correct_val = entry.get('is_correct')
                        is_validated = (validated_val == 1 or validated_val is True)
                        is_mismatch = (is_correct_val == 0 or is_correct_val is False)
                        
                        if is_validated and is_mismatch:
                            if current_run_start is None:
                                current_run_start = idx
                            current_run_length += 1
                        else:
                            if current_run_start is not None:
                                consecutive_runs.append({
                                    'start_idx': current_run_start,
                                    'length': current_run_length
                                })
                                current_run_start = None
                                current_run_length = 0
                    
                    # ë§ˆì§€ë§‰ êµ¬ê°„ ì²˜ë¦¬
                    if current_run_start is not None:
                        consecutive_runs.append({
                            'start_idx': current_run_start,
                            'length': current_run_length
                        })
                    
                    if len(consecutive_runs) > 0:
                        runs_df_data = []
                        for run in consecutive_runs:
                            runs_df_data.append({
                                'ì‹œì‘ ì¸ë±ìŠ¤': run['start_idx'],
                                'ì—°ì† ê¸¸ì´': run['length'],
                                '6ê°œ ë¯¸ë§Œ': 'âœ…' if run['length'] < 6 else 'âŒ'
                            })
                        runs_df = pd.DataFrame(runs_df_data)
                        st.dataframe(runs_df, use_container_width=True, hide_index=True)
            else:
                st.info("ğŸ’¡ íˆìŠ¤í† ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ’¡ ì²« ì¼ì¹˜ë¡œ ì‹œì‘í•˜ëŠ” ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # íˆìŠ¤í† ë¦¬ í™•ì¸ìš© (ì²« ì¼ì¹˜ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ì „ì²´ ìŠ¤í… ë³´ê¸°)
            if result['total_steps'] > 0:
                st.markdown("---")
                st.markdown("### ì „ì²´ íˆìŠ¤í† ë¦¬ (ì²« ì¼ì¹˜ ì—†ìŒ)")
                
                history_data = []
                for idx, entry in enumerate(result['all_steps']):
                    is_correct = entry.get('is_correct')
                    match_status = 'âœ…' if (is_correct == 1 or is_correct is True) else ('âŒ' if (is_correct == 0 or is_correct is False) else '-')
                    skipped_val = entry.get('skipped')
                    skipped = 'â­ï¸' if (skipped_val == 1 or skipped_val is True) else ''
                    is_forced = 'âš¡' if (entry.get('is_forced') == 1 or entry.get('is_forced') is True) else ''
                    
                    has_prediction_val = entry.get('has_prediction')
                    has_prediction = (has_prediction_val == 1 or has_prediction_val is True)
                    
                    history_data.append({
                        'ì¸ë±ìŠ¤': idx,
                        'ì„¸ì…˜ ID': entry.get('session_id'),
                        'ìŠ¤í…': entry.get('step'),
                        'Prefix': entry.get('prefix', ''),
                        'ì˜ˆì¸¡': f"{entry.get('predicted_value') or '-'}{is_forced}{skipped}",
                        'ì‹¤ì œê°’': entry.get('actual_value', ''),
                        'ì¼ì¹˜': match_status,
                        'ì‹ ë¢°ë„': f"{entry.get('confidence', 0):.1f}%" if has_prediction else '-'
                    })
                
                history_df = pd.DataFrame(history_data)
                st.dataframe(history_df, use_container_width=True, hide_index=True)
    
    # ì²« ìŠ¤í… ìŠ¤í‚µ ë¶„ì„ ì„¹ì…˜
    st.markdown("---")
    st.markdown("## ì²« ìŠ¤í… ìŠ¤í‚µ ë¶„ì„")
    st.markdown("ì²« ë²ˆì§¸ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ìŠ¤í…ì—ì„œ ìŠ¤í‚µìœ¼ë¡œ ì‹œì‘í•œ ê²Œì„ê³¼ ê·¸ë ‡ì§€ ì•Šì€ ê²Œì„ì˜ ìŠ¹ë¥  ìƒê´€ê´€ê³„ ë¶„ì„")
    
    with st.form("first_step_skip_analysis_form", clear_on_submit=False):
        st.markdown("### ì„¤ì •")
        
        col_skip1, col_skip2, col_skip3 = st.columns(3)
        
        with col_skip1:
            skip_window_size = st.selectbox(
                "ìœˆë„ìš° í¬ê¸°",
                options=[5, 6, 7, 8, 9],
                index=2,
                key="skip_analysis_window_size",
                help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ìœˆë„ìš° í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
            skip_method = st.selectbox(
                "ì˜ˆì¸¡ ë°©ë²•",
                options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜"],
                index=0,
                key="skip_analysis_method",
                help="ì˜ˆì¸¡ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col_skip2:
            skip_use_threshold = st.checkbox(
                "ì„ê³„ê°’ ì „ëµ ì‚¬ìš©",
                value=True,
                key="skip_analysis_use_threshold",
                help="ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€"
            )
            skip_threshold_val = st.number_input(
                "ì„ê³„ê°’",
                min_value=0,
                max_value=100,
                value=56,
                step=1,
                key="skip_analysis_threshold",
                help="ì‹ ë¢°ë„ ì„ê³„ê°’ (%)",
                disabled=not skip_use_threshold
            )
            skip_max_interval = st.number_input(
                "ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©",
                min_value=1,
                max_value=20,
                value=6,
                step=1,
                key="skip_analysis_max_interval",
                help="ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©"
            )
        
        with col_skip3:
            skip_confidence_threshold = st.number_input(
                "ìŠ¤í‚µ ì‹ ë¢°ë„ ì„ê³„ê°’",
                min_value=0.0,
                max_value=100.0,
                value=51.0,
                step=0.5,
                key="skip_analysis_confidence_threshold",
                help="ì´ ê°’ ë¯¸ë§Œì˜ ì‹ ë¢°ë„ëŠ” ìŠ¤í‚µë©ë‹ˆë‹¤"
            )
            
            # cutoff_grid_string_id ì„ íƒ
            cutoff_query_skip = "SELECT id, created_at FROM preprocessed_grid_strings ORDER BY id"
            cutoff_df_skip = pd.read_sql_query(cutoff_query_skip, get_db_connection())
            cutoff_options_skip = [(None, "ì „ì²´ ë°ì´í„°")]
            for _, row in cutoff_df_skip.iterrows():
                cutoff_options_skip.append((row['id'], row['created_at']))
            
            cutoff_id_skip = st.selectbox(
                "í•™ìŠµ ë°ì´í„° ê¸°ì¤€ (Cutoff Grid String ID)",
                options=[opt[0] for opt in cutoff_options_skip],
                format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else next((f"ID {opt[0]} - {opt[1]}" for opt in cutoff_options_skip if opt[0] == x), f"ID {x} ì´í›„"),
                key="skip_analysis_cutoff_id",
                help="ì´ ID ì´í•˜ì˜ ë°ì´í„°ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤"
            )
        
        submitted_skip = st.form_submit_button("ì²« ìŠ¤í… ìŠ¤í‚µ ë¶„ì„ ì‹¤í–‰", type="primary")
        
        if submitted_skip:
            if cutoff_id_skip is None:
                st.error("í•™ìŠµ ë°ì´í„° ê¸°ì¤€ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ê²€ì¦ ì‹¤í–‰ ì¤‘..."):
                    try:
                        # ë°°ì¹˜ ê²€ì¦ ì‹¤í–‰
                        batch_results_skip = batch_validate_with_first_step_skip_analysis(
                            cutoff_id_skip,
                            window_size=skip_window_size,
                            method=skip_method,
                            use_threshold=skip_use_threshold,
                            threshold=skip_threshold_val if skip_use_threshold else 60,
                            max_interval=skip_max_interval,
                            reverse_forced_prediction=False,
                            confidence_skip_threshold=skip_confidence_threshold
                        )
                        
                        if batch_results_skip and len(batch_results_skip.get('results', [])) > 0:
                            # ê²°ê³¼ ì €ì¥
                            validation_id_skip = save_first_step_skip_analysis_results(
                                cutoff_id_skip,
                                skip_window_size,
                                skip_method,
                                skip_use_threshold,
                                skip_threshold_val if skip_use_threshold else None,
                                skip_max_interval,
                                skip_confidence_threshold,
                                batch_results_skip,
                                grid_string_ids=batch_results_skip.get('grid_string_ids')
                            )
                            
                            if validation_id_skip:
                                st.session_state.first_step_skip_analysis_validation_id = validation_id_skip
                                st.success(f"âœ… ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {validation_id_skip[:8]}...)")
                                
                                # ë¶„ì„ ì‹¤í–‰
                                analysis_result = analyze_first_step_skip_correlation(validation_id_skip)
                                
                                if analysis_result:
                                    st.markdown("### ë¶„ì„ ê²°ê³¼")
                                    
                                    # ìš”ì•½ í†µê³„
                                    col_summary1, col_summary2 = st.columns(2)
                                    
                                    with col_summary1:
                                        st.markdown("#### ìŠ¤í‚µìœ¼ë¡œ ì‹œì‘í•œ ê²Œì„")
                                        st.metric("ê²Œì„ ìˆ˜", analysis_result['skip_start_count'])
                                        if analysis_result['skip_start_avg_accuracy'] is not None:
                                            st.metric("í‰ê·  ìŠ¹ë¥ ", f"{analysis_result['skip_start_avg_accuracy']:.2f}%")
                                        if analysis_result['skip_start_outlier_rate'] is not None:
                                            st.metric("ì´ìƒì¹˜ ë°œìƒ ë¹„ìœ¨", f"{analysis_result['skip_start_outlier_rate']:.2f}%")
                                            st.caption(f"ì´ìƒì¹˜ ë°œìƒ: {analysis_result['skip_start_outlier_count']}ê°œ")
                                    
                                    with col_summary2:
                                        st.markdown("#### ìŠ¤í‚µ ì—†ì´ ì‹œì‘í•œ ê²Œì„")
                                        st.metric("ê²Œì„ ìˆ˜", analysis_result['non_skip_start_count'])
                                        if analysis_result['non_skip_start_avg_accuracy'] is not None:
                                            st.metric("í‰ê·  ìŠ¹ë¥ ", f"{analysis_result['non_skip_start_avg_accuracy']:.2f}%")
                                        if analysis_result['non_skip_start_outlier_rate'] is not None:
                                            st.metric("ì´ìƒì¹˜ ë°œìƒ ë¹„ìœ¨", f"{analysis_result['non_skip_start_outlier_rate']:.2f}%")
                                            st.caption(f"ì´ìƒì¹˜ ë°œìƒ: {analysis_result['non_skip_start_outlier_count']}ê°œ")
                                    
                                    # ë¹„êµ ì°¨íŠ¸
                                    if analysis_result['skip_start_avg_accuracy'] is not None and analysis_result['non_skip_start_avg_accuracy'] is not None:
                                        st.markdown("#### ìŠ¹ë¥  ë¹„êµ")
                                        comparison_data = {
                                            'ì‹œì‘ ìœ í˜•': ['ìŠ¤í‚µìœ¼ë¡œ ì‹œì‘', 'ìŠ¤í‚µ ì—†ì´ ì‹œì‘'],
                                            'í‰ê·  ìŠ¹ë¥ ': [
                                                analysis_result['skip_start_avg_accuracy'],
                                                analysis_result['non_skip_start_avg_accuracy']
                                            ]
                                        }
                                        comparison_df = pd.DataFrame(comparison_data)
                                        st.bar_chart(comparison_df.set_index('ì‹œì‘ ìœ í˜•'))
                                        
                                        # ì°¨ì´ ê³„ì‚°
                                        accuracy_diff = analysis_result['non_skip_start_avg_accuracy'] - analysis_result['skip_start_avg_accuracy']
                                        st.info(f"ìŠ¹ë¥  ì°¨ì´: {accuracy_diff:+.2f}% (ìŠ¤í‚µ ì—†ì´ ì‹œì‘í•œ ê²Œì„ì´ {'ë†’ìŒ' if accuracy_diff > 0 else 'ë‚®ìŒ'})")
                                    
                                    # ì´ìƒì¹˜ ë°œìƒ ë¹„ìœ¨ ë¹„êµ
                                    if analysis_result['skip_start_outlier_rate'] is not None and analysis_result['non_skip_start_outlier_rate'] is not None:
                                        st.markdown("#### ì´ìƒì¹˜ ë°œìƒ ë¹„ìœ¨ ë¹„êµ")
                                        outlier_data = {
                                            'ì‹œì‘ ìœ í˜•': ['ìŠ¤í‚µìœ¼ë¡œ ì‹œì‘', 'ìŠ¤í‚µ ì—†ì´ ì‹œì‘'],
                                            'ì´ìƒì¹˜ ë°œìƒ ë¹„ìœ¨': [
                                                analysis_result['skip_start_outlier_rate'],
                                                analysis_result['non_skip_start_outlier_rate']
                                            ]
                                        }
                                        outlier_df = pd.DataFrame(outlier_data)
                                        st.bar_chart(outlier_df.set_index('ì‹œì‘ ìœ í˜•'))
                                        
                                        # ì°¨ì´ ê³„ì‚°
                                        outlier_diff = analysis_result['skip_start_outlier_rate'] - analysis_result['non_skip_start_outlier_rate']
                                        st.info(f"ì´ìƒì¹˜ ë°œìƒ ë¹„ìœ¨ ì°¨ì´: {outlier_diff:+.2f}% (ìŠ¤í‚µìœ¼ë¡œ ì‹œì‘í•œ ê²Œì„ì´ {'ë†’ìŒ' if outlier_diff > 0 else 'ë‚®ìŒ'})")
                                    
                                    # ìƒì„¸ ë°ì´í„°
                                    st.markdown("#### ìƒì„¸ ë°ì´í„°")
                                    if 'skip_start_df' in analysis_result and len(analysis_result['skip_start_df']) > 0:
                                        st.markdown("**ìŠ¤í‚µìœ¼ë¡œ ì‹œì‘í•œ ê²Œì„**")
                                        st.dataframe(analysis_result['skip_start_df'], use_container_width=True)
                                    
                                    if 'non_skip_start_df' in analysis_result and len(analysis_result['non_skip_start_df']) > 0:
                                        st.markdown("**ìŠ¤í‚µ ì—†ì´ ì‹œì‘í•œ ê²Œì„**")
                                        st.dataframe(analysis_result['non_skip_start_df'], use_container_width=True)
                        else:
                            st.error("ê²€ì¦ ì‹¤í–‰ ì‹¤íŒ¨ ë˜ëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        import traceback
                        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

if __name__ == "__main__":
    main()
