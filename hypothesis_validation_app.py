"""
reconstructed_grid ê°€ì„¤ ê²€ì¦ ì•±
N-gram ê¸°ë°˜ íŒ¨í„´ ì˜ˆì¸¡ ê°€ì„¤ ê²€ì¦ ì‹œìŠ¤í…œ
"""

import streamlit as st
import sqlite3
import pandas as pd
import os
import json
import uuid
from collections import Counter, defaultdict
from datetime import datetime
from bs4 import BeautifulSoup

# SVG íŒŒì‹± ëª¨ë“ˆ import
from svg_parser_module import (
    parse_bead_road_svg,
    grid_to_string_column_wise,
    save_parsed_grid_string_to_db,
    generate_and_save_ngram_chunks,
    create_ngram_chunks_table,
    TABLE_WIDTH,
    TABLE_HEIGHT
)

# í˜ì´ì§€ ì„¤ì • (ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ ì„¤ì •)
# ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ importë  ë•ŒëŠ” ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ try-exceptë¡œ ì²˜ë¦¬
try:
    st.set_page_config(
        page_title="Hypothesis Validation System",
        page_icon="ğŸ”¬",
        layout="wide"
    )
except st.errors.StreamlitAPIException:
    # ì´ë¯¸ ì„¤ì •ë˜ì—ˆê±°ë‚˜ ë‹¤ë¥¸ ì•±ì—ì„œ ë¨¼ì € ì„¤ì •í•œ ê²½ìš° ë¬´ì‹œ
    pass

# DB ê²½ë¡œ
DB_PATH = 'hypothesis_validation.db'

# Table dimensions (ëª¨ë“ˆì—ì„œ importí•˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬)
# TABLE_WIDTH = 15
# TABLE_HEIGHT = 6

# SVG íŒŒì‹± í•¨ìˆ˜ëŠ” svg_parser_moduleì—ì„œ importë¨

def get_db_connection():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), DB_PATH)
        if not os.path.exists(db_path):
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")
            return None
        return sqlite3.connect(db_path)
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        return None

def create_scenario_validation_tables():
    """ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ìƒì„±"""
    conn = get_db_connection()
    if conn is None:
        return False
    
    cursor = conn.cursor()
    
    try:
        # í…Œì´ë¸” 1: scenario_validation_sessions (ê²€ì¦ ì„¸ì…˜ ìš”ì•½)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS scenario_validation_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL UNIQUE,
                grid_string TEXT NOT NULL,
                grid_string_hash TEXT,
                string_length INTEGER NOT NULL,
                b_count INTEGER NOT NULL,
                p_count INTEGER NOT NULL,
                b_ratio REAL,
                p_ratio REAL,
                window_size INTEGER NOT NULL,
                prediction_method TEXT NOT NULL,
                train_ratio REAL,
                result TEXT NOT NULL,
                max_consecutive_mismatches INTEGER NOT NULL,
                consecutive_5_count INTEGER NOT NULL,
                total_steps INTEGER NOT NULL,
                matches INTEGER NOT NULL,
                mismatches INTEGER NOT NULL,
                match_rate REAL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_result 
            ON scenario_validation_sessions(result)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_window_method 
            ON scenario_validation_sessions(window_size, prediction_method)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_created_at 
            ON scenario_validation_sessions(created_at)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_max_consecutive 
            ON scenario_validation_sessions(max_consecutive_mismatches)
        ''')
        
        # í…Œì´ë¸” 2: scenario_validation_steps (ê° ìŠ¤í… ìƒì„¸)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS scenario_validation_steps (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                step_number INTEGER NOT NULL,
                step_index INTEGER NOT NULL,
                prefix TEXT NOT NULL,
                predicted_value TEXT NOT NULL,
                actual_value TEXT NOT NULL,
                is_match INTEGER NOT NULL,
                confidence REAL,
                predicted_ratio REAL,
                actual_ratio REAL,
                consecutive_mismatches INTEGER NOT NULL,
                FOREIGN KEY (validation_id) REFERENCES scenario_validation_sessions(validation_id)
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_id 
            ON scenario_validation_steps(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_step_number 
            ON scenario_validation_steps(validation_id, step_number)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_is_match 
            ON scenario_validation_steps(validation_id, is_match)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_consecutive 
            ON scenario_validation_steps(validation_id, consecutive_mismatches)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_prefix 
            ON scenario_validation_steps(prefix)
        ''')
        
        # í…Œì´ë¸” 3: scenario_consecutive_5_occurrences (ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ë°œìƒ ìœ„ì¹˜)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS scenario_consecutive_5_occurrences (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                validation_id TEXT NOT NULL,
                occurrence_index INTEGER NOT NULL,
                start_step INTEGER NOT NULL,
                end_step INTEGER NOT NULL,
                steps_list TEXT,
                FOREIGN KEY (validation_id) REFERENCES scenario_validation_sessions(validation_id)
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_validation_id_occurrences 
            ON scenario_consecutive_5_occurrences(validation_id)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_steps 
            ON scenario_consecutive_5_occurrences(start_step, end_step)
        ''')
        
        conn.commit()
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        conn.close()

# create_ngram_chunks_tableëŠ” svg_parser_moduleì—ì„œ importë¨

def create_stored_predictions_table():
    """
    ì˜ˆì¸¡ê°’ ì €ì¥ í…Œì´ë¸” ìƒì„± (DBì— ì˜êµ¬ ì €ì¥)
    - ì´ì „ ë°ì´í„° ì „ì²´ë¡œ í•™ìŠµí•œ prefixë³„ ì˜ˆì¸¡ê°’ ì €ì¥
    - grid_string_idëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ (prefixê°€ unique)
    
    Returns:
        bool: í…Œì´ë¸” ìƒì„± ì„±ê³µ ì—¬ë¶€
    """
    conn = get_db_connection()
    if conn is None:
        return False
    
    cursor = conn.cursor()
    
    try:
        # ê¸°ì¡´ í…Œì´ë¸”ì´ ìˆìœ¼ë©´ ì‚­ì œí•˜ê³  ì¬ìƒì„± (êµ¬ì¡° ë³€ê²½)
        cursor.execute('DROP TABLE IF EXISTS stored_predictions')
        
        cursor.execute('''
            CREATE TABLE stored_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                window_size INTEGER NOT NULL,
                prefix TEXT NOT NULL,
                predicted_value TEXT,
                confidence REAL,
                b_ratio REAL,
                p_ratio REAL,
                method TEXT NOT NULL,
                threshold REAL NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                updated_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                UNIQUE(window_size, prefix, method, threshold)
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_window_prefix 
            ON stored_predictions(window_size, prefix)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_method_threshold 
            ON stored_predictions(method, threshold)
        ''')
        
        conn.commit()
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"stored_predictions í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        conn.close()

def create_prefix_trend_rules_table():
    """
    prefix_trend_rules í…Œì´ë¸” ìƒì„±
    
    prefixì˜ b/p ë¹„ìœ¨ê³¼ suffix ë¶„í¬ì˜ ê´€ê³„ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”
    
    Returns:
        bool: í…Œì´ë¸” ìƒì„± ì„±ê³µ ì—¬ë¶€
    """
    conn = get_db_connection()
    if conn is None:
        return False
    
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS prefix_trend_rules (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                window_size INTEGER NOT NULL,
                prefix TEXT NOT NULL,
                b_ratio REAL NOT NULL,
                p_ratio REAL NOT NULL,
                b_suffix_count INTEGER NOT NULL,
                p_suffix_count INTEGER NOT NULL,
                total_count INTEGER NOT NULL,
                trend_follow INTEGER NOT NULL,
                confidence REAL NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                updated_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                UNIQUE(window_size, prefix)
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_prefix_trend_window_prefix 
            ON prefix_trend_rules(window_size, prefix)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_prefix_trend_window 
            ON prefix_trend_rules(window_size)
        ''')
        
        conn.commit()
        return True
        
    except Exception as e:
        conn.rollback()
        st.error(f"prefix_trend_rules í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        conn.close()

# generate_and_save_ngram_chunksëŠ” svg_parser_moduleì—ì„œ importë¨

def batch_generate_ngram_chunks_for_existing_data(window_sizes=[5, 6, 7, 8, 9]):
    """
    ê¸°ì¡´ preprocessed_grid_strings ë°ì´í„°ì— ëŒ€í•´ ngram_chunksë¥¼ ì¼ê´„ ìƒì„±
    
    Args:
        window_sizes: ìƒì„±í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
    """
    df_strings = load_preprocessed_data()
    
    if len(df_strings) == 0:
        st.warning("âš ï¸ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total = len(df_strings)
    processed = 0
    errors = []
    
    for idx, row in df_strings.iterrows():
        status_text.text(f"ì²˜ë¦¬ ì¤‘: {idx + 1}/{total} (ID: {row['id']})")
        progress_bar.progress((idx + 1) / total)
        
        try:
            generate_and_save_ngram_chunks(
                row['id'],
                row['grid_string'],
                window_sizes
            )
            processed += 1
        except Exception as e:
            errors.append(f"ID {row['id']}: {str(e)}")
    
    progress_bar.empty()
    status_text.empty()
    
    if errors:
        st.warning(f"âš ï¸ {len(errors)}ê°œ ì˜¤ë¥˜ ë°œìƒ (ì²˜ë¦¬ ì™„ë£Œ: {processed}/{total})")
        with st.expander("ì˜¤ë¥˜ ìƒì„¸"):
            for error in errors:
                st.text(error)
    else:
        st.success(f"âœ… {processed}/{total}ê°œ grid_stringì˜ ngram_chunks ìƒì„± ì™„ë£Œ")

def save_scenario_validation_result(result_data, grid_string, window_size, 
                                    prediction_method, train_ratio):
    """
    ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ ê²°ê³¼ë¥¼ DBì— ì €ì¥
    
    Args:
        result_data: simulate_game_scenarioì˜ ë°˜í™˜ê°’
        grid_string: ê²€ì¦í•œ ë¬¸ìì—´
        window_size: ìœˆë„ìš° í¬ê¸°
        prediction_method: ì˜ˆì¸¡ ë°©ë²•
        train_ratio: í•™ìŠµ ì„¸íŠ¸ ë¹„ìœ¨
    
    Returns:
        str: validation_id (ì €ì¥ëœ ê²€ì¦ ID)
    """
    # í…Œì´ë¸” ìƒì„± í™•ì¸
    if not create_scenario_validation_tables():
        raise Exception("í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨")
    
    validation_id = str(uuid.uuid4())
    conn = get_db_connection()
    if conn is None:
        raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
    
    cursor = conn.cursor()
    
    try:
        # 1. ì„¸ì…˜ ìš”ì•½ ì €ì¥
        stats = result_data['stats']
        b_count = grid_string.count('b')
        p_count = grid_string.count('p')
        string_length = len(grid_string)
        
        cursor.execute('''
            INSERT INTO scenario_validation_sessions (
                validation_id, grid_string, string_length,
                b_count, p_count, b_ratio, p_ratio,
                window_size, prediction_method, train_ratio,
                result, max_consecutive_mismatches, consecutive_5_count,
                total_steps, matches, mismatches, match_rate
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            validation_id,
            grid_string,
            string_length,
            b_count,
            p_count,
            (b_count / string_length * 100) if string_length > 0 else 0,
            (p_count / string_length * 100) if string_length > 0 else 0,
            window_size,
            prediction_method,
            train_ratio,
            result_data['result'],
            result_data['max_consecutive_mismatches'],
            stats['consecutive_5_count'],
            stats['total'],
            stats['matches'],
            stats['mismatches'],
            (stats['matches'] / stats['total'] * 100) if stats['total'] > 0 else 0
        ))
        
        # 2. ê° ìŠ¤í… ìƒì„¸ ì €ì¥
        for entry in result_data['history']:
            ratios = entry.get('ratios', {})
            cursor.execute('''
                INSERT INTO scenario_validation_steps (
                    validation_id, step_number, step_index,
                    prefix, predicted_value, actual_value, is_match,
                    confidence, predicted_ratio, actual_ratio,
                    consecutive_mismatches
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                validation_id,
                entry['step'],
                entry['index'],
                entry['prefix'],
                entry['predicted'],
                entry['actual'],
                1 if entry['is_match'] else 0,
                entry['confidence'],
                ratios.get(entry['predicted'], 0.0),
                ratios.get(entry['actual'], 0.0),
                entry.get('consecutive_mismatches', 0)
            ))
        
        # 3. ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ë°œìƒ ìœ„ì¹˜ ì €ì¥
        for idx, pos_info in enumerate(result_data['consecutive_5_positions'], 1):
            cursor.execute('''
                INSERT INTO scenario_consecutive_5_occurrences (
                    validation_id, occurrence_index,
                    start_step, end_step, steps_list
                ) VALUES (?, ?, ?, ?, ?)
            ''', (
                validation_id,
                idx,
                pos_info['start_step'],
                pos_info['end_step'],
                json.dumps(pos_info['steps'])
            ))
        
        conn.commit()
        return validation_id
        
    except Exception as e:
        conn.rollback()
        raise e
    finally:
        conn.close()

# save_parsed_grid_string_to_dbëŠ” svg_parser_moduleì—ì„œ importë¨

def load_predictions_from_table(window_size, prefix, method, threshold):
    """
    DB í…Œì´ë¸”ì—ì„œ ì˜ˆì¸¡ê°’ ì¡°íšŒ (grid_string_id ì œê±°)
    
    Args:
        window_size: ìœˆë„ìš° í¬ê¸°
        prefix: prefix ë¬¸ìì—´
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì„ê³„ê°’
    
    Returns:
        dict: {
            'predicted_value': ì˜ˆì¸¡ê°’,
            'confidence': ì‹ ë¢°ë„,
            'b_ratio': b ë¹„ìœ¨,
            'p_ratio': p ë¹„ìœ¨
        } or None (ì—†ëŠ” ê²½ìš°)
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        cursor = conn.cursor()
        cursor.execute('''
            SELECT predicted_value, confidence, b_ratio, p_ratio
            FROM stored_predictions
            WHERE window_size = ? 
              AND prefix = ? 
              AND method = ? 
              AND threshold = ?
        ''', (window_size, prefix, method, threshold))
        
        row = cursor.fetchone()
        if row:
            return {
                'predicted_value': row[0],
                'confidence': row[1],
                'b_ratio': row[2],
                'p_ratio': row[3]
            }
        return None
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ê°’ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return None
    finally:
        conn.close()

def save_or_update_predictions_for_historical_data(
    cutoff_grid_string_id=None,
    window_sizes=[5, 6, 7, 8, 9],
    methods=["ë¹ˆë„ ê¸°ë°˜"],
    thresholds=[0, 50, 60, 70, 80, 90, 100],
    batch_size=1000
):
    """
    ì´ì „ ë°ì´í„°ë¡œ ì˜ˆì¸¡ê°’ì„ ê³„ì‚°í•˜ì—¬ DB í…Œì´ë¸”ì— ì €ì¥/ì—…ë°ì´íŠ¸
    - ì´ì „ ë°ì´í„° ì „ì²´ë¡œ ëª¨ë¸ êµ¬ì¶•
    - ëª¨ë“  ê°€ëŠ¥í•œ prefixì— ëŒ€í•œ ì˜ˆì¸¡ê°’ë§Œ ì €ì¥ (grid_string_id ì—†ì´)
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string_id (Noneì´ë©´ ì „ì²´ ë°ì´í„°)
            - ì´ ID ì´í•˜ê°€ ì´ì „ ë°ì´í„° (id <= cutoff_grid_string_id)
        window_sizes: ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        methods: ì˜ˆì¸¡ ë°©ë²• ë¦¬ìŠ¤íŠ¸
        thresholds: ì„ê³„ê°’ ë¦¬ìŠ¤íŠ¸ (0ì€ ì„ê³„ê°’ ì—†ì´ ëª¨ë“  ì˜ˆì¸¡ í¬í•¨)
        batch_size: ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° (ì„±ëŠ¥ ìµœì í™”)
    
    Returns:
        dict: {
            'total_saved': ì €ì¥/ì—…ë°ì´íŠ¸ëœ ì´ ë ˆì½”ë“œ ìˆ˜,
            'new_records': ìƒˆë¡œ ìƒì„±ëœ ë ˆì½”ë“œ ìˆ˜,
            'updated_records': ì—…ë°ì´íŠ¸ëœ ë ˆì½”ë“œ ìˆ˜,
            'unique_prefixes': ê³ ìœ  prefix ìˆ˜
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # ì´ì „ ë°ì´í„° ì„ íƒ
        if cutoff_grid_string_id is None:
            query = "SELECT id FROM preprocessed_grid_strings ORDER BY id"
            params = []
        else:
            query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id"
            params = [cutoff_grid_string_id]
        
        df_historical = pd.read_sql_query(query, conn, params=params)
        
        if len(df_historical) == 0:
            return {
                'total_saved': 0,
                'new_records': 0,
                'updated_records': 0,
                'unique_prefixes': 0
            }
        
        # ì´ì „ ë°ì´í„°ì˜ ngram_chunks ë¡œë“œ
        historical_ids = df_historical['id'].tolist()
        
        total_saved = 0
        new_records = 0
        updated_records = 0
        unique_prefixes_set = set()
        
        cursor = conn.cursor()
        
        for window_size in window_sizes:
            # í•´ë‹¹ ìœˆë„ìš° í¬ê¸°ì˜ ngram_chunks ë¡œë“œ
            train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=historical_ids)
            
            if len(train_ngrams) == 0:
                continue
            
            # ëª¨ë¸ êµ¬ì¶• (ì´ì „ ë°ì´í„° ì „ì²´)
            for method in methods:
                if method == "ë¹ˆë„ ê¸°ë°˜":
                    model = build_frequency_model(train_ngrams)
                # elif method == "ë§ˆë¥´ì½”í”„ ì²´ì¸":
                #     model = build_markov_model(train_ngrams)
                elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                    model = build_weighted_model(train_ngrams)
                elif method == "ì•ˆì „ ìš°ì„ ":
                    model = build_safety_first_model(train_ngrams)
                else:
                    model = build_frequency_model(train_ngrams)
                
                # ëª¨ë“  ê°€ëŠ¥í•œ prefix ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
                all_prefixes = set()
                for _, row in train_ngrams.iterrows():
                    all_prefixes.add(row['prefix'])
                
                # ê° prefixì— ëŒ€í•´ ì˜ˆì¸¡ê°’ ê³„ì‚° ë° ì €ì¥
                batch_data = []
                
                for prefix in all_prefixes:
                    unique_prefixes_set.add((window_size, prefix))
                    
                    # ê° ì„ê³„ê°’ì— ëŒ€í•´ ì˜ˆì¸¡ê°’ ê³„ì‚°
                    for threshold in thresholds:
                        if threshold == 0:
                            # ì„ê³„ê°’ ì—†ì´ ëª¨ë“  ì˜ˆì¸¡ í¬í•¨
                            prediction_result = predict_for_prefix(model, prefix, method)
                        else:
                            # ì„ê³„ê°’ ì „ëµ ì‚¬ìš©
                            prediction_result = predict_confidence_threshold(model, prefix, method, threshold)
                        
                        predicted = prediction_result.get('predicted')
                        confidence = prediction_result.get('confidence', 0.0)
                        ratios = prediction_result.get('ratios', {})
                        
                        b_ratio = ratios.get('b', 0.0)
                        p_ratio = ratios.get('p', 0.0)
                        
                        batch_data.append((
                            window_size,
                            prefix,
                            predicted,
                            confidence,
                            b_ratio,
                            p_ratio,
                            method,
                            threshold
                        ))
                
                # ë°°ì¹˜ë¡œ ì €ì¥/ì—…ë°ì´íŠ¸
                if batch_data:
                    for i in range(0, len(batch_data), batch_size):
                        batch = batch_data[i:i + batch_size]
                        
                        for item in batch:
                            try:
                                # ê¸°ì¡´ ë ˆì½”ë“œ í™•ì¸
                                cursor.execute('''
                                    SELECT id FROM stored_predictions
                                    WHERE window_size = ? 
                                      AND prefix = ? 
                                      AND method = ? 
                                      AND threshold = ?
                                ''', (item[0], item[1], item[6], item[7]))
                                
                                existing = cursor.fetchone()
                                
                                cursor.execute('''
                                    INSERT OR REPLACE INTO stored_predictions (
                                        window_size, prefix,
                                        predicted_value, confidence, b_ratio, p_ratio,
                                        method, threshold, updated_at
                                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
                                ''', item)
                                
                                if existing:
                                    updated_records += 1
                                else:
                                    new_records += 1
                                
                                total_saved += 1
                            except Exception as e:
                                continue
        
        conn.commit()
        
        return {
            'total_saved': total_saved,
            'new_records': new_records,
            'updated_records': updated_records,
            'unique_prefixes': len(unique_prefixes_set)
        }
        
    except Exception as e:
        conn.rollback()
        st.error(f"ì˜ˆì¸¡ê°’ ì €ì¥/ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None
    finally:
        conn.close()

def load_preprocessed_data():
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ"""
    try:
        conn = get_db_connection()
        if conn is None:
            return pd.DataFrame()
        
        query = """
            SELECT 
                id,
                source_session_id,
                source_id,
                grid_string,
                string_length,
                b_count,
                p_count,
                b_ratio,
                p_ratio,
                created_at,
                processed_at
            FROM preprocessed_grid_strings
            ORDER BY created_at DESC
        """
        df = pd.read_sql_query(query, conn)
        conn.close()
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()

def load_ngram_chunks(window_size=None, grid_string_ids=None):
    """N-gram ì¡°ê° ë¡œë“œ"""
    conn = None
    try:
        conn = get_db_connection()
        if conn is None:
            return pd.DataFrame()
        
        query = """
            SELECT 
                id,
                grid_string_id,
                window_size,
                chunk_index,
                prefix,
                suffix,
                full_chunk
            FROM ngram_chunks
            WHERE 1=1
        """
        params = []
        
        if window_size is not None:
            query += " AND window_size = ?"
            params.append(window_size)
        
        if grid_string_ids is not None and len(grid_string_ids) > 0:
            # SQLiteì˜ íŒŒë¼ë¯¸í„° ì œí•œ(999ê°œ)ì„ ê³ ë ¤í•˜ì—¬ ë°°ì¹˜ë¡œ ì²˜ë¦¬
            if len(grid_string_ids) > 900:
                # ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
                all_dfs = []
                batch_size = 900
                for i in range(0, len(grid_string_ids), batch_size):
                    batch_ids = grid_string_ids[i:i + batch_size]
                    placeholders = ','.join(['?'] * len(batch_ids))
                    batch_query = query + f" AND grid_string_id IN ({placeholders})"
                    batch_query += " ORDER BY grid_string_id, window_size, chunk_index"
                    batch_df = pd.read_sql_query(batch_query, conn, params=params + batch_ids)
                    all_dfs.append(batch_df)
                
                if all_dfs:
                    df = pd.concat(all_dfs, ignore_index=True)
                else:
                    df = pd.DataFrame()
            else:
                placeholders = ','.join(['?'] * len(grid_string_ids))
                query += f" AND grid_string_id IN ({placeholders})"
                params.extend(grid_string_ids)
                query += " ORDER BY grid_string_id, window_size, chunk_index"
                df = pd.read_sql_query(query, conn, params=params)
        else:
            query += " ORDER BY grid_string_id, window_size, chunk_index"
            df = pd.read_sql_query(query, conn, params=params)
        
        return df
    except Exception as e:
        st.error(f"N-gram ì¡°ê° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()
    finally:
        if conn:
            conn.close()

def build_frequency_model(ngrams_df):
    """
    ë¹ˆë„ ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
    
    Args:
        ngrams_df: N-gram ì¡°ê° DataFrame
    
    Returns:
        dict: {prefix: {suffix: count, ...}, ...}
    """
    model = defaultdict(lambda: Counter())
    
    for _, row in ngrams_df.iterrows():
        prefix = row['prefix']
        suffix = row['suffix']
        model[prefix][suffix] += 1
    
    return dict(model)

def predict_frequency(model, prefix):
    """ë¹ˆë„ ê¸°ë°˜ ì˜ˆì¸¡"""
    if prefix not in model:
        return None, {}
    
    suffix_counts = model[prefix]
    if not suffix_counts:
        return None, {}
    
    # ê°€ì¥ ë¹ˆë²ˆí•œ suffix
    most_common = suffix_counts.most_common(1)[0]
    predicted = most_common[0]
    
    # ë¹„ìœ¨ ê³„ì‚°
    total = sum(suffix_counts.values())
    ratios = {suffix: (count / total * 100) for suffix, count in suffix_counts.items()}
    
    return predicted, ratios

# ============================================================================
# ë§ˆë¥´ì½”í”„ ì²´ì¸ ëª¨ë¸ (ì œê±° ì˜ˆì • - ì£¼ì„ ì²˜ë¦¬)
# ============================================================================
# def build_markov_model(ngrams_df):
#     """ë§ˆë¥´ì½”í”„ ì²´ì¸ ëª¨ë¸ (ë¹ˆë„ ê¸°ë°˜ê³¼ ë™ì¼í•˜ê²Œ êµ¬í˜„)"""
#     return build_frequency_model(ngrams_df)
# 
# def predict_markov(model, prefix):
#     """ë§ˆë¥´ì½”í”„ ì²´ì¸ ì˜ˆì¸¡"""
#     return predict_frequency(model, prefix)
# ============================================================================

def build_weighted_model(ngrams_df, weight_decay=0.95, id_weight_decay=0.99):
    """
    ê°€ì¤‘ì¹˜ ê¸°ë°˜ ëª¨ë¸ êµ¬ì¶•
    ìµœê·¼ ì¡°ê°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
    - grid_string_idê°€ í´ìˆ˜ë¡ ìµœê·¼ ë°ì´í„°ë¡œ ê°„ì£¼í•˜ì—¬ ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
    - ê° grid_string_id ë‚´ì—ì„œë„ chunk_indexê°€ í´ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
    
    Args:
        ngrams_df: N-gram ì¡°ê° DataFrame
        weight_decay: ê°€ì¤‘ì¹˜ ê°ì‡ ìœ¨ (0~1) - chunk_index ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê°ì‡ ìœ¨
        id_weight_decay: grid_string_id ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê°ì‡ ìœ¨ (0~1) - ê¸°ë³¸ê°’ 0.99
    
    Returns:
        dict: {prefix: {suffix: weighted_count, ...}, ...}
    """
    model = defaultdict(lambda: defaultdict(float))
    
    # ì „ì²´ grid_string_id ë²”ìœ„ ê³„ì‚°
    if len(ngrams_df) == 0:
        return dict(model)
    
    max_grid_string_id = ngrams_df['grid_string_id'].max()
    
    # grid_string_idë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ìˆœì„œ ë³´ì¡´
    grouped = ngrams_df.groupby('grid_string_id')
    
    for grid_string_id, group_df in grouped:
        # grid_string_id ê¸°ë°˜ ê°€ì¤‘ì¹˜ (í° idì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
        # max_grid_string_idì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìµœê·¼ ë°ì´í„°ë¡œ ê°„ì£¼
        id_weight = id_weight_decay ** (max_grid_string_id - grid_string_id)
        
        # ìµœê·¼ ì¡°ê°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
        group_df = group_df.sort_values('chunk_index')
        max_index = len(group_df)
        
        for idx, (_, row) in enumerate(group_df.iterrows()):
            # chunk_index ê¸°ë°˜ ê°€ì¤‘ì¹˜ (ìµœê·¼ chunkì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
            chunk_weight = weight_decay ** (max_index - idx - 1)
            
            # ìµœì¢… ê°€ì¤‘ì¹˜ = id_weight * chunk_weight
            # ìµœê·¼ grid_string_idì˜ ìµœê·¼ chunkì— ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜
            weight = id_weight * chunk_weight
            
            prefix = row['prefix']
            suffix = row['suffix']
            model[prefix][suffix] += weight
    
    return dict(model)

def predict_weighted(model, prefix):
    """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì˜ˆì¸¡"""
    if prefix not in model:
        return None, {}
    
    suffix_weights = model[prefix]
    if not suffix_weights:
        return None, {}
    
    # ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜ì˜ suffix
    predicted = max(suffix_weights.items(), key=lambda x: x[1])[0]
    
    # ê°€ì¤‘ì¹˜ë¥¼ ë¹„ìœ¨ë¡œ ë³€í™˜
    total = sum(suffix_weights.values())
    ratios = {suffix: (weight / total * 100) for suffix, weight in suffix_weights.items()}
    
    return predicted, ratios

# ============================================================================
# ì•ˆì „ ìš°ì„  ì ì‘í˜• ëª¨ë¸ (Safety-First Adaptive Model)
# ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ ìˆì–´ ì œê±° ì‹œ ì´ ì„¹ì…˜ë§Œ ì‚­ì œí•˜ë©´ ë¨
# ============================================================================

def build_safety_first_model(ngrams_df):
    """
    ì•ˆì „ ìš°ì„  ì ì‘í˜• ëª¨ë¸ êµ¬ì¶• (ë…ë¦½ì  êµ¬í˜„)
    
    ë¹ˆë„ ê¸°ë°˜ ëª¨ë¸ì„ ë‚´ë¶€ì—ì„œ ì§ì ‘ êµ¬ì¶•í•˜ì—¬ ê¸°ì¡´ í•¨ìˆ˜ì™€ ë…ë¦½ì 
    
    Args:
        ngrams_df: N-gram ì¡°ê° DataFrame
    
    Returns:
        dict: {prefix: {suffix: count, ...}, ...}
    """
    model = defaultdict(lambda: Counter())
    
    for _, row in ngrams_df.iterrows():
        prefix = row['prefix']
        suffix = row['suffix']
        model[prefix][suffix] += 1
    
    return dict(model)

def predict_safety_first(model, prefix, recent_history=None, consecutive_mismatches=0):
    """
    ì•ˆì „ ìš°ì„  ì ì‘í˜• ì˜ˆì¸¡ (ë…ë¦½ì  êµ¬í˜„)
    
    ì—°ì† ë¶ˆì¼ì¹˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì•ˆì „ ëª¨ë“œë¥¼ ìë™ìœ¼ë¡œ í™œì„±í™”
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸ (build_safety_first_modelë¡œ êµ¬ì¶•)
        prefix: ì˜ˆì¸¡í•  prefix ë¬¸ìì—´
        recent_history: ìµœê·¼ ì˜ˆì¸¡ íˆìŠ¤í† ë¦¬ [(predicted, actual, is_match), ...]
        consecutive_mismatches: í˜„ì¬ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜
    
    Returns:
        dict: {
            'predicted': ì˜ˆì¸¡ê°’,
            'ratios': ë¹„ìœ¨ ë”•ì…”ë„ˆë¦¬,
            'confidence': ì‹ ë¢°ë„,
            'strategy_name': 'ì•ˆì „ìš°ì„ _ì ì‘í˜•',
            'is_safety_mode': ì•ˆì „ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€,
            'safety_reason': ì•ˆì „ ëª¨ë“œ í™œì„±í™” ì´ìœ 
        }
    """
    # 1. ê¸°ë³¸ ë¹ˆë„ ê¸°ë°˜ ì˜ˆì¸¡ (ë…ë¦½ì ìœ¼ë¡œ ê³„ì‚°)
    if prefix not in model:
        return {
            'predicted': None,
            'ratios': {},
            'confidence': 0.0,
            'strategy_name': 'ì•ˆì „ìš°ì„ _ì ì‘í˜•',
            'is_safety_mode': False,
            'safety_reason': None
        }
    
    suffix_counts = model[prefix]
    if not suffix_counts:
        return {
            'predicted': None,
            'ratios': {},
            'confidence': 0.0,
            'strategy_name': 'ì•ˆì „ìš°ì„ _ì ì‘í˜•',
            'is_safety_mode': False,
            'safety_reason': None
        }
    
    # ê°€ì¥ ë¹ˆë²ˆí•œ suffix
    most_common = suffix_counts.most_common(1)[0]
    base_predicted = most_common[0]
    
    # ë¹„ìœ¨ ê³„ì‚°
    total = sum(suffix_counts.values())
    base_ratios = {suffix: (count / total * 100) for suffix, count in suffix_counts.items()}
    base_confidence = max(base_ratios.values()) if base_ratios else 0.0
    
    # 2. ì•ˆì „ ëª¨ë“œ íŒë‹¨
    is_safety_mode = False
    safety_reason = None
    predicted = base_predicted
    ratios = base_ratios.copy()
    
    # ì¡°ê±´ 1: ì—°ì† ë¶ˆì¼ì¹˜ê°€ 2íšŒ ì´ìƒì´ë©´ ì•ˆì „ ëª¨ë“œ
    if consecutive_mismatches >= 2:
        is_safety_mode = True
        safety_reason = f"ì—°ì† ë¶ˆì¼ì¹˜ {consecutive_mismatches}íšŒ"
        # ë°˜ëŒ€ ì˜ˆì¸¡ìœ¼ë¡œ ì „í™˜
        predicted = 'p' if base_predicted == 'b' else 'b'
        # ë¹„ìœ¨ë„ ë°˜ì „
        ratios = {'b': base_ratios.get('p', 0.0), 'p': base_ratios.get('b', 0.0)}
    
    # ì¡°ê±´ 2: ìµœê·¼ íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ì„±ê³µë¥  ê³„ì‚°
    elif recent_history and len(recent_history) >= 5:
        recent = recent_history[-5:]  # ìµœê·¼ 5ê°œ
        recent_success_rate = sum(1 for h in recent if h[2]) / len(recent)  # is_matchê°€ Trueì¸ ë¹„ìœ¨
        
        # ìµœê·¼ ì„±ê³µë¥ ì´ 40% ë¯¸ë§Œì´ë©´ ì•ˆì „ ëª¨ë“œ
        if recent_success_rate < 0.4:
            is_safety_mode = True
            safety_reason = f"ìµœê·¼ ì„±ê³µë¥  {recent_success_rate*100:.1f}%"
            # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ë°˜ëŒ€ ì˜ˆì¸¡
            if base_confidence < 60:
                predicted = 'p' if base_predicted == 'b' else 'b'
                ratios = {'b': base_ratios.get('p', 0.0), 'p': base_ratios.get('b', 0.0)}
    
    # ì¡°ê±´ 3: ì‹ ë¢°ë„ê°€ ë§¤ìš° ë‚®ìœ¼ë©´ (45-55%) ì•ˆì „ ëª¨ë“œ
    elif 45 <= base_confidence <= 55:
        is_safety_mode = True
        safety_reason = f"ì‹ ë¢°ë„ê°€ ë„ˆë¬´ ë‚®ìŒ ({base_confidence:.1f}%)"
        # ë°˜ëŒ€ ì˜ˆì¸¡ìœ¼ë¡œ ì „í™˜
        predicted = 'p' if base_predicted == 'b' else 'b'
        ratios = {'b': base_ratios.get('p', 0.0), 'p': base_ratios.get('b', 0.0)}
    
    # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
    confidence = max(ratios.values()) if ratios else 0.0
    
    return {
        'predicted': predicted,
        'ratios': ratios,
        'confidence': confidence,
        'strategy_name': 'ì•ˆì „ìš°ì„ _ì ì‘í˜•',
        'is_safety_mode': is_safety_mode,
        'safety_reason': safety_reason
    }

# ============================================================================
# ì•ˆì „ ìš°ì„  ëª¨ë¸ ë
# ============================================================================

# ============================================================================
# ê· í˜• íšŒë³µ íŠ¸ë Œë“œ ëª¨ë¸ (ë…ë¦½ êµ¬í˜„)
# ============================================================================

def calculate_prefix_ratio(prefix):
    """
    prefix ë¬¸ìì—´ì˜ b/p ë¹„ìœ¨ ê³„ì‚°
    
    Args:
        prefix: prefix ë¬¸ìì—´ (ì˜ˆ: "bbbbpp")
    
    Returns:
        dict: {'b_ratio': float, 'p_ratio': float, 'b_count': int, 'p_count': int}
    """
    b_count = prefix.count('b')
    p_count = prefix.count('p')
    total = len(prefix)
    
    if total == 0:
        return {'b_ratio': 0.5, 'p_ratio': 0.5, 'b_count': 0, 'p_count': 0}
    
    return {
        'b_ratio': b_count / total,
        'p_ratio': p_count / total,
        'b_count': b_count,
        'p_count': p_count
    }

def generate_and_save_prefix_trend_rules(window_size, grid_string_ids=None):
    """
    prefix ë¹„ìœ¨ ê·œì¹™ ìƒì„± ë° DB ì €ì¥
    
    ngram_chunks í…Œì´ë¸”ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ ê° prefixë³„ë¡œ 
    b/p ë¹„ìœ¨ê³¼ suffix ë¶„í¬ë¥¼ ë¶„ì„í•˜ì—¬ íŠ¸ë Œë“œ ê·œì¹™ì„ ìƒì„±í•˜ê³  ì €ì¥
    
    Args:
        window_size: ìœˆë„ìš° í¬ê¸°
        grid_string_ids: íŠ¹ì • grid_string_id ëª©ë¡ (Noneì´ë©´ ì „ì²´)
    
    Returns:
        int: ì €ì¥ëœ ê·œì¹™ ìˆ˜
    """
    conn = get_db_connection()
    if conn is None:
        return 0
    
    try:
        # ngram_chunksì—ì„œ ë°ì´í„° ë¡œë“œ
        if grid_string_ids is not None and len(grid_string_ids) > 0:
            if len(grid_string_ids) > 900:
                # ë°°ì¹˜ë¡œ ì²˜ë¦¬
                all_ngrams = []
                batch_size = 900
                for i in range(0, len(grid_string_ids), batch_size):
                    batch_ids = grid_string_ids[i:i + batch_size]
                    placeholders = ','.join(['?'] * len(batch_ids))
                    query = f"""
                        SELECT prefix, suffix
                        FROM ngram_chunks
                        WHERE window_size = ? AND grid_string_id IN ({placeholders})
                    """
                    batch_df = pd.read_sql_query(query, conn, params=[window_size] + batch_ids)
                    all_ngrams.append(batch_df)
                
                if all_ngrams:
                    ngrams_df = pd.concat(all_ngrams, ignore_index=True)
                else:
                    ngrams_df = pd.DataFrame()
            else:
                placeholders = ','.join(['?'] * len(grid_string_ids))
                query = f"""
                    SELECT prefix, suffix
                    FROM ngram_chunks
                    WHERE window_size = ? AND grid_string_id IN ({placeholders})
                """
                ngrams_df = pd.read_sql_query(query, conn, params=[window_size] + grid_string_ids)
        else:
            query = """
                SELECT prefix, suffix
                FROM ngram_chunks
                WHERE window_size = ?
            """
            ngrams_df = pd.read_sql_query(query, conn, params=[window_size])
        
        if len(ngrams_df) == 0:
            return 0
        
        # prefixë³„ë¡œ suffix ë¶„í¬ ë¶„ì„
        prefix_analysis = defaultdict(lambda: {'b': 0, 'p': 0})
        
        for _, row in ngrams_df.iterrows():
            prefix = row['prefix']
            suffix = row['suffix']
            prefix_analysis[prefix][suffix] += 1
        
        # ê·œì¹™ ê³„ì‚° ë° ì €ì¥
        cursor = conn.cursor()
        saved_count = 0
        
        for prefix, suffix_counts in prefix_analysis.items():
            # prefixì˜ b/p ë¹„ìœ¨ ê³„ì‚°
            prefix_ratio = calculate_prefix_ratio(prefix)
            b_ratio = prefix_ratio['b_ratio']
            
            # suffix ë¶„í¬
            b_suffix_count = suffix_counts['b']
            p_suffix_count = suffix_counts['p']
            total_count = b_suffix_count + p_suffix_count
            
            if total_count == 0:
                continue
            
            b_suffix_ratio = b_suffix_count / total_count
            p_suffix_ratio = p_suffix_count / total_count
            
            # ê·œì¹™ ê²°ì •: íŠ¸ë Œë“œ ë”°ë¦„ vs ë°˜ëŒ€
            if b_ratio > 0.5:  # prefixì—ì„œ bê°€ ë§ìŒ
                # suffixë„ bê°€ ë§ìœ¼ë©´ íŠ¸ë Œë“œ ë”°ë¦„
                trend_follow = 1 if b_suffix_ratio > p_suffix_ratio else 0
            elif b_ratio < 0.5:  # prefixì—ì„œ pê°€ ë§ìŒ
                # suffixë„ pê°€ ë§ìœ¼ë©´ íŠ¸ë Œë“œ ë”°ë¦„
                trend_follow = 1 if p_suffix_ratio > b_suffix_ratio else 0
            else:  # ê· í˜• (50%)
                # ì°¨ì´ê°€ ì‘ìœ¼ë©´ íŠ¸ë Œë“œ ë”°ë¦„ìœ¼ë¡œ ê°„ì£¼
                trend_follow = 1 if abs(b_suffix_ratio - p_suffix_ratio) < 0.2 else 0
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = abs(b_suffix_ratio - p_suffix_ratio)
            
            # DBì— ì €ì¥ (INSERT OR REPLACE)
            cursor.execute('''
                INSERT OR REPLACE INTO prefix_trend_rules (
                    window_size, prefix, b_ratio, p_ratio,
                    b_suffix_count, p_suffix_count, total_count,
                    trend_follow, confidence, updated_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now', '+9 hours'))
            ''', (
                window_size, prefix, b_ratio, prefix_ratio['p_ratio'],
                b_suffix_count, p_suffix_count, total_count,
                trend_follow, confidence
            ))
            
            if cursor.rowcount > 0:
                saved_count += 1
        
        conn.commit()
        return saved_count
        
    except Exception as e:
        conn.rollback()
        st.error(f"prefix_trend_rules ìƒì„± ë° ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return 0
    finally:
        conn.close()

def load_prefix_trend_rules(window_size):
    """
    DBì—ì„œ prefix ë¹„ìœ¨ ê·œì¹™ ë¡œë“œ
    
    Args:
        window_size: ìœˆë„ìš° í¬ê¸°
    
    Returns:
        dict: {prefix: {'b_ratio': float, 'p_ratio': float, 'trend_follow': bool, 'confidence': float, ...}, ...}
    """
    conn = get_db_connection()
    if conn is None:
        return {}
    
    try:
        query = """
            SELECT prefix, b_ratio, p_ratio, b_suffix_count, p_suffix_count,
                   total_count, trend_follow, confidence
            FROM prefix_trend_rules
            WHERE window_size = ?
        """
        df = pd.read_sql_query(query, conn, params=[window_size])
        
        if len(df) == 0:
            return {}
        
        rules = {}
        for _, row in df.iterrows():
            rules[row['prefix']] = {
                'b_ratio': row['b_ratio'],
                'p_ratio': row['p_ratio'],
                'b_suffix_count': int(row['b_suffix_count']),
                'p_suffix_count': int(row['p_suffix_count']),
                'total_count': int(row['total_count']),
                'trend_follow': bool(row['trend_follow']),
                'confidence': row['confidence']
            }
        
        return rules
        
    except Exception as e:
        st.error(f"prefix_trend_rules ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return {}
    finally:
        conn.close()

def build_balance_recovery_trend_model_final(ngrams_df, window_size):
    """
    ê· í˜• íšŒë³µ íŠ¸ë Œë“œ ëª¨ë¸ êµ¬ì¶• (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: DB ìš°ì„ , ì—†ìœ¼ë©´ ê³„ì‚° í›„ ì €ì¥)
    
    Args:
        ngrams_df: N-gram ì¡°ê° DataFrame
        window_size: ìœˆë„ìš° í¬ê¸°
    
    Returns:
        dict: {'prefix_rules': dict, 'frequency_model': dict}
    """
    # 1. DBì—ì„œ ê·œì¹™ ë¡œë“œ ì‹œë„
    prefix_rules = load_prefix_trend_rules(window_size)
    
    # 2. ê·œì¹™ì´ ì—†ê±°ë‚˜ ë¶€ì¡±í•˜ë©´ ê³„ì‚° í›„ ì €ì¥
    if not prefix_rules:
        # ngrams_dfì—ì„œ ê·œì¹™ ê³„ì‚°
        saved_count = generate_and_save_prefix_trend_rules(window_size)
        if saved_count > 0:
            # ë‹¤ì‹œ ë¡œë“œ
            prefix_rules = load_prefix_trend_rules(window_size)
    
    # 3. ë¹ˆë„ ëª¨ë¸ êµ¬ì¶• (í•­ìƒ ì˜ˆì¸¡ê°’ ë°˜í™˜ ë³´ì¥)
    frequency_model = build_frequency_model(ngrams_df)
    
    return {
        'prefix_rules': prefix_rules,
        'frequency_model': frequency_model
    }

def predict_balance_recovery_trend_final(model, prefix):
    """
    ê· í˜• íšŒë³µ íŠ¸ë Œë“œ ëª¨ë¸ë¡œ ì˜ˆì¸¡ (í•­ìƒ ì˜ˆì¸¡ê°’ ë°˜í™˜ ë³´ì¥)
    
    Args:
        model: build_balance_recovery_trend_model_finalë¡œ êµ¬ì¶•ëœ ëª¨ë¸
        prefix: ì˜ˆì¸¡í•  prefix
    
    Returns:
        tuple: (predicted, ratios) - í•­ìƒ ê°’ ë°˜í™˜
    """
    # ê¸°ë³¸ ë¹ˆë„ ëª¨ë¸ ì˜ˆì¸¡ (í•­ìƒ ìˆìŒ)
    freq_predicted, freq_ratios = predict_frequency(model['frequency_model'], prefix)
    
    # prefix ê·œì¹™ì´ ìˆìœ¼ë©´ ì ìš©
    if prefix in model['prefix_rules']:
        rule = model['prefix_rules'][prefix]
        trend_follow = rule['trend_follow']
        confidence = rule['confidence']
        b_ratio = rule['b_ratio']
        
        # ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡
        if trend_follow:
            # íŠ¸ë Œë“œ ë”°ë¦„: prefix ë¹„ìœ¨ê³¼ ê°™ì€ ë°©í–¥
            if b_ratio > 0.5:
                rule_predicted = 'b'
            elif b_ratio < 0.5:
                rule_predicted = 'p'
            else:
                # ê· í˜•ì´ë©´ ê¸°ë³¸ ë¹ˆë„ ëª¨ë¸ ì‚¬ìš©
                return freq_predicted, freq_ratios
        else:
            # íŠ¸ë Œë“œ ë°˜ëŒ€ (íšŒë³µ): prefix ë¹„ìœ¨ê³¼ ë°˜ëŒ€ ë°©í–¥
            if b_ratio > 0.5:
                rule_predicted = 'p'  # bê°€ ë§ìœ¼ë©´ p ì˜ˆì¸¡ (íšŒë³µ)
            elif b_ratio < 0.5:
                rule_predicted = 'b'  # pê°€ ë§ìœ¼ë©´ b ì˜ˆì¸¡ (íšŒë³µ)
            else:
                # ê· í˜•ì´ë©´ ê¸°ë³¸ ë¹ˆë„ ëª¨ë¸ ì‚¬ìš©
                return freq_predicted, freq_ratios
        
        # ê·œì¹™ê³¼ ë¹ˆë„ ëª¨ë¸ ê°€ì¤‘ í‰ê·  (ì‹ ë¢°ë„ ê¸°ë°˜)
        rule_weight = min(0.6, confidence * 1.2)  # ìµœëŒ€ 60%
        freq_weight = 1.0 - rule_weight
        
        # ê·œì¹™ ë¹„ìœ¨
        if rule_predicted == 'b':
            rule_b = 0.5 + (confidence * 0.25)
            rule_p = 1.0 - rule_b
        else:
            rule_p = 0.5 + (confidence * 0.25)
            rule_b = 1.0 - rule_p
        
        # ë¹ˆë„ ë¹„ìœ¨
        freq_b = freq_ratios.get('b', 50) / 100
        freq_p = freq_ratios.get('p', 50) / 100
        
        # ê°€ì¤‘ í‰ê· 
        combined_b = (rule_b * rule_weight) + (freq_b * freq_weight)
        combined_p = (rule_p * rule_weight) + (freq_p * freq_weight)
        
        # ì •ê·œí™”
        total = combined_b + combined_p
        if total > 0:
            combined_b = combined_b / total
            combined_p = combined_p / total
        
        predicted = 'b' if combined_b > combined_p else 'p'
        ratios = {
            'b': combined_b * 100,
            'p': combined_p * 100
        }
        
        return predicted, ratios
    
    # ê·œì¹™ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë¹ˆë„ ëª¨ë¸ë§Œ ì‚¬ìš© (í•­ìƒ ì˜ˆì¸¡ê°’ ë°˜í™˜)
    return freq_predicted, freq_ratios

def evaluate_predictions(predictions, actuals):
    """ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€"""
    if len(predictions) != len(actuals) or len(predictions) == 0:
        return {}
    
    correct = sum(1 for p, a in zip(predictions, actuals) if p == a)
    total = len(predictions)
    accuracy = (correct / total * 100) if total > 0 else 0.0
    
    # ë¬¸ìë³„ í†µê³„
    b_predictions = [p for p in predictions if p == 'b']
    p_predictions = [p for p in predictions if p == 'p']
    b_actuals = [a for a in actuals if a == 'b']
    p_actuals = [a for a in actuals if a == 'p']
    
    b_correct = sum(1 for p, a in zip(b_predictions, b_actuals) if len(b_predictions) > 0 and len(b_actuals) > 0)
    p_correct = sum(1 for p, a in zip(p_predictions, p_actuals) if len(p_predictions) > 0 and len(p_actuals) > 0)
    
    return {
        'accuracy': accuracy,
        'correct': correct,
        'total': total,
        'b_predicted': len(b_predictions),
        'p_predicted': len(p_predictions),
        'b_actual': len(b_actuals),
        'p_actual': len(p_actuals)
    }

def predict_for_prefix(model, prefix, method="ë¹ˆë„ ê¸°ë°˜"):
    """
    ë‹¨ì¼ prefixì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        prefix: ì˜ˆì¸¡í•  prefix ë¬¸ìì—´
        method: ì˜ˆì¸¡ ë°©ë²•
    
    Returns:
        dict: {predicted, ratios, confidence}
    """
    if method == "ë¹ˆë„ ê¸°ë°˜":
        predicted, ratios = predict_frequency(model, prefix)
    elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
        predicted, ratios = predict_weighted(model, prefix)
    elif method == "ì•ˆì „ ìš°ì„ ":
        # ì•ˆì „ ìš°ì„  ëª¨ë¸ì€ íˆìŠ¤í† ë¦¬ ì—†ì´ í˜¸ì¶œ (ê¸°ë³¸ ëª¨ë“œë§Œ ì‚¬ìš©)
        result = predict_safety_first(model, prefix, recent_history=None, consecutive_mismatches=0)
        predicted = result.get('predicted')
        ratios = result.get('ratios', {})
    else:  # ê¸°ë³¸ê°’: ë¹ˆë„ ê¸°ë°˜
        predicted, ratios = predict_frequency(model, prefix)
    
    confidence = max(ratios.values()) if ratios else 0.0
    
    return {
        'predicted': predicted,
        'ratios': ratios,
        'confidence': confidence
    }

def predict_ensemble_voting(model, prefix, methods=['ë¹ˆë„ ê¸°ë°˜', 'ê°€ì¤‘ì¹˜ ê¸°ë°˜', 'ì•ˆì „ ìš°ì„ ']):
    """
    ì•™ìƒë¸” ì „ëµ - ë‹¤ìˆ˜ê²° íˆ¬í‘œ ë°©ì‹
    
    ì—¬ëŸ¬ ì˜ˆì¸¡ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ íˆ¬í‘œí•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ ê²°ì •
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸ (ì—¬ëŸ¬ ë°©ë²•ì´ ë™ì¼í•œ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì‚¬ìš©)
        prefix: ì˜ˆì¸¡í•  prefix ë¬¸ìì—´
        methods: ì‚¬ìš©í•  ì˜ˆì¸¡ ë°©ë²• ë¦¬ìŠ¤íŠ¸
    
    Returns:
        dict: {predicted, ratios, confidence, strategy_name}
    """
    votes = {'b': 0, 'p': 0}
    all_ratios = {'b': [], 'p': []}
    
    for method in methods:
        # ì•ˆì „ ìš°ì„  ëª¨ë¸ì€ ì§ì ‘ í˜¸ì¶œ (íˆìŠ¤í† ë¦¬ ì—†ì´ - ê¸°ë³¸ ëª¨ë“œë§Œ ì‚¬ìš©)
        if method == 'ì•ˆì „ ìš°ì„ ':
            result = predict_safety_first(model, prefix, recent_history=None, consecutive_mismatches=0)
        else:
            result = predict_for_prefix(model, prefix, method)
        
        predicted = result.get('predicted')
        ratios = result.get('ratios', {})
        
        if predicted is not None:
            votes[predicted] += 1
            for suffix, ratio in ratios.items():
                all_ratios[suffix].append(ratio)
    
    # ë‹¤ìˆ˜ê²° íˆ¬í‘œ
    if votes['b'] > votes['p']:
        predicted = 'b'
    elif votes['p'] > votes['b']:
        predicted = 'p'
    else:
        # ë™ì ì¸ ê²½ìš° í‰ê·  ë¹„ìœ¨ì´ ë†’ì€ ê²ƒì„ ì„ íƒ
        avg_b = sum(all_ratios['b']) / len(all_ratios['b']) if all_ratios['b'] else 0
        avg_p = sum(all_ratios['p']) / len(all_ratios['p']) if all_ratios['p'] else 0
        predicted = 'b' if avg_b > avg_p else 'p'
    
    # í•©ì‚° ë¹„ìœ¨ ê³„ì‚°
    total_ratios = {}
    for suffix in ['b', 'p']:
        if all_ratios[suffix]:
            total_ratios[suffix] = sum(all_ratios[suffix]) / len(all_ratios[suffix])
        else:
            total_ratios[suffix] = 0.0
    
    # ì •ê·œí™”
    total = sum(total_ratios.values())
    if total > 0:
        ratios = {suffix: (ratio / total * 100) for suffix, ratio in total_ratios.items()}
    else:
        ratios = {'b': 50.0, 'p': 50.0}
    
    confidence = max(ratios.values()) if ratios else 0.0
    
    return {
        'predicted': predicted,
        'ratios': ratios,
        'confidence': confidence,
        'strategy_name': 'ì•™ìƒë¸”_íˆ¬í‘œ'
    }

def predict_ensemble_weighted(model, prefix, methods=['ë¹ˆë„ ê¸°ë°˜', 'ê°€ì¤‘ì¹˜ ê¸°ë°˜', 'ì•ˆì „ ìš°ì„ '], weights=None):
    """
    ì•™ìƒë¸” ì „ëµ - ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ í‰ê·  ë°©ì‹
    
    ê° ì˜ˆì¸¡ ë°©ë²•ì˜ ì‹ ë¢°ë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ ê²°ì •
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        prefix: ì˜ˆì¸¡í•  prefix ë¬¸ìì—´
        methods: ì‚¬ìš©í•  ì˜ˆì¸¡ ë°©ë²• ë¦¬ìŠ¤íŠ¸
        weights: ê° ë°©ë²•ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ (Noneì´ë©´ ì‹ ë¢°ë„ ê¸°ë°˜ ìë™ ê³„ì‚°)
    
    Returns:
        dict: {predicted, ratios, confidence, strategy_name}
    """
    predictions = []
    confidences = []
    
    for method in methods:
        # ì•ˆì „ ìš°ì„  ëª¨ë¸ì€ ì§ì ‘ í˜¸ì¶œ (íˆìŠ¤í† ë¦¬ ì—†ì´ - ê¸°ë³¸ ëª¨ë“œë§Œ ì‚¬ìš©)
        if method == 'ì•ˆì „ ìš°ì„ ':
            result = predict_safety_first(model, prefix, recent_history=None, consecutive_mismatches=0)
        else:
            result = predict_for_prefix(model, prefix, method)
        
        if result['predicted'] is not None:
            predictions.append(result)
            confidences.append(result['confidence'])
    
    if not predictions:
        return {
            'predicted': None,
            'ratios': {},
            'confidence': 0.0,
            'strategy_name': 'ì•™ìƒë¸”_ê°€ì¤‘í‰ê· '
        }
    
    # ê°€ì¤‘ì¹˜ ê³„ì‚° (ì‹ ë¢°ë„ ê¸°ë°˜)
    if weights is None:
        total_confidence = sum(confidences)
        if total_confidence > 0:
            weights = [c / total_confidence for c in confidences]
        else:
            weights = [1.0 / len(confidences)] * len(confidences)
    
    # ê°€ì¤‘ í‰ê·  ë¹„ìœ¨ ê³„ì‚°
    weighted_ratios = {'b': 0.0, 'p': 0.0}
    for i, pred in enumerate(predictions):
        weight = weights[i] if i < len(weights) else 1.0 / len(predictions)
        for suffix, ratio in pred['ratios'].items():
            weighted_ratios[suffix] += ratio * weight
    
    # ì •ê·œí™”
    total = sum(weighted_ratios.values())
    if total > 0:
        ratios = {suffix: (ratio / total * 100) for suffix, ratio in weighted_ratios.items()}
    else:
        ratios = {'b': 50.0, 'p': 50.0}
    
    # ê°€ì¥ ë†’ì€ ë¹„ìœ¨ì˜ suffix ì„ íƒ
    predicted = max(ratios.items(), key=lambda x: x[1])[0]
    confidence = ratios[predicted]
    
    return {
        'predicted': predicted,
        'ratios': ratios,
        'confidence': confidence,
        'strategy_name': 'ì•™ìƒë¸”_ê°€ì¤‘í‰ê· '
    }

def predict_ensemble_new_voting(models_dict, prefix):
    """
    ìƒˆë¡œìš´ ì•™ìƒë¸” ì „ëµ - ë‹¤ìˆ˜ê²° íˆ¬í‘œ ë°©ì‹ (ê¸°ì¡´ê³¼ ë…ë¦½)
    
    ë¹ˆë„ ê¸°ë°˜, ê°€ì¤‘ì¹˜ ê¸°ë°˜, ê· í˜• íšŒë³µ íŠ¸ë Œë“œ ëª¨ë¸ì„ ì¡°í•©í•˜ì—¬ ë‹¤ìˆ˜ê²° íˆ¬í‘œ
    
    Args:
        models_dict: {'ë¹ˆë„ ê¸°ë°˜': model, 'ê°€ì¤‘ì¹˜ ê¸°ë°˜': model, 'ê· í˜• íšŒë³µ íŠ¸ë Œë“œ': model}
        prefix: ì˜ˆì¸¡í•  prefix ë¬¸ìì—´
    
    Returns:
        dict: {
            'predicted': str,
            'ratios': dict,
            'confidence': float,
            'strategy_name': str,
            'individual_predictions': dict
        }
    """
    votes = {'b': 0, 'p': 0}
    all_ratios = {'b': [], 'p': []}
    individual_predictions = {}
    
    # ê° ëª¨ë¸ë³„ ì˜ˆì¸¡
    for method_name, model in models_dict.items():
        if method_name == 'ë¹ˆë„ ê¸°ë°˜':
            predicted, ratios = predict_frequency(model, prefix)
        elif method_name == 'ê°€ì¤‘ì¹˜ ê¸°ë°˜':
            predicted, ratios = predict_weighted(model, prefix)
        elif method_name == 'ê· í˜• íšŒë³µ íŠ¸ë Œë“œ':
            predicted, ratios = predict_balance_recovery_trend_final(model, prefix)
        else:
            continue
        
        # ì˜ˆì¸¡ê°’ì´ Noneì´ë©´ ìŠ¤í‚µ (í•˜ì§€ë§Œ ëª¨ë“  ëª¨ë¸ì´ í•­ìƒ ì˜ˆì¸¡ê°’ ë°˜í™˜í•˜ë„ë¡ ë³´ì¥)
        if predicted is not None:
            votes[predicted] += 1
            for suffix, ratio in ratios.items():
                all_ratios[suffix].append(ratio)
            
            individual_predictions[method_name] = {
                'predicted': predicted,
                'ratios': ratios,
                'confidence': max(ratios.values()) if ratios else 0.0
            }
    
    # ë‹¤ìˆ˜ê²° íˆ¬í‘œ
    if votes['b'] > votes['p']:
        predicted = 'b'
    elif votes['p'] > votes['b']:
        predicted = 'p'
    else:
        # ë™ì ì¸ ê²½ìš° í‰ê·  ë¹„ìœ¨ì´ ë†’ì€ ê²ƒì„ ì„ íƒ
        avg_b = sum(all_ratios['b']) / len(all_ratios['b']) if all_ratios['b'] else 0
        avg_p = sum(all_ratios['p']) / len(all_ratios['p']) if all_ratios['p'] else 0
        predicted = 'b' if avg_b > avg_p else 'p'
    
    # í•©ì‚° ë¹„ìœ¨ ê³„ì‚°
    total_ratios = {}
    for suffix in ['b', 'p']:
        if all_ratios[suffix]:
            total_ratios[suffix] = sum(all_ratios[suffix]) / len(all_ratios[suffix])
        else:
            total_ratios[suffix] = 0.0
    
    # ì •ê·œí™”
    total = sum(total_ratios.values())
    if total > 0:
        ratios = {suffix: (ratio / total * 100) for suffix, ratio in total_ratios.items()}
    else:
        ratios = {'b': 50.0, 'p': 50.0}
    
    confidence = max(ratios.values()) if ratios else 0.0
    
    return {
        'predicted': predicted,
        'ratios': ratios,
        'confidence': confidence,
        'strategy_name': 'ì•™ìƒë¸”_íˆ¬í‘œ_ì‹ ê·œ',
        'individual_predictions': individual_predictions,
        'votes': votes
    }

def validate_ensemble_interactive_scenario(grid_string_id, cutoff_grid_string_id, window_size=7, use_threshold=False):
    """
    ì•™ìƒë¸” íˆ¬í‘œ ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤ ë°©ì‹ìœ¼ë¡œ ë‹¨ì¼ grid_string ê²€ì¦
    
    Args:
        grid_string_id: ê²€ì¦í•  grid_stringì˜ ID
        cutoff_grid_string_id: í•™ìŠµ ë°ì´í„° ê¸°ì¤€ ID (ì´ ID ì´í•˜ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©)
        window_size: ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 7)
        use_threshold: ì„ê³„ê°’ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
    
    Returns:
        dict: {
            'grid_string_id': int,
            'max_consecutive_failures': int,
            'total_steps': int,
            'total_failures': int,
            'accuracy': float,
            'history': list
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # grid_string ë¡œë“œ
        query = "SELECT grid_string FROM preprocessed_grid_strings WHERE id = ?"
        df = pd.read_sql_query(query, conn, params=[grid_string_id])
        
        if len(df) == 0:
            return None
        
        grid_string = df.iloc[0]['grid_string']
        
        if len(grid_string) < window_size:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'total_steps': 0,
                'total_failures': 0,
                'accuracy': 0.0,
                'history': []
            }
        
        # í•™ìŠµ ë°ì´í„° êµ¬ì¶• (cutoff_grid_string_id ì´í•˜, ê²€ì¦ ë°ì´í„° ì œì™¸)
        # grid_string_idê°€ cutoff_grid_string_id ì´í•˜ì¸ ê²½ìš° í•™ìŠµ ë°ì´í„°ì—ì„œ ì œì™¸
        train_ids_query = "SELECT id FROM preprocessed_grid_strings WHERE id <= ? AND id < ? ORDER BY id"
        train_ids_df = pd.read_sql_query(train_ids_query, conn, params=[cutoff_grid_string_id, grid_string_id])
        train_ids = train_ids_df['id'].tolist() if len(train_ids_df) > 0 else []
        
        # N-gram ë¡œë“œ
        train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
        
        if len(train_ngrams) == 0:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'total_steps': 0,
                'total_failures': 0,
                'accuracy': 0.0,
                'history': []
            }
        
        # ëª¨ë¸ êµ¬ì¶•
        frequency_model = build_frequency_model(train_ngrams)
        weighted_model = build_weighted_model(train_ngrams)
        trend_model = build_balance_recovery_trend_model_final(train_ngrams, window_size)
        
        models_dict = {
            'ë¹ˆë„ ê¸°ë°˜': frequency_model,
            'ê°€ì¤‘ì¹˜ ê¸°ë°˜': weighted_model,
            'ê· í˜• íšŒë³µ íŠ¸ë Œë“œ': trend_model
        }
        
        # ì‹œë‚˜ë¦¬ì˜¤ ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        prefix_length = window_size - 1
        history = []
        consecutive_failures = 0
        max_consecutive_failures = 0
        total_steps = 0
        total_failures = 0
        
        # ì´ˆê¸° prefix ìƒì„±
        if len(grid_string) < prefix_length:
            return {
                'grid_string_id': grid_string_id,
                'max_consecutive_failures': 0,
                'total_steps': 0,
                'total_failures': 0,
                'accuracy': 0.0,
                'history': []
            }
        
        current_prefix = grid_string[:prefix_length]
        
        # ê° ìŠ¤í…ë§ˆë‹¤ ì˜ˆì¸¡ ë° ê²€ì¦
        for i in range(prefix_length, len(grid_string)):
            total_steps += 1
            actual_value = grid_string[i]
            
            # ì˜ˆì¸¡
            prediction_result = predict_ensemble_new_voting(models_dict, current_prefix)
            predicted_value = prediction_result.get('predicted')
            
            # ì˜ˆì¸¡ê°’ì´ Noneì´ë©´ ìŠ¤í‚µ (ì„ê³„ê°’ ë¯¸ì‚¬ìš©ì´ë¯€ë¡œ í•­ìƒ ì˜ˆì¸¡ê°’ì´ ìˆì–´ì•¼ í•¨)
            if predicted_value is None:
                continue
            
            # ì‹¤ì œê°’ê³¼ ë¹„êµ
            is_correct = predicted_value == actual_value
            
            if not is_correct:
                consecutive_failures += 1
                total_failures += 1
                if consecutive_failures > max_consecutive_failures:
                    max_consecutive_failures = consecutive_failures
            else:
                consecutive_failures = 0
            
            # íˆìŠ¤í† ë¦¬ ê¸°ë¡ (ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ê°’ ë° íˆ¬í‘œ ê²°ê³¼ í¬í•¨)
            history.append({
                'step': total_steps,
                'prefix': current_prefix,
                'predicted': predicted_value,
                'actual': actual_value,
                'is_correct': is_correct,
                'confidence': prediction_result.get('confidence', 0.0),
                'consecutive_failures': consecutive_failures,
                'individual_predictions': prediction_result.get('individual_predictions', {}),
                'votes': prediction_result.get('votes', {'b': 0, 'p': 0})
            })
            
            # ë‹¤ìŒ prefix ìƒì„±
            current_prefix = get_next_prefix(current_prefix, actual_value, window_size)
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = ((total_steps - total_failures) / total_steps * 100) if total_steps > 0 else 0.0
        
        return {
            'grid_string_id': grid_string_id,
            'max_consecutive_failures': max_consecutive_failures,
            'total_steps': total_steps,
            'total_failures': total_failures,
            'accuracy': accuracy,
            'history': history
        }
        
    except Exception as e:
        st.error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (grid_string_id={grid_string_id}): {str(e)}")
        return None
    finally:
        conn.close()

def batch_validate_ensemble_scenario(cutoff_grid_string_id, window_size=7, use_threshold=False):
    """
    cutoff_grid_string_id ì´í›„ì˜ ëª¨ë“  grid_stringì— ëŒ€í•´ ë°°ì¹˜ ê²€ì¦ ì‹¤í–‰
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ grid_string ID (ì´ ID ì´í›„ì˜ ë°ì´í„° ê²€ì¦)
        window_size: ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 7)
        use_threshold: ì„ê³„ê°’ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
    
    Returns:
        dict: {
            'results': list,
            'summary': dict
        }
    """
    conn = get_db_connection()
    if conn is None:
        return None
    
    try:
        # cutoff_grid_string_id ì´í›„ì˜ ëª¨ë“  grid_string ë¡œë“œ
        query = "SELECT id FROM preprocessed_grid_strings WHERE id > ? ORDER BY id"
        df = pd.read_sql_query(query, conn, params=[cutoff_grid_string_id])
        
        if len(df) == 0:
            return {
                'results': [],
                'summary': {
                    'total_grid_strings': 0,
                    'avg_accuracy': 0.0,
                    'max_consecutive_failures': 0,
                    'avg_max_consecutive_failures': 0.0
                }
            }
        
        grid_string_ids = df['id'].tolist()
        results = []
        
        # ê° grid_stringì— ëŒ€í•´ ê²€ì¦ ì‹¤í–‰
        for grid_string_id in grid_string_ids:
            result = validate_ensemble_interactive_scenario(
                grid_string_id,
                cutoff_grid_string_id,
                window_size=window_size, 
                use_threshold=use_threshold
            )
            
            if result is not None:
                results.append(result)
        
        # ìš”ì•½ í†µê³„ ê³„ì‚°
        if len(results) > 0:
            total_grid_strings = len(results)
            avg_accuracy = sum(r['accuracy'] for r in results) / total_grid_strings
            max_consecutive_failures = max(r['max_consecutive_failures'] for r in results)
            avg_max_consecutive_failures = sum(r['max_consecutive_failures'] for r in results) / total_grid_strings
            
            summary = {
                'total_grid_strings': total_grid_strings,
                'avg_accuracy': avg_accuracy,
                'max_consecutive_failures': max_consecutive_failures,
                'avg_max_consecutive_failures': avg_max_consecutive_failures,
                'total_steps': sum(r['total_steps'] for r in results),
                'total_failures': sum(r['total_failures'] for r in results)
            }
        else:
            summary = {
                'total_grid_strings': 0,
                'avg_accuracy': 0.0,
                'max_consecutive_failures': 0,
                'avg_max_consecutive_failures': 0.0,
                'total_steps': 0,
                'total_failures': 0
            }
        
        return {
            'results': results,
            'summary': summary
        }
        
    except Exception as e:
        st.error(f"ë°°ì¹˜ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    finally:
        conn.close()

def predict_confidence_threshold(model, prefix, method="ë¹ˆë„ ê¸°ë°˜", threshold=60):
    """
    ì‹ ë¢°ë„ ì„ê³„ê°’ ì „ëµ - ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ë¯¸ë§Œì´ë©´ ì˜ˆì¸¡í•˜ì§€ ì•ŠìŒ
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        prefix: ì˜ˆì¸¡í•  prefix ë¬¸ìì—´
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 60%)
    
    Returns:
        dict: {predicted, ratios, confidence, strategy_name}
    """
    result = predict_for_prefix(model, prefix, method)
    confidence = result.get('confidence', 0.0)
    predicted = result.get('predicted')
    
    # ì˜ˆì¸¡ê°’ì´ ì—†ìœ¼ë©´ None ë°˜í™˜
    if predicted is None:
        return {
            'predicted': None,
            'ratios': result.get('ratios', {}),
            'confidence': confidence,
            'strategy_name': f'ì‹ ë¢°ë„ì„ê³„ê°’_{threshold}'
        }
    
    # ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ë¥¼ ê³ ë ¤í•˜ì—¬ ë°˜ì˜¬ë¦¼ëœ ê°’ì„ ë¹„êµ
    # ì„ê³„ê°’ ì´ìƒì´ë©´ ì˜ˆì¸¡ê°’ ë°˜í™˜ (threshold=57ì´ë©´ confidence>=57ì´ë©´ ì˜ˆì¸¡)
    # ë°˜ì˜¬ë¦¼í•˜ì—¬ ë¹„êµ (ì˜ˆ: 56.9 -> 57, 57.0 -> 57)
    confidence_rounded = round(confidence, 1)
    threshold_rounded = round(threshold, 1)
    
    if confidence_rounded < threshold_rounded:
        # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ì˜ˆì¸¡í•˜ì§€ ì•ŠìŒ
        return {
            'predicted': None,
            'ratios': result.get('ratios', {}),
            'confidence': confidence,
            'strategy_name': f'ì‹ ë¢°ë„ì„ê³„ê°’_{threshold}'
        }
    
    return {
        'predicted': result.get('predicted'),
        'ratios': result.get('ratios', {}),
        'confidence': confidence,
        'strategy_name': f'ì‹ ë¢°ë„ì„ê³„ê°’_{threshold}'
    }

def predict_confidence_reverse(model, prefix, method="ë¹ˆë„ ê¸°ë°˜", threshold=50):
    """
    ì‹ ë¢°ë„ ì—­ì „ëµ - ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ë¯¸ë§Œì´ë©´ ë°˜ëŒ€ ì˜ˆì¸¡
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        prefix: ì˜ˆì¸¡í•  prefix ë¬¸ìì—´
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 50%)
    
    Returns:
        dict: {predicted, ratios, confidence, strategy_name}
    """
    result = predict_for_prefix(model, prefix, method)
    predicted = result.get('predicted')
    ratios = result.get('ratios', {})
    confidence = result.get('confidence', 0.0)
    
    if confidence < threshold and predicted is not None:
        # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ë°˜ëŒ€ ì˜ˆì¸¡
        reverse_predicted = 'p' if predicted == 'b' else 'b'
        reverse_ratios = {}
        for suffix, ratio in ratios.items():
            reverse_ratios[suffix] = 100.0 - ratio
        
        # ì •ê·œí™”
        total = sum(reverse_ratios.values())
        if total > 0:
            reverse_ratios = {suffix: (ratio / total * 100) for suffix, ratio in reverse_ratios.items()}
        
        return {
            'predicted': reverse_predicted,
            'ratios': reverse_ratios,
            'confidence': max(reverse_ratios.values()) if reverse_ratios else 0.0,
            'strategy_name': f'ì‹ ë¢°ë„ì—­ì „_{threshold}'
        }
    
    return {
        'predicted': predicted,
        'ratios': ratios,
        'confidence': confidence,
        'strategy_name': f'ì‹ ë¢°ë„ì—­ì „_{threshold}'
    }

def predict_reverse(model, prefix, method="ë¹ˆë„ ê¸°ë°˜"):
    """
    ì—­ì „ëµ - ì˜ˆì¸¡ê³¼ ë°˜ëŒ€ë¡œ ì˜ˆì¸¡ (ì—°ì† ì¼ì¹˜ 5íšŒ ì´ìƒ ë°©ì§€)
    
    ê°€ì¥ ë‚®ì€ ë¹ˆë„ì˜ suffixë¥¼ ì˜ˆì¸¡
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        prefix: ì˜ˆì¸¡í•  prefix ë¬¸ìì—´
        method: ì˜ˆì¸¡ ë°©ë²•
    
    Returns:
        dict: {predicted, ratios, confidence, strategy_name}
    """
    result = predict_for_prefix(model, prefix, method)
    predicted = result.get('predicted')
    ratios = result.get('ratios', {})
    
    if not ratios:
        return {
            'predicted': None,
            'ratios': {},
            'confidence': 0.0,
            'strategy_name': 'ì—­ì „ëµ'
        }
    
    # ê°€ì¥ ë‚®ì€ ë¹ˆë„ì˜ suffix ì„ íƒ
    reverse_predicted = min(ratios.items(), key=lambda x: x[1])[0]
    
    # ë¹„ìœ¨ ì—­ì „ (ë‚®ì€ ë¹„ìœ¨ì´ ë†’ì€ ë¹„ìœ¨ë¡œ)
    reverse_ratios = {}
    for suffix, ratio in ratios.items():
        reverse_ratios[suffix] = 100.0 - ratio
    
    # ì •ê·œí™”
    total = sum(reverse_ratios.values())
    if total > 0:
        reverse_ratios = {suffix: (ratio / total * 100) for suffix, ratio in reverse_ratios.items()}
    
    confidence = reverse_ratios[reverse_predicted] if reverse_predicted in reverse_ratios else 0.0
    
    return {
        'predicted': reverse_predicted,
        'ratios': reverse_ratios,
        'confidence': confidence,
        'strategy_name': 'ì—­ì „ëµ'
    }

def predict_with_fallback_interval(
    model, 
    prefix, 
    method="ë¹ˆë„ ê¸°ë°˜", 
    threshold=60,
    max_interval=5,
    current_interval=0
):
    """
    ìµœëŒ€ ê°„ê²© ì œì•½ì´ ìˆëŠ” ì˜ˆì¸¡ ì „ëµ
    
    ì„ê³„ê°’ ê¸°ë°˜ ì˜ˆì¸¡ì„ ì‹œë„í•˜ë˜, ìµœëŒ€ ê°„ê²©ì„ ë„˜ê¸°ë©´ ì„ê³„ê°’ì„ ë¬´ì‹œí•˜ê³  ê°•ì œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        prefix: ì˜ˆì¸¡í•  prefix ë¬¸ìì—´
        method: ì˜ˆì¸¡ ë°©ë²•
        threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© (ì´ ê°„ê²©ì„ ë„˜ê¸°ë©´ ê°•ì œ ì˜ˆì¸¡)
        current_interval: í˜„ì¬ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
    
    Returns:
        dict: {
            'predicted': ì˜ˆì¸¡ê°’ (Noneì¼ ìˆ˜ ìˆìŒ),
            'confidence': ì‹ ë¢°ë„,
            'ratios': ë¹„ìœ¨,
            'is_forced': ê°•ì œ ì˜ˆì¸¡ ì—¬ë¶€,
            'strategy_name': ì „ëµ ì´ë¦„
        }
    """
    # ê¸°ë³¸ ì˜ˆì¸¡ ì‹œë„ (ì„ê³„ê°’ ê¸°ë°˜)
    prediction_result = predict_confidence_threshold(model, prefix, method, threshold)
    
    # ì˜ˆì¸¡ê°’ì´ ìˆê³  ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ ë°˜í™˜
    if prediction_result.get('predicted') is not None:
        return {
            **prediction_result,
            'is_forced': False,
            'strategy_name': f'ì„ê³„ê°’_{threshold}'
        }
    
    # ì˜ˆì¸¡ê°’ì´ ì—†ê³  ìµœëŒ€ ê°„ê²©ì„ ë„˜ê²¼ìœ¼ë©´ ê°•ì œ ì˜ˆì¸¡
    # current_intervalì€ ì´ë¯¸ ì˜ˆì¸¡ ì—†ìŒì´ ë°œìƒí•œ íšŸìˆ˜
    # ì˜ˆ: max_interval=6ì´ë©´ ê°„ê²© 6ì¼ ë•Œ ê°•ì œ ì˜ˆì¸¡ (ì˜ˆì¸¡ ì—†ìŒì´ 6ë²ˆ ë°œìƒ)
    # current_interval >= max_intervalì´ë©´ ê°•ì œ ì˜ˆì¸¡
    # ì˜ˆ: max_interval=6ì´ë©´ ê°„ê²© 6ì¼ ë•Œ ê°•ì œ ì˜ˆì¸¡ (ì˜ˆì¸¡ ì—†ìŒì´ 6ë²ˆ ë°œìƒ)
    if current_interval >= max_interval:
        # ì„ê³„ê°’ ì—†ì´ ì˜ˆì¸¡
        forced_result = predict_for_prefix(model, prefix, method)
        return {
            **forced_result,
            'is_forced': True,
            'strategy_name': f'ê°•ì œì˜ˆì¸¡_ê°„ê²©{max_interval}'
        }
    
    # ì˜ˆì¸¡ê°’ì´ ì—†ê³  ê°„ê²©ì´ ì•„ì§ ì•ˆ ë„˜ì—ˆìœ¼ë©´ None ë°˜í™˜
    return {
        'predicted': None,
        'confidence': prediction_result.get('confidence', 0.0),
        'ratios': prediction_result.get('ratios', {}),
        'is_forced': False,
        'strategy_name': f'ì„ê³„ê°’_{threshold}'
    }

def get_next_prefix(current_prefix, value, window_size):
    """
    í˜„ì¬ prefixì™€ ì„ íƒëœ ê°’ìœ¼ë¡œ ë‹¤ìŒ prefix ìƒì„±
    
    Args:
        current_prefix: í˜„ì¬ prefix
        value: ì„ íƒëœ ê°’ ('b' ë˜ëŠ” 'p')
        window_size: ìœˆë„ìš° í¬ê¸°
    
    Returns:
        str: ë‹¤ìŒ prefix (ë§ˆì§€ë§‰ N-1ìë¦¬)
    """
    new_string = current_prefix + value
    # ìœˆë„ìš° í¬ê¸°ê°€ Nì´ë©´ prefixëŠ” N-1ìë¦¬
    prefix_length = window_size - 1
    if len(new_string) >= prefix_length:
        return new_string[-prefix_length:]
    return new_string

def generate_prediction_tree(model, initial_prefix, window_size, method="ë¹ˆë„ ê¸°ë°˜", max_depth=5, cache=None):
    """
    ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ íŠ¸ë¦¬ ìƒì„± (ëª¨ë“  ê°€ëŠ¥í•œ ê²½ë¡œ ìë™ ìƒì„±)
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        initial_prefix: ì´ˆê¸° prefix
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        max_depth: ìµœëŒ€ ê¹Šì´
        cache: ìºì‹œ ë”•ì…”ë„ˆë¦¬ (ì¤‘ë³µ ê³„ì‚° ë°©ì§€)
    
    Returns:
        dict: íŠ¸ë¦¬ ë°ì´í„° êµ¬ì¡°
    """
    if cache is None:
        cache = {}
    
    # í˜„ì¬ prefixì— ëŒ€í•œ ì˜ˆì¸¡
    prediction_result = predict_for_prefix(model, initial_prefix, method)
    ratios = prediction_result.get('ratios', {})
    
    # íŠ¸ë¦¬ ë…¸ë“œ ìƒì„±
    node = {
        'prefix': initial_prefix,
        'predictions': ratios,
        'children': []
    }
    
    # ìµœëŒ€ ê¹Šì´ì— ë„ë‹¬í•˜ë©´ ì¢…ë£Œ
    if max_depth <= 1:
        return node
    
    # ëª¨ë“  ê°€ëŠ¥í•œ í›„ë³´ê°’('b', 'p')ì— ëŒ€í•´ ê²½ë¡œ ìƒì„±
    candidates = ['b', 'p']
    
    for candidate in candidates:
        # ë‹¤ìŒ prefix ìƒì„±
        next_prefix = get_next_prefix(initial_prefix, candidate, window_size)
        
        # ìºì‹œ í™•ì¸
        cache_key = f"{next_prefix}_{max_depth-1}"
        if cache_key in cache:
            child_node = cache[cache_key]
        else:
            # ì¬ê·€ì ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ ìƒì„±
            child_node = generate_prediction_tree(
                model, next_prefix, window_size, method, max_depth - 1, cache
            )
            cache[cache_key] = child_node
        
        # ê²½ë¡œ ì •ë³´ ì¶”ê°€
        child_node['path_value'] = candidate  # ì´ ê²½ë¡œë¡œ ì˜¤ê¸° ìœ„í•´ ì„ íƒëœ ê°’
        node['children'].append(child_node)
    
    return node

def display_prediction_tree_html(node, max_depth=5):
    """
    íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ HTMLë¡œ ê°€ë¡œ í™•ì¥ í˜•íƒœë¡œ í‘œì‹œ (ì˜¤ë¥¸ìª½ìœ¼ë¡œ í™•ì¥)
    
    Args:
        node: íŠ¸ë¦¬ ë…¸ë“œ
        max_depth: ìµœëŒ€ ê¹Šì´
    """
    html = """
    <style>
    .prediction-tree-container {
        font-family: 'Courier New', monospace;
        font-size: 13px;
        margin: 20px 0;
        overflow-x: auto;
    }
    .tree-row {
        display: flex;
        align-items: flex-start;
        margin: 15px 0;
        min-height: 80px;
    }
    .tree-node {
        display: inline-block;
        vertical-align: top;
        margin: 0 20px;
        padding: 12px;
        border: 2px solid #4CAF50;
        border-radius: 8px;
        background: linear-gradient(135deg, #f9f9f9 0%, #ffffff 100%);
        min-width: 140px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .tree-node-root {
        border-color: #2196F3;
        background: linear-gradient(135deg, #E3F2FD 0%, #BBDEFB 100%);
        font-weight: bold;
        box-shadow: 0 4px 8px rgba(33,150,243,0.3);
    }
    .tree-prefix {
        font-size: 18px;
        font-weight: bold;
        color: #1976D2;
        margin-bottom: 8px;
        text-align: center;
        padding: 5px;
        background-color: rgba(255,255,255,0.5);
        border-radius: 4px;
    }
    .tree-predictions {
        font-size: 12px;
        margin-top: 8px;
    }
    .tree-pred-item {
        margin: 4px 0;
        padding: 4px 8px;
        border-radius: 4px;
        text-align: center;
    }
    .tree-pred-high {
        background-color: #C8E6C9;
        font-weight: bold;
        color: #2E7D32;
    }
    .tree-pred-low {
        background-color: #FFE0B2;
        color: #E65100;
    }
    .tree-connector {
        display: inline-block;
        margin: 0 10px;
        font-size: 24px;
        color: #666;
        vertical-align: middle;
        line-height: 80px;
    }
    .tree-path-label {
        font-size: 10px;
        color: #666;
        margin-top: 5px;
        font-style: italic;
        text-align: center;
    }
    .tree-branch {
        display: flex;
        flex-direction: column;
        align-items: center;
    }
    </style>
    """
    
    # íŠ¸ë¦¬ë¥¼ ë ˆë²¨ë³„ë¡œ êµ¬ì„±
    levels = {}
    
    def traverse_tree(n, depth=0, path_label="", parent_prefix=""):
        if depth > max_depth:
            return
        
        prefix = n.get('prefix', '')
        predictions = n.get('predictions', {})
        path_value = n.get('path_value', '')
        
        # ì˜ˆì¸¡ê°’ì„ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬
        sorted_predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True) if predictions else []
        
        node_data = {
            'prefix': prefix,
            'predictions': sorted_predictions,
            'path_label': path_label,
            'path_value': path_value,
            'parent_prefix': parent_prefix
        }
        
        if depth not in levels:
            levels[depth] = []
        levels[depth].append(node_data)
        
        # ìì‹ ë…¸ë“œ ì²˜ë¦¬ (ì˜ˆì¸¡ê°’ ë†’ì€ ìˆœì„œë¡œ)
        children = n.get('children', [])
        if children:
            # ì˜ˆì¸¡ê°’ì´ ë†’ì€ ê²½ë¡œë¥¼ ë¨¼ì € í‘œì‹œí•˜ê¸° ìœ„í•´ ì •ë ¬
            sorted_children = sorted(children, key=lambda c: max(c.get('predictions', {}).values()) if c.get('predictions') else 0, reverse=True)
            
            for child in sorted_children:
                child_path_value = child.get('path_value', '')
                new_path_label = f"{path_label} â†’ {child_path_value}" if path_label else child_path_value
                traverse_tree(child, depth + 1, new_path_label, prefix)
    
    traverse_tree(node)
    
    # HTML ìƒì„± - ê°€ë¡œ í™•ì¥ í˜•íƒœ
    html += '<div class="prediction-tree-container">'
    
    for depth in sorted(levels.keys()):
        html += f'<div class="tree-row">'
        html += f'<div style="min-width: 80px; text-align: center; padding-top: 30px; font-weight: bold; color: #666;">Step {depth + 1}</div>'
        
        nodes_at_level = levels[depth]
        
        # ê°™ì€ ë¶€ëª¨ë¥¼ ê°€ì§„ ë…¸ë“œë“¤ì„ ê·¸ë£¹í™”
        parent_groups = {}
        for node_data in nodes_at_level:
            parent = node_data['parent_prefix']
            if parent not in parent_groups:
                parent_groups[parent] = []
            parent_groups[parent].append(node_data)
        
        # ê° ë¶€ëª¨ ê·¸ë£¹ë³„ë¡œ í‘œì‹œ
        for parent, group_nodes in parent_groups.items():
            html += '<div class="tree-branch">'
            
            for node_data in group_nodes:
                prefix = node_data['prefix']
                predictions = node_data['predictions']
                path_value = node_data['path_value']
                
                node_class = "tree-node tree-node-root" if depth == 0 else "tree-node"
                
                html += f'<div class="{node_class}">'
                html += f'<div class="tree-prefix">{prefix}</div>'
                
                if path_value:
                    html += f'<div class="tree-path-label">ê²½ë¡œ: {path_value}</div>'
                
                if predictions:
                    html += '<div class="tree-predictions">'
                    for idx, (value, ratio) in enumerate(predictions):
                        pred_class = "tree-pred-item tree-pred-high" if idx == 0 else "tree-pred-item tree-pred-low"
                        html += f'<div class="{pred_class}">{value}: {ratio:.1f}%</div>'
                    html += '</div>'
                else:
                    html += '<div class="tree-predictions" style="color: #999;">ë°ì´í„° ì—†ìŒ</div>'
                
                html += '</div>'
            
            html += '</div>'
            
            # ë‹¤ìŒ ë ˆë²¨ë¡œ ì—°ê²°ì„  í‘œì‹œ (ë§ˆì§€ë§‰ ë ˆë²¨ì´ ì•„ë‹Œ ê²½ìš°)
            if depth < max(levels.keys()):
                html += '<div class="tree-connector">â†’</div>'
        
        html += '</div>'
    
    html += '</div>'
    
    st.markdown(html, unsafe_allow_html=True)

def display_prediction_tree(node, depth=0, max_display_depth=5):
    """
    íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ UIì— í‘œì‹œ (HTML ë²„ì „ ì‚¬ìš©)
    
    Args:
        node: íŠ¸ë¦¬ ë…¸ë“œ
        depth: í˜„ì¬ ê¹Šì´ (ì‚¬ìš© ì•ˆ í•¨, í˜¸í™˜ì„± ìœ ì§€)
        max_display_depth: ìµœëŒ€ í‘œì‹œ ê¹Šì´
    """
    display_prediction_tree_html(node, max_display_depth)

def extract_prefixes_from_string(grid_string, window_size):
    """
    grid_stringì„ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ìŠ¬ë¼ì´ì‹±í•˜ì—¬ prefixì™€ suffix ì¶”ì¶œ
    
    Args:
        grid_string: ì…ë ¥ ë¬¸ìì—´ (ì˜ˆ: "bbbbppbbpp...")
        window_size: ìœˆë„ìš° í¬ê¸°
    
    Returns:
        list: [(prefix, suffix, index), ...]
    """
    if not grid_string or len(grid_string) < window_size:
        return []
    
    prefixes = []
    for i in range(len(grid_string) - window_size + 1):
        chunk = grid_string[i:i + window_size]
        prefix = chunk[:-1]  # ì• N-1ê°œ
        suffix = chunk[-1]   # ë§ˆì§€ë§‰ 1ê°œ
        prefixes.append((prefix, suffix, i))
    
    return prefixes

def simulate_game_scenario(model, grid_string, window_size, method="ë¹ˆë„ ê¸°ë°˜", strategy_func=None, skip_ending_mismatch=True, max_interval=None, threshold=60, truncate_at_last_match=True):
    """
    ê²Œì„ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ (ëª¨ë“  ìŠ¤í… ì§„í–‰ í›„ ì—°ì† ë¶ˆì¼ì¹˜/ì¼ì¹˜ 5ê°œ ê²€ì¦)
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        grid_string: ê²€ì¦í•  ë¬¸ìì—´
        window_size: ìœˆë„ìš° í¬ê¸°
        method: ì˜ˆì¸¡ ë°©ë²•
        strategy_func: ì»¤ìŠ¤í…€ ì „ëµ í•¨ìˆ˜ (Noneì´ë©´ ê¸°ë³¸ predict_for_prefix ì‚¬ìš©)
        skip_ending_mismatch: Trueë©´ ë¶ˆì¼ì¹˜ ìƒíƒœë¡œ ëë‚˜ëŠ” ì¼€ì´ìŠ¤ ìŠ¤í‚µ (ì „ì²´ ìŠ¤í‚µ)
        max_interval: ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© (Noneì´ë©´ ê°•ì œ ì˜ˆì¸¡ ì‚¬ìš© ì•ˆ í•¨)
        threshold: ì‹ ë¢°ë„ ì„ê³„ê°’ (max_interval ì‚¬ìš© ì‹œ í•„ìš”)
        truncate_at_last_match: Trueë©´ ë¶ˆì¼ì¹˜ë¡œ ëë‚  ë•Œ ë§ˆì§€ë§‰ ì¼ì¹˜ ìŠ¤í…ê¹Œì§€ë§Œ ìœ íš¨ ì²˜ë¦¬
    
    Returns:
        dict: {
            'result': 'has_5_consecutive' | 'no_5_consecutive' | 'skipped_ending_mismatch',
            'ends_with_match': ë§ˆì§€ë§‰ ìƒíƒœê°€ ì¼ì¹˜ì¸ì§€ ì—¬ë¶€,
            'ends_with_mismatch': ë§ˆì§€ë§‰ ìƒíƒœê°€ ë¶ˆì¼ì¹˜ì¸ì§€ ì—¬ë¶€,
            'ending_consecutive_mismatches': ì¢…ë£Œ ì‹œ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜,
            'max_consecutive_mismatches': ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜,
            'max_consecutive_matches': ìµœëŒ€ ì—°ì† ì¼ì¹˜ ìˆ˜,
            'consecutive_5_positions': ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œê°€ ë°œìƒí•œ ìœ„ì¹˜ë“¤,
            'consecutive_5_match_positions': ì—°ì† ì¼ì¹˜ 5ê°œê°€ ë°œìƒí•œ ìœ„ì¹˜ë“¤,
            'history': [ê° ìŠ¤í…ì˜ ê²°ê³¼],
            'stats': í†µê³„ ì •ë³´,
            'skipped': ìŠ¤í‚µ ì—¬ë¶€,
            'truncated': ì¼ì¹˜ ì¢…ë£Œ ì§€ì ì—ì„œ ì˜ë ¸ëŠ”ì§€ ì—¬ë¶€,
            'last_match_step': ë§ˆì§€ë§‰ ì¼ì¹˜ ìŠ¤í… ë²ˆí˜¸ (truncated=Trueì¼ ë•Œ),
            'truncated_steps': ì˜ë¦° ìŠ¤í… ìˆ˜ (ì „ì²´ - ìœ íš¨),
            'forced_predictions': ê°•ì œ ì˜ˆì¸¡ ìˆ˜ (max_interval ì‚¬ìš© ì‹œ),
            'forced_prediction_ratio': ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ (max_interval ì‚¬ìš© ì‹œ),
            'avg_interval': í‰ê·  ê°„ê²© (max_interval ì‚¬ìš© ì‹œ),
            'max_interval_actual': ì‹¤ì œ ìµœëŒ€ ê°„ê²© (max_interval ì‚¬ìš© ì‹œ),
            'min_interval': ìµœì†Œ ê°„ê²© (max_interval ì‚¬ìš© ì‹œ)
        }
    """
    # prefixë“¤ ì¶”ì¶œ
    prefixes_data = extract_prefixes_from_string(grid_string, window_size)
    
    if not prefixes_data:
        return {
            'result': 'no_5_consecutive',
            'max_consecutive_mismatches': 0,
            'max_consecutive_matches': 0,
            'consecutive_5_positions': [],
            'consecutive_5_match_positions': [],
            'history': [],
            'stats': {
                'total': 0,
                'matches': 0,
                'mismatches': 0,
                'max_consecutive_mismatches': 0,
                'max_consecutive_matches': 0,
                'consecutive_5_count': 0,
                'consecutive_5_match_count': 0
            }
        }
    
    history = []
    consecutive_mismatches = 0
    consecutive_matches = 0
    max_consecutive_mismatches = 0
    max_consecutive_matches = 0
    consecutive_5_positions = []  # ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œê°€ ë°œìƒí•œ ìœ„ì¹˜ë“¤ (ê²¹ì¹˜ì§€ ì•ŠëŠ” êµ¬ê°„ë§Œ)
    consecutive_5_match_positions = []  # ì—°ì† ì¼ì¹˜ 5ê°œê°€ ë°œìƒí•œ ìœ„ì¹˜ë“¤ (ê²¹ì¹˜ì§€ ì•ŠëŠ” êµ¬ê°„ë§Œ)
    total_matches = 0
    total_mismatches = 0
    
    # íˆìŠ¤í† ë¦¬ ì¶”ì  (ì•ˆì „ ìš°ì„  ëª¨ë¸ìš©)
    prediction_history = []  # [(predicted, actual, is_match), ...]
    
    # ê°•ì œ ì˜ˆì¸¡ ê´€ë ¨ ë³€ìˆ˜ (max_interval ì‚¬ìš© ì‹œ)
    current_interval = 0  # í˜„ì¬ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²©
    forced_predictions = 0  # ê°•ì œ ì˜ˆì¸¡ ìˆ˜
    total_predictions = 0  # ì „ì²´ ì˜ˆì¸¡ ìˆ˜
    intervals = []  # ì˜ˆì¸¡ ê°„ê²© ë¦¬ìŠ¤íŠ¸
    
    # ì—°ì† ë¶ˆì¼ì¹˜ êµ¬ê°„ ì¶”ì  (ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´)
    current_consecutive_start = None  # í˜„ì¬ ì—°ì† ë¶ˆì¼ì¹˜ êµ¬ê°„ì˜ ì‹œì‘ step
    current_consecutive_match_start = None  # í˜„ì¬ ì—°ì† ì¼ì¹˜ êµ¬ê°„ì˜ ì‹œì‘ step
    
    # ì•ˆì „ ìš°ì„  ëª¨ë¸ ë˜í¼ í•¨ìˆ˜ ìƒì„± (íˆìŠ¤í† ë¦¬ì™€ consecutive_mismatches ì „ë‹¬)
    def create_safety_first_wrapper(hist, consec_mismatches):
        def wrapper(m, p, mthd):
            return predict_safety_first(m, p, recent_history=hist, consecutive_mismatches=consec_mismatches)
        return wrapper
    
    def add_or_merge_consecutive_range(start_step, end_step, positions_list):
        """ì—°ì† êµ¬ê°„ì„ ì¶”ê°€í•˜ê±°ë‚˜ ê¸°ì¡´ êµ¬ê°„ê³¼ ë³‘í•©"""
        # ê¸°ì¡´ êµ¬ê°„ê³¼ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
        merged = False
        for existing_pos in positions_list:
            existing_start = existing_pos['start_step']
            existing_end = existing_pos['end_step']
            
            # ê²¹ì¹˜ëŠ” ê²½ìš°: ë‘ êµ¬ê°„ì´ ê²¹ì¹˜ê±°ë‚˜ ì¸ì ‘í•œ ê²½ìš°
            # (ìƒˆ êµ¬ê°„ì˜ ì‹œì‘ì´ ê¸°ì¡´ êµ¬ê°„ì˜ ë ì´í•˜ì´ê³ , ìƒˆ êµ¬ê°„ì˜ ëì´ ê¸°ì¡´ êµ¬ê°„ì˜ ì‹œì‘ ì´ìƒ)
            if start_step <= existing_end + 1 and end_step >= existing_start - 1:
                # ë” ë„“ì€ êµ¬ê°„ìœ¼ë¡œ ë³‘í•©
                new_start = min(start_step, existing_start)
                new_end = max(end_step, existing_end)
                existing_pos['start_step'] = new_start
                existing_pos['end_step'] = new_end
                existing_pos['steps'] = list(range(new_start, new_end + 1))
                merged = True
                break
        
        # ê²¹ì¹˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œ ì¶”ê°€
        if not merged:
            positions_list.append({
                'start_step': start_step,
                'end_step': end_step,
                'steps': list(range(start_step, end_step + 1))
            })
    
    # ëª¨ë“  ìŠ¤í…ì„ ì§„í–‰í•˜ë©´ì„œ ì—°ì† ë¶ˆì¼ì¹˜/ì¼ì¹˜ ì¶”ì 
    for step, (prefix, actual_suffix, index) in enumerate(prefixes_data, 1):
        # ì˜ˆì¸¡ê°’ ê³„ì‚°
        if max_interval is not None:
            # ê°•ì œ ì˜ˆì¸¡ ì „ëµ ì‚¬ìš©
            prediction_result = predict_with_fallback_interval(
                model, prefix, method, threshold, max_interval, current_interval
            )
        elif strategy_func:
            # strategy_func í˜¸ì¶œ (ì•ˆì „ ìš°ì„  ëª¨ë¸ì¸ ê²½ìš° íˆìŠ¤í† ë¦¬ëŠ” ë˜í¼ì—ì„œ ì „ë‹¬ë¨)
            # ì•ˆì „ ìš°ì„  ëª¨ë¸ ë˜í¼ì˜ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            if hasattr(strategy_func, '_history_ref') and hasattr(strategy_func, '_mismatches_ref'):
                strategy_func._history_ref['data'] = prediction_history.copy()
                strategy_func._mismatches_ref['count'] = consecutive_mismatches
            
            prediction_result = strategy_func(model, prefix, method)
        else:
            prediction_result = predict_for_prefix(model, prefix, method)
        
        predicted = prediction_result.get('predicted')
        ratios = prediction_result.get('ratios', {})
        confidence = prediction_result.get('confidence', 0.0)
        is_forced = prediction_result.get('is_forced', False)
        
        if predicted is None:
            # ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê°„ê²© ì¦ê°€ (max_interval ì‚¬ìš© ì‹œ)
            if max_interval is not None:
                current_interval += 1
            continue
        
        # ì˜ˆì¸¡ê°’ì´ ìˆìœ¼ë©´
        if max_interval is not None:
            total_predictions += 1
            if is_forced:
                forced_predictions += 1
            # ê°„ê²© ê¸°ë¡ (ì´ì „ ì˜ˆì¸¡ ì´í›„ì˜ ê°„ê²©)
            if current_interval > 0:
                intervals.append(current_interval)
            current_interval = 0  # ë¦¬ì…‹
        
        # ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
        is_match = (predicted == actual_suffix)
        
        # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ìŠ¤í…ì—ì„œ ì‚¬ìš©)
        prediction_history.append((predicted, actual_suffix, is_match))
        # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
        if len(prediction_history) > 10:
            prediction_history.pop(0)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        if is_match:
            total_matches += 1
            consecutive_matches += 1
            max_consecutive_matches = max(max_consecutive_matches, consecutive_matches)
            
            # ì—°ì† ë¶ˆì¼ì¹˜ê°€ 5 ì´ìƒì´ì—ˆëŠ”ì§€ í™•ì¸ (ì¼ì¹˜ ì „ì— 5ê°œ ì—°ì†ì´ ìˆì—ˆëŠ”ì§€)
            if consecutive_mismatches >= 5 and current_consecutive_start is not None:
                end_step = step - 1
                add_or_merge_consecutive_range(current_consecutive_start, end_step, consecutive_5_positions)
            
            # ì—°ì† ë¶ˆì¼ì¹˜ ë¦¬ì…‹
            consecutive_mismatches = 0
            current_consecutive_start = None
            
            # ì—°ì† ì¼ì¹˜ êµ¬ê°„ ì‹œì‘ ì¶”ì 
            if consecutive_matches == 1:
                current_consecutive_match_start = step
        else:
            total_mismatches += 1
            consecutive_mismatches += 1
            max_consecutive_mismatches = max(max_consecutive_mismatches, consecutive_mismatches)
            
            # ì—°ì† ì¼ì¹˜ê°€ 5 ì´ìƒì´ì—ˆëŠ”ì§€ í™•ì¸ (ë¶ˆì¼ì¹˜ ì „ì— 5ê°œ ì—°ì†ì´ ìˆì—ˆëŠ”ì§€)
            if consecutive_matches >= 5 and current_consecutive_match_start is not None:
                end_step = step - 1
                add_or_merge_consecutive_range(current_consecutive_match_start, end_step, consecutive_5_match_positions)
            
            # ì—°ì† ì¼ì¹˜ ë¦¬ì…‹
            consecutive_matches = 0
            current_consecutive_match_start = None
            
            # ì—°ì† ë¶ˆì¼ì¹˜ êµ¬ê°„ ì‹œì‘ ì¶”ì 
            if consecutive_mismatches == 1:
                current_consecutive_start = step
        
        # íˆìŠ¤í† ë¦¬ ê¸°ë¡ (ëª¨ë“  ìŠ¤í… ê¸°ë¡)
        history.append({
            'step': step,
            'index': index,
            'prefix': prefix,
            'predicted': predicted,
            'actual': actual_suffix,
            'is_match': is_match,
            'confidence': confidence,
            'ratios': ratios,
            'consecutive_mismatches': consecutive_mismatches,
            'consecutive_matches': consecutive_matches
        })
    
    # ë§ˆì§€ë§‰ì— ì—°ì† ë¶ˆì¼ì¹˜ê°€ 5 ì´ìƒì¸ì§€ í™•ì¸
    if consecutive_mismatches >= 5 and current_consecutive_start is not None:
        end_step = len(history)
        add_or_merge_consecutive_range(current_consecutive_start, end_step, consecutive_5_positions)
    
    # ë§ˆì§€ë§‰ì— ì—°ì† ì¼ì¹˜ê°€ 5 ì´ìƒì¸ì§€ í™•ì¸
    if consecutive_matches >= 5 and current_consecutive_match_start is not None:
        end_step = len(history)
        add_or_merge_consecutive_range(current_consecutive_match_start, end_step, consecutive_5_match_positions)
    
    # ë§ˆì§€ë§‰ ìƒíƒœ í™•ì¸
    ends_with_match = (consecutive_matches > 0 and consecutive_mismatches == 0)
    ends_with_mismatch = (consecutive_mismatches > 0)
    ending_consecutive_mismatches = consecutive_mismatches
    
    # ë¶ˆì¼ì¹˜ ìƒíƒœë¡œ ëë‚˜ëŠ” ê²½ìš° ì²˜ë¦¬
    if ends_with_mismatch:
        # skip_ending_mismatch=Trueë©´ ì „ì²´ ìŠ¤í‚µ (ê¸°ì¡´ ë™ì‘)
        if skip_ending_mismatch:
            stats = {
                'total': len(history),
                'matches': total_matches,
                'mismatches': total_mismatches,
                'max_consecutive_mismatches': max_consecutive_mismatches,
                'max_consecutive_matches': max_consecutive_matches,
                'consecutive_5_count': len(consecutive_5_positions),
                'consecutive_5_match_count': len(consecutive_5_match_positions)
            }
            
            return {
                'result': 'skipped_ending_mismatch',
                'ends_with_match': False,
                'ends_with_mismatch': True,
                'ending_consecutive_mismatches': ending_consecutive_mismatches,
                'max_consecutive_mismatches': max_consecutive_mismatches,
                'max_consecutive_matches': max_consecutive_matches,
                'consecutive_5_positions': consecutive_5_positions,
                'consecutive_5_match_positions': consecutive_5_match_positions,
                'history': history,
                'stats': stats,
                'skipped': True,
                'truncated': False,
                'last_match_step': None,
                'truncated_steps': 0
            }
        
        # truncate_at_last_match=Trueë©´ ë§ˆì§€ë§‰ ì¼ì¹˜ ìŠ¤í…ê¹Œì§€ë§Œ ìœ íš¨ ì²˜ë¦¬
        if truncate_at_last_match:
            # historyë¥¼ ì—­ìˆœìœ¼ë¡œ ìˆœíšŒí•˜ë©´ì„œ ë§ˆì§€ë§‰ ì¼ì¹˜ ìŠ¤í… ì°¾ê¸°
            last_match_step = None
            for i in range(len(history) - 1, -1, -1):
                if history[i]['is_match']:
                    last_match_step = history[i]['step']
                    break
            
            # ì¼ì¹˜ ìŠ¤í…ì´ ì—†ìœ¼ë©´ ì „ì²´ ìŠ¤í‚µ
            if last_match_step is None:
                stats = {
                    'total': len(history),
                    'matches': total_matches,
                    'mismatches': total_mismatches,
                    'max_consecutive_mismatches': max_consecutive_mismatches,
                    'max_consecutive_matches': max_consecutive_matches,
                    'consecutive_5_count': len(consecutive_5_positions),
                    'consecutive_5_match_count': len(consecutive_5_match_positions)
                }
                
                return {
                    'result': 'skipped_ending_mismatch',
                    'ends_with_match': False,
                    'ends_with_mismatch': True,
                    'ending_consecutive_mismatches': ending_consecutive_mismatches,
                    'max_consecutive_mismatches': max_consecutive_mismatches,
                    'max_consecutive_matches': max_consecutive_matches,
                    'consecutive_5_positions': consecutive_5_positions,
                    'consecutive_5_match_positions': consecutive_5_match_positions,
                    'history': history,
                    'stats': stats,
                    'skipped': True,
                    'truncated': False,
                    'last_match_step': None,
                    'truncated_steps': 0
                }
            
            # last_match_stepê¹Œì§€ë§Œ ìœ íš¨í•œ history ì¶”ì¶œ
            valid_history = [h for h in history if h['step'] <= last_match_step]
            truncated_steps = len(history) - len(valid_history)
            
            # í†µê³„ ì¬ê³„ì‚°
            valid_total_matches = sum(1 for h in valid_history if h['is_match'])
            valid_total_mismatches = sum(1 for h in valid_history if not h['is_match'])
            
            # ì—°ì† ë¶ˆì¼ì¹˜/ì¼ì¹˜ ì¬ê³„ì‚°
            valid_consecutive_mismatches = 0
            valid_consecutive_matches = 0
            valid_max_consecutive_mismatches = 0
            valid_max_consecutive_matches = 0
            valid_consecutive_5_positions = []
            valid_consecutive_5_match_positions = []
            valid_current_consecutive_start = None
            valid_current_consecutive_match_start = None
            
            for h in valid_history:
                if h['is_match']:
                    valid_consecutive_matches += 1
                    valid_max_consecutive_matches = max(valid_max_consecutive_matches, valid_consecutive_matches)
                    
                    # ì—°ì† ë¶ˆì¼ì¹˜ê°€ 5 ì´ìƒì´ì—ˆëŠ”ì§€ í™•ì¸
                    if valid_consecutive_mismatches >= 5 and valid_current_consecutive_start is not None:
                        end_step = h['step'] - 1
                        add_or_merge_consecutive_range(valid_current_consecutive_start, end_step, valid_consecutive_5_positions)
                    
                    valid_consecutive_mismatches = 0
                    valid_current_consecutive_start = None
                    
                    if valid_consecutive_matches == 1:
                        valid_current_consecutive_match_start = h['step']
                else:
                    valid_consecutive_mismatches += 1
                    valid_max_consecutive_mismatches = max(valid_max_consecutive_mismatches, valid_consecutive_mismatches)
                    
                    # ì—°ì† ì¼ì¹˜ê°€ 5 ì´ìƒì´ì—ˆëŠ”ì§€ í™•ì¸
                    if valid_consecutive_matches >= 5 and valid_current_consecutive_match_start is not None:
                        end_step = h['step'] - 1
                        add_or_merge_consecutive_range(valid_current_consecutive_match_start, end_step, valid_consecutive_5_match_positions)
                    
                    valid_consecutive_matches = 0
                    valid_current_consecutive_match_start = None
                    
                    if valid_consecutive_mismatches == 1:
                        valid_current_consecutive_start = h['step']
            
            # ë§ˆì§€ë§‰ì— ì—°ì† ë¶ˆì¼ì¹˜/ì¼ì¹˜ê°€ 5 ì´ìƒì¸ì§€ í™•ì¸
            if valid_consecutive_mismatches >= 5 and valid_current_consecutive_start is not None:
                end_step = len(valid_history)
                add_or_merge_consecutive_range(valid_current_consecutive_start, end_step, valid_consecutive_5_positions)
            
            if valid_consecutive_matches >= 5 and valid_current_consecutive_match_start is not None:
                end_step = len(valid_history)
                add_or_merge_consecutive_range(valid_current_consecutive_match_start, end_step, valid_consecutive_5_match_positions)
            
            # ê²°ê³¼ ê²°ì • (ì¬ê³„ì‚°ëœ í†µê³„ ê¸°ì¤€)
            valid_has_5_consecutive_mismatch = valid_max_consecutive_mismatches >= 5
            valid_has_5_consecutive_match = valid_max_consecutive_matches >= 5
            
            if valid_has_5_consecutive_mismatch or valid_has_5_consecutive_match:
                valid_result = 'has_5_consecutive'
            else:
                valid_result = 'no_5_consecutive'
            
            # í†µê³„ ì •ë³´ (ì¬ê³„ì‚°ëœ ê°’)
            valid_stats = {
                'total': len(valid_history),
                'matches': valid_total_matches,
                'mismatches': valid_total_mismatches,
                'max_consecutive_mismatches': valid_max_consecutive_mismatches,
                'max_consecutive_matches': valid_max_consecutive_matches,
                'consecutive_5_count': len(valid_consecutive_5_positions),
                'consecutive_5_match_count': len(valid_consecutive_5_match_positions)
            }
            
            # ê°•ì œ ì˜ˆì¸¡ í†µê³„ ê³„ì‚° (ìœ íš¨ ë²”ìœ„ë§Œ)
            result_dict = {
                'result': valid_result,
                'ends_with_match': True,  # ìœ íš¨ ë²”ìœ„ëŠ” ì¼ì¹˜ë¡œ ëë‚¨
                'ends_with_mismatch': False,
                'ending_consecutive_mismatches': 0,
                'max_consecutive_mismatches': valid_max_consecutive_mismatches,
                'max_consecutive_matches': valid_max_consecutive_matches,
                'consecutive_5_positions': valid_consecutive_5_positions,
                'consecutive_5_match_positions': valid_consecutive_5_match_positions,
                'history': valid_history,  # ì˜ë¦° history
                'stats': valid_stats,
                'skipped': False,
                'truncated': True,
                'last_match_step': last_match_step,
                'truncated_steps': truncated_steps
            }
            
            # max_interval ì‚¬ìš© ì‹œ ì¶”ê°€ í†µê³„ (ìœ íš¨ ë²”ìœ„ë§Œ)
            if max_interval is not None:
                # ìœ íš¨ ë²”ìœ„ì˜ ê°•ì œ ì˜ˆì¸¡ í†µê³„ë§Œ ê³„ì‚°
                valid_forced_predictions = 0
                valid_total_predictions = 0
                valid_intervals = []
                
                for h in valid_history:
                    if h.get('predicted') is not None:
                        valid_total_predictions += 1
                        # ê°•ì œ ì˜ˆì¸¡ ì—¬ë¶€ëŠ” historyì— ì €ì¥ë˜ì–´ ìˆì§€ ì•Šìœ¼ë¯€ë¡œ ê°„ë‹¨íˆ ì²˜ë¦¬
                        # ì‹¤ì œë¡œëŠ” simulate_game_scenario ë‚´ë¶€ì—ì„œ ì¶”ì í•´ì•¼ í•˜ì§€ë§Œ,
                        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì²˜ë¦¬
                
                # ê°„ê²© í†µê³„ëŠ” ìœ íš¨ ë²”ìœ„ ë‚´ì—ì„œë§Œ ê³„ì‚°
                if valid_intervals:
                    avg_interval = sum(valid_intervals) / len(valid_intervals)
                    max_interval_actual = max(valid_intervals)
                    min_interval = min(valid_intervals)
                else:
                    avg_interval = 0
                    max_interval_actual = 0
                    min_interval = 0
                
                forced_prediction_ratio = (valid_forced_predictions / valid_total_predictions * 100) if valid_total_predictions > 0 else 0
                
                result_dict.update({
                    'forced_predictions': valid_forced_predictions,
                    'forced_prediction_ratio': forced_prediction_ratio,
                    'avg_interval': avg_interval,
                    'max_interval_actual': max_interval_actual,
                    'min_interval': min_interval,
                    'total_predictions': valid_total_predictions
                })
            
            return result_dict
    
    # ê²°ê³¼ ê²°ì • (ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ ì´ìƒ OR ì—°ì† ì¼ì¹˜ 5íšŒ ì´ìƒ = ì‹¤íŒ¨)
    has_5_consecutive_mismatch = max_consecutive_mismatches >= 5
    has_5_consecutive_match = max_consecutive_matches >= 5
    
    if has_5_consecutive_mismatch or has_5_consecutive_match:
        result = 'has_5_consecutive'
    else:
        result = 'no_5_consecutive'
    
    # í†µê³„ ì •ë³´
    stats = {
        'total': len(history),
        'matches': total_matches,
        'mismatches': total_mismatches,
        'max_consecutive_mismatches': max_consecutive_mismatches,
        'max_consecutive_matches': max_consecutive_matches,
        'consecutive_5_count': len(consecutive_5_positions),  # ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œê°€ ë°œìƒí•œ íšŸìˆ˜
        'consecutive_5_match_count': len(consecutive_5_match_positions)  # ì—°ì† ì¼ì¹˜ 5ê°œê°€ ë°œìƒí•œ íšŸìˆ˜
    }
    
    # ê°•ì œ ì˜ˆì¸¡ í†µê³„ ê³„ì‚°
    result_dict = {
        'result': result,
        'ends_with_match': ends_with_match,
        'ends_with_mismatch': ends_with_mismatch,
        'ending_consecutive_mismatches': ending_consecutive_mismatches,
        'max_consecutive_mismatches': max_consecutive_mismatches,
        'max_consecutive_matches': max_consecutive_matches,
        'consecutive_5_positions': consecutive_5_positions,
        'consecutive_5_match_positions': consecutive_5_match_positions,
        'history': history,
        'stats': stats,
        'skipped': False,
        'truncated': False,
        'last_match_step': None,
        'truncated_steps': 0
    }
    
    # max_interval ì‚¬ìš© ì‹œ ì¶”ê°€ í†µê³„
    if max_interval is not None:
        forced_prediction_ratio = (forced_predictions / total_predictions * 100) if total_predictions > 0 else 0
        avg_interval = sum(intervals) / len(intervals) if intervals else 0
        max_interval_actual = max(intervals) if intervals else 0
        min_interval = min(intervals) if intervals else 0
        
        result_dict.update({
            'forced_predictions': forced_predictions,
            'forced_prediction_ratio': forced_prediction_ratio,
            'avg_interval': avg_interval,
            'max_interval_actual': max_interval_actual,
            'min_interval': min_interval,
            'total_predictions': total_predictions
        })
    
    return result_dict

def test_strategy_on_all_data(strategy_func, strategy_name, df_strings, window_sizes, method="ë¹ˆë„ ê¸°ë°˜", train_ratio=80):
    """
    íŠ¹ì • ì „ëµì„ ì „ì²´ DB ë°ì´í„°ì— ëŒ€í•´ ì‹œê³„ì—´ ëˆ„ì  ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    
    Args:
        strategy_func: ì „ëµ í•¨ìˆ˜ (model, prefix, method) -> dict
        strategy_name: ì „ëµ ì´ë¦„
        df_strings: ì „ì²˜ë¦¬ëœ ë°ì´í„° DataFrame
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ê¸°ë³¸ ì˜ˆì¸¡ ë°©ë²•
        train_ratio: í•™ìŠµ ì„¸íŠ¸ ë¹„ìœ¨ (ì‹œê³„ì—´ ëˆ„ì ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    
    Returns:
        dict: {
            window_size: {
                'strategy_name': ì „ëµ ì´ë¦„,
                'total_grid_strings': ì „ì²´ grid_string ìˆ˜,
                'tested_grid_strings': í…ŒìŠ¤íŠ¸ëœ grid_string ìˆ˜,
                'total_steps': ì „ì²´ ìŠ¤í… ìˆ˜,
                'total_matches': ì „ì²´ ì¼ì¹˜ ìˆ˜,
                'total_mismatches': ì „ì²´ ë¶ˆì¼ì¹˜ ìˆ˜,
                'avg_accuracy': í‰ê·  ì •í™•ë„,
                'max_consecutive_mismatches': ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜,
                'max_consecutive_matches': ìµœëŒ€ ì—°ì† ì¼ì¹˜ ìˆ˜,
                'total_consecutive_5_count': ì „ì²´ ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ë°œìƒ íšŸìˆ˜,
                'total_consecutive_5_match_count': ì „ì²´ ì—°ì† ì¼ì¹˜ 5ê°œ ë°œìƒ íšŸìˆ˜,
                'grid_string_results': [ê° grid_stringë³„ ê²°ê³¼],
                'all_histories': [ëª¨ë“  grid_stringì˜ history ë¦¬ìŠ¤íŠ¸]  # ì‹ ë¢°ë„ í†µê³„ ë¶„ì„ìš©
            }
        }
    """
    # created_at ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ (ê³¼ê±° â†’ í˜„ì¬)
    df_sorted = df_strings.sort_values('created_at').reset_index(drop=True)
    
    results_by_window = {}
    
    for window_size in window_sizes:
        window_results = {
            'strategy_name': strategy_name,
            'total_grid_strings': len(df_sorted),
            'tested_grid_strings': 0,
            'valid_test_count': 0,  # ìœ íš¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜
            'skipped_count': 0,  # ìŠ¤í‚µëœ ì¼€ì´ìŠ¤ ìˆ˜
            'ending_mismatch_count': 0,  # ë¶ˆì¼ì¹˜ ìƒíƒœë¡œ ëë‚œ ì¼€ì´ìŠ¤ ìˆ˜
            'total_steps': 0,
            'total_matches': 0,
            'total_mismatches': 0,
            'max_consecutive_mismatches': 0,
            'max_consecutive_matches': 0,
            'total_consecutive_5_count': 0,
            'total_consecutive_5_match_count': 0,
            'grid_string_results': [],
            'all_histories': [],  # ì‹ ë¢°ë„ í†µê³„ ë¶„ì„ìš© history ìˆ˜ì§‘
            # ê°•ì œ ì˜ˆì¸¡ í†µê³„ (max_interval ì‚¬ìš© ì‹œ)
            'total_forced_predictions': 0,
            'total_all_predictions': 0,
            'all_intervals': []
        }
        
        # ì‹œê³„ì—´ ìˆœì„œëŒ€ë¡œ ê° grid_string í…ŒìŠ¤íŠ¸
        for idx, row in df_sorted.iterrows():
            current_grid_string = row['grid_string']
            current_id = row['id']
            
            # í˜„ì¬ grid_string ê¸¸ì´ ê²€ì¦
            if len(current_grid_string) < window_size:
                continue
            
            # ì´ì „ê¹Œì§€ì˜ ëª¨ë“  grid_string ID (í˜„ì¬ ì œì™¸)
            previous_ids = df_sorted.iloc[:idx]['id'].tolist()
            
            # ì´ì „ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ grid_stringì€ ìŠ¤í‚µ (í•™ìŠµ ë°ì´í„° ì—†ìŒ)
            if len(previous_ids) == 0:
                continue
            
            try:
                # ì´ì „ê¹Œì§€ì˜ ëˆ„ì  ë°ì´í„°ë¡œ ëª¨ë¸ êµ¬ì¶•
                train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=previous_ids)
                
                if len(train_ngrams) == 0:
                    continue
                
                # ëª¨ë¸ êµ¬ì¶•
                if method == "ë¹ˆë„ ê¸°ë°˜":
                    model = build_frequency_model(train_ngrams)
                # elif method == "ë§ˆë¥´ì½”í”„ ì²´ì¸":
                #     model = build_markov_model(train_ngrams)
                elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                    model = build_weighted_model(train_ngrams)
                elif method == "ì•ˆì „ ìš°ì„ ":
                    model = build_safety_first_model(train_ngrams)
                else:
                    model = build_frequency_model(train_ngrams)
                
                # ì „ëµ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²Œì„ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
                game_result = simulate_game_scenario(
                    model,
                    current_grid_string,
                    window_size,
                    method,
                    strategy_func=strategy_func,
                    skip_ending_mismatch=True
                )
                
                # ìŠ¤í‚µëœ ì¼€ì´ìŠ¤ ì²˜ë¦¬
                if game_result.get('skipped', False):
                    window_results['skipped_count'] += 1
                    window_results['tested_grid_strings'] += 1  # í…ŒìŠ¤íŠ¸ëŠ” í–ˆì§€ë§Œ ìŠ¤í‚µë¨
                    if game_result.get('ends_with_mismatch', False):
                        window_results['ending_mismatch_count'] += 1
                    continue  # ìŠ¤í‚µëœ ì¼€ì´ìŠ¤ëŠ” í†µê³„ì—ì„œ ì œì™¸
                
                # ì˜ë¦° ì¼€ì´ìŠ¤ ì²˜ë¦¬
                if game_result.get('truncated', False):
                    window_results['truncated_count'] += 1
                    window_results['total_truncated_steps'] += game_result.get('truncated_steps', 0)
                
                # ìœ íš¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
                window_results['valid_test_count'] += 1
                window_results['tested_grid_strings'] += 1
                
                # history ìˆ˜ì§‘ (ì‹ ë¢°ë„ í†µê³„ ë¶„ì„ìš© - ì¤‘ë³µ ê³„ì‚° ë°©ì§€)
                if game_result.get('history'):
                    window_results['all_histories'].append(game_result['history'])
                
                # ê²°ê³¼ ì§‘ê³„
                stats = game_result['stats']
                window_results['total_steps'] += stats['total']
                window_results['total_matches'] += stats['matches']
                window_results['total_mismatches'] += stats['mismatches']
                window_results['max_consecutive_mismatches'] = max(
                    window_results['max_consecutive_mismatches'],
                    game_result['max_consecutive_mismatches']
                )
                window_results['max_consecutive_matches'] = max(
                    window_results['max_consecutive_matches'],
                    game_result['max_consecutive_matches']
                )
                window_results['total_consecutive_5_count'] += stats['consecutive_5_count']
                window_results['total_consecutive_5_match_count'] += stats.get('consecutive_5_match_count', 0)
                
                # ê°•ì œ ì˜ˆì¸¡ í†µê³„ ìˆ˜ì§‘ (max_interval ì‚¬ìš© ì‹œ)
                if game_result.get('forced_predictions', 0) > 0:
                    window_results['total_forced_predictions'] += game_result.get('forced_predictions', 0)
                    window_results['total_all_predictions'] += game_result.get('total_predictions', 0)
                    if game_result.get('avg_interval', 0) > 0:
                        window_results['all_intervals'].append(game_result.get('avg_interval', 0))
                
                # ê° grid_stringë³„ ê²°ê³¼ ì €ì¥
                accuracy = (stats['matches'] / stats['total'] * 100) if stats['total'] > 0 else 0
                window_results['grid_string_results'].append({
                    'grid_string_id': current_id,
                    'grid_string_length': len(current_grid_string),
                    'steps': stats['total'],
                    'matches': stats['matches'],
                    'mismatches': stats['mismatches'],
                    'accuracy': accuracy,
                    'max_consecutive_mismatches': game_result['max_consecutive_mismatches'],
                    'max_consecutive_matches': game_result['max_consecutive_matches'],
                    'consecutive_5_count': stats['consecutive_5_count'],
                    'consecutive_5_match_count': stats.get('consecutive_5_match_count', 0)
                })
                
            except Exception as e:
                # ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ grid_string ìŠ¤í‚µ
                continue
        
        # í‰ê·  ì •í™•ë„ ê³„ì‚°
        if window_results['total_steps'] > 0:
            window_results['avg_accuracy'] = (window_results['total_matches'] / window_results['total_steps'] * 100)
        else:
            window_results['avg_accuracy'] = 0
        
        results_by_window[window_size] = window_results
    
    return results_by_window

def analyze_confidence_statistics(history_list, threshold=70):
    """
    ì‹ ë¢°ë„ ìˆ˜ì¤€ë³„ í†µê³„ ë¶„ì„
    
    Args:
        history_list: ëª¨ë“  grid_stringì˜ history ë¦¬ìŠ¤íŠ¸ (ê° historyëŠ” simulate_game_scenarioì˜ history)
        threshold: ë¶„ì„í•  ì„ê³„ê°’
    
    Returns:
        dict: ì‹ ë¢°ë„ í†µê³„ ì •ë³´
    """
    all_confidences = []
    high_confidence_steps = []  # ì„ê³„ê°’ ì´ìƒì¸ ì˜ˆì¸¡ì˜ step ìœ„ì¹˜
    confidence_intervals = []  # ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ê°„ ê°„ê²©
    
    # ì‹ ë¢°ë„ êµ¬ê°„ë³„ ì¹´ìš´íŠ¸
    confidence_bins = {
        '0-50': 0,
        '50-60': 0,
        '60-70': 0,
        '70-80': 0,
        '80-90': 0,
        '90-100': 0
    }
    
    # ëª¨ë“  historyì—ì„œ ì‹ ë¢°ë„ ìˆ˜ì§‘
    total_steps = 0  # ì „ì²´ ìŠ¤í… ìˆ˜ (ì˜ˆì¸¡ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
    abstained_steps = []  # ì˜ˆì¸¡ì„ í•˜ì§€ ì•Šì€ ìŠ¤í…ë“¤
    all_steps = []  # ëª¨ë“  ìŠ¤í… (ì˜ˆì¸¡ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
    
    for history in history_list:
        for entry in history:
            step = entry.get('step', 0)
            total_steps += 1
            all_steps.append(step)
            
            # ì˜ˆì¸¡ì„ í•˜ì§€ ì•Šì€ ê²½ìš° (abstained)
            if entry.get('is_abstained', False) or entry.get('predicted') is None:
                abstained_steps.append(step)
                continue  # ì˜ˆì¸¡ì„ í•˜ì§€ ì•Šì€ ê²½ìš°ëŠ” ì‹ ë¢°ë„ í†µê³„ì— í¬í•¨í•˜ì§€ ì•ŠìŒ
            
            confidence = entry.get('confidence', 0.0)
            
            if confidence is not None:
                all_confidences.append(confidence)
                
                # êµ¬ê°„ë³„ ì¹´ìš´íŠ¸
                if confidence < 50:
                    confidence_bins['0-50'] += 1
                elif confidence < 60:
                    confidence_bins['50-60'] += 1
                elif confidence < 70:
                    confidence_bins['60-70'] += 1
                elif confidence < 80:
                    confidence_bins['70-80'] += 1
                elif confidence < 90:
                    confidence_bins['80-90'] += 1
                else:
                    confidence_bins['90-100'] += 1
                
                # ì„ê³„ê°’ ì´ìƒì¸ ì˜ˆì¸¡ ì¶”ì 
                if confidence >= threshold:
                    high_confidence_steps.append(step)
    
    # ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ê°„ ê°„ê²© ê³„ì‚° (ëª¨ë“  ìŠ¤í…ì„ ê³ ë ¤)
    # ê°„ê²© = ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ì‚¬ì´ì˜ ìŠ¤í… ìˆ˜ (ì˜ˆì¸¡í•˜ì§€ ì•Šì€ ìŠ¤í…ë„ í¬í•¨)
    if len(high_confidence_steps) > 1:
        high_confidence_steps_sorted = sorted(high_confidence_steps)
        for i in range(1, len(high_confidence_steps_sorted)):
            # ë‘ ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ì‚¬ì´ì˜ step ì°¨ì´ (ì¤‘ê°„ì— ì˜ˆì¸¡í•˜ì§€ ì•Šì€ ìŠ¤í…ë„ í¬í•¨)
            interval = high_confidence_steps_sorted[i] - high_confidence_steps_sorted[i-1]
            confidence_intervals.append(interval)
    
    # ì²« ë²ˆì§¸ ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ê¹Œì§€ì˜ ê°„ê²©ë„ ê³„ì‚°
    if len(high_confidence_steps) > 0 and len(all_steps) > 0:
        first_high_step = min(high_confidence_steps)
        first_step = min(all_steps)
        if first_high_step > first_step:
            # ì²« ë²ˆì§¸ ì˜ˆì¸¡ ì „ê¹Œì§€ì˜ ê°„ê²©ë„ ì¶”ê°€
            confidence_intervals.append(first_high_step - first_step)
    
    # ë§ˆì§€ë§‰ ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ì´í›„ì˜ ê°„ê²©ë„ ê³„ì‚° (ì„ íƒì‚¬í•­)
    # ì´ê±´ í˜„ì¬ êµ¬í˜„ì—ì„œëŠ” ì œì™¸ (ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì´í›„ëŠ” ëŒ€ê¸° ì‹œê°„ì´ ì¤‘ìš”í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
    
    # í†µê³„ ê³„ì‚°
    total_predictions = len(all_confidences)  # ì‹¤ì œë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•œ íšŸìˆ˜
    total_abstained = len(abstained_steps)  # ì˜ˆì¸¡ì„ í•˜ì§€ ì•Šì€ íšŸìˆ˜
    high_confidence_count = len(high_confidence_steps)
    
    # ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ë¹„ìœ¨ (ì‹¤ì œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ì—ì„œ)
    high_confidence_ratio = (high_confidence_count / total_predictions * 100) if total_predictions > 0 else 0
    
    # ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì˜ˆì¸¡ ìˆ˜í–‰ ë¹„ìœ¨
    prediction_ratio = (total_predictions / total_steps * 100) if total_steps > 0 else 0
    
    # ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ë¹„ìœ¨ (ëª¨ë“  ìŠ¤í… ê¸°ì¤€)
    high_confidence_ratio_overall = (high_confidence_count / total_steps * 100) if total_steps > 0 else 0
    
    avg_confidence = sum(all_confidences) / len(all_confidences) if all_confidences else 0
    min_confidence = min(all_confidences) if all_confidences else 0
    max_confidence = max(all_confidences) if all_confidences else 0
    
    avg_interval = sum(confidence_intervals) / len(confidence_intervals) if confidence_intervals else 0
    max_interval = max(confidence_intervals) if confidence_intervals else 0
    min_interval = min(confidence_intervals) if confidence_intervals else 0
    
    return {
        'total_steps': total_steps,  # ì „ì²´ ìŠ¤í… ìˆ˜
        'total_predictions': total_predictions,  # ì‹¤ì œë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•œ íšŸìˆ˜
        'total_abstained': total_abstained,  # ì˜ˆì¸¡ì„ í•˜ì§€ ì•Šì€ íšŸìˆ˜
        'prediction_ratio': prediction_ratio,  # ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì˜ˆì¸¡ ìˆ˜í–‰ ë¹„ìœ¨
        'high_confidence_count': high_confidence_count,
        'high_confidence_ratio': high_confidence_ratio,  # ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì„ê³„ê°’ ì´ìƒ ë¹„ìœ¨
        'high_confidence_ratio_overall': high_confidence_ratio_overall,  # ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’ ì´ìƒ ë¹„ìœ¨
        'confidence_bins': confidence_bins,
        'avg_confidence': avg_confidence,
        'min_confidence': min_confidence,
        'max_confidence': max_confidence,
        'avg_interval': avg_interval,
        'max_interval': max_interval,
        'min_interval': min_interval,
        'confidence_intervals': confidence_intervals,
        'threshold': threshold
    }

def analyze_confidence_statistics_by_window(df_strings, window_size, threshold, method="ë¹ˆë„ ê¸°ë°˜", train_ratio=80, use_threshold_strategy=True):
    """
    íŠ¹ì • ìœˆë„ìš° í¬ê¸°ì™€ ì„ê³„ê°’ì— ëŒ€í•´ ì‹ ë¢°ë„ í†µê³„ ë¶„ì„
    
    Args:
        df_strings: ì „ì²˜ë¦¬ëœ ë°ì´í„° DataFrame
        window_size: ìœˆë„ìš° í¬ê¸°
        threshold: ì„ê³„ê°’
        method: ê¸°ë³¸ ì˜ˆì¸¡ ë°©ë²•
        train_ratio: í•™ìŠµ ì„¸íŠ¸ ë¹„ìœ¨
        use_threshold_strategy: ì„ê³„ê°’ ì „ëµ ì‚¬ìš© ì—¬ë¶€ (Falseë©´ ëª¨ë“  ì˜ˆì¸¡ í¬í•¨)
    
    Returns:
        dict: ì‹ ë¢°ë„ í†µê³„ ì •ë³´
    """
    # created_at ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
    df_sorted = df_strings.sort_values('created_at').reset_index(drop=True)
    
    all_histories = []
    
    # ì‹œê³„ì—´ ìˆœì„œëŒ€ë¡œ ê° grid_string í…ŒìŠ¤íŠ¸í•˜ì—¬ history ìˆ˜ì§‘
    for idx, row in df_sorted.iterrows():
        current_grid_string = row['grid_string']
        
        if len(current_grid_string) < window_size:
            continue
        
        previous_ids = df_sorted.iloc[:idx]['id'].tolist()
        
        if len(previous_ids) == 0:
            continue
        
        try:
            train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=previous_ids)
            
            if len(train_ngrams) == 0:
                continue
            
            # ëª¨ë¸ êµ¬ì¶•
            if method == "ë¹ˆë„ ê¸°ë°˜":
                model = build_frequency_model(train_ngrams)
            # elif method == "ë§ˆë¥´ì½”í”„ ì²´ì¸":
            #     model = build_markov_model(train_ngrams)
            elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                model = build_weighted_model(train_ngrams)
            elif method == "ì•ˆì „ ìš°ì„ ":
                model = build_safety_first_model(train_ngrams)
            else:
                model = build_frequency_model(train_ngrams)
            
            # ì „ëµ í•¨ìˆ˜ ì„¤ì •
            if use_threshold_strategy:
                # ì„ê³„ê°’ ì „ëµ í•¨ìˆ˜
                strategy_func = lambda m, p, method: predict_confidence_threshold(m, p, method, threshold=threshold)
            else:
                # ì„ê³„ê°’ ì—†ì´ ëª¨ë“  ì˜ˆì¸¡ í¬í•¨
                strategy_func = None
            
            # ê²Œì„ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
            game_result = simulate_game_scenario(
                model,
                current_grid_string,
                window_size,
                method,
                strategy_func=strategy_func,
                skip_ending_mismatch=False,  # truncate_at_last_match ì‚¬ìš©
                truncate_at_last_match=True
            )
            
            # history ìˆ˜ì§‘ (ëª¨ë“  history í¬í•¨ - ì˜ˆì¸¡í•˜ì§€ ì•Šì€ ê²½ìš°ë„ í¬í•¨)
            if game_result['history']:
                all_histories.append(game_result['history'])
                
        except Exception as e:
            continue
    
    # ì‹ ë¢°ë„ í†µê³„ ë¶„ì„
    if all_histories:
        return analyze_confidence_statistics(all_histories, threshold)
    else:
        return {
            'total_steps': 0,
            'total_predictions': 0,
            'total_abstained': 0,
            'prediction_ratio': 0,
            'high_confidence_count': 0,
            'high_confidence_ratio': 0,
            'high_confidence_ratio_overall': 0,
            'confidence_bins': {},
            'avg_confidence': 0,
            'min_confidence': 0,
            'max_confidence': 0,
            'avg_interval': 0,
            'max_interval': 0,
            'min_interval': 0,
            'confidence_intervals': [],
            'threshold': threshold
        }

def find_optimal_combination_for_new_data(
    cutoff_grid_string_id,
    window_sizes,
    thresholds,
    method="ë¹ˆë„ ê¸°ë°˜",
    use_stored_predictions=True,
    max_intervals=None
):
    """
    ìƒˆë¡œìš´ ë°ì´í„°ë§Œìœ¼ë¡œ ìµœì  ì¡°í•© ì°¾ê¸°
    
    Args:
        cutoff_grid_string_id: ê¸°ì¤€ì´ ë˜ëŠ” grid_string_id (ì´ ID ì´í›„ê°€ ìƒˆë¡œìš´ ë°ì´í„°)
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        thresholds: í…ŒìŠ¤íŠ¸í•  ì„ê³„ê°’ ë¦¬ìŠ¤íŠ¸
        method: ê¸°ë³¸ ì˜ˆì¸¡ ë°©ë²•
        use_stored_predictions: Trueë©´ DB í…Œì´ë¸”ì—ì„œ ì¡°íšŒ, Falseë©´ ì‹¤ì‹œê°„ ê³„ì‚°
        max_intervals: í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ê°„ê²© ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ê°•ì œ ì˜ˆì¸¡ ì‚¬ìš© ì•ˆ í•¨)
    
    Returns:
        list: [{
            'window_size': ìœˆë„ìš° í¬ê¸°,
            'threshold': ì„ê³„ê°’,
            'max_interval': ìµœëŒ€ ê°„ê²© (Noneì´ë©´ ì‚¬ìš© ì•ˆ í•¨),
            'max_consecutive_mismatches': ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜,
            'max_consecutive_matches': ìµœëŒ€ ì—°ì† ì¼ì¹˜ ìˆ˜,
            'total_consecutive_5_count': ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ ì´ìƒ íšŸìˆ˜,
            'total_consecutive_5_match_count': ì—°ì† ì¼ì¹˜ 5íšŒ ì´ìƒ íšŸìˆ˜,
            'total_failures': ì´ ì‹¤íŒ¨ íšŸìˆ˜,
            'max_failures': ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ,
            'avg_accuracy': í‰ê·  ì •í™•ë„,
            'tested_grid_strings': í…ŒìŠ¤íŠ¸ëœ grid_string ìˆ˜,
            'forced_predictions': ê°•ì œ ì˜ˆì¸¡ ìˆ˜ (max_interval ì‚¬ìš© ì‹œ),
            'forced_prediction_ratio': ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ (max_interval ì‚¬ìš© ì‹œ),
            'avg_interval': í‰ê·  ê°„ê²© (max_interval ì‚¬ìš© ì‹œ),
            'max_interval_actual': ì‹¤ì œ ìµœëŒ€ ê°„ê²© (max_interval ì‚¬ìš© ì‹œ),
            'confidence_stats': ì‹ ë¢°ë„ í†µê³„
        }, ...]
    """
    conn = get_db_connection()
    if conn is None:
        return {}
    
    try:
        # ì´ì „ ë°ì´í„° ì„ íƒ (id <= cutoff_grid_string_id)
        df_historical = pd.read_sql_query(
            "SELECT id FROM preprocessed_grid_strings WHERE id <= ? ORDER BY id",
            conn,
            params=[cutoff_grid_string_id]
        )
        historical_ids = df_historical['id'].tolist()
        
        # ìƒˆë¡œìš´ ë°ì´í„° ì„ íƒ (id > cutoff_grid_string_id)
        df_new = pd.read_sql_query(
            "SELECT id, grid_string, created_at FROM preprocessed_grid_strings WHERE id > ? ORDER BY id",
            conn,
            params=[cutoff_grid_string_id]
        )
        
        if len(df_new) == 0:
            return {}
        
        all_combination_results = []
        
        # ì´ì „ ë°ì´í„°ë¡œ ëª¨ë¸ êµ¬ì¶• (í•œ ë²ˆë§Œ)
        models_by_window = {}
        for window_size in window_sizes:
            train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=historical_ids)
            
            if len(train_ngrams) == 0:
                continue
            
            if method == "ë¹ˆë„ ê¸°ë°˜":
                models_by_window[window_size] = build_frequency_model(train_ngrams)
            # elif method == "ë§ˆë¥´ì½”í”„ ì²´ì¸":
            #     models_by_window[window_size] = build_markov_model(train_ngrams)
            elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                models_by_window[window_size] = build_weighted_model(train_ngrams)
            elif method == "ì•ˆì „ ìš°ì„ ":
                models_by_window[window_size] = build_safety_first_model(train_ngrams)
            else:
                models_by_window[window_size] = build_frequency_model(train_ngrams)
        
        # ê° ìœˆë„ìš° í¬ê¸° Ã— ì„ê³„ê°’ Ã— max_interval ì¡°í•© í…ŒìŠ¤íŠ¸
        # max_intervalsê°€ Noneì´ë©´ [None]ìœ¼ë¡œ ì²˜ë¦¬ (ê°•ì œ ì˜ˆì¸¡ ì‚¬ìš© ì•ˆ í•¨)
        test_max_intervals = max_intervals if max_intervals is not None else [None]
        
        for window_size in window_sizes:
            if window_size not in models_by_window:
                continue
            
            model = models_by_window[window_size]
            
            for threshold in thresholds:
                for max_interval in test_max_intervals:
                    # ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸
                    all_histories = []
                    total_steps = 0
                    total_matches = 0
                    total_mismatches = 0
                    max_consecutive_mismatches = 0
                    max_consecutive_matches = 0
                    total_consecutive_5_count = 0
                    total_consecutive_5_match_count = 0
                    tested_grid_strings = 0
                    skipped_count = 0
                    valid_test_count = 0
                    ending_mismatch_count = 0
                    total_forced_predictions = 0
                    total_all_predictions = 0
                    all_intervals = []
                    
                    for _, row in df_new.iterrows():
                        grid_string_id = row['id']
                        grid_string = row['grid_string']
                        
                        if len(grid_string) < window_size:
                            continue
                        
                        # ì „ëµ í•¨ìˆ˜ ìƒì„± (max_interval ì‚¬ìš© ì‹œ strategy_funcëŠ” None)
                        if max_interval is not None:
                            # max_interval ì‚¬ìš© ì‹œ simulate_game_scenario ë‚´ë¶€ì—ì„œ predict_with_fallback_interval ì‚¬ìš©
                            strategy_func = None
                        elif threshold == 0:
                            strategy_func = None
                        else:
                            strategy_func = lambda m, p, method: predict_confidence_threshold(m, p, method, threshold)
                        
                        # ê²Œì„ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
                        game_result = simulate_game_scenario(
                            model,
                            grid_string,
                            window_size,
                            method,
                            strategy_func=strategy_func,
                            skip_ending_mismatch=False,  # ëª¨ë“  grid_stringì„ ìœ íš¨ í…ŒìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                            max_interval=max_interval,
                            threshold=threshold,
                            truncate_at_last_match=False  # ëª¨ë“  ìŠ¤í…ì„ ìœ íš¨ í…ŒìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                        )
                    
                    # ìŠ¤í‚µëœ ì¼€ì´ìŠ¤ ì²˜ë¦¬
                    if game_result.get('skipped', False):
                        skipped_count += 1
                        tested_grid_strings += 1
                        if game_result.get('ends_with_mismatch', False):
                            ending_mismatch_count += 1
                        continue  # ìŠ¤í‚µëœ ì¼€ì´ìŠ¤ëŠ” í†µê³„ì—ì„œ ì œì™¸
                    
                    # ìœ íš¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
                    valid_test_count += 1
                    tested_grid_strings += 1
                    
                    # history ìˆ˜ì§‘
                    if game_result.get('history'):
                        all_histories.append(game_result['history'])
                    
                    # í†µê³„ ì§‘ê³„
                    stats = game_result['stats']
                    total_steps += stats['total']
                    total_matches += stats['matches']
                    total_mismatches += stats['mismatches']
                    max_consecutive_mismatches = max(max_consecutive_mismatches, game_result['max_consecutive_mismatches'])
                    max_consecutive_matches = max(max_consecutive_matches, game_result['max_consecutive_matches'])
                    total_consecutive_5_count += stats['consecutive_5_count']
                    total_consecutive_5_match_count += stats.get('consecutive_5_match_count', 0)
                    
                    # ê°•ì œ ì˜ˆì¸¡ í†µê³„ ìˆ˜ì§‘ (max_interval ì‚¬ìš© ì‹œ)
                    if max_interval is not None:
                        total_forced_predictions += game_result.get('forced_predictions', 0)
                        total_all_predictions += game_result.get('total_predictions', 0)
                        # ê°„ê²© í†µê³„ ìˆ˜ì§‘
                        if game_result.get('avg_interval', 0) > 0:
                            all_intervals.append(game_result.get('avg_interval', 0))
                    
                    # ì‹ ë¢°ë„ í†µê³„ ë¶„ì„
                    if all_histories:
                        confidence_stats = analyze_confidence_statistics(all_histories, threshold)
                    else:
                        confidence_stats = {
                            'total_steps': 0,
                            'total_predictions': 0,
                            'total_abstained': 0,
                            'prediction_ratio': 0,
                            'high_confidence_count': 0,
                            'high_confidence_ratio': 0,
                            'high_confidence_ratio_overall': 0,
                            'confidence_bins': {},
                            'avg_confidence': 0,
                            'min_confidence': 0,
                            'max_confidence': 0,
                            'avg_interval': 0,
                            'max_interval': 0,
                            'min_interval': 0,
                            'confidence_intervals': [],
                            'threshold': threshold
                        }
                    
                    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
                    avg_accuracy = (total_matches / total_steps * 100) if total_steps > 0 else 0
                    total_failures = total_consecutive_5_count + total_consecutive_5_match_count
                    max_failures = max(max_consecutive_mismatches, max_consecutive_matches)
                    
                    # ìŠ¤í‚µ í†µê³„ ê³„ì‚°
                    total_count = len(df_new[df_new['grid_string'].str.len() >= window_size])
                    skipped_ratio = (skipped_count / total_count * 100) if total_count > 0 else 0
                    valid_ratio = (valid_test_count / total_count * 100) if total_count > 0 else 0
                    
                    # ê°•ì œ ì˜ˆì¸¡ í†µê³„ ê³„ì‚°
                    forced_prediction_ratio = (total_forced_predictions / total_all_predictions * 100) if total_all_predictions > 0 else 0
                    avg_interval_overall = sum(all_intervals) / len(all_intervals) if all_intervals else 0
                    
                    result_dict = {
                        'window_size': window_size,
                        'threshold': threshold,
                        'max_interval': max_interval,
                        'max_consecutive_mismatches': max_consecutive_mismatches,
                        'max_consecutive_matches': max_consecutive_matches,
                        'total_consecutive_5_count': total_consecutive_5_count,
                        'total_consecutive_5_match_count': total_consecutive_5_match_count,
                        'total_failures': total_failures,
                        'max_failures': max_failures,
                        'avg_accuracy': avg_accuracy,
                        'tested_grid_strings': tested_grid_strings,
                        'valid_test_count': valid_test_count,
                        'skipped_count': skipped_count,
                        'ending_mismatch_count': ending_mismatch_count,
                        'skipped_ratio': skipped_ratio,
                        'valid_ratio': valid_ratio,
                        'confidence_stats': confidence_stats
                    }
                    
                    # max_interval ì‚¬ìš© ì‹œ ì¶”ê°€ í†µê³„
                    if max_interval is not None:
                        result_dict.update({
                            'forced_predictions': total_forced_predictions,
                            'forced_prediction_ratio': forced_prediction_ratio,
                            'avg_interval': avg_interval_overall,
                            'total_predictions': total_all_predictions
                        })
                    
                    all_combination_results.append(result_dict)
        
        return all_combination_results
        
    except Exception as e:
        st.error(f"ìµœì  ì¡°í•© ì°¾ê¸° ì˜¤ë¥˜: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return []
    finally:
        conn.close()

def calculate_optimal_score(combination_result, min_prediction_ratio=20, forced_prediction_weight=2.0):
    """
    ìµœì  ì¡°í•© ì„ íƒì„ ìœ„í•œ ì ìˆ˜ ê³„ì‚°
    
    ì˜ˆì¸¡ ë¹ˆë„ì™€ ì‹¤íŒ¨ ì§€í‘œë¥¼ ê· í˜•ìˆê²Œ ê³ ë ¤í•˜ëŠ” ì ìˆ˜ ì‹œìŠ¤í…œ
    
    Args:
        combination_result: ì¡°í•© ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        min_prediction_ratio: ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ (ê¸°ë³¸ê°’: 20%)
        forced_prediction_weight: ê°•ì œ ì˜ˆì¸¡ í˜ë„í‹° ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 2.0)
    
    Returns:
        float: ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    """
    # ì‹¤íŒ¨ í˜ë„í‹°
    failure_penalty = combination_result['max_failures'] * 100 + combination_result['total_failures'] * 10
    
    # ì˜ˆì¸¡ ë¹ˆë„ ë³´ë„ˆìŠ¤/í˜ë„í‹°
    conf_stats = combination_result.get('confidence_stats', {})
    prediction_ratio = conf_stats.get('high_confidence_ratio_overall', 0)
    
    if prediction_ratio < min_prediction_ratio:
        # ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ ë¯¸ë§Œì´ë©´ í° í˜ë„í‹°
        prediction_penalty = (min_prediction_ratio - prediction_ratio) * 50
    else:
        # ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ ì´ìƒì´ë©´ ë³´ë„ˆìŠ¤ (ë„ˆë¬´ ë†’ì•„ë„ ì˜ë¯¸ ì—†ìœ¼ë¯€ë¡œ ì œí•œ)
        prediction_bonus = -min((prediction_ratio - min_prediction_ratio) * 2, 100)  # ìµœëŒ€ ë³´ë„ˆìŠ¤ ì œí•œ
        prediction_penalty = prediction_bonus
    
    # ê°•ì œ ì˜ˆì¸¡ í˜ë„í‹° (max_interval ì‚¬ìš© ì‹œ)
    forced_penalty = 0
    if 'forced_prediction_ratio' in combination_result:
        forced_penalty = combination_result['forced_prediction_ratio'] * forced_prediction_weight
    
    total_score = failure_penalty + prediction_penalty + forced_penalty
    
    return total_score

def batch_test_window_sizes_on_all_data(df_strings, window_sizes, method="ë¹ˆë„ ê¸°ë°˜", train_ratio=80):
    """
    DB ì „ì²´ grid_stringì— ëŒ€í•´ ì‹œê³„ì—´ ëˆ„ì  ë°©ì‹ìœ¼ë¡œ ì—¬ëŸ¬ ìœˆë„ìš° í¬ê¸°ë¥¼ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
    
    ì‹œê³„ì—´ ëˆ„ì  ë°©ì‹:
    - created_at ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ (ê³¼ê±° â†’ í˜„ì¬)
    - ê° grid_stringì— ëŒ€í•´:
      - ì´ì „ê¹Œì§€ì˜ ëª¨ë“  grid_stringì˜ ngram_chunksë¡œ ëª¨ë¸ êµ¬ì¶•
      - í˜„ì¬ grid_stringì„ í…ŒìŠ¤íŠ¸
      - ê²°ê³¼ ìˆ˜ì§‘
    
    Args:
        df_strings: ì „ì²˜ë¦¬ëœ ë°ì´í„° DataFrame (created_at ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ í•„ìš”)
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ì˜ˆì¸¡ ë°©ë²•
        train_ratio: í•™ìŠµ ì„¸íŠ¸ ë¹„ìœ¨ (ì‹œê³„ì—´ ëˆ„ì ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    
    Returns:
        dict: {
            window_size: {
                'total_grid_strings': ì „ì²´ grid_string ìˆ˜,
                'tested_grid_strings': í…ŒìŠ¤íŠ¸ëœ grid_string ìˆ˜,
                'total_steps': ì „ì²´ ìŠ¤í… ìˆ˜,
                'total_matches': ì „ì²´ ì¼ì¹˜ ìˆ˜,
                'total_mismatches': ì „ì²´ ë¶ˆì¼ì¹˜ ìˆ˜,
                'avg_accuracy': í‰ê·  ì •í™•ë„,
                'max_consecutive_mismatches': ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜ (ì „ì²´ ì¤‘),
                'total_consecutive_5_count': ì „ì²´ ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ë°œìƒ íšŸìˆ˜,
                'grid_string_results': [ê° grid_stringë³„ ê²°ê³¼]
            }
        }
    """
    # created_at ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ (ê³¼ê±° â†’ í˜„ì¬)
    df_sorted = df_strings.sort_values('created_at').reset_index(drop=True)
    
    results_by_window = {}
    
    for window_size in window_sizes:
        window_results = {
            'total_grid_strings': len(df_sorted),
            'tested_grid_strings': 0,
            'total_steps': 0,
            'total_matches': 0,
            'total_mismatches': 0,
            'max_consecutive_mismatches': 0,
            'total_consecutive_5_count': 0,
            'grid_string_results': []
        }
        
        # ì‹œê³„ì—´ ìˆœì„œëŒ€ë¡œ ê° grid_string í…ŒìŠ¤íŠ¸
        for idx, row in df_sorted.iterrows():
            current_grid_string = row['grid_string']
            current_id = row['id']
            
            # í˜„ì¬ grid_string ê¸¸ì´ ê²€ì¦
            if len(current_grid_string) < window_size:
                continue
            
            # ì´ì „ê¹Œì§€ì˜ ëª¨ë“  grid_string ID (í˜„ì¬ ì œì™¸)
            previous_ids = df_sorted.iloc[:idx]['id'].tolist()
            
            # ì´ì „ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ grid_stringì€ ìŠ¤í‚µ (í•™ìŠµ ë°ì´í„° ì—†ìŒ)
            if len(previous_ids) == 0:
                continue
            
            try:
                # ì´ì „ê¹Œì§€ì˜ ëˆ„ì  ë°ì´í„°ë¡œ ëª¨ë¸ êµ¬ì¶•
                train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=previous_ids)
                
                if len(train_ngrams) == 0:
                    continue
                
                # ëª¨ë¸ êµ¬ì¶•
                if method == "ë¹ˆë„ ê¸°ë°˜":
                    model = build_frequency_model(train_ngrams)
                # elif method == "ë§ˆë¥´ì½”í”„ ì²´ì¸":
                #     model = build_markov_model(train_ngrams)
                elif method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                    model = build_weighted_model(train_ngrams)
                elif method == "ì•ˆì „ ìš°ì„ ":
                    model = build_safety_first_model(train_ngrams)
                else:
                    model = build_frequency_model(train_ngrams)
                
                # í˜„ì¬ grid_string í…ŒìŠ¤íŠ¸
                game_result = simulate_game_scenario(
                    model,
                    current_grid_string,
                    window_size,
                    method
                )
                
                # ê²°ê³¼ ì§‘ê³„
                stats = game_result['stats']
                window_results['tested_grid_strings'] += 1
                window_results['total_steps'] += stats['total']
                window_results['total_matches'] += stats['matches']
                window_results['total_mismatches'] += stats['mismatches']
                window_results['max_consecutive_mismatches'] = max(
                    window_results['max_consecutive_mismatches'],
                    game_result['max_consecutive_mismatches']
                )
                window_results['total_consecutive_5_count'] += stats['consecutive_5_count']
                
                # ê° grid_stringë³„ ê²°ê³¼ ì €ì¥
                accuracy = (stats['matches'] / stats['total'] * 100) if stats['total'] > 0 else 0
                window_results['grid_string_results'].append({
                    'grid_string_id': current_id,
                    'grid_string_length': len(current_grid_string),
                    'steps': stats['total'],
                    'matches': stats['matches'],
                    'mismatches': stats['mismatches'],
                    'accuracy': accuracy,
                    'max_consecutive_mismatches': game_result['max_consecutive_mismatches'],
                    'consecutive_5_count': stats['consecutive_5_count']
                })
                
            except Exception as e:
                # ì—ëŸ¬ ë°œìƒ ì‹œ í•´ë‹¹ grid_string ìŠ¤í‚µ
                continue
        
        # í‰ê·  ì •í™•ë„ ê³„ì‚°
        if window_results['total_steps'] > 0:
            window_results['avg_accuracy'] = (window_results['total_matches'] / window_results['total_steps'] * 100)
        else:
            window_results['avg_accuracy'] = 0
        
        results_by_window[window_size] = window_results
    
    return results_by_window

def batch_test_strategies(strategies, df_strings, window_sizes, method="ë¹ˆë„ ê¸°ë°˜", train_ratio=80):
    """
    ì—¬ëŸ¬ ì „ëµì„ í•œ ë²ˆì— í…ŒìŠ¤íŠ¸
    
    Args:
        strategies: ì „ëµ ë¦¬ìŠ¤íŠ¸ [(strategy_func, strategy_name), ...]
        df_strings: ì „ì²˜ë¦¬ëœ ë°ì´í„° DataFrame
        window_sizes: í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸° ë¦¬ìŠ¤íŠ¸
        method: ê¸°ë³¸ ì˜ˆì¸¡ ë°©ë²•
        train_ratio: í•™ìŠµ ì„¸íŠ¸ ë¹„ìœ¨
    
    Returns:
        dict: {
            strategy_name: {
                window_size: {
                    'strategy_name': ì „ëµ ì´ë¦„,
                    'total_grid_strings': ì „ì²´ grid_string ìˆ˜,
                    'tested_grid_strings': í…ŒìŠ¤íŠ¸ëœ grid_string ìˆ˜,
                    ...
                }
            }
        }
    """
    all_results = {}
    
    for strategy_func, strategy_name in strategies:
        strategy_results = test_strategy_on_all_data(
            strategy_func,
            strategy_name,
            df_strings,
            window_sizes,
            method,
            train_ratio
        )
        all_results[strategy_name] = strategy_results
    
    return all_results

def display_window_size_comparison_all_data(results_by_window):
    """
    ì „ì²´ DB ë°ì´í„°ì— ëŒ€í•œ ìœˆë„ìš° í¬ê¸°ë³„ ë¹„êµ ê²°ê³¼ë¥¼ í…Œì´ë¸”ë¡œ í‘œì‹œí•˜ê³  ìµœì  ìœˆë„ìš° í¬ê¸° ì¶”ì²œ
    
    Args:
        results_by_window: batch_test_window_sizes_on_all_dataì˜ ë°˜í™˜ê°’
    """
    if not results_by_window:
        st.warning("âš ï¸ ë¹„êµí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë¹„êµ í…Œì´ë¸” ë°ì´í„° ìƒì„±
    comparison_data = []
    for window_size, result in results_by_window.items():
        # ìŠ¤í‚µ í†µê³„ ê³„ì‚°
        total_count = result.get('total_grid_strings', 0)
        skipped_count = result.get('skipped_count', 0)
        valid_count = result.get('valid_test_count', 0)
        skipped_ratio = (skipped_count / total_count * 100) if total_count > 0 else 0
        valid_ratio = (valid_count / total_count * 100) if total_count > 0 else 0
        
        comparison_data.append({
            'ìœˆë„ìš° í¬ê¸°': window_size,
            'ìœ íš¨ í…ŒìŠ¤íŠ¸ ìˆ˜': valid_count,
            'ìŠ¤í‚µ ìˆ˜': skipped_count,
            'ìŠ¤í‚µ ë¹„ìœ¨ (%)': f"{skipped_ratio:.1f}",
            'í…ŒìŠ¤íŠ¸ëœ Grid ìˆ˜': result['tested_grid_strings'],
            'ì „ì²´ Grid ìˆ˜': result['total_grid_strings'],
            'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': result['max_consecutive_mismatches'],
            'ì „ì²´ ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ íšŸìˆ˜': result['total_consecutive_5_count'],
            'í‰ê·  ì •í™•ë„ (%)': f"{result['avg_accuracy']:.2f}",
            'ì „ì²´ ìŠ¤í… ìˆ˜': result['total_steps'],
            'ì „ì²´ ì¼ì¹˜ ìˆ˜': result['total_matches'],
            'ì „ì²´ ë¶ˆì¼ì¹˜ ìˆ˜': result['total_mismatches']
        })
    
    # ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì˜¤ë¦„ì°¨ìˆœ)
    comparison_data.sort(key=lambda x: x['ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜'])
    
    # ë¹„êµ í…Œì´ë¸” í‘œì‹œ
    st.markdown("### ğŸ“Š ìœˆë„ìš° í¬ê¸°ë³„ ì „ì²´ DB í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    comparison_df = pd.DataFrame(comparison_data)
    st.dataframe(comparison_df, use_container_width=True, hide_index=True)
    
    # ìµœì  ìœˆë„ìš° í¬ê¸° ì¶”ì²œ
    st.markdown("---")
    st.markdown("### ğŸ¯ ìµœì  ìœˆë„ìš° í¬ê¸° ì¶”ì²œ")
    
    # ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜ê°€ ê°€ì¥ ì ì€ ê²ƒ ì°¾ê¸°
    best_by_max_consecutive = min(results_by_window.items(), key=lambda x: x[1]['max_consecutive_mismatches'])
    best_window_size = best_by_max_consecutive[0]
    best_max_consecutive = best_by_max_consecutive[1]['max_consecutive_mismatches']
    
    # ë™ì¼í•œ ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜ë¥¼ ê°€ì§„ ê²ƒë“¤ ì°¾ê¸°
    candidates = [(w, r) for w, r in results_by_window.items() if r['max_consecutive_mismatches'] == best_max_consecutive]
    
    if len(candidates) == 1:
        # ë‹¨ì¼ ìµœì ê°’
        best_result = best_by_max_consecutive[1]
        st.success(f"âœ… **ìµœì  ìœˆë„ìš° í¬ê¸°: {best_window_size}**")
        
        # ìŠ¤í‚µ í†µê³„ í‘œì‹œ
        total_count = best_result.get('total_grid_strings', 0)
        skipped_count = best_result.get('skipped_count', 0)
        valid_count = best_result.get('valid_test_count', 0)
        skipped_ratio = (skipped_count / total_count * 100) if total_count > 0 else 0
        valid_ratio = (valid_count / total_count * 100) if total_count > 0 else 0
        
        st.info(f"""
        **í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í†µê³„:**
        - ì „ì²´ Grid String: {total_count}ê°œ
        - ìœ íš¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {valid_count}ê°œ ({valid_ratio:.1f}%)
        - ìŠ¤í‚µëœ ì¼€ì´ìŠ¤: {skipped_count}ê°œ ({skipped_ratio:.1f}%)
          - ë¶ˆì¼ì¹˜ ìƒíƒœë¡œ ì¢…ë£Œ: {best_result.get('ending_mismatch_count', 0)}ê°œ
        """)
        
        st.info(f"""
        **ì„±ëŠ¥ ì§€í‘œ:**
        - ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜: {best_result['max_consecutive_mismatches']}ê°œ
        - ì „ì²´ ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ íšŸìˆ˜: {best_result['total_consecutive_5_count']}íšŒ
        - í‰ê·  ì •í™•ë„: {best_result['avg_accuracy']:.2f}%
        - í…ŒìŠ¤íŠ¸ëœ Grid ìˆ˜: {best_result['tested_grid_strings']}/{total_count}
        """)
    else:
        # ë™ì ì¸ ê²½ìš° ì¶”ê°€ ê¸°ì¤€ ì ìš©
        # 1ìˆœìœ„: ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ íšŸìˆ˜ê°€ ì ì€ ê²ƒ
        best_by_consecutive_5 = min(candidates, key=lambda x: x[1]['total_consecutive_5_count'])
        best_consecutive_5 = best_by_consecutive_5[1]['total_consecutive_5_count']
        
        # 2ìˆœìœ„: ì •í™•ë„ê°€ ë†’ì€ ê²ƒ
        final_candidates = [(w, r) for w, r in candidates if r['total_consecutive_5_count'] == best_consecutive_5]
        best = max(final_candidates, key=lambda x: x[1]['avg_accuracy'])
        
        best_window_size = best[0]
        best_result = best[1]
        
        st.success(f"âœ… **ìµœì  ìœˆë„ìš° í¬ê¸°: {best_window_size}** (ë™ì ì ì¤‘ ì„ íƒ)")
        st.info(f"""
        - ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜: {best_result['max_consecutive_mismatches']}ê°œ
        - ì „ì²´ ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ íšŸìˆ˜: {best_result['total_consecutive_5_count']}íšŒ
        - í‰ê·  ì •í™•ë„: {best_result['avg_accuracy']:.2f}%
        - í…ŒìŠ¤íŠ¸ëœ Grid ìˆ˜: {best_result['tested_grid_strings']}/{best_result['total_grid_strings']}
        """)
        
        if len(candidates) > 1:
            st.warning(f"âš ï¸ {len(candidates)}ê°œì˜ ìœˆë„ìš° í¬ê¸°ê°€ ë™ì¼í•œ ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜ ìˆ˜({best_max_consecutive})ë¥¼ ê°€ì§‘ë‹ˆë‹¤.")
    
    # ìƒì„¸ ê²°ê³¼ í‘œì‹œ (í™•ì¥ ê°€ëŠ¥í•œ ì„¹ì…˜)
    st.markdown("---")
    with st.expander("ğŸ“‹ ê° ìœˆë„ìš° í¬ê¸°ë³„ ìƒì„¸ ê²°ê³¼"):
        for window_size, result in sorted(results_by_window.items()):
            st.markdown(f"#### ìœˆë„ìš° í¬ê¸°: {window_size}")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", result['max_consecutive_mismatches'])
            with col2:
                st.metric("ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ", result['total_consecutive_5_count'])
            with col3:
                st.metric("í‰ê·  ì •í™•ë„", f"{result['avg_accuracy']:.2f}%")
            with col4:
                st.metric("í…ŒìŠ¤íŠ¸ëœ Grid", f"{result['tested_grid_strings']}/{result['total_grid_strings']}")
            
            # Grid Stringë³„ ê²°ê³¼ ìš”ì•½
            if result['grid_string_results']:
                st.markdown("**Grid Stringë³„ ê²°ê³¼ ìš”ì•½:**")
                grid_summary = []
                for gr in result['grid_string_results']:
                    grid_summary.append({
                        'Grid ID': gr['grid_string_id'],
                        'ê¸¸ì´': gr['grid_string_length'],
                        'ìŠ¤í…': gr['steps'],
                        'ì •í™•ë„': f"{gr['accuracy']:.2f}%",
                        'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': gr['max_consecutive_mismatches'],
                        'ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ': gr['consecutive_5_count']
                    })
                
                grid_summary_df = pd.DataFrame(grid_summary)
                st.dataframe(grid_summary_df, use_container_width=True, hide_index=True)
            
            st.markdown("---")

def display_strategy_comparison(strategy_results, window_size=None):
    """
    ì „ëµë³„ ê²°ê³¼ë¥¼ ë¹„êµí•˜ê³  ìµœì  ì „ëµ ì¶”ì²œ
    
    Args:
        strategy_results: batch_test_strategiesì˜ ë°˜í™˜ê°’
        window_size: íŠ¹ì • ìœˆë„ìš° í¬ê¸°ë§Œ ë¹„êµ (Noneì´ë©´ ëª¨ë“  ìœˆë„ìš° í¬ê¸°)
    """
    if not strategy_results:
        st.warning("âš ï¸ ë¹„êµí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ìœˆë„ìš° í¬ê¸°ë³„ë¡œ ê²°ê³¼ ì •ë¦¬
    if window_size is None:
        # ëª¨ë“  ìœˆë„ìš° í¬ê¸°ì— ëŒ€í•´ ë¹„êµ
        all_window_sizes = set()
        for strategy_name, results in strategy_results.items():
            all_window_sizes.update(results.keys())
        window_sizes_to_compare = sorted(all_window_sizes)
    else:
        window_sizes_to_compare = [window_size]
    
    for window_size in window_sizes_to_compare:
        st.markdown(f"### ğŸ“Š ìœˆë„ìš° í¬ê¸° {window_size} - ì „ëµë³„ ë¹„êµ")
        
        comparison_data = []
        for strategy_name, results in strategy_results.items():
            if window_size not in results:
                continue
            
            result = results[window_size]
            # ì‹¤íŒ¨ ì§€í‘œ: ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ ì´ìƒ OR ì—°ì† ì¼ì¹˜ 5íšŒ ì´ìƒ
            total_failures = result.get('total_consecutive_5_count', 0) + result.get('total_consecutive_5_match_count', 0)
            max_failures = max(
                result.get('max_consecutive_mismatches', 0),
                result.get('max_consecutive_matches', 0)
            )
            
            # ìŠ¤í‚µ í†µê³„ ê³„ì‚°
            total_count = result.get('total_grid_strings', 0)
            skipped_count = result.get('skipped_count', 0)
            valid_count = result.get('valid_test_count', 0)
            truncated_count = result.get('truncated_count', 0)
            total_truncated_steps = result.get('total_truncated_steps', 0)
            skipped_ratio = (skipped_count / total_count * 100) if total_count > 0 else 0
            valid_ratio = (valid_count / total_count * 100) if total_count > 0 else 0
            
            comparison_data.append({
                'ì „ëµ ì´ë¦„': strategy_name,
                'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': result.get('max_consecutive_mismatches', 0),
                'ìµœëŒ€ ì—°ì† ì¼ì¹˜': result.get('max_consecutive_matches', 0),
                'ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ': max_failures,
                'ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ+': result.get('total_consecutive_5_count', 0),
                'ì—°ì† ì¼ì¹˜ 5íšŒ+': result.get('total_consecutive_5_match_count', 0),
                'ì´ ì‹¤íŒ¨ íšŸìˆ˜': total_failures,
                'í‰ê·  ì •í™•ë„ (%)': f"{result.get('avg_accuracy', 0):.2f}",
                'ìœ íš¨ í…ŒìŠ¤íŠ¸ ìˆ˜': valid_count,
                'ìŠ¤í‚µ ìˆ˜': skipped_count,
                'ìŠ¤í‚µ ë¹„ìœ¨ (%)': f"{skipped_ratio:.1f}",
                'ì˜ë¦° ì¼€ì´ìŠ¤ ìˆ˜': truncated_count,
                'ì˜ë¦° ìŠ¤í… ìˆ˜': total_truncated_steps,
                'í…ŒìŠ¤íŠ¸ëœ Grid ìˆ˜': result.get('tested_grid_strings', 0),
                'ì „ì²´ ìŠ¤í… ìˆ˜': result.get('total_steps', 0)
            })
        
        if not comparison_data:
            st.warning(f"âš ï¸ ìœˆë„ìš° í¬ê¸° {window_size}ì— ëŒ€í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        # ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì˜¤ë¦„ì°¨ìˆœ)
        comparison_data.sort(key=lambda x: (x['ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ'], x['ì´ ì‹¤íŒ¨ íšŸìˆ˜']))
        
        comparison_df = pd.DataFrame(comparison_data)
        st.dataframe(comparison_df, use_container_width=True, hide_index=True)
        
        # ìµœì  ì „ëµ ì¶”ì²œ
        st.markdown("---")
        st.markdown(f"### ğŸ¯ ìœˆë„ìš° í¬ê¸° {window_size} - ìµœì  ì „ëµ ì¶”ì²œ")
        
        # ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œê°€ ê°€ì¥ ë‚®ì€ ì „ëµ ì°¾ê¸°
        best_strategy = min(comparison_data, key=lambda x: (x['ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ'], x['ì´ ì‹¤íŒ¨ íšŸìˆ˜']))
        best_strategy_name = best_strategy['ì „ëµ ì´ë¦„']
        best_result = strategy_results[best_strategy_name][window_size]
        
        st.success(f"âœ… **ìµœì  ì „ëµ: {best_strategy_name}**")
        
        # ìŠ¤í‚µ ë° ì˜ë¦¼ í†µê³„
        best_skipped_count = best_result.get('skipped_count', 0)
        best_truncated_count = best_result.get('truncated_count', 0)
        best_total_truncated_steps = best_result.get('total_truncated_steps', 0)
        best_valid_count = best_result.get('valid_test_count', 0)
        
        st.info(f"""
        - ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜: {best_result.get('max_consecutive_mismatches', 0)}ê°œ
        - ìµœëŒ€ ì—°ì† ì¼ì¹˜: {best_result.get('max_consecutive_matches', 0)}ê°œ
        - ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ: {best_strategy['ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ']}ê°œ
        - ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ+: {best_result.get('total_consecutive_5_count', 0)}íšŒ
        - ì—°ì† ì¼ì¹˜ 5íšŒ+: {best_result.get('total_consecutive_5_match_count', 0)}íšŒ
        - ì´ ì‹¤íŒ¨ íšŸìˆ˜: {best_strategy['ì´ ì‹¤íŒ¨ íšŸìˆ˜']}íšŒ
        - í‰ê·  ì •í™•ë„: {best_result.get('avg_accuracy', 0):.2f}%
        - ìœ íš¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {best_valid_count}ê°œ
        - ìŠ¤í‚µëœ ì¼€ì´ìŠ¤: {best_skipped_count}ê°œ
        - ì˜ë¦° ì¼€ì´ìŠ¤: {best_truncated_count}ê°œ
        - ì˜ë¦° ìŠ¤í… ìˆ˜: {best_total_truncated_steps}ê°œ
        """)
        
        st.markdown("---")

def display_game_result(result_data):
    """
    ê²Œì„ ê²°ê³¼ë¥¼ UIì— í‘œì‹œ
    
    Args:
        result_data: simulate_game_scenarioì˜ ë°˜í™˜ê°’
    """
    result = result_data['result']
    history = result_data['history']
    max_consecutive_mismatches = result_data['max_consecutive_mismatches']
    consecutive_5_positions = result_data['consecutive_5_positions']
    stats = result_data['stats']
    
    # ê²Œì„ ê²°ê³¼ í‘œì‹œ
    st.markdown("### ê²€ì¦ ê²°ê³¼")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if result == 'has_5_consecutive':
            st.error(f"âŒ **ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ë°œê²¬!** (ì´ {stats['consecutive_5_count']}íšŒ ë°œìƒ)")
        else:
            st.success(f"âœ… **ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ì—†ìŒ**")
    
    with col2:
        st.metric("ì´ ê²€ì¦ ìˆ˜", stats['total'])
    
    with col3:
        st.metric("ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜", max_consecutive_mismatches)
    
    # ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ë°œìƒ ìœ„ì¹˜ í‘œì‹œ
    if consecutive_5_positions:
        st.markdown("---")
        st.markdown("### âš ï¸ ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ë°œìƒ ìœ„ì¹˜")
        
        for idx, pos_info in enumerate(consecutive_5_positions, 1):
            st.markdown(f"**ë°œìƒ #{idx}**: Step {pos_info['start_step']} ~ Step {pos_info['end_step']}")
            st.markdown(f"  - ìŠ¤í…: {', '.join(map(str, pos_info['steps']))}")
    
    # í†µê³„ ì •ë³´
    st.markdown("---")
    st.markdown("### í†µê³„ ì •ë³´")
    
    stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
    
    with stat_col1:
        st.metric("ì¼ì¹˜ ìˆ˜", stats['matches'])
    
    with stat_col2:
        st.metric("ë¶ˆì¼ì¹˜ ìˆ˜", stats['mismatches'])
    
    with stat_col3:
        accuracy = (stats['matches'] / stats['total'] * 100) if stats['total'] > 0 else 0
        st.metric("ì¼ì¹˜ìœ¨", f"{accuracy:.1f}%")
    
    with stat_col4:
        st.metric("ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ íšŸìˆ˜", stats['consecutive_5_count'])
    
    # ìƒì„¸ íˆìŠ¤í† ë¦¬ (ì—­ìˆœ - ìµœì‹ ìˆœ)
    if history:
        st.markdown("---")
        st.markdown("### ìƒì„¸ íˆìŠ¤í† ë¦¬")
        
        history_data = []
        # ì—­ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœì´ ìœ„ì—)
        reversed_history = list(reversed(history))
        for entry in reversed_history:
            match_icon = "âœ…" if entry['is_match'] else "âŒ"
            consecutive_info = f"({entry.get('consecutive_mismatches', 0)}ì—°ì†)" if not entry['is_match'] else ""
            history_data.append({
                'Step': entry['step'],
                'Index': entry['index'],
                'Prefix': entry['prefix'],
                'ì˜ˆì¸¡ê°’': entry['predicted'],
                'ì‹¤ì œê°’': entry['actual'],
                'ì¼ì¹˜': match_icon,
                'ì—°ì†ë¶ˆì¼ì¹˜': entry.get('consecutive_mismatches', 0),
                'ì‹ ë¢°ë„': f"{entry['confidence']:.1f}%"
            })
        
        history_df = pd.DataFrame(history_data)
        st.dataframe(history_df, use_container_width=True, hide_index=True)
        
        # ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ì´ìƒì¸ êµ¬ê°„ ê°•ì¡°
        if max_consecutive_mismatches >= 5:
            st.warning(f"âš ï¸ ìµœëŒ€ {max_consecutive_mismatches}ê°œê°€ ì—°ì†ìœ¼ë¡œ ë¶ˆì¼ì¹˜í–ˆìŠµë‹ˆë‹¤.")

def main():
    st.title("ğŸ”¬ Hypothesis Validation System")
    st.markdown("N-gram ê¸°ë°˜ íŒ¨í„´ ì˜ˆì¸¡ ê°€ì„¤ ê²€ì¦")
    st.markdown("---")
    
    # ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ í…Œì´ë¸” ìƒì„± (ìµœì´ˆ 1íšŒ)
    create_scenario_validation_tables()
    # ngram_chunks í…Œì´ë¸” ìƒì„± (ìµœì´ˆ 1íšŒ)
    create_ngram_chunks_table()
    # stored_predictions í…Œì´ë¸” ìƒì„± (ìµœì´ˆ 1íšŒ)
    create_stored_predictions_table()
    # prefix_trend_rules í…Œì´ë¸” ìƒì„± (ìµœì´ˆ 1íšŒ)
    create_prefix_trend_rules_table()
    
    # ë°ì´í„° ë¡œë“œ
    df_strings = load_preprocessed_data()
    
    if len(df_strings) == 0:
        st.warning("âš ï¸ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € `preprocess_grid_data.py`ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    # ì‚¬ì´ë“œë°”: ì„¤ì •
    st.sidebar.header("âš™ï¸ ì„¤ì •")
    
    # ìœˆë„ìš° í¬ê¸° ì„ íƒ
    window_size = st.sidebar.selectbox(
        "ìœˆë„ìš° í¬ê¸°",
        options=[5, 6, 7, 8, 9],
        index=0
    )
    
    # ì˜ˆì¸¡ ë°©ë²• ì„ íƒ
    prediction_method = st.sidebar.selectbox(
        "ì˜ˆì¸¡ ë°©ë²•",
        options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
        index=0
    )
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• 
    train_ratio = st.sidebar.slider(
        "í•™ìŠµ ì„¸íŠ¸ ë¹„ìœ¨ (%)",
        min_value=50,
        max_value=90,
        value=80,
        step=5
    )
    
    # ë°ì´í„° ê°œìš”
    st.header("ğŸ“Š ë°ì´í„° ê°œìš”")
    
    # ngram_chunks ì¼ê´„ ìƒì„± ë²„íŠ¼
    col_info1, col_info2 = st.columns([3, 1])
    with col_info1:
        st.markdown("**ngram_chunks ìƒíƒœ í™•ì¸ ë° ì¼ê´„ ìƒì„±**")
    with col_info2:
        if st.button("ê¸°ì¡´ ë°ì´í„° ngram_chunks ì¼ê´„ ìƒì„±", key="batch_generate_ngrams", use_container_width=True):
            with st.spinner("ngram_chunks ìƒì„± ì¤‘..."):
                batch_generate_ngram_chunks_for_existing_data()
                st.rerun()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì „ì²´ ì„¸ì…˜ ìˆ˜", len(df_strings))
    
    with col2:
        total_chars = df_strings['string_length'].sum()
        st.metric("ì´ ë¬¸ì ìˆ˜", f"{total_chars:,}")
    
    with col3:
        avg_length = df_strings['string_length'].mean()
        st.metric("í‰ê·  ë¬¸ìì—´ ê¸¸ì´", f"{avg_length:.1f}")
    
    with col4:
        avg_b_ratio = df_strings['b_ratio'].mean()
        st.metric("í‰ê·  'b' ë¹„ìœ¨", f"{avg_b_ratio:.1f}%")
    
    st.markdown("---")
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• 
    split_idx = int(len(df_strings) * train_ratio / 100)
    train_ids = df_strings.iloc[:split_idx]['id'].tolist()
    test_ids = df_strings.iloc[split_idx:]['id'].tolist()
    
    st.header("ğŸ“ˆ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€")
    
    with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
        # í•™ìŠµ ì„¸íŠ¸ N-gram ë¡œë“œ
        train_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=train_ids)
        
        if len(train_ngrams) == 0:
            st.warning("âš ï¸ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ N-gram ë¡œë“œ
        test_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=test_ids)
        
        if len(test_ngrams) == 0:
            st.warning("âš ï¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    # ëª¨ë¸ êµ¬ì¶•
    with st.spinner(f"{prediction_method} ëª¨ë¸ êµ¬ì¶• ì¤‘..."):
        if prediction_method == "ë¹ˆë„ ê¸°ë°˜":
            model = build_frequency_model(train_ngrams)
            predict_func = predict_frequency
        # elif prediction_method == "ë§ˆë¥´ì½”í”„ ì²´ì¸":
        #     model = build_markov_model(train_ngrams)
        #     predict_func = predict_markov
        elif prediction_method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
            model = build_weighted_model(train_ngrams)
            predict_func = predict_weighted
        elif prediction_method == "ì•ˆì „ ìš°ì„ ":
            model = build_safety_first_model(train_ngrams)
            predict_func = lambda m, p: predict_safety_first(m, p, recent_history=None, consecutive_mismatches=0)
        else:  # ê¸°ë³¸ê°’: ë¹ˆë„ ê¸°ë°˜
            model = build_frequency_model(train_ngrams)
            predict_func = predict_frequency
    
    st.success(f"âœ… ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ (ê³ ìœ  prefix íŒ¨í„´: {len(model):,}ê°œ)")
    
    # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì˜ˆì¸¡
    with st.spinner("ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘..."):
        predictions = []
        actuals = []
        confidence_scores = []
        
        for _, row in test_ngrams.iterrows():
            prefix = row['prefix']
            actual = row['suffix']
            
            predicted, ratios = predict_func(model, prefix)
            
            if predicted is not None:
                predictions.append(predicted)
                actuals.append(actual)
                # ê°€ì¥ ë†’ì€ ë¹„ìœ¨ì„ confidenceë¡œ ì‚¬ìš©
                confidence = max(ratios.values()) if ratios else 0.0
                confidence_scores.append(confidence)
    
    # í‰ê°€ ê²°ê³¼
    if len(predictions) > 0:
        metrics = evaluate_predictions(predictions, actuals)
        
        st.markdown("### í‰ê°€ ê²°ê³¼")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì •í™•ë„", f"{metrics['accuracy']:.2f}%")
        
        with col2:
            st.metric("ì •ë‹µ ìˆ˜", f"{metrics['correct']}/{metrics['total']}")
        
        with col3:
            avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
            st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.2f}%")
        
        with col4:
            st.metric("í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í¬ê¸°", f"{metrics['total']:,}")
        
        # ìƒì„¸ í†µê³„
        st.markdown("### ìƒì„¸ í†µê³„")
        
        stats_data = {
            'í•­ëª©': ['ì „ì²´', "'b' ì˜ˆì¸¡", "'p' ì˜ˆì¸¡"],
            'ì˜ˆì¸¡ ìˆ˜': [
                metrics['total'],
                metrics['b_predicted'],
                metrics['p_predicted']
            ],
            'ì‹¤ì œ ìˆ˜': [
                metrics['total'],
                metrics['b_actual'],
                metrics['p_actual']
            ]
        }
        stats_df = pd.DataFrame(stats_data)
        st.dataframe(stats_df, use_container_width=True, hide_index=True)
    else:
        st.warning("âš ï¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # íŒ¨í„´ ë¶„ì„
    st.header("ğŸ” íŒ¨í„´ ë¶„ì„")
    
    # ê°€ì¥ ë¹ˆë²ˆí•œ prefix íŒ¨í„´
    st.markdown("### ê°€ì¥ ë¹ˆë²ˆí•œ Prefix íŒ¨í„´ (Top 10)")
    
    prefix_counts = train_ngrams['prefix'].value_counts().head(10)
    prefix_df = pd.DataFrame({
        'Prefix': prefix_counts.index,
        'ë¹ˆë„': prefix_counts.values
    })
    st.dataframe(prefix_df, use_container_width=True, hide_index=True)
    
    # ì„¸ì…˜ë³„ ìƒì„¸ ë¶„ì„
    st.markdown("---")
    st.header("ğŸ“‹ ì„¸ì…˜ë³„ ë¶„ì„")
    
    session_options = [
        f"{row['source_session_id'][:8]}... (ê¸¸ì´: {row['string_length']})"
        for _, row in df_strings.iterrows()
    ]
    
    selected_idx = st.selectbox(
        "ì„¸ì…˜ ì„ íƒ",
        options=range(len(df_strings)),
        format_func=lambda x: session_options[x] if x < len(session_options) else f"ì„¸ì…˜ {x}"
    )
    
    if selected_idx < len(df_strings):
        selected_row = df_strings.iloc[selected_idx]
        selected_id = selected_row['id']
        selected_string = selected_row['grid_string']
        
        st.markdown(f"**ì„¸ì…˜ ID**: `{selected_row['source_session_id']}`")
        st.markdown(f"**ë¬¸ìì—´ ê¸¸ì´**: {selected_row['string_length']}")
        st.markdown(f"**'b' ë¹„ìœ¨**: {selected_row['b_ratio']:.2f}%")
        st.markdown(f"**'p' ë¹„ìœ¨**: {selected_row['p_ratio']:.2f}%")
        
        # í•´ë‹¹ ì„¸ì…˜ì˜ N-gram ì¡°ê° ë¡œë“œ
        session_ngrams = load_ngram_chunks(window_size=window_size, grid_string_ids=[selected_id])
        
        if len(session_ngrams) > 0:
            st.markdown(f"### ìœˆë„ìš° í¬ê¸° {window_size} ì¡°ê° (ì²˜ìŒ 20ê°œ)")
            
            display_ngrams = session_ngrams.head(20).copy()
            display_ngrams['ì˜ˆì¸¡ê°’'] = display_ngrams['prefix'].apply(
                lambda p: predict_func(model, p)[0] if p in model else 'N/A'
            )
            
            display_df = display_ngrams[['chunk_index', 'prefix', 'suffix', 'ì˜ˆì¸¡ê°’', 'full_chunk']].copy()
            display_df.columns = ['ì¸ë±ìŠ¤', 'Prefix', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì „ì²´ ì¡°ê°']
            display_df['ì¼ì¹˜'] = display_df['ì‹¤ì œê°’'] == display_df['ì˜ˆì¸¡ê°’']
            
            st.dataframe(display_df, use_container_width=True, hide_index=True)
            
            # í•´ë‹¹ ì„¸ì…˜ì˜ ì •í™•ë„
            session_predictions = []
            session_actuals = []
            
            for _, row in session_ngrams.iterrows():
                prefix = row['prefix']
                actual = row['suffix']
                predicted, _ = predict_func(model, prefix)
                
                if predicted is not None:
                    session_predictions.append(predicted)
                    session_actuals.append(actual)
            
            if len(session_predictions) > 0:
                session_metrics = evaluate_predictions(session_predictions, session_actuals)
                st.metric("ì´ ì„¸ì…˜ì˜ ì •í™•ë„", f"{session_metrics['accuracy']:.2f}%")
    
    st.markdown("---")
    
    # Prefix ì˜ˆì¸¡ ë° ê²€ì¦ ì„¹ì…˜
    st.header("ğŸ”® Prefix ì˜ˆì¸¡ ë° ê²€ì¦")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        prefix_input = st.text_input(
            "Prefix ì…ë ¥",
            value="bbbbb",
            help="ì˜ˆì¸¡í•  prefixë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'bbbbb', 'bbbbp' ë“±)"
        )
    
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        predict_button = st.button("ì˜ˆì¸¡", type="primary", use_container_width=True)
    
    if predict_button and prefix_input:
        # prefix ê¸¸ì´ ê²€ì¦
        prefix_length = len(prefix_input)
        expected_prefix_length = window_size - 1
        
        if prefix_length != expected_prefix_length:
            st.warning(f"âš ï¸ Prefix ê¸¸ì´ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ìœˆë„ìš° í¬ê¸° {window_size}ì— ë§ê²Œ {expected_prefix_length}ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        else:
            # ì˜ˆì¸¡ ìˆ˜í–‰
            prediction_result = predict_for_prefix(model, prefix_input, prediction_method)
            
            if prediction_result['predicted']:
                st.markdown("### ì˜ˆì¸¡ ê²°ê³¼")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**Prefix**: `{prefix_input}`")
                    st.markdown(f"**ì˜ˆì¸¡ê°’**: `{prediction_result['predicted']}`")
                    st.metric("ì‹ ë¢°ë„", f"{prediction_result['confidence']:.2f}%")
                
                with col2:
                    st.markdown("**ì˜ˆì¸¡ í™•ë¥  ë¶„í¬:**")
                    ratios = prediction_result['ratios']
                    for value, ratio in sorted(ratios.items(), key=lambda x: x[1], reverse=True):
                        st.progress(ratio / 100, text=f"'{value}': {ratio:.2f}%")
                
                # ì‹¤ì œê°’ ì…ë ¥ ë° ê²€ì¦
                st.markdown("---")
                st.markdown("### ì‹¤ì œê°’ ì…ë ¥ ë° ê²€ì¦")
                
                actual_value = st.radio(
                    "ì‹¤ì œê°’ ì„ íƒ",
                    options=['b', 'p'],
                    horizontal=True
                )
                
                if st.button("ê²€ì¦", type="primary"):
                    is_correct = prediction_result['predicted'] == actual_value
                    predicted_ratio = ratios.get(actual_value, 0.0)
                    
                    if is_correct:
                        st.success(f"âœ… ì˜ˆì¸¡ ì •í™•! ì˜ˆì¸¡ê°’ '{prediction_result['predicted']}'ì™€ ì‹¤ì œê°’ '{actual_value}'ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤.")
                    else:
                        st.error(f"âŒ ì˜ˆì¸¡ ë¶ˆì¼ì¹˜. ì˜ˆì¸¡ê°’ '{prediction_result['predicted']}'ì™€ ì‹¤ì œê°’ '{actual_value}'ê°€ ë‹¤ë¦…ë‹ˆë‹¤.")
                    
                    st.info(f"ì‹¤ì œê°’ '{actual_value}'ì˜ ì˜ˆì¸¡ í™•ë¥ : {predicted_ratio:.2f}%")
            else:
                st.warning(f"âš ï¸ Prefix '{prefix_input}'ì— ëŒ€í•œ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤ ì„¹ì…˜
    st.header("ğŸŒ³ ì¸í„°ë™í‹°ë¸Œ ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤")
    
    # ì„¤ì • ì„¹ì…˜ (st.formìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ rerun ìµœì†Œí™”)
    with st.form("interactive_settings_form", clear_on_submit=False):
        st.markdown("### âš™ï¸ ì„¤ì •")
        col_setting1, col_setting2, col_setting3 = st.columns(3)
        
        with col_setting1:
            interactive_window_size = st.selectbox(
                "ìœˆë„ìš° í¬ê¸°",
                options=[5, 6, 7, 8, 9],
                index=2,  # 7ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
                key="interactive_window_size",
                help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ìœˆë„ìš° í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col_setting2:
            interactive_method = st.selectbox(
                "ì˜ˆì¸¡ ë°©ë²•",
                options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
                index=0,
                key="interactive_method",
                help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col_setting3:
            use_threshold = st.checkbox(
                "ì„ê³„ê°’ ì „ëµ ì‚¬ìš©",
                value=True,
                key="interactive_use_threshold",
                help="ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•˜ë„ë¡ ì„¤ì •"
            )
            interactive_threshold = None
            if use_threshold:
                interactive_threshold = st.number_input(
                    "ì„ê³„ê°’ (%)",
                    min_value=0,
                    max_value=100,
                    value=60,
                    step=1,
                    key="interactive_threshold",
                    help="ì´ ì‹ ë¢°ë„ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤"
                )
        
        # ìµœëŒ€ ê°„ê²© ì„¤ì • (ê°•ì œ ì˜ˆì¸¡ìš©)
        col_setting4, col_setting5 = st.columns(2)
        with col_setting4:
            interactive_max_interval = st.number_input(
                "ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© (ìŠ¤í…)",
                min_value=1,
                max_value=20,
                value=6,
                step=1,
                key="interactive_max_interval",
                help="ì´ ê°„ê²©ì„ ë„˜ê¸°ë©´ ì„ê³„ê°’ ë¬´ì‹œí•˜ê³  ê°•ì œ ì˜ˆì¸¡í•©ë‹ˆë‹¤"
            )
        
        # ì„¤ì • ì ìš© ë²„íŠ¼
        if st.form_submit_button("ì„¤ì • ì ìš©", use_container_width=True):
            # ì„¤ì • ë³€ê²½ ê°ì§€ ë° ì´ˆê¸°í™”
            if 'last_interactive_window_size' not in st.session_state:
                st.session_state.last_interactive_window_size = interactive_window_size
                st.session_state.last_interactive_method = interactive_method
                st.session_state.last_interactive_threshold = interactive_threshold
                st.session_state.last_interactive_max_interval = interactive_max_interval
            elif (st.session_state.last_interactive_window_size != interactive_window_size or
                  st.session_state.last_interactive_method != interactive_method or
                  st.session_state.last_interactive_threshold != interactive_threshold or
                  st.session_state.last_interactive_max_interval != interactive_max_interval):
                # ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆìœ¼ë©´ ì´ˆê¸°í™” ë° ìºì‹œ ë¬´íš¨í™”
                st.session_state.interactive_path = []
                st.session_state.interactive_current_prefix = None
                st.session_state.interactive_step = 0
                st.session_state.interactive_current_interval = 0
                
                # ëª¨ë¸ ìºì‹œ ë¬´íš¨í™” (ì„¤ì • ë³€ê²½ ì‹œ)
                if 'last_interactive_window_size' in st.session_state and 'last_interactive_method' in st.session_state:
                    old_model_key = f'interactive_model_{st.session_state.last_interactive_window_size}_{st.session_state.last_interactive_method}'
                    old_data_key = f'interactive_data_{st.session_state.last_interactive_window_size}'
                    old_ngrams_key = f'interactive_ngrams_{st.session_state.last_interactive_window_size}'
                    if old_model_key in st.session_state:
                        del st.session_state[old_model_key]
                    if old_data_key in st.session_state:
                        del st.session_state[old_data_key]
                    if old_ngrams_key in st.session_state:
                        del st.session_state[old_ngrams_key]
                
                st.session_state.last_interactive_window_size = interactive_window_size
                st.session_state.last_interactive_method = interactive_method
                st.session_state.last_interactive_threshold = interactive_threshold
                st.session_state.last_interactive_max_interval = interactive_max_interval
                st.rerun()
    
    # Session state ì´ˆê¸°í™”
    if 'interactive_path' not in st.session_state:
        st.session_state.interactive_path = []
        st.session_state.interactive_current_prefix = None
        st.session_state.interactive_step = 0
        st.session_state.interactive_current_interval = 0
        st.session_state.last_interactive_window_size = interactive_window_size
        st.session_state.last_interactive_method = interactive_method
        st.session_state.last_interactive_threshold = interactive_threshold
        st.session_state.last_interactive_max_interval = interactive_max_interval
    
    st.markdown("---")
    
    # ì´ˆê¸° prefix ì…ë ¥ (st.formìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ rerun ìµœì†Œí™”)
    with st.form("start_interactive_form", clear_on_submit=False):
        col1, col2 = st.columns([2, 1])
        
        with col1:
            initial_prefix = st.text_input(
                "ì´ˆê¸° Prefix ì…ë ¥",
                value="bbbbb",
                key="initial_prefix",
                help=f"ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ì„ ì‹œì‘í•  ì´ˆê¸° prefixë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸¸ì´: {interactive_window_size - 1})"
            )
        
        with col2:
            st.markdown("<br>", unsafe_allow_html=True)
            if st.form_submit_button("ì‹œì‘", type="primary", use_container_width=True):
                # prefix ê¸¸ì´ ê²€ì¦
                prefix_length = len(initial_prefix)
                expected_prefix_length = interactive_window_size - 1
                
                if prefix_length != expected_prefix_length:
                    st.warning(f"âš ï¸ Prefix ê¸¸ì´ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ìœˆë„ìš° í¬ê¸° {interactive_window_size}ì— ë§ê²Œ {expected_prefix_length}ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    st.session_state.interactive_path = []
                    st.session_state.interactive_current_prefix = initial_prefix
                    st.session_state.interactive_step = 1
                    st.session_state.interactive_current_interval = 0
                    st.rerun()
    
    if st.button("ì´ˆê¸°í™”", use_container_width=True, key="reset_interactive"):
        st.session_state.interactive_path = []
        st.session_state.interactive_current_prefix = None
        st.session_state.interactive_step = 0
        st.session_state.interactive_current_interval = 0
        st.rerun()
    
    # ì¸í„°ë™í‹°ë¸Œ ë‹¨ê³„ë³„ ì§„í–‰
    if st.session_state.interactive_current_prefix and st.session_state.interactive_step > 0:
        current_prefix = st.session_state.interactive_current_prefix
        current_step = st.session_state.interactive_step
        
        st.markdown("---")
        st.markdown(f"### Step {current_step}: `{current_prefix}`")
        
        # í˜„ì¬ ìŠ¤í…ì˜ ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ í‚¤
        prediction_result_key = f'interactive_prediction_step_{current_step}'
        prediction_interval_key = f'interactive_interval_before_step_{current_step}'
        
        # ìºì‹œëœ ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê³„ì‚°
        if prediction_result_key in st.session_state and st.session_state[prediction_result_key] is not None:
            prediction_result = st.session_state[prediction_result_key]
            df_strings = None
            train_ngrams = None
            interactive_model = None
        else:
            # ëª¨ë¸ ë° ë°ì´í„° ìºì‹±
            model_cache_key = f'interactive_model_{interactive_window_size}_{interactive_method}'
            data_cache_key = f'interactive_data_{interactive_window_size}'
            ngrams_cache_key = f'interactive_ngrams_{interactive_window_size}'
            
            # ì„¤ì • ë³€ê²½ ê°ì§€
            settings_changed = (
                'last_interactive_window_size' not in st.session_state or
                st.session_state.last_interactive_window_size != interactive_window_size or
                st.session_state.last_interactive_method != interactive_method
            )
            
            # ìºì‹œ í™•ì¸ ë° ëª¨ë¸ êµ¬ì¶•
            if not settings_changed and model_cache_key in st.session_state:
                # ìºì‹œëœ ëª¨ë¸ ë° ë°ì´í„° ì¬ì‚¬ìš©
                interactive_model = st.session_state[model_cache_key]
                df_strings = st.session_state.get(data_cache_key)
                train_ngrams = st.session_state.get(ngrams_cache_key)
            else:
                # ëª¨ë¸ êµ¬ì¶• ë° ìºì‹±
                df_strings = None
                train_ngrams = None
                interactive_model = None
                
                with st.spinner("ëª¨ë¸ êµ¬ì¶• ì¤‘..."):
                    # í•™ìŠµ ë°ì´í„° ë¡œë“œ
                    df_strings = load_preprocessed_data()
                    if len(df_strings) == 0:
                        st.warning("âš ï¸ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        prediction_result = {'predicted': None, 'ratios': {}, 'confidence': 0.0, 'is_forced': False}
                    else:
                        # í•™ìŠµ ì„¸íŠ¸ ë¶„í• 
                        train_ratio = 80
                        split_idx = int(len(df_strings) * train_ratio / 100)
                        train_ids = df_strings.iloc[:split_idx]['id'].tolist()
                        
                        # N-gram ë¡œë“œ
                        train_ngrams = load_ngram_chunks(window_size=interactive_window_size, grid_string_ids=train_ids)
                        
                        if len(train_ngrams) == 0:
                            st.warning(f"âš ï¸ ìœˆë„ìš° í¬ê¸° {interactive_window_size}ì— ëŒ€í•œ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            prediction_result = {'predicted': None, 'ratios': {}, 'confidence': 0.0, 'is_forced': False}
                        else:
                            # ëª¨ë¸ êµ¬ì¶•
                            if interactive_method == "ë¹ˆë„ ê¸°ë°˜":
                                interactive_model = build_frequency_model(train_ngrams)
                            # elif interactive_method == "ë§ˆë¥´ì½”í”„ ì²´ì¸":
                            #     interactive_model = build_markov_model(train_ngrams)
                            elif interactive_method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                                interactive_model = build_weighted_model(train_ngrams)
                            elif interactive_method == "ì•ˆì „ ìš°ì„ ":
                                interactive_model = build_safety_first_model(train_ngrams)
                            else:  # ê¸°ë³¸ê°’: ë¹ˆë„ ê¸°ë°˜
                                interactive_model = build_frequency_model(train_ngrams)
                            
                            # ëª¨ë¸ ë° ë°ì´í„° ìºì‹±
                            st.session_state[model_cache_key] = interactive_model
                            st.session_state[data_cache_key] = df_strings
                            st.session_state[ngrams_cache_key] = train_ngrams
            
            # ì˜ˆì¸¡ ê³„ì‚° (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
            if interactive_model is not None:
                # ì˜ˆì¸¡ ê³„ì‚° (ê°„ê²© ì—…ë°ì´íŠ¸ëŠ” í•˜ì§€ ì•ŠìŒ)
                if use_threshold and interactive_threshold is not None:
                    # ê°•ì œ ì˜ˆì¸¡ ì „ëµ ì‚¬ìš©
                    current_interval_for_prediction = st.session_state.interactive_current_interval
                    
                    # ë””ë²„ê¹…: ì˜ˆì¸¡ ì „ ê°„ê²© ìƒíƒœ ì €ì¥
                    st.session_state[prediction_interval_key] = current_interval_for_prediction
                    
                    prediction_result = predict_with_fallback_interval(
                        interactive_model,
                        current_prefix,
                        interactive_method,
                        threshold=interactive_threshold,
                        max_interval=interactive_max_interval,
                        current_interval=current_interval_for_prediction
                    )
                    # ê°„ê²© ì—…ë°ì´íŠ¸ëŠ” í•˜ì§€ ì•ŠìŒ (ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°ˆ ë•Œ ì—…ë°ì´íŠ¸)
                else:
                    prediction_result = predict_for_prefix(interactive_model, current_prefix, interactive_method)
                    if 'is_forced' not in prediction_result:
                        prediction_result['is_forced'] = False
            else:
                prediction_result = {'predicted': None, 'ratios': {}, 'confidence': 0.0, 'is_forced': False}
            
            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
            st.session_state[prediction_result_key] = prediction_result
        
        # ë””ë²„ê¹…: ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
        if use_threshold and interactive_threshold is not None:
            st.info(f"ğŸ” **ë””ë²„ê¹…**: ìŠ¤í…={current_step}, prefix='{current_prefix}', ì˜ˆì¸¡ ì „ ê°„ê²©={st.session_state.interactive_current_interval}, ì˜ˆì¸¡ê°’={prediction_result.get('predicted')}, ê°•ì œì˜ˆì¸¡={prediction_result.get('is_forced', False)}, ì‹ ë¢°ë„={prediction_result.get('confidence', 0):.2f}%")
        
        # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°
        if prediction_result.get('predicted') is not None:
            ratios = prediction_result.get('ratios', {})
            sorted_ratios = sorted(ratios.items(), key=lambda x: x[1], reverse=True) if ratios else []
            
            # ì˜ˆì¸¡ê°’ í‘œì‹œ
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.markdown("**ì˜ˆì¸¡ í™•ë¥ :**")
                if sorted_ratios:
                    for value, ratio in sorted_ratios:
                        color = "ğŸŸ¢" if ratio == max(ratios.values()) else "ğŸŸ¡"
                        st.markdown(f"{color} **'{value}'**: {ratio:.2f}%")
                        st.progress(ratio / 100)
                else:
                    st.info("ì˜ˆì¸¡ í™•ë¥  ì •ë³´ ì—†ìŒ")
            
            with col2:
                st.markdown("**ì˜ˆì¸¡ê°’:**")
                is_forced = prediction_result.get('is_forced', False)
                prediction_display = prediction_result['predicted']
                if is_forced:
                    prediction_display = f"{prediction_display} âš¡"  # ê°•ì œ ì˜ˆì¸¡ í‘œì‹œ
                st.markdown(f"### `{prediction_display}`")
                confidence_display = f"{prediction_result.get('confidence', 0):.2f}%"
                if is_forced:
                    confidence_display += " (ê°•ì œ)"
                st.metric("ì‹ ë¢°ë„", confidence_display)
                
                # ë””ë²„ê¹…: ê°„ê²© ì •ë³´ í‘œì‹œ
                if use_threshold and interactive_threshold is not None:
                    if prediction_interval_key in st.session_state:
                        interval_before = st.session_state[prediction_interval_key]
                        st.info(f"ğŸ” **ë””ë²„ê¹… ì •ë³´**: ì˜ˆì¸¡ ì „ ê°„ê²©={interval_before}, í˜„ì¬ ê°„ê²©={st.session_state.interactive_current_interval}/{interactive_max_interval} (ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì´í›„ ì˜ˆì¸¡ ì—†ìŒ ì—°ì† ìŠ¤í… ìˆ˜)")
                    else:
                        st.info(f"ğŸ” **ë””ë²„ê¹… ì •ë³´**: í˜„ì¬ ê°„ê²©={st.session_state.interactive_current_interval}/{interactive_max_interval} (ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì´í›„ ì˜ˆì¸¡ ì—†ìŒ ì—°ì† ìŠ¤í… ìˆ˜)")
            
            # ë‹¤ìŒ 1ê°œ ìŠ¤í… ì‹¤ì œê°’ ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°
            st.markdown("---")
            st.markdown('<p style="font-size: 1em; color: #666; margin-top: -10px;"><strong>ë‹¤ìŒ ìŠ¤í… ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°:</strong></p>', unsafe_allow_html=True)
            
            # ë‹¤ìŒ prefix ìƒì„± (bì™€ p ë‘ ê²½ìš° ëª¨ë‘)
            next_prefix_b = get_next_prefix(current_prefix, 'b', interactive_window_size)
            next_prefix_p = get_next_prefix(current_prefix, 'p', interactive_window_size)
            
            # ë¯¸ë¦¬ë³´ê¸° ê³„ì‚°ì„ ìœ„í•´ ëª¨ë¸ì´ í•„ìš”í•˜ë©´ ìºì‹œì—ì„œ ë¡œë“œ
            if interactive_model is None:
                model_cache_key = f'interactive_model_{interactive_window_size}_{interactive_method}'
                if model_cache_key in st.session_state:
                    interactive_model = st.session_state[model_cache_key]
            
            # ë‹¤ìŒ prefixì— ëŒ€í•œ ì˜ˆì¸¡ (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
            if interactive_model is not None:
                next_pred_b = None
                next_pred_p = None
                next_conf_b = 0.0
                next_conf_p = 0.0
                next_forced_b = False
                next_forced_p = False
                
                try:
                    if use_threshold and interactive_threshold is not None:
                        # ë‹¤ìŒ ìŠ¤í… ì˜ˆì¸¡ìš© ê°„ê²© ê³„ì‚°
                        # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 0ìœ¼ë¡œ ë¦¬ì…‹
                        # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ì—†ì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 1 ì¦ê°€
                        if prediction_result.get('predicted') is not None:
                            # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 0ìœ¼ë¡œ ë¦¬ì…‹
                            next_interval = 0
                        else:
                            # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ì—†ì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 1 ì¦ê°€
                            next_interval = st.session_state.interactive_current_interval + 1
                        
                        # ê°„ê²©ì„ ê³ ë ¤í•˜ì—¬ ì˜ˆì¸¡ (ê°„ê²©ì´ 0ì´ë¯€ë¡œ ê°•ì œ ì˜ˆì¸¡ì€ ë°œìƒí•˜ì§€ ì•ŠìŒ)
                        next_result_b = predict_with_fallback_interval(
                            interactive_model,
                            next_prefix_b,
                            interactive_method,
                            threshold=interactive_threshold,
                            max_interval=interactive_max_interval,
                            current_interval=next_interval
                        )
                        next_result_p = predict_with_fallback_interval(
                            interactive_model,
                            next_prefix_p,
                            interactive_method,
                            threshold=interactive_threshold,
                            max_interval=interactive_max_interval,
                            current_interval=next_interval
                        )
                        
                        next_forced_b = next_result_b.get('is_forced', False)
                        next_forced_p = next_result_p.get('is_forced', False)
                    else:
                        next_result_b = predict_for_prefix(interactive_model, next_prefix_b, interactive_method)
                        next_result_p = predict_for_prefix(interactive_model, next_prefix_p, interactive_method)
                        next_forced_b = False
                        next_forced_p = False
                    
                    next_pred_b = next_result_b.get('predicted')
                    next_pred_p = next_result_p.get('predicted')
                    next_conf_b = next_result_b.get('confidence', 0.0)
                    next_conf_p = next_result_p.get('confidence', 0.0)
                except Exception as e:
                    pass
                
                # ê²½ë¡œ í‘œì‹œ
                col_path1, col_path2 = st.columns(2)
                with col_path1:
                    if next_pred_b is not None and str(next_pred_b).strip() != '':
                        forced_marker = " âš¡" if next_forced_b else ""
                        st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_b}{forced_marker}</code> ({next_conf_b:.1f}%)</p>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
                
                with col_path2:
                    if next_pred_p is not None and str(next_pred_p).strip() != '':
                        forced_marker = " âš¡" if next_forced_p else ""
                        st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_p}{forced_marker}</code> ({next_conf_p:.1f}%)</p>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
            else:
                # ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° prefixë§Œ í‘œì‹œ
                col_path1, col_path2 = st.columns(2)
                with col_path1:
                    st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code></p>', unsafe_allow_html=True)
                with col_path2:
                    st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code></p>', unsafe_allow_html=True)
        else:
            # ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê²½ìš° (ì„ê³„ê°’ ë¯¸ë§Œ ë“±)
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.markdown("**ì˜ˆì¸¡ í™•ë¥ :**")
                st.info("âš ï¸ ì˜ˆì¸¡ ë°ì´í„° ì—†ìŒ")
                if use_threshold and interactive_threshold is not None:
                    if prediction_interval_key in st.session_state:
                        interval_before = st.session_state[prediction_interval_key]
                    else:
                        interval_before = st.session_state.interactive_current_interval
                    st.info(f"ğŸ” **ë””ë²„ê¹… ì •ë³´**: ì˜ˆì¸¡ ì „ ê°„ê²©={interval_before}, í˜„ì¬ ê°„ê²©={st.session_state.interactive_current_interval}/{interactive_max_interval} (ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì´í›„ ì˜ˆì¸¡ ì—†ìŒ ì—°ì† ìŠ¤í… ìˆ˜)")
                    st.caption(f"ì„ê³„ê°’({interactive_threshold}%) ë¯¸ë§Œì´ê±°ë‚˜ í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                else:
                    st.caption("í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            
            with col2:
                st.markdown("**ì˜ˆì¸¡ê°’:**")
                st.markdown("### `-`")
                st.metric("ì‹ ë¢°ë„", "N/A")
            
            # ë‹¤ìŒ 1ê°œ ìŠ¤í… ì‹¤ì œê°’ ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°
            st.markdown("---")
            st.markdown('<p style="font-size: 1em; color: #666; margin-top: -10px;"><strong>ë‹¤ìŒ ìŠ¤í… ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°:</strong></p>', unsafe_allow_html=True)
            
            # ë‹¤ìŒ prefix ìƒì„± (bì™€ p ë‘ ê²½ìš° ëª¨ë‘)
            next_prefix_b = get_next_prefix(current_prefix, 'b', interactive_window_size)
            next_prefix_p = get_next_prefix(current_prefix, 'p', interactive_window_size)
            
            # ë¯¸ë¦¬ë³´ê¸° ê³„ì‚°ì„ ìœ„í•´ ëª¨ë¸ì´ í•„ìš”í•˜ë©´ ìºì‹œì—ì„œ ë¡œë“œ
            if interactive_model is None:
                model_cache_key = f'interactive_model_{interactive_window_size}_{interactive_method}'
                if model_cache_key in st.session_state:
                    interactive_model = st.session_state[model_cache_key]
            
            # ë‹¤ìŒ prefixì— ëŒ€í•œ ì˜ˆì¸¡ (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
            if interactive_model is not None:
                next_pred_b = None
                next_pred_p = None
                next_conf_b = 0.0
                next_conf_p = 0.0
                next_forced_b = False
                next_forced_p = False
                
                try:
                    if use_threshold and interactive_threshold is not None:
                        # ë‹¤ìŒ ìŠ¤í… ì˜ˆì¸¡ìš© ê°„ê²© ê³„ì‚°
                        # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ì—†ì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 1 ì¦ê°€
                        # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 0ìœ¼ë¡œ ë¦¬ì…‹
                        if prediction_result.get('predicted') is None:
                            # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ì—†ì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 1 ì¦ê°€
                            next_interval = st.session_state.interactive_current_interval + 1
                        else:
                            # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆìœ¼ë©´, ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ë©´ ê°„ê²©ì´ 0ìœ¼ë¡œ ë¦¬ì…‹
                            next_interval = 0
                        
                        next_result_b = predict_with_fallback_interval(
                            interactive_model,
                            next_prefix_b,
                            interactive_method,
                            threshold=interactive_threshold,
                            max_interval=interactive_max_interval,
                            current_interval=next_interval
                        )
                        next_result_p = predict_with_fallback_interval(
                            interactive_model,
                            next_prefix_p,
                            interactive_method,
                            threshold=interactive_threshold,
                            max_interval=interactive_max_interval,
                            current_interval=next_interval
                        )
                    else:
                        next_result_b = predict_for_prefix(interactive_model, next_prefix_b, interactive_method)
                        next_result_p = predict_for_prefix(interactive_model, next_prefix_p, interactive_method)
                    
                    next_pred_b = next_result_b.get('predicted')
                    next_pred_p = next_result_p.get('predicted')
                    next_conf_b = next_result_b.get('confidence', 0.0)
                    next_conf_p = next_result_p.get('confidence', 0.0)
                    next_forced_b = next_result_b.get('is_forced', False)
                    next_forced_p = next_result_p.get('is_forced', False)
                except:
                    pass
                
                # ê²½ë¡œ í‘œì‹œ
                col_path1, col_path2 = st.columns(2)
                with col_path1:
                    if next_pred_b is not None:
                        forced_marker = " âš¡" if next_forced_b else ""
                        st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_b}{forced_marker}</code> ({next_conf_b:.1f}%)</p>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
                
                with col_path2:
                    if next_pred_p is not None:
                        forced_marker = " âš¡" if next_forced_p else ""
                        st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_p}{forced_marker}</code> ({next_conf_p:.1f}%)</p>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
            else:
                # ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° prefixë§Œ í‘œì‹œ
                col_path1, col_path2 = st.columns(2)
                with col_path1:
                    st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code></p>', unsafe_allow_html=True)
                with col_path2:
                    st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code></p>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ì‹¤ì œê°’ ì…ë ¥: "ë‹¤ìŒ ìŠ¤í… (B)"ì™€ "ë‹¤ìŒ ìŠ¤í… (P)" ë²„íŠ¼
        st.markdown("**ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”:**")
        
        # ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•œ CSS (ë°°ê²½ìƒ‰ ì œê±° ë° ìƒ‰ìƒ êµ¬ë¶„)
        st.markdown("""
        <style>
        /* B ë²„íŠ¼ ìŠ¤íƒ€ì¼ (ë¹¨ê°„ìƒ‰) */
        button[kind="secondary"]:has-text("ğŸ”´") {
            background-color: transparent !important;
            color: #FF0000 !important;
            border: 2px solid #FF0000 !important;
            font-weight: bold !important;
        }
        button[kind="secondary"]:has-text("ğŸ”´"):hover {
            background-color: rgba(255, 0, 0, 0.1) !important;
        }
        /* P ë²„íŠ¼ ìŠ¤íƒ€ì¼ (íŒŒë€ìƒ‰) */
        button[kind="secondary"]:has-text("ğŸ”µ") {
            background-color: transparent !important;
            color: #0066FF !important;
            border: 2px solid #0066FF !important;
            font-weight: bold !important;
        }
        button[kind="secondary"]:has-text("ğŸ”µ"):hover {
            background-color: rgba(0, 102, 255, 0.1) !important;
        }
        </style>
        """, unsafe_allow_html=True)
        
        button_col1, button_col2, button_col3 = st.columns([1, 1, 2])
        
        with button_col1:
            if st.button("ğŸ”´ ë‹¤ìŒ ìŠ¤í… (B)", key=f"next_step_b_{current_step}", use_container_width=True):
                actual_value = 'b'
                
                # ê²½ë¡œ ê¸°ë¡
                if prediction_result.get('predicted') is not None:
                    ratios = prediction_result.get('ratios', {})
                    is_forced = prediction_result.get('is_forced', False)
                    path_entry = {
                        'step': current_step,
                        'prefix': current_prefix,
                        'predictions': ratios,
                        'predicted': prediction_result['predicted'],
                        'actual': actual_value,
                        'is_correct': prediction_result['predicted'] == actual_value,
                        'confidence': prediction_result.get('confidence', 0.0),
                        'has_prediction': True,
                        'is_forced': is_forced
                    }
                else:
                    path_entry = {
                        'step': current_step,
                        'prefix': current_prefix,
                        'predictions': {},
                        'predicted': None,
                        'actual': actual_value,
                        'is_correct': None,
                        'confidence': 0.0,
                        'has_prediction': False,
                        'is_forced': False
                    }
                
                st.session_state.interactive_path.append(path_entry)
                
                # ê°„ê²© ì—…ë°ì´íŠ¸: ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° ì „ì— ì´ì „ ìŠ¤í…ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í™•ì¸
                # ê°„ê²©ì€ "ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì´í›„ ì˜ˆì¸¡ ì—†ìŒì´ ì—°ì† ë°œìƒí•œ ìŠ¤í… ìˆ˜"
                # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆë‹¤ë©´ ê°„ê²©ì€ 0ìœ¼ë¡œ ë¦¬ì…‹
                if path_entry.get('has_prediction', False):
                    # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆìœ¼ë©´ ê°„ê²© ë¦¬ì…‹
                    st.session_state.interactive_current_interval = 0
                else:
                    # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ì—†ì—ˆìœ¼ë©´ ê°„ê²© ê³„ì‚°
                    # interactive_pathë¥¼ ì—­ìˆœìœ¼ë¡œ ìˆœíšŒí•˜ì—¬ ë§ˆì§€ë§‰ ì˜ˆì¸¡ì´ ìˆì—ˆë˜ ìŠ¤í…ì„ ì°¾ê³ , ê·¸ ì´í›„ì˜ ì˜ˆì¸¡ ì—†ìŒ ìŠ¤í… ìˆ˜ë¥¼ ê³„ì‚°
                    last_prediction_step = None
                    for i in range(len(st.session_state.interactive_path) - 1, -1, -1):
                        entry = st.session_state.interactive_path[i]
                        if entry.get('has_prediction', False):
                            last_prediction_step = entry['step']
                            break
                    
                    if last_prediction_step is not None:
                        # ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì´í›„ ì˜ˆì¸¡ ì—†ìŒ ìŠ¤í… ìˆ˜ ê³„ì‚°
                        no_prediction_count = 0
                        for i in range(len(st.session_state.interactive_path) - 1, -1, -1):
                            entry = st.session_state.interactive_path[i]
                            if entry['step'] > last_prediction_step and not entry.get('has_prediction', False):
                                no_prediction_count += 1
                            elif entry['step'] <= last_prediction_step:
                                break
                        st.session_state.interactive_current_interval = no_prediction_count
                    else:
                        # ì•„ì§ ì˜ˆì¸¡ì´ ì—†ì—ˆë˜ ê²½ìš°: ì˜ˆì¸¡ì´ ì—†ì—ˆë˜ ìŠ¤í… ìˆ˜ë¥¼ ì¹´ìš´íŠ¸
                        no_prediction_count = 0
                        for entry in st.session_state.interactive_path:
                            if not entry.get('has_prediction', False):
                                no_prediction_count += 1
                        st.session_state.interactive_current_interval = no_prediction_count
                
                # ë‹¤ìŒ prefix ìƒì„± ë° ìŠ¤í… ì¦ê°€
                next_prefix = get_next_prefix(current_prefix, actual_value, interactive_window_size)
                st.session_state.interactive_current_prefix = next_prefix
                st.session_state.interactive_step = current_step + 1
                
                # í˜„ì¬ ìŠ¤í…ì˜ ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ ì‚­ì œ
                if prediction_result_key in st.session_state:
                    del st.session_state[prediction_result_key]
                if prediction_interval_key in st.session_state:
                    del st.session_state[prediction_interval_key]
                
                st.rerun()
        
        with button_col2:
            if st.button("ğŸ”µ ë‹¤ìŒ ìŠ¤í… (P)", key=f"next_step_p_{current_step}", use_container_width=True):
                actual_value = 'p'
                
                # ê²½ë¡œ ê¸°ë¡
                if prediction_result.get('predicted') is not None:
                    ratios = prediction_result.get('ratios', {})
                    is_forced = prediction_result.get('is_forced', False)
                    path_entry = {
                        'step': current_step,
                        'prefix': current_prefix,
                        'predictions': ratios,
                        'predicted': prediction_result['predicted'],
                        'actual': actual_value,
                        'is_correct': prediction_result['predicted'] == actual_value,
                        'confidence': prediction_result.get('confidence', 0.0),
                        'has_prediction': True,
                        'is_forced': is_forced
                    }
                else:
                    path_entry = {
                        'step': current_step,
                        'prefix': current_prefix,
                        'predictions': {},
                        'predicted': None,
                        'actual': actual_value,
                        'is_correct': None,
                        'confidence': 0.0,
                        'has_prediction': False,
                        'is_forced': False
                    }
                
                st.session_state.interactive_path.append(path_entry)
                
                # ê°„ê²© ì—…ë°ì´íŠ¸: ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° ì „ì— ì´ì „ ìŠ¤í…ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í™•ì¸
                # ê°„ê²©ì€ "ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì´í›„ ì˜ˆì¸¡ ì—†ìŒì´ ì—°ì† ë°œìƒí•œ ìŠ¤í… ìˆ˜"
                # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆë‹¤ë©´ ê°„ê²©ì€ 0ìœ¼ë¡œ ë¦¬ì…‹
                if path_entry.get('has_prediction', False):
                    # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ìˆì—ˆìœ¼ë©´ ê°„ê²© ë¦¬ì…‹
                    st.session_state.interactive_current_interval = 0
                else:
                    # í˜„ì¬ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì´ ì—†ì—ˆìœ¼ë©´ ê°„ê²© ê³„ì‚°
                    # interactive_pathë¥¼ ì—­ìˆœìœ¼ë¡œ ìˆœíšŒí•˜ì—¬ ë§ˆì§€ë§‰ ì˜ˆì¸¡ì´ ìˆì—ˆë˜ ìŠ¤í…ì„ ì°¾ê³ , ê·¸ ì´í›„ì˜ ì˜ˆì¸¡ ì—†ìŒ ìŠ¤í… ìˆ˜ë¥¼ ê³„ì‚°
                    last_prediction_step = None
                    for i in range(len(st.session_state.interactive_path) - 1, -1, -1):
                        entry = st.session_state.interactive_path[i]
                        if entry.get('has_prediction', False):
                            last_prediction_step = entry['step']
                            break
                    
                    if last_prediction_step is not None:
                        # ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì´í›„ ì˜ˆì¸¡ ì—†ìŒ ìŠ¤í… ìˆ˜ ê³„ì‚°
                        no_prediction_count = 0
                        for i in range(len(st.session_state.interactive_path) - 1, -1, -1):
                            entry = st.session_state.interactive_path[i]
                            if entry['step'] > last_prediction_step and not entry.get('has_prediction', False):
                                no_prediction_count += 1
                            elif entry['step'] <= last_prediction_step:
                                break
                        st.session_state.interactive_current_interval = no_prediction_count
                    else:
                        # ì•„ì§ ì˜ˆì¸¡ì´ ì—†ì—ˆë˜ ê²½ìš°: ì˜ˆì¸¡ì´ ì—†ì—ˆë˜ ìŠ¤í… ìˆ˜ë¥¼ ì¹´ìš´íŠ¸
                        no_prediction_count = 0
                        for entry in st.session_state.interactive_path:
                            if not entry.get('has_prediction', False):
                                no_prediction_count += 1
                        st.session_state.interactive_current_interval = no_prediction_count
                
                # ë‹¤ìŒ prefix ìƒì„± ë° ìŠ¤í… ì¦ê°€
                next_prefix = get_next_prefix(current_prefix, actual_value, interactive_window_size)
                st.session_state.interactive_current_prefix = next_prefix
                st.session_state.interactive_step = current_step + 1
                
                # í˜„ì¬ ìŠ¤í…ì˜ ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ ì‚­ì œ
                if prediction_result_key in st.session_state:
                    del st.session_state[prediction_result_key]
                if prediction_interval_key in st.session_state:
                    del st.session_state[prediction_interval_key]
                
                st.rerun()
        
        with button_col3:
            # ì´ì „ ìŠ¤í…ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°
            st.markdown("<br>", unsafe_allow_html=True)
            if st.button("ì´ì „ ìŠ¤í…", key=f"prev_step_{current_step}", use_container_width=True, disabled=len(st.session_state.interactive_path) == 0):
                if len(st.session_state.interactive_path) > 0:
                    # ë§ˆì§€ë§‰ ê²½ë¡œ í•­ëª© ì œê±°
                    last_entry = st.session_state.interactive_path.pop()
                    
                    # ì´ì „ prefixë¡œ ë³µì›
                    st.session_state.interactive_current_prefix = last_entry['prefix']
                    
                    # ìŠ¤í… ë²ˆí˜¸ ê°ì†Œ
                    st.session_state.interactive_step = current_step - 1
                    
                    # ê°„ê²© ë³µì›: interactive_pathë¥¼ ì—­ìˆœìœ¼ë¡œ ìˆœíšŒí•˜ì—¬ ë§ˆì§€ë§‰ ì˜ˆì¸¡ì´ ìˆì—ˆë˜ ìŠ¤í…ì„ ì°¾ê³ , ê·¸ ì´í›„ì˜ ì˜ˆì¸¡ ì—†ìŒ ìŠ¤í… ìˆ˜ë¥¼ ê³„ì‚°
                    interval = 0
                    for entry in reversed(st.session_state.interactive_path):
                        if entry.get('has_prediction', False):
                            # ì˜ˆì¸¡ì´ ìˆì—ˆë˜ ìŠ¤í…ì„ ì°¾ìœ¼ë©´ ì¤‘ë‹¨
                            break
                        interval += 1
                    st.session_state.interactive_current_interval = interval
        
        # ê²½ë¡œ íˆìŠ¤í† ë¦¬ í‘œì‹œ (ì—­ìˆœ - ìµœì‹ ìˆœ)
        if st.session_state.interactive_path:
            st.markdown("---")
            st.markdown("### ê²½ë¡œ íˆìŠ¤í† ë¦¬")
            
            # ì—­ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœì´ ìœ„ì—)
            reversed_path = list(reversed(st.session_state.interactive_path))
            for idx, entry in enumerate(reversed_path, 1):
                if entry.get('has_prediction', True):
                    # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°
                    status = "âœ…" if entry.get('is_correct') else "âŒ"
                    is_forced = entry.get('is_forced', False)
                    forced_marker = " âš¡" if is_forced else ""
                    predicted_str = f"`{entry['predicted']}{forced_marker}`"
                    confidence_str = f"({entry.get('confidence', 0):.1f}%)"
                    if is_forced:
                        confidence_str += " (ê°•ì œ)"
                else:
                    # ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê²½ìš°
                    status = "âšª"
                    predicted_str = "`-` (ì˜ˆì¸¡ ì—†ìŒ)"
                    confidence_str = "(ì„ê³„ê°’ ë¯¸ë§Œ)"
                
                st.markdown(
                    f"**Step {entry['step']}**: `{entry['prefix']}` â†’ "
                    f"ì˜ˆì¸¡: {predicted_str} {confidence_str} / "
                    f"ì‹¤ì œ: `{entry['actual']}` {status}"
                )
        
        # í†µê³„ ìš”ì•½ (í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©)
        if st.session_state.interactive_path:
            st.markdown("---")
            st.markdown("### í˜„ì¬ê¹Œì§€ í†µê³„")
            
            total_steps = len(st.session_state.interactive_path)
            steps_with_prediction = sum(1 for e in st.session_state.interactive_path if e.get('has_prediction', True))
            correct_count = sum(1 for e in st.session_state.interactive_path if e.get('is_correct') == True)
            accuracy = (correct_count / steps_with_prediction * 100) if steps_with_prediction > 0 else 0
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì´ ìŠ¤í…", f"{total_steps}")
            with col2:
                st.metric("ì˜ˆì¸¡ ìˆ˜í–‰", f"{steps_with_prediction}")
            with col3:
                st.metric("ì •í™•ë„", f"{accuracy:.1f}%")
            with col4:
                if steps_with_prediction > 0:
                    avg_confidence = sum(e.get('confidence', 0) for e in st.session_state.interactive_path if e.get('has_prediction', True)) / steps_with_prediction
                    st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.1f}%")
                else:
                    st.metric("í‰ê·  ì‹ ë¢°ë„", "N/A")
            
            # ìƒì„¸ íˆìŠ¤í† ë¦¬ (ì—­ìˆœ - ìµœì‹ ìˆœ)
            st.markdown("---")
            st.markdown("### ìƒì„¸ íˆìŠ¤í† ë¦¬")
            
            history_data = []
            # ì—­ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœì´ ìœ„ì—)
            reversed_path = list(reversed(st.session_state.interactive_path))
            for entry in reversed_path:
                # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° êµ¬ë¶„
                if entry.get('has_prediction', True) and entry.get('predicted') is not None:
                    # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°
                    is_forced = entry.get('is_forced', False)
                    forced_marker = " âš¡" if is_forced else ""
                    predicted_value = f"{entry['predicted']}{forced_marker}"
                    predicted_prob = f"{entry['predictions'].get(entry['predicted'], 0):.1f}%"
                    if is_forced:
                        predicted_prob += " (ê°•ì œ)"
                    match_status = 'âœ…' if entry.get('is_correct') == True else 'âŒ'
                else:
                    # ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê²½ìš°
                    predicted_value = '-'
                    predicted_prob = 'N/A'
                    match_status = 'âšª (ì˜ˆì¸¡ ì—†ìŒ)'
                
                history_data.append({
                    'Step': entry['step'],
                    'Prefix': entry['prefix'],
                    'ì˜ˆì¸¡ê°’': predicted_value,
                    'ì˜ˆì¸¡í™•ë¥ ': predicted_prob,
                    'ì‹¤ì œê°’': entry['actual'],
                    'ì¼ì¹˜': match_status
                })
            
            history_df = pd.DataFrame(history_data)
            st.dataframe(history_df, use_container_width=True, hide_index=True)
            
            if st.button("ìƒˆë¡œ ì‹œì‘", type="primary"):
                st.session_state.interactive_path = []
                st.session_state.interactive_current_prefix = None
                st.session_state.interactive_step = 0
                st.session_state.interactive_current_interval = 0
    
    st.markdown("---")
    
    # ìƒˆë¡œìš´ ì•™ìƒë¸” íˆ¬í‘œ ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤ ì„¹ì…˜ (ì™„ì „ ë…ë¦½)
    st.header("ğŸ¯ ì•™ìƒë¸” íˆ¬í‘œ ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤")
    
    # ì„¤ì • ì„¹ì…˜ (st.formìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ rerun ìµœì†Œí™”)
    with st.form("ensemble_interactive_settings_form", clear_on_submit=False):
        st.markdown("### âš™ï¸ ì„¤ì •")
        col_setting1, col_setting2, col_setting3 = st.columns(3)
        
        with col_setting1:
            ensemble_interactive_window_size = st.selectbox(
                "ìœˆë„ìš° í¬ê¸°",
                options=[5, 6, 7, 8, 9],
                index=2,  # 7ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
                key="ensemble_interactive_window_size",
                help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ìœˆë„ìš° í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col_setting2:
            ensemble_interactive_use_threshold = st.checkbox(
                "ì„ê³„ê°’ ì „ëµ ì‚¬ìš©",
                value=True,
                key="ensemble_interactive_use_threshold",
                help="ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•˜ë„ë¡ ì„¤ì •"
            )
            ensemble_interactive_threshold = None
            if ensemble_interactive_use_threshold:
                ensemble_interactive_threshold = st.number_input(
                    "ì„ê³„ê°’ (%)",
                    min_value=0,
                    max_value=100,
                    value=60,
                    step=1,
                    key="ensemble_interactive_threshold",
                    help="ì´ ì‹ ë¢°ë„ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤"
                )
        
        with col_setting3:
            ensemble_interactive_max_interval = st.number_input(
                "ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© (ìŠ¤í…)",
                min_value=1,
                max_value=20,
                value=6,
                step=1,
                key="ensemble_interactive_max_interval",
                help="ì´ ê°„ê²©ì„ ë„˜ê¸°ë©´ ì„ê³„ê°’ ë¬´ì‹œí•˜ê³  ê°•ì œ ì˜ˆì¸¡í•©ë‹ˆë‹¤"
            )
        
        # ì„¤ì • ì ìš© ë²„íŠ¼
        if st.form_submit_button("ì„¤ì • ì ìš©", use_container_width=True):
            # ì„¤ì • ë³€ê²½ ê°ì§€ ë° ì´ˆê¸°í™”
            if 'last_ensemble_interactive_window_size' not in st.session_state:
                st.session_state.last_ensemble_interactive_window_size = ensemble_interactive_window_size
                st.session_state.last_ensemble_interactive_threshold = ensemble_interactive_threshold
                st.session_state.last_ensemble_interactive_max_interval = ensemble_interactive_max_interval
            elif (st.session_state.last_ensemble_interactive_window_size != ensemble_interactive_window_size or
                  st.session_state.last_ensemble_interactive_threshold != ensemble_interactive_threshold or
                  st.session_state.last_ensemble_interactive_max_interval != ensemble_interactive_max_interval):
                # ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆìœ¼ë©´ ì´ˆê¸°í™” ë° ìºì‹œ ë¬´íš¨í™”
                st.session_state.ensemble_interactive_path = []
                st.session_state.ensemble_interactive_current_prefix = None
                st.session_state.ensemble_interactive_step = 0
                st.session_state.ensemble_interactive_current_interval = 0
                
                # ëª¨ë¸ ìºì‹œ ë¬´íš¨í™”
                if 'last_ensemble_interactive_window_size' in st.session_state:
                    old_window_size = st.session_state.last_ensemble_interactive_window_size
                    for model_type in ['frequency', 'weighted', 'trend']:
                        old_model_key = f'ensemble_model_{model_type}_{old_window_size}'
                        if old_model_key in st.session_state:
                            del st.session_state[old_model_key]
                
                st.session_state.last_ensemble_interactive_window_size = ensemble_interactive_window_size
                st.session_state.last_ensemble_interactive_threshold = ensemble_interactive_threshold
                st.session_state.last_ensemble_interactive_max_interval = ensemble_interactive_max_interval
                st.rerun()
    
    # Session state ì´ˆê¸°í™”
    if 'ensemble_interactive_path' not in st.session_state:
        st.session_state.ensemble_interactive_path = []
        st.session_state.ensemble_interactive_current_prefix = None
        st.session_state.ensemble_interactive_step = 0
        st.session_state.ensemble_interactive_current_interval = 0
        st.session_state.last_ensemble_interactive_window_size = ensemble_interactive_window_size
        st.session_state.last_ensemble_interactive_threshold = ensemble_interactive_threshold
        st.session_state.last_ensemble_interactive_max_interval = ensemble_interactive_max_interval
    
    st.markdown("---")
    
    # ì´ˆê¸° prefix ì…ë ¥ (st.formìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ rerun ìµœì†Œí™”)
    with st.form("start_ensemble_interactive_form", clear_on_submit=False):
        col1, col2 = st.columns([2, 1])
        
        with col1:
            ensemble_initial_prefix = st.text_input(
                "ì´ˆê¸° Prefix ì…ë ¥",
                value="bbbbb",
                key="ensemble_initial_prefix",
                help=f"ë‹¤ë‹¨ê³„ ì˜ˆì¸¡ì„ ì‹œì‘í•  ì´ˆê¸° prefixë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸¸ì´: {ensemble_interactive_window_size - 1})"
            )
        
        with col2:
            st.markdown("<br>", unsafe_allow_html=True)
            if st.form_submit_button("ì‹œì‘", type="primary", use_container_width=True):
                # prefix ê¸¸ì´ ê²€ì¦
                prefix_length = len(ensemble_initial_prefix)
                expected_prefix_length = ensemble_interactive_window_size - 1
                
                if prefix_length != expected_prefix_length:
                    st.warning(f"âš ï¸ Prefix ê¸¸ì´ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ìœˆë„ìš° í¬ê¸° {ensemble_interactive_window_size}ì— ë§ê²Œ {expected_prefix_length}ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    st.session_state.ensemble_interactive_path = []
                    st.session_state.ensemble_interactive_current_prefix = ensemble_initial_prefix
                    st.session_state.ensemble_interactive_step = 1
                    st.session_state.ensemble_interactive_current_interval = 0
                    st.rerun()
    
    if st.button("ì´ˆê¸°í™”", use_container_width=True, key="reset_ensemble_interactive"):
        st.session_state.ensemble_interactive_path = []
        st.session_state.ensemble_interactive_current_prefix = None
        st.session_state.ensemble_interactive_step = 0
        st.session_state.ensemble_interactive_current_interval = 0
        st.rerun()
    
    # ì¸í„°ë™í‹°ë¸Œ ë‹¨ê³„ë³„ ì§„í–‰
    if st.session_state.ensemble_interactive_current_prefix and st.session_state.ensemble_interactive_step > 0:
        current_prefix = st.session_state.ensemble_interactive_current_prefix
        current_step = st.session_state.ensemble_interactive_step
        
        st.markdown("---")
        st.markdown(f"### Step {current_step}: `{current_prefix}`")
        
        # í˜„ì¬ ìŠ¤í…ì˜ ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ í‚¤
        prediction_result_key = f'ensemble_interactive_prediction_step_{current_step}'
        prediction_interval_key = f'ensemble_interactive_interval_before_step_{current_step}'
        
        # ìºì‹œëœ ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê³„ì‚°
        if prediction_result_key in st.session_state and st.session_state[prediction_result_key] is not None:
            prediction_result = st.session_state[prediction_result_key]
            df_strings = None
            train_ngrams = None
            frequency_model = None
            weighted_model = None
            trend_model = None
        else:
            # ëª¨ë¸ ë° ë°ì´í„° ìºì‹±
            model_frequency_key = f'ensemble_model_frequency_{ensemble_interactive_window_size}'
            model_weighted_key = f'ensemble_model_weighted_{ensemble_interactive_window_size}'
            model_trend_key = f'ensemble_model_trend_{ensemble_interactive_window_size}'
            data_cache_key = f'ensemble_interactive_data_{ensemble_interactive_window_size}'
            ngrams_cache_key = f'ensemble_interactive_ngrams_{ensemble_interactive_window_size}'
            
            # ì„¤ì • ë³€ê²½ ê°ì§€
            settings_changed = (
                'last_ensemble_interactive_window_size' not in st.session_state or
                st.session_state.last_ensemble_interactive_window_size != ensemble_interactive_window_size
            )
            
            # ìºì‹œ í™•ì¸ ë° ëª¨ë¸ êµ¬ì¶•
            if not settings_changed and (model_frequency_key in st.session_state and 
                                        model_weighted_key in st.session_state and 
                                        model_trend_key in st.session_state):
                # ìºì‹œëœ ëª¨ë¸ ë° ë°ì´í„° ì¬ì‚¬ìš©
                frequency_model = st.session_state[model_frequency_key]
                weighted_model = st.session_state[model_weighted_key]
                trend_model = st.session_state[model_trend_key]
                df_strings = st.session_state.get(data_cache_key)
                train_ngrams = st.session_state.get(ngrams_cache_key)
            else:
                # ëª¨ë¸ êµ¬ì¶• ë° ìºì‹±
                df_strings = None
                train_ngrams = None
                frequency_model = None
                weighted_model = None
                trend_model = None
                
                with st.spinner("ëª¨ë¸ êµ¬ì¶• ì¤‘..."):
                    # í•™ìŠµ ë°ì´í„° ë¡œë“œ
                    df_strings = load_preprocessed_data()
                    if len(df_strings) == 0:
                        st.warning("âš ï¸ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        prediction_result = {
                            'predicted': None, 
                            'ratios': {}, 
                            'confidence': 0.0, 
                            'is_forced': False,
                            'individual_predictions': {},
                            'votes': {'b': 0, 'p': 0}
                        }
                    else:
                        # í•™ìŠµ ì„¸íŠ¸ ë¶„í• 
                        train_ratio = 80
                        split_idx = int(len(df_strings) * train_ratio / 100)
                        train_ids = df_strings.iloc[:split_idx]['id'].tolist()
                        
                        # N-gram ë¡œë“œ
                        train_ngrams = load_ngram_chunks(window_size=ensemble_interactive_window_size, grid_string_ids=train_ids)
                        
                        if len(train_ngrams) == 0:
                            st.warning(f"âš ï¸ ìœˆë„ìš° í¬ê¸° {ensemble_interactive_window_size}ì— ëŒ€í•œ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            prediction_result = {
                                'predicted': None, 
                                'ratios': {}, 
                                'confidence': 0.0, 
                                'is_forced': False,
                                'individual_predictions': {},
                                'votes': {'b': 0, 'p': 0}
                            }
                        else:
                            # ëª¨ë¸ êµ¬ì¶•
                            frequency_model = build_frequency_model(train_ngrams)
                            weighted_model = build_weighted_model(train_ngrams)
                            trend_model = build_balance_recovery_trend_model_final(train_ngrams, ensemble_interactive_window_size)
                            
                            # ëª¨ë¸ ë° ë°ì´í„° ìºì‹±
                            st.session_state[model_frequency_key] = frequency_model
                            st.session_state[model_weighted_key] = weighted_model
                            st.session_state[model_trend_key] = trend_model
                            st.session_state[data_cache_key] = df_strings
                            st.session_state[ngrams_cache_key] = train_ngrams
            
            # ì˜ˆì¸¡ ê³„ì‚° (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
            if frequency_model is not None and weighted_model is not None and trend_model is not None:
                # models_dict êµ¬ì„±
                models_dict = {
                    'ë¹ˆë„ ê¸°ë°˜': frequency_model,
                    'ê°€ì¤‘ì¹˜ ê¸°ë°˜': weighted_model,
                    'ê· í˜• íšŒë³µ íŠ¸ë Œë“œ': trend_model
                }
                
                # ì˜ˆì¸¡ ê³„ì‚°
                if ensemble_interactive_use_threshold and ensemble_interactive_threshold is not None:
                    # ê°•ì œ ì˜ˆì¸¡ ì „ëµ ì‚¬ìš©
                    current_interval_for_prediction = st.session_state.ensemble_interactive_current_interval
                    
                    # ë””ë²„ê¹…: ì˜ˆì¸¡ ì „ ê°„ê²© ìƒíƒœ ì €ì¥
                    st.session_state[prediction_interval_key] = current_interval_for_prediction
                    
                    # ì•™ìƒë¸” íˆ¬í‘œ ì˜ˆì¸¡
                    ensemble_result = predict_ensemble_new_voting(models_dict, current_prefix)
                    
                    # ì„ê³„ê°’ ì²´í¬ ë° ê°•ì œ ì˜ˆì¸¡ ì²˜ë¦¬
                    if ensemble_result['confidence'] < ensemble_interactive_threshold:
                        # ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ë¯¸ë§Œ
                        if current_interval_for_prediction >= ensemble_interactive_max_interval:
                            # ê°•ì œ ì˜ˆì¸¡
                            prediction_result = {
                                **ensemble_result,
                                'is_forced': True
                            }
                        else:
                            # ì˜ˆì¸¡ ì—†ìŒ
                            prediction_result = {
                                'predicted': None,
                                'ratios': {},
                                'confidence': 0.0,
                                'is_forced': False,
                                'individual_predictions': ensemble_result.get('individual_predictions', {}),
                                'votes': ensemble_result.get('votes', {'b': 0, 'p': 0})
                            }
                    else:
                        # ì •ìƒ ì˜ˆì¸¡
                        prediction_result = {
                            **ensemble_result,
                            'is_forced': False
                        }
                else:
                    # ì„ê³„ê°’ ì „ëµ ë¯¸ì‚¬ìš©
                    prediction_result = predict_ensemble_new_voting(models_dict, current_prefix)
                    prediction_result['is_forced'] = False
            else:
                prediction_result = {
                    'predicted': None, 
                    'ratios': {}, 
                    'confidence': 0.0, 
                    'is_forced': False,
                    'individual_predictions': {},
                    'votes': {'b': 0, 'p': 0}
                }
            
            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
            st.session_state[prediction_result_key] = prediction_result
        
        # ë””ë²„ê¹…: ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
        if ensemble_interactive_use_threshold and ensemble_interactive_threshold is not None:
            st.info(f"ğŸ” **ë””ë²„ê¹…**: ìŠ¤í…={current_step}, prefix='{current_prefix}', ì˜ˆì¸¡ ì „ ê°„ê²©={st.session_state.ensemble_interactive_current_interval}, ì˜ˆì¸¡ê°’={prediction_result.get('predicted')}, ê°•ì œì˜ˆì¸¡={prediction_result.get('is_forced', False)}, ì‹ ë¢°ë„={prediction_result.get('confidence', 0):.2f}%")
        
        # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°
        if prediction_result.get('predicted') is not None:
            ratios = prediction_result.get('ratios', {})
            sorted_ratios = sorted(ratios.items(), key=lambda x: x[1], reverse=True) if ratios else []
            individual_predictions = prediction_result.get('individual_predictions', {})
            votes = prediction_result.get('votes', {'b': 0, 'p': 0})
            
            # ì˜ˆì¸¡ê°’ í‘œì‹œ
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.markdown("**ì•™ìƒë¸” ì˜ˆì¸¡ í™•ë¥ :**")
                if sorted_ratios:
                    for value, ratio in sorted_ratios:
                        color = "ğŸŸ¢" if ratio == max(ratios.values()) else "ğŸŸ¡"
                        st.markdown(f"{color} **'{value}'**: {ratio:.2f}%")
                        st.progress(ratio / 100)
                else:
                    st.info("ì˜ˆì¸¡ í™•ë¥  ì •ë³´ ì—†ìŒ")
                
                # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ í‘œì‹œ
                st.markdown("**ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡:**")
                for method_name, pred_info in individual_predictions.items():
                    pred_value = pred_info.get('predicted', '-')
                    pred_conf = pred_info.get('confidence', 0)
                    st.markdown(f"- **{method_name}**: `{pred_value}` ({pred_conf:.1f}%)")
                
                # íˆ¬í‘œ ê²°ê³¼
                st.markdown("**íˆ¬í‘œ ê²°ê³¼:**")
                st.markdown(f"- **b**: {votes.get('b', 0)}í‘œ")
                st.markdown(f"- **p**: {votes.get('p', 0)}í‘œ")
            
            with col2:
                st.markdown("**ì•™ìƒë¸” ìµœì¢… ì˜ˆì¸¡ê°’:**")
                is_forced = prediction_result.get('is_forced', False)
                prediction_display = prediction_result['predicted']
                if is_forced:
                    prediction_display = f"{prediction_display} âš¡"  # ê°•ì œ ì˜ˆì¸¡ í‘œì‹œ
                st.markdown(f"### `{prediction_display}`")
                confidence_display = f"{prediction_result.get('confidence', 0):.2f}%"
                if is_forced:
                    confidence_display += " (ê°•ì œ)"
                st.metric("ì‹ ë¢°ë„", confidence_display)
                
                # ë””ë²„ê¹…: ê°„ê²© ì •ë³´ í‘œì‹œ
                if ensemble_interactive_use_threshold and ensemble_interactive_threshold is not None:
                    if prediction_interval_key in st.session_state:
                        interval_before = st.session_state[prediction_interval_key]
                        st.info(f"ğŸ” **ë””ë²„ê¹… ì •ë³´**: ì˜ˆì¸¡ ì „ ê°„ê²©={interval_before}, í˜„ì¬ ê°„ê²©={st.session_state.ensemble_interactive_current_interval}/{ensemble_interactive_max_interval}")
                    else:
                        st.info(f"ğŸ” **ë””ë²„ê¹… ì •ë³´**: í˜„ì¬ ê°„ê²©={st.session_state.ensemble_interactive_current_interval}/{ensemble_interactive_max_interval}")
            
            # ë‹¤ìŒ 1ê°œ ìŠ¤í… ì‹¤ì œê°’ ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°
            st.markdown("---")
            st.markdown('<p style="font-size: 1em; color: #666; margin-top: -10px;"><strong>ë‹¤ìŒ ìŠ¤í… ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°:</strong></p>', unsafe_allow_html=True)
            
            # ë‹¤ìŒ prefix ìƒì„± (bì™€ p ë‘ ê²½ìš° ëª¨ë‘)
            next_prefix_b = get_next_prefix(current_prefix, 'b', ensemble_interactive_window_size)
            next_prefix_p = get_next_prefix(current_prefix, 'p', ensemble_interactive_window_size)
            
            # ë¯¸ë¦¬ë³´ê¸° ê³„ì‚°ì„ ìœ„í•´ ëª¨ë¸ì´ í•„ìš”í•˜ë©´ ìºì‹œì—ì„œ ë¡œë“œ
            if frequency_model is None or weighted_model is None or trend_model is None:
                model_frequency_key = f'ensemble_model_frequency_{ensemble_interactive_window_size}'
                model_weighted_key = f'ensemble_model_weighted_{ensemble_interactive_window_size}'
                model_trend_key = f'ensemble_model_trend_{ensemble_interactive_window_size}'
                if model_frequency_key in st.session_state:
                    frequency_model = st.session_state[model_frequency_key]
                if model_weighted_key in st.session_state:
                    weighted_model = st.session_state[model_weighted_key]
                if model_trend_key in st.session_state:
                    trend_model = st.session_state[model_trend_key]
            
            # ë‹¤ìŒ prefixì— ëŒ€í•œ ì˜ˆì¸¡ (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
            if frequency_model is not None and weighted_model is not None and trend_model is not None:
                next_pred_b = None
                next_pred_p = None
                next_conf_b = 0.0
                next_conf_p = 0.0
                next_forced_b = False
                next_forced_p = False
                
                try:
                    models_dict = {
                        'ë¹ˆë„ ê¸°ë°˜': frequency_model,
                        'ê°€ì¤‘ì¹˜ ê¸°ë°˜': weighted_model,
                        'ê· í˜• íšŒë³µ íŠ¸ë Œë“œ': trend_model
                    }
                    
                    if ensemble_interactive_use_threshold and ensemble_interactive_threshold is not None:
                        # ë‹¤ìŒ ìŠ¤í… ì˜ˆì¸¡ìš© ê°„ê²© ê³„ì‚°
                        if prediction_result.get('predicted') is not None:
                            next_interval = 0
                        else:
                            next_interval = st.session_state.ensemble_interactive_current_interval + 1
                        
                        # ê°„ê²©ì„ ê³ ë ¤í•˜ì—¬ ì˜ˆì¸¡
                        next_result_b = predict_ensemble_new_voting(models_dict, next_prefix_b)
                        next_result_p = predict_ensemble_new_voting(models_dict, next_prefix_p)
                        
                        # ì„ê³„ê°’ ì²´í¬
                        if next_result_b['confidence'] < ensemble_interactive_threshold:
                            if next_interval >= ensemble_interactive_max_interval:
                                next_forced_b = True
                            else:
                                next_result_b = {'predicted': None, 'confidence': 0.0}
                        
                        if next_result_p['confidence'] < ensemble_interactive_threshold:
                            if next_interval >= ensemble_interactive_max_interval:
                                next_forced_p = True
                            else:
                                next_result_p = {'predicted': None, 'confidence': 0.0}
                        
                        next_forced_b = next_result_b.get('predicted') is not None and next_forced_b
                        next_forced_p = next_result_p.get('predicted') is not None and next_forced_p
                    else:
                        next_result_b = predict_ensemble_new_voting(models_dict, next_prefix_b)
                        next_result_p = predict_ensemble_new_voting(models_dict, next_prefix_p)
                        next_forced_b = False
                        next_forced_p = False
                    
                    next_pred_b = next_result_b.get('predicted')
                    next_pred_p = next_result_p.get('predicted')
                    next_conf_b = next_result_b.get('confidence', 0.0)
                    next_conf_p = next_result_p.get('confidence', 0.0)
                except Exception as e:
                    pass
                
                # ê²½ë¡œ í‘œì‹œ
                col_path1, col_path2 = st.columns(2)
                with col_path1:
                    if next_pred_b is not None and str(next_pred_b).strip() != '':
                        forced_marker = " âš¡" if next_forced_b else ""
                        st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_b}{forced_marker}</code> ({next_conf_b:.1f}%)</p>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
                
                with col_path2:
                    if next_pred_p is not None and str(next_pred_p).strip() != '':
                        forced_marker = " âš¡" if next_forced_p else ""
                        st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_p}{forced_marker}</code> ({next_conf_p:.1f}%)</p>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
            else:
                # ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° prefixë§Œ í‘œì‹œ
                col_path1, col_path2 = st.columns(2)
                with col_path1:
                    st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code></p>', unsafe_allow_html=True)
                with col_path2:
                    st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code></p>', unsafe_allow_html=True)
        else:
            # ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê²½ìš° (ì„ê³„ê°’ ë¯¸ë§Œ ë“±)
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.markdown("**ì˜ˆì¸¡ í™•ë¥ :**")
                st.info("âš ï¸ ì˜ˆì¸¡ ë°ì´í„° ì—†ìŒ")
                if ensemble_interactive_use_threshold and ensemble_interactive_threshold is not None:
                    if prediction_interval_key in st.session_state:
                        interval_before = st.session_state[prediction_interval_key]
                    else:
                        interval_before = st.session_state.ensemble_interactive_current_interval
                    st.info(f"ğŸ” **ë””ë²„ê¹… ì •ë³´**: ì˜ˆì¸¡ ì „ ê°„ê²©={interval_before}, í˜„ì¬ ê°„ê²©={st.session_state.ensemble_interactive_current_interval}/{ensemble_interactive_max_interval}")
                    st.caption(f"ì„ê³„ê°’({ensemble_interactive_threshold}%) ë¯¸ë§Œì´ê±°ë‚˜ í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                else:
                    st.caption("í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            
            with col2:
                st.markdown("**ì˜ˆì¸¡ê°’:**")
                st.markdown("### `-`")
                st.metric("ì‹ ë¢°ë„", "N/A")
            
            # ë‹¤ìŒ 1ê°œ ìŠ¤í… ì‹¤ì œê°’ ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°
            st.markdown("---")
            st.markdown('<p style="font-size: 1em; color: #666; margin-top: -10px;"><strong>ë‹¤ìŒ ìŠ¤í… ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°:</strong></p>', unsafe_allow_html=True)
            
            # ë‹¤ìŒ prefix ìƒì„± (bì™€ p ë‘ ê²½ìš° ëª¨ë‘)
            next_prefix_b = get_next_prefix(current_prefix, 'b', ensemble_interactive_window_size)
            next_prefix_p = get_next_prefix(current_prefix, 'p', ensemble_interactive_window_size)
            
            # ë¯¸ë¦¬ë³´ê¸° ê³„ì‚°ì„ ìœ„í•´ ëª¨ë¸ì´ í•„ìš”í•˜ë©´ ìºì‹œì—ì„œ ë¡œë“œ
            if frequency_model is None or weighted_model is None or trend_model is None:
                model_frequency_key = f'ensemble_model_frequency_{ensemble_interactive_window_size}'
                model_weighted_key = f'ensemble_model_weighted_{ensemble_interactive_window_size}'
                model_trend_key = f'ensemble_model_trend_{ensemble_interactive_window_size}'
                if model_frequency_key in st.session_state:
                    frequency_model = st.session_state[model_frequency_key]
                if model_weighted_key in st.session_state:
                    weighted_model = st.session_state[model_weighted_key]
                if model_trend_key in st.session_state:
                    trend_model = st.session_state[model_trend_key]
            
            # ë‹¤ìŒ prefixì— ëŒ€í•œ ì˜ˆì¸¡ (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
            if frequency_model is not None and weighted_model is not None and trend_model is not None:
                next_pred_b = None
                next_pred_p = None
                next_conf_b = 0.0
                next_conf_p = 0.0
                next_forced_b = False
                next_forced_p = False
                
                try:
                    models_dict = {
                        'ë¹ˆë„ ê¸°ë°˜': frequency_model,
                        'ê°€ì¤‘ì¹˜ ê¸°ë°˜': weighted_model,
                        'ê· í˜• íšŒë³µ íŠ¸ë Œë“œ': trend_model
                    }
                    
                    if ensemble_interactive_use_threshold and ensemble_interactive_threshold is not None:
                        # ë‹¤ìŒ ìŠ¤í… ì˜ˆì¸¡ìš© ê°„ê²© ê³„ì‚°
                        if prediction_result.get('predicted') is None:
                            next_interval = st.session_state.ensemble_interactive_current_interval + 1
                        else:
                            next_interval = 0
                        
                        next_result_b = predict_ensemble_new_voting(models_dict, next_prefix_b)
                        next_result_p = predict_ensemble_new_voting(models_dict, next_prefix_p)
                        
                        # ì„ê³„ê°’ ì²´í¬
                        if next_result_b['confidence'] < ensemble_interactive_threshold:
                            if next_interval >= ensemble_interactive_max_interval:
                                next_forced_b = True
                            else:
                                next_result_b = {'predicted': None, 'confidence': 0.0}
                        
                        if next_result_p['confidence'] < ensemble_interactive_threshold:
                            if next_interval >= ensemble_interactive_max_interval:
                                next_forced_p = True
                            else:
                                next_result_p = {'predicted': None, 'confidence': 0.0}
                        
                        next_forced_b = next_result_b.get('predicted') is not None and next_forced_b
                        next_forced_p = next_result_p.get('predicted') is not None and next_forced_p
                    else:
                        next_result_b = predict_ensemble_new_voting(models_dict, next_prefix_b)
                        next_result_p = predict_ensemble_new_voting(models_dict, next_prefix_p)
                        next_forced_b = False
                        next_forced_p = False
                    
                    next_pred_b = next_result_b.get('predicted')
                    next_pred_p = next_result_p.get('predicted')
                    next_conf_b = next_result_b.get('confidence', 0.0)
                    next_conf_p = next_result_p.get('confidence', 0.0)
                    next_forced_b = next_result_b.get('is_forced', False) or next_forced_b
                    next_forced_p = next_result_p.get('is_forced', False) or next_forced_p
                except:
                    pass
                
                # ê²½ë¡œ í‘œì‹œ
                col_path1, col_path2 = st.columns(2)
                with col_path1:
                    if next_pred_b is not None:
                        forced_marker = " âš¡" if next_forced_b else ""
                        st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_b}{forced_marker}</code> ({next_conf_b:.1f}%)</p>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
                
                with col_path2:
                    if next_pred_p is not None:
                        forced_marker = " âš¡" if next_forced_p else ""
                        st.markdown(f'<p style="font-size: 0.95em; color: #333;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>{next_pred_p}{forced_marker}</code> ({next_conf_p:.1f}%)</p>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code> â†’ ì˜ˆì¸¡: <code>-</code></p>', unsafe_allow_html=True)
            else:
                # ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° prefixë§Œ í‘œì‹œ
                col_path1, col_path2 = st.columns(2)
                with col_path1:
                    st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>b</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_b}</code></p>', unsafe_allow_html=True)
                with col_path2:
                    st.markdown(f'<p style="font-size: 0.95em; color: #666;">ì‹¤ì œê°’ <strong>p</strong> â†’ ë‹¤ìŒ prefix: <code>{next_prefix_p}</code></p>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ì‹¤ì œê°’ ì…ë ¥: "ë‹¤ìŒ ìŠ¤í… (B)"ì™€ "ë‹¤ìŒ ìŠ¤í… (P)" ë²„íŠ¼
        st.markdown("**ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰í•˜ì„¸ìš”:**")
        
        # ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•œ CSS
        st.markdown("""
        <style>
        button[kind="secondary"]:has-text("ğŸ”´") {
            background-color: transparent !important;
            color: #FF0000 !important;
            border: 2px solid #FF0000 !important;
            font-weight: bold !important;
        }
        button[kind="secondary"]:has-text("ğŸ”´"):hover {
            background-color: rgba(255, 0, 0, 0.1) !important;
        }
        button[kind="secondary"]:has-text("ğŸ”µ") {
            background-color: transparent !important;
            color: #0066FF !important;
            border: 2px solid #0066FF !important;
            font-weight: bold !important;
        }
        button[kind="secondary"]:has-text("ğŸ”µ"):hover {
            background-color: rgba(0, 102, 255, 0.1) !important;
        }
        </style>
        """, unsafe_allow_html=True)
        
        button_col1, button_col2, button_col3 = st.columns([1, 1, 2])
        
        with button_col1:
            if st.button("ğŸ”´ ë‹¤ìŒ ìŠ¤í… (B)", key=f"ensemble_next_step_b_{current_step}", use_container_width=True):
                actual_value = 'b'
                
                # ê²½ë¡œ ê¸°ë¡
                if prediction_result.get('predicted') is not None:
                    ratios = prediction_result.get('ratios', {})
                    is_forced = prediction_result.get('is_forced', False)
                    individual_predictions = prediction_result.get('individual_predictions', {})
                    votes = prediction_result.get('votes', {'b': 0, 'p': 0})
                    path_entry = {
                        'step': current_step,
                        'prefix': current_prefix,
                        'predictions': ratios,
                        'predicted': prediction_result['predicted'],
                        'actual': actual_value,
                        'is_correct': prediction_result['predicted'] == actual_value,
                        'confidence': prediction_result.get('confidence', 0.0),
                        'has_prediction': True,
                        'is_forced': is_forced,
                        'individual_predictions': individual_predictions,
                        'votes': votes
                    }
                else:
                    path_entry = {
                        'step': current_step,
                        'prefix': current_prefix,
                        'predictions': {},
                        'predicted': None,
                        'actual': actual_value,
                        'is_correct': None,
                        'confidence': 0.0,
                        'has_prediction': False,
                        'is_forced': False,
                        'individual_predictions': {},
                        'votes': {'b': 0, 'p': 0}
                    }
                
                st.session_state.ensemble_interactive_path.append(path_entry)
                
                # ê°„ê²© ì—…ë°ì´íŠ¸
                if path_entry.get('has_prediction', False):
                    st.session_state.ensemble_interactive_current_interval = 0
                else:
                    last_prediction_step = None
                    for i in range(len(st.session_state.ensemble_interactive_path) - 1, -1, -1):
                        entry = st.session_state.ensemble_interactive_path[i]
                        if entry.get('has_prediction', False):
                            last_prediction_step = entry['step']
                            break
                    
                    if last_prediction_step is not None:
                        no_prediction_count = 0
                        for i in range(len(st.session_state.ensemble_interactive_path) - 1, -1, -1):
                            entry = st.session_state.ensemble_interactive_path[i]
                            if entry['step'] > last_prediction_step and not entry.get('has_prediction', False):
                                no_prediction_count += 1
                            elif entry['step'] <= last_prediction_step:
                                break
                        st.session_state.ensemble_interactive_current_interval = no_prediction_count
                    else:
                        no_prediction_count = 0
                        for entry in st.session_state.ensemble_interactive_path:
                            if not entry.get('has_prediction', False):
                                no_prediction_count += 1
                        st.session_state.ensemble_interactive_current_interval = no_prediction_count
                
                # ë‹¤ìŒ prefix ìƒì„± ë° ìŠ¤í… ì¦ê°€
                next_prefix = get_next_prefix(current_prefix, actual_value, ensemble_interactive_window_size)
                st.session_state.ensemble_interactive_current_prefix = next_prefix
                st.session_state.ensemble_interactive_step = current_step + 1
                
                # í˜„ì¬ ìŠ¤í…ì˜ ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ ì‚­ì œ
                if prediction_result_key in st.session_state:
                    del st.session_state[prediction_result_key]
                if prediction_interval_key in st.session_state:
                    del st.session_state[prediction_interval_key]
                
                st.rerun()
        
        with button_col2:
            if st.button("ğŸ”µ ë‹¤ìŒ ìŠ¤í… (P)", key=f"ensemble_next_step_p_{current_step}", use_container_width=True):
                actual_value = 'p'
                
                # ê²½ë¡œ ê¸°ë¡
                if prediction_result.get('predicted') is not None:
                    ratios = prediction_result.get('ratios', {})
                    is_forced = prediction_result.get('is_forced', False)
                    individual_predictions = prediction_result.get('individual_predictions', {})
                    votes = prediction_result.get('votes', {'b': 0, 'p': 0})
                    path_entry = {
                        'step': current_step,
                        'prefix': current_prefix,
                        'predictions': ratios,
                        'predicted': prediction_result['predicted'],
                        'actual': actual_value,
                        'is_correct': prediction_result['predicted'] == actual_value,
                        'confidence': prediction_result.get('confidence', 0.0),
                        'has_prediction': True,
                        'is_forced': is_forced,
                        'individual_predictions': individual_predictions,
                        'votes': votes
                    }
                else:
                    path_entry = {
                        'step': current_step,
                        'prefix': current_prefix,
                        'predictions': {},
                        'predicted': None,
                        'actual': actual_value,
                        'is_correct': None,
                        'confidence': 0.0,
                        'has_prediction': False,
                        'is_forced': False,
                        'individual_predictions': {},
                        'votes': {'b': 0, 'p': 0}
                    }
                
                st.session_state.ensemble_interactive_path.append(path_entry)
                
                # ê°„ê²© ì—…ë°ì´íŠ¸
                if path_entry.get('has_prediction', False):
                    st.session_state.ensemble_interactive_current_interval = 0
                else:
                    last_prediction_step = None
                    for i in range(len(st.session_state.ensemble_interactive_path) - 1, -1, -1):
                        entry = st.session_state.ensemble_interactive_path[i]
                        if entry.get('has_prediction', False):
                            last_prediction_step = entry['step']
                            break
                    
                    if last_prediction_step is not None:
                        no_prediction_count = 0
                        for i in range(len(st.session_state.ensemble_interactive_path) - 1, -1, -1):
                            entry = st.session_state.ensemble_interactive_path[i]
                            if entry['step'] > last_prediction_step and not entry.get('has_prediction', False):
                                no_prediction_count += 1
                            elif entry['step'] <= last_prediction_step:
                                break
                        st.session_state.ensemble_interactive_current_interval = no_prediction_count
                    else:
                        no_prediction_count = 0
                        for entry in st.session_state.ensemble_interactive_path:
                            if not entry.get('has_prediction', False):
                                no_prediction_count += 1
                        st.session_state.ensemble_interactive_current_interval = no_prediction_count
                
                # ë‹¤ìŒ prefix ìƒì„± ë° ìŠ¤í… ì¦ê°€
                next_prefix = get_next_prefix(current_prefix, actual_value, ensemble_interactive_window_size)
                st.session_state.ensemble_interactive_current_prefix = next_prefix
                st.session_state.ensemble_interactive_step = current_step + 1
                
                # í˜„ì¬ ìŠ¤í…ì˜ ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ ì‚­ì œ
                if prediction_result_key in st.session_state:
                    del st.session_state[prediction_result_key]
                if prediction_interval_key in st.session_state:
                    del st.session_state[prediction_interval_key]
                
                st.rerun()
        
        with button_col3:
            # ì´ì „ ìŠ¤í…ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°
            st.markdown("<br>", unsafe_allow_html=True)
            if st.button("ì´ì „ ìŠ¤í…", key=f"ensemble_prev_step_{current_step}", use_container_width=True, disabled=len(st.session_state.ensemble_interactive_path) == 0):
                if len(st.session_state.ensemble_interactive_path) > 0:
                    # ë§ˆì§€ë§‰ ê²½ë¡œ í•­ëª© ì œê±°
                    last_entry = st.session_state.ensemble_interactive_path.pop()
                    
                    # ì´ì „ prefixë¡œ ë³µì›
                    st.session_state.ensemble_interactive_current_prefix = last_entry['prefix']
                    
                    # ìŠ¤í… ë²ˆí˜¸ ê°ì†Œ
                    st.session_state.ensemble_interactive_step = current_step - 1
                    
                    # ê°„ê²© ë³µì›
                    interval = 0
                    for entry in reversed(st.session_state.ensemble_interactive_path):
                        if entry.get('has_prediction', False):
                            break
                        interval += 1
                    st.session_state.ensemble_interactive_current_interval = interval
                    
                    st.rerun()
        
        # ê²½ë¡œ íˆìŠ¤í† ë¦¬ í‘œì‹œ (ì—­ìˆœ - ìµœì‹ ìˆœ)
        if st.session_state.ensemble_interactive_path:
            st.markdown("---")
            st.markdown("### ê²½ë¡œ íˆìŠ¤í† ë¦¬")
            
            # ì—­ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœì´ ìœ„ì—)
            reversed_path = list(reversed(st.session_state.ensemble_interactive_path))
            for idx, entry in enumerate(reversed_path, 1):
                if entry.get('has_prediction', True):
                    # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°
                    status = "âœ…" if entry.get('is_correct') else "âŒ"
                    is_forced = entry.get('is_forced', False)
                    forced_marker = " âš¡" if is_forced else ""
                    predicted_str = f"`{entry['predicted']}{forced_marker}`"
                    confidence_str = f"({entry.get('confidence', 0):.1f}%)"
                    if is_forced:
                        confidence_str += " (ê°•ì œ)"
                else:
                    # ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê²½ìš°
                    status = "âšª"
                    predicted_str = "`-` (ì˜ˆì¸¡ ì—†ìŒ)"
                    confidence_str = "(ì„ê³„ê°’ ë¯¸ë§Œ)"
                
                st.markdown(
                    f"**Step {entry['step']}**: `{entry['prefix']}` â†’ "
                    f"ì˜ˆì¸¡: {predicted_str} {confidence_str} / "
                    f"ì‹¤ì œ: `{entry['actual']}` {status}"
                )
        
        # í†µê³„ ìš”ì•½ (í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©)
        if st.session_state.ensemble_interactive_path:
            st.markdown("---")
            st.markdown("### í˜„ì¬ê¹Œì§€ í†µê³„")
            
            total_steps = len(st.session_state.ensemble_interactive_path)
            steps_with_prediction = sum(1 for e in st.session_state.ensemble_interactive_path if e.get('has_prediction', True))
            correct_count = sum(1 for e in st.session_state.ensemble_interactive_path if e.get('is_correct') == True)
            accuracy = (correct_count / steps_with_prediction * 100) if steps_with_prediction > 0 else 0
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì´ ìŠ¤í…", f"{total_steps}")
            with col2:
                st.metric("ì˜ˆì¸¡ ìˆ˜í–‰", f"{steps_with_prediction}")
            with col3:
                st.metric("ì •í™•ë„", f"{accuracy:.1f}%")
            with col4:
                if steps_with_prediction > 0:
                    avg_confidence = sum(e.get('confidence', 0) for e in st.session_state.ensemble_interactive_path if e.get('has_prediction', True)) / steps_with_prediction
                    st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.1f}%")
                else:
                    st.metric("í‰ê·  ì‹ ë¢°ë„", "N/A")
            
            # ìƒì„¸ íˆìŠ¤í† ë¦¬ (ì—­ìˆœ - ìµœì‹ ìˆœ)
            st.markdown("---")
            st.markdown("### ìƒì„¸ íˆìŠ¤í† ë¦¬")
            
            history_data = []
            # ì—­ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœì´ ìœ„ì—)
            reversed_path = list(reversed(st.session_state.ensemble_interactive_path))
            for entry in reversed_path:
                # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° êµ¬ë¶„
                if entry.get('has_prediction', True) and entry.get('predicted') is not None:
                    # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ê²½ìš°
                    is_forced = entry.get('is_forced', False)
                    forced_marker = " âš¡" if is_forced else ""
                    predicted_value = f"{entry['predicted']}{forced_marker}"
                    predicted_prob = f"{entry['predictions'].get(entry['predicted'], 0):.1f}%"
                    if is_forced:
                        predicted_prob += " (ê°•ì œ)"
                    match_status = 'âœ…' if entry.get('is_correct') == True else 'âŒ'
                    
                    # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ê°’
                    individual_preds = entry.get('individual_predictions', {})
                    individual_str = ", ".join([f"{k}:{v.get('predicted', '-')}" for k, v in individual_preds.items()])
                    votes = entry.get('votes', {'b': 0, 'p': 0})
                    votes_str = f"b:{votes.get('b', 0)}, p:{votes.get('p', 0)}"
                else:
                    # ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ê²½ìš°
                    predicted_value = '-'
                    predicted_prob = 'N/A'
                    match_status = 'âšª (ì˜ˆì¸¡ ì—†ìŒ)'
                    individual_str = '-'
                    votes_str = '-'
                
                history_data.append({
                    'Step': entry['step'],
                    'Prefix': entry['prefix'],
                    'ì•™ìƒë¸” ì˜ˆì¸¡': predicted_value,
                    'ì•™ìƒë¸” í™•ë¥ ': predicted_prob,
                    'ê°œë³„ ëª¨ë¸': individual_str,
                    'íˆ¬í‘œ': votes_str,
                    'ì‹¤ì œê°’': entry['actual'],
                    'ì¼ì¹˜': match_status
                })
            
            history_df = pd.DataFrame(history_data)
            st.dataframe(history_df, use_container_width=True, hide_index=True)
            
            if st.button("ìƒˆë¡œ ì‹œì‘", type="primary", key="ensemble_new_start"):
                st.session_state.ensemble_interactive_path = []
                st.session_state.ensemble_interactive_current_prefix = None
                st.session_state.ensemble_interactive_step = 0
                st.session_state.ensemble_interactive_current_interval = 0
                st.rerun()
    
    st.markdown("---")
    
    # SVG íŒŒì‹± ì„¹ì…˜
    st.header("ğŸ“¥ SVG íŒŒì‹±")
    
    st.markdown("""
    SVG ì½”ë“œë¥¼ ì…ë ¥í•˜ì—¬ Grid Stringì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    íŒŒì‹±ëœ Grid Stringì€ ìë™ìœ¼ë¡œ ì €ì¥ë˜ì–´ ê²Œì„ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)
    
    # SVG ì…ë ¥ ë¦¬ì…‹ì„ ìœ„í•œ key ê´€ë¦¬
    if 'svg_input_key_counter' not in st.session_state:
        st.session_state.svg_input_key_counter = 0
    
    svg_code_input = st.text_area(
        "SVG ì½”ë“œ ì…ë ¥",
        value="",
        help="SVG ì½”ë“œë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”",
        key=f"svg_input_{st.session_state.svg_input_key_counter}",
        height=100
    )
    
    col_svg1, col_svg2 = st.columns([3, 1])
    
    with col_svg1:
        if svg_code_input:
            st.info("SVG ì½”ë“œë¥¼ ì…ë ¥í•œ í›„ 'íŒŒì‹±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        if 'parsed_grid_string' in st.session_state and st.session_state.parsed_grid_string:
            st.success(f"âœ… íŒŒì‹±ëœ Grid Stringì´ ìˆìŠµë‹ˆë‹¤. (ê¸¸ì´: {len(st.session_state.parsed_grid_string)})")
            # íŒŒì‹±ëœ Grid String í‘œì‹œ
            st.markdown("**íŒŒì‹±ëœ Grid String:**")
            st.code(st.session_state.parsed_grid_string, language=None)
    
    with col_svg2:
        st.markdown("<br>", unsafe_allow_html=True)
        parse_button = st.button("íŒŒì‹±", type="primary", use_container_width=True, key="parse_svg_button")
    
    with col_svg2:
        st.markdown("<br>", unsafe_allow_html=True)
        save_button = st.button("DB ì €ì¥", use_container_width=True, key="save_parsed_to_db_button", 
                                disabled=('parsed_grid_string' not in st.session_state or not st.session_state.parsed_grid_string))
    
    with col_svg2:
        st.markdown("<br>", unsafe_allow_html=True)
        if st.button("ë¦¬ì…‹", use_container_width=True, key="reset_svg_input_button"):
            # SVG ì…ë ¥ ì´ˆê¸°í™” (key ë³€ê²½ìœ¼ë¡œ text_area ë¦¬ì…‹)
            st.session_state.svg_input_key_counter += 1
            # íŒŒì‹±ëœ Grid String ì´ˆê¸°í™”
            if 'parsed_grid_string' in st.session_state:
                del st.session_state.parsed_grid_string
            st.rerun()
    
    if parse_button and svg_code_input:
        if not svg_code_input or not svg_code_input.strip():
            st.warning("âš ï¸ SVG ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            try:
                # íŒŒì‹± ì „ì— ì´ì „ íŒŒì‹± ê²°ê³¼ ì´ˆê¸°í™” (ì¤‘ë³µ ë°©ì§€)
                if 'parsed_grid_string' in st.session_state:
                    del st.session_state.parsed_grid_string
                
                with st.spinner("SVG íŒŒì‹± ì¤‘..."):
                    # SVG íŒŒì‹±
                    parsed_grid = parse_bead_road_svg(svg_code_input)
                    
                    # Gridë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    grid_string_parsed = grid_to_string_column_wise(parsed_grid)
                    
                    if grid_string_parsed:
                        # Session stateì— ì €ì¥í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì‚¬ìš©
                        st.session_state.parsed_grid_string = grid_string_parsed
                        
                        st.success(f"âœ… íŒŒì‹± ì™„ë£Œ! Grid String ê¸¸ì´: {len(grid_string_parsed)}")
                        
                        # íŒŒì‹±ëœ Grid String ì „ì²´ í‘œì‹œ
                        st.markdown("**íŒŒì‹±ëœ Grid String:**")
                        st.code(grid_string_parsed, language=None)
                        
                        # íŒŒì‹± ì™„ë£Œ í›„ ë²„íŠ¼ ìƒíƒœ ì´ˆê¸°í™”ë¥¼ ìœ„í•´ rerun
                        st.rerun()
                    else:
                        st.warning("âš ï¸ íŒŒì‹±ëœ Gridì—ì„œ ìœ íš¨í•œ ë¬¸ìì—´ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ SVG íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                import traceback
                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    # DB ì €ì¥ ê¸°ëŠ¥
    if save_button:
        if 'parsed_grid_string' in st.session_state and st.session_state.parsed_grid_string:
            try:
                # DBì— ì €ì¥
                grid_string_to_save = st.session_state.parsed_grid_string
                save_parsed_grid_string_to_db(grid_string_to_save)
                st.success("âœ… DB ì €ì¥ ì™„ë£Œ!")
            except Exception as e:
                st.error(f"âŒ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        else:
            st.warning("âš ï¸ ì €ì¥í•  Grid Stringì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € SVGë¥¼ íŒŒì‹±í•´ì£¼ì„¸ìš”.")
    
    st.markdown("---")
    
    # ê²Œì„ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ ì„¹ì…˜
    st.header("ğŸ® ê²Œì„ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦")
    
    st.markdown("""
    **ê²€ì¦ ê·œì¹™:**
    - Grid Stringì„ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ prefixë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤
    - ê° prefixì— ëŒ€í•´ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì„ ë¹„êµí•©ë‹ˆë‹¤
    """)
    
    # Grid String ì…ë ¥
    grid_string_input = st.text_input(
        "Grid String ì…ë ¥",
        value="",
        help="ê²€ì¦í•  ë¬¸ìì—´ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'bbbbppbbppbbpp...')",
        key="game_grid_string_text_input"
    )
    
    if grid_string_input:
        st.info(f"ì…ë ¥ëœ ë¬¸ìì—´ ê¸¸ì´: {len(grid_string_input)}")
    
    st.markdown("---")
    
    # ê²Œì„ ì‹œë‚˜ë¦¬ì˜¤ ìë™ ê²€ì¦ ì„¹ì…˜
    st.header("ğŸ® ê²Œì„ ì‹œë‚˜ë¦¬ì˜¤ ìë™ ê²€ì¦")
    
    st.markdown("""
    **ê²€ì¦ ê·œì¹™:**
    - Grid Stringì„ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ prefixë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤
    - ê° prefixì— ëŒ€í•´ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì„ ë¹„êµí•©ë‹ˆë‹¤
    - **ëª¨ë“  ìŠ¤í…ì„ ì§„í–‰**í•˜ì—¬ ì „ì²´ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤
    - **ê²€ì¦ ëª©í‘œ**: ë¶ˆì¼ì¹˜ ê°’ì´ 5ê°œ ì—°ì†ë˜ëŠ” ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤
    """)
    
    # ì„¤ì • ì„¹ì…˜
    st.markdown("### âš™ï¸ ì„¤ì •")
    col_setting1, col_setting2, col_setting3 = st.columns(3)
    
    with col_setting1:
        game_window_size = st.selectbox(
            "ìœˆë„ìš° í¬ê¸°",
            options=[5, 6, 7, 8, 9],
            index=2,  # 7ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
            key="game_window_size",
            help="ê²€ì¦ì— ì‚¬ìš©í•  ìœˆë„ìš° í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
    
    with col_setting2:
        game_method = st.selectbox(
            "ì˜ˆì¸¡ ë°©ë²•",
            options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
            index=0,
            key="game_method",
            help="ê²€ì¦ì— ì‚¬ìš©í•  ì˜ˆì¸¡ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”"
        )
    
    with col_setting3:
        game_use_threshold = st.checkbox(
            "ì„ê³„ê°’ ì „ëµ ì‚¬ìš©",
            value=True,
            key="game_use_threshold",
            help="ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•˜ë„ë¡ ì„¤ì •"
        )
        game_threshold = None
        if game_use_threshold:
            game_threshold = st.number_input(
                "ì„ê³„ê°’ (%)",
                min_value=0,
                max_value=100,
                value=60,
                step=1,
                key="game_threshold",
                help="ì´ ì‹ ë¢°ë„ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤"
            )
    
    st.markdown("---")
    
    # Grid String ì…ë ¥ (ì§ì ‘ ì…ë ¥ë§Œ)
    grid_string_input = st.text_area(
        "Grid String ì…ë ¥",
        value="",
        help="ê²€ì¦í•  ë¬¸ìì—´ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'bbbbppbbppbbpp...') ë˜ëŠ” ìœ„ì—ì„œ íŒŒì‹±í•œ Grid Stringì„ ì‚¬ìš©í•˜ì„¸ìš”",
        height=100,
        key="game_grid_string_input"
    )
    
    # ì €ì¥ëœ Grid String ì‚¬ìš© ì˜µì…˜
    if 'parsed_grid_string' in st.session_state and st.session_state.parsed_grid_string:
        use_parsed = st.checkbox(
            "íŒŒì‹±ëœ Grid String ì‚¬ìš©",
            value=False,
            key="use_parsed_grid_string",
            help="ìœ„ì—ì„œ íŒŒì‹±í•œ Grid Stringì„ ì‚¬ìš©í•©ë‹ˆë‹¤"
        )
        
        if use_parsed:
            grid_string_input = st.session_state.parsed_grid_string
            st.info(f"âœ… íŒŒì‹±ëœ Grid Stringì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (ê¸¸ì´: {len(grid_string_input)})")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.markdown(f"**ì…ë ¥ëœ ë¬¸ìì—´ ê¸¸ì´**: {len(grid_string_input)}")
        if grid_string_input:
            st.markdown(f"**ë¬¸ì êµ¬ì„±**: 'b': {grid_string_input.count('b')}ê°œ, 'p': {grid_string_input.count('p')}ê°œ")
    
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        start_validation_button = st.button("ê²€ì¦ ì‹œì‘", type="primary", use_container_width=True, key="start_game_validation")
    
    if start_validation_button and grid_string_input:
        # ë¬¸ìì—´ ê²€ì¦
        if len(grid_string_input) < game_window_size:
            st.warning(f"âš ï¸ ë¬¸ìì—´ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ {game_window_size}ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            # ëª¨ë¸ êµ¬ì¶•
            with st.spinner("ëª¨ë¸ êµ¬ì¶• ì¤‘..."):
                df_strings = load_preprocessed_data()
                if len(df_strings) == 0:
                    st.warning("âš ï¸ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # í•™ìŠµ ì„¸íŠ¸ ë¶„í• 
                    train_ratio = 80
                    split_idx = int(len(df_strings) * train_ratio / 100)
                    train_ids = df_strings.iloc[:split_idx]['id'].tolist()
                    
                    # N-gram ë¡œë“œ
                    train_ngrams = load_ngram_chunks(window_size=game_window_size, grid_string_ids=train_ids)
                    
                    if len(train_ngrams) == 0:
                        st.warning(f"âš ï¸ ìœˆë„ìš° í¬ê¸° {game_window_size}ì— ëŒ€í•œ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # ëª¨ë¸ êµ¬ì¶•
                        if game_method == "ë¹ˆë„ ê¸°ë°˜":
                            game_model = build_frequency_model(train_ngrams)
                        # elif game_method == "ë§ˆë¥´ì½”í”„ ì²´ì¸":
                        #     game_model = build_markov_model(train_ngrams)
                        elif game_method == "ê°€ì¤‘ì¹˜ ê¸°ë°˜":
                            game_model = build_weighted_model(train_ngrams)
                        elif game_method == "ì•ˆì „ ìš°ì„ ":
                            game_model = build_safety_first_model(train_ngrams)
                        else:  # ê¸°ë³¸ê°’: ë¹ˆë„ ê¸°ë°˜
                            game_model = build_frequency_model(train_ngrams)
                        
                        # ì „ëµ í•¨ìˆ˜ ì„¤ì •
                        strategy_func = None
                        if game_use_threshold and game_threshold is not None:
                            strategy_func = lambda m, p, method: predict_confidence_threshold(
                                m, p, method, threshold=game_threshold
                            )
                        
                        # ê²Œì„ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
                        with st.spinner("ê²Œì„ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ ì¤‘..."):
                            game_result = simulate_game_scenario(
                                game_model,
                                grid_string_input,
                                game_window_size,
                                game_method,
                                strategy_func=strategy_func
                            )
                        
                        st.markdown("---")
                        
                        # ê²°ê³¼ í‘œì‹œ
                        display_game_result(game_result)
                        
                        # ì¶”ê°€ ì •ë³´
                        if game_result['history']:
                            st.markdown("---")
                            st.markdown("### ì˜ˆì¸¡ í™•ë¥  ìƒì„¸")
                            
                            # ë§ˆì§€ë§‰ ëª‡ ê°œ ìŠ¤í…ì˜ ì˜ˆì¸¡ í™•ë¥  í‘œì‹œ
                            recent_history = game_result['history'][-5:] if len(game_result['history']) > 5 else game_result['history']
                            
                            for entry in recent_history:
                                with st.expander(f"Step {entry['step']}: `{entry['prefix']}` â†’ ì˜ˆì¸¡: `{entry['predicted']}`, ì‹¤ì œ: `{entry['actual']}`"):
                                    ratios = entry['ratios']
                                    sorted_ratios = sorted(ratios.items(), key=lambda x: x[1], reverse=True)
                                    
                                    for value, ratio in sorted_ratios:
                                        is_predicted = (value == entry['predicted'])
                                        label = f"**'{value}'**: {ratio:.2f}% {'(ì˜ˆì¸¡ê°’)' if is_predicted else ''}"
                                        st.progress(ratio / 100, text=label)
                        
                        # ê²°ê³¼ ì €ì¥ ê¸°ëŠ¥
                        st.markdown("---")
                        st.markdown("### ê²°ê³¼ ì €ì¥")
                        
                        save_result = st.checkbox("ê²€ì¦ ê²°ê³¼ë¥¼ DBì— ì €ì¥", value=False, key="save_validation_result")
                        
                        if save_result:
                            if st.button("ì €ì¥", type="primary", key="save_validation"):
                                try:
                                    validation_id = save_scenario_validation_result(
                                        game_result,
                                        grid_string_input,
                                        game_window_size,
                                        game_method,
                                        train_ratio
                                    )
                                    st.success(f"âœ… ê²€ì¦ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. Validation ID: `{validation_id}`")
                                    st.info(f"ğŸ’¡ ì €ì¥ëœ ë°ì´í„°: ì„¸ì…˜ ìš”ì•½, {len(game_result['history'])}ê°œ ìŠ¤í… ìƒì„¸, {len(game_result['consecutive_5_positions'])}ê°œ ì—°ì† ë¶ˆì¼ì¹˜ 5ê°œ ë°œìƒ ìœ„ì¹˜")
                                except Exception as e:
                                    st.error(f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    st.markdown("---")
    
    # ìœˆë„ìš° í¬ê¸° ìµœì í™” (ì „ì²´ DB) ì„¹ì…˜
    st.header("ğŸ” ìœˆë„ìš° í¬ê¸° ìµœì í™” (ì „ì²´ DB)")
    
    st.markdown("""
    **ì‹œê³„ì—´ ëˆ„ì  í…ŒìŠ¤íŠ¸ ë°©ì‹:**
    - DBì˜ ëª¨ë“  grid_stringì„ ì‹œê³„ì—´ ìˆœì„œ(created_at)ë¡œ ì •ë ¬í•©ë‹ˆë‹¤
    - ê° grid_stringì— ëŒ€í•´:
      - ì´ì „ê¹Œì§€ì˜ ëª¨ë“  grid_stringì˜ ngram_chunksë¡œ ëª¨ë¸ êµ¬ì¶•
      - í˜„ì¬ grid_stringì„ í…ŒìŠ¤íŠ¸
      - ê²°ê³¼ ìˆ˜ì§‘
    - ê° ìœˆë„ìš° í¬ê¸°ë³„ë¡œ ì „ì²´ ì„±ëŠ¥ì„ í‰ê°€í•˜ì—¬ ìµœì ì˜ ìœˆë„ìš° í¬ê¸°ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤
    """)
    
    # ìœˆë„ìš° í¬ê¸° ë²”ìœ„ ì…ë ¥
    col_range1, col_range2 = st.columns(2)
    with col_range1:
        window_size_start = st.number_input(
            "ìœˆë„ìš° í¬ê¸° ì‹œì‘",
            min_value=5,
            max_value=15,
            value=6,
            step=1,
            help="í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸°ì˜ ì‹œì‘ê°’",
            key="opt_window_start"
        )
    with col_range2:
        window_size_end = st.number_input(
            "ìœˆë„ìš° í¬ê¸° ë",
            min_value=5,
            max_value=15,
            value=9,
            step=1,
            help="í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸°ì˜ ëê°’",
            key="opt_window_end"
        )
    
    # ìœ íš¨ì„± ê²€ì‚¬
    if window_size_start > window_size_end:
        st.warning("âš ï¸ ì‹œì‘ê°’ì´ ëê°’ë³´ë‹¤ í½ë‹ˆë‹¤.")
        window_sizes_list = []
    else:
        window_sizes_list = list(range(window_size_start, window_size_end + 1))
        st.info(f"í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸°: {window_sizes_list}")
    
    # ì „ì²´ DB í…ŒìŠ¤íŠ¸ ë²„íŠ¼
    col_opt1, col_opt2 = st.columns([3, 1])
    with col_opt1:
        st.markdown(f"**DB ì „ì²´ Grid String ìˆ˜**: {len(df_strings)}ê°œ")
        if len(df_strings) == 0:
            st.warning("âš ï¸ DBì— grid_stringì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê±°ë‚˜ íŒŒì‹±í•˜ì—¬ ì €ì¥í•˜ì„¸ìš”.")
    with col_opt2:
        st.markdown("<br>", unsafe_allow_html=True)
        start_optimization_button = st.button("ì „ì²´ DB ìµœì í™” í…ŒìŠ¤íŠ¸", type="primary", use_container_width=True, key="start_optimization_test")
    
    # ì „ì²´ DB ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if start_optimization_button and window_sizes_list and len(df_strings) > 0:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            total_tests = len(window_sizes_list)
            results_by_window = {}
            
            for idx, test_window_size in enumerate(window_sizes_list):
                status_text.text(f"ìœˆë„ìš° í¬ê¸° {test_window_size} í…ŒìŠ¤íŠ¸ ì¤‘... ({idx + 1}/{total_tests})")
                progress_bar.progress((idx + 1) / total_tests)
                
                # ê° ìœˆë„ìš° í¬ê¸°ë³„ë¡œ ì „ì²´ DB í…ŒìŠ¤íŠ¸
                window_result = batch_test_window_sizes_on_all_data(
                    df_strings,
                    [test_window_size],
                    prediction_method,
                    train_ratio
                )
                results_by_window.update(window_result)
            
            progress_bar.empty()
            status_text.empty()
            
            st.markdown("---")
            
            # ë¹„êµ ê²°ê³¼ í‘œì‹œ
            display_window_size_comparison_all_data(results_by_window)
            
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"âŒ ìµœì í™” í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    st.markdown("---")
    
    # ì „ëµ íƒìƒ‰ ë° í…ŒìŠ¤íŠ¸ ì„¹ì…˜
    st.header("ğŸ”¬ ì „ëµ íƒìƒ‰ ë° í…ŒìŠ¤íŠ¸")
    
    st.markdown("""
    **ëª©í‘œ:**
    - ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ ì´ìƒ OR ì—°ì† ì¼ì¹˜ 5íšŒ ì´ìƒ = ì‹¤íŒ¨ë¡œ íŒë‹¨
    - ë‹¤ì–‘í•œ ì˜ˆì¸¡ ì „ëµì„ ìë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    - ìµœì ì˜ ì „ëµì„ ì°¾ì•„ ì¶”ì²œ
    
    **ì‚¬ìš© ê°€ëŠ¥í•œ ì „ëµ:**
    - ê¸°ë³¸ ì „ëµ: ë¹ˆë„ ê¸°ë°˜, ê°€ì¤‘ì¹˜ ê¸°ë°˜, ì•ˆì „ ìš°ì„ 
    - ì•™ìƒë¸” ì „ëµ: íˆ¬í‘œ ë°©ì‹, ê°€ì¤‘ í‰ê·  ë°©ì‹
    - ì‹ ë¢°ë„ ì„ê³„ê°’ ì „ëµ: ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ì˜ˆì¸¡ ë³´ë¥˜ ë˜ëŠ” ë°˜ëŒ€ ì˜ˆì¸¡
    - ì—­ì „ëµ: ì˜ˆì¸¡ê³¼ ë°˜ëŒ€ë¡œ ì˜ˆì¸¡
    """)
    
    # ì „ëµ ì„ íƒ
    st.markdown("### ì „ëµ ì„ íƒ")
    
    col_strategy1, col_strategy2 = st.columns(2)
    
    with col_strategy1:
        use_basic = st.checkbox("ê¸°ë³¸ ì „ëµ (ë¹ˆë„ ê¸°ë°˜)", value=True, key="strategy_basic")
        use_ensemble_voting = st.checkbox("ì•™ìƒë¸” - íˆ¬í‘œ ë°©ì‹", value=False, key="strategy_ensemble_voting")
        use_ensemble_weighted = st.checkbox("ì•™ìƒë¸” - ê°€ì¤‘ í‰ê· ", value=False, key="strategy_ensemble_weighted")
        use_confidence_threshold = st.checkbox("ì‹ ë¢°ë„ ì„ê³„ê°’ (60%)", value=False, key="strategy_confidence_threshold")
    
    with col_strategy2:
        use_confidence_reverse = st.checkbox("ì‹ ë¢°ë„ ì—­ì „ (50%)", value=False, key="strategy_confidence_reverse")
        use_reverse = st.checkbox("ì—­ì „ëµ", value=False, key="strategy_reverse")
        # use_markov = st.checkbox("ë§ˆë¥´ì½”í”„ ì²´ì¸", value=False, key="strategy_markov")  # ì œê±°ë¨
        use_weighted = st.checkbox("ê°€ì¤‘ì¹˜ ê¸°ë°˜", value=False, key="strategy_weighted")
        use_safety_first = st.checkbox("ì•ˆì „ ìš°ì„ ", value=False, key="strategy_safety_first")
    
    # ìœˆë„ìš° í¬ê¸° ë²”ìœ„ ì„¤ì •
    st.markdown("### í…ŒìŠ¤íŠ¸ ì„¤ì •")
    
    col_window1, col_window2 = st.columns(2)
    with col_window1:
        strategy_window_start = st.number_input(
            "ìœˆë„ìš° í¬ê¸° ì‹œì‘",
            min_value=5,
            max_value=15,
            value=6,
            step=1,
            help="í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸°ì˜ ì‹œì‘ê°’",
            key="strategy_window_start"
        )
    with col_window2:
        strategy_window_end = st.number_input(
            "ìœˆë„ìš° í¬ê¸° ë",
            min_value=5,
            max_value=15,
            value=9,
            step=1,
            help="í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸°ì˜ ëê°’",
            key="strategy_window_end"
        )
    
    # ìœ íš¨ì„± ê²€ì‚¬
    if strategy_window_start > strategy_window_end:
        st.warning("âš ï¸ ì‹œì‘ê°’ì´ ëê°’ë³´ë‹¤ í½ë‹ˆë‹¤.")
        strategy_window_sizes_list = []
    else:
        strategy_window_sizes_list = list(range(strategy_window_start, strategy_window_end + 1))
        st.info(f"í…ŒìŠ¤íŠ¸í•  ìœˆë„ìš° í¬ê¸°: {strategy_window_sizes_list}")
    
    # ê¸°ë³¸ ì˜ˆì¸¡ ë°©ë²• ì„ íƒ
    base_method = st.selectbox(
        "ê¸°ë³¸ ì˜ˆì¸¡ ë°©ë²•",
        options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
        index=0,
        key="strategy_base_method"
    )
    
    # ì „ëµ í…ŒìŠ¤íŠ¸ ë²„íŠ¼
    col_test1, col_test2 = st.columns([3, 1])
    with col_test1:
        st.markdown(f"**DB ì „ì²´ Grid String ìˆ˜**: {len(df_strings)}ê°œ")
        if len(df_strings) == 0:
            st.warning("âš ï¸ DBì— grid_stringì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê±°ë‚˜ íŒŒì‹±í•˜ì—¬ ì €ì¥í•˜ì„¸ìš”.")
    with col_test2:
        st.markdown("<br>", unsafe_allow_html=True)
        start_strategy_test_button = st.button("ì „ëµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰", type="primary", use_container_width=True, key="start_strategy_test")
    
    # ì „ëµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if start_strategy_test_button and strategy_window_sizes_list and len(df_strings) > 0:
        # ì„ íƒëœ ì „ëµ ìˆ˜ì§‘
        selected_strategies = []
        
        if use_basic:
            selected_strategies.append((lambda m, p, method: predict_for_prefix(m, p, method), "ê¸°ë³¸_ë¹ˆë„ê¸°ë°˜"))
        
        # if use_markov:
        #     selected_strategies.append((lambda m, p, method: predict_for_prefix(m, p, "ë§ˆë¥´ì½”í”„ ì²´ì¸"), "ë§ˆë¥´ì½”í”„ì²´ì¸"))  # ì œê±°ë¨
        
        if use_safety_first:
            # ì•ˆì „ ìš°ì„  ëª¨ë¸ì€ íˆìŠ¤í† ë¦¬ê°€ í•„ìš”í•˜ë¯€ë¡œ ë˜í¼ í•¨ìˆ˜ ìƒì„±
            # simulate_game_scenario ë‚´ë¶€ì—ì„œ íˆìŠ¤í† ë¦¬ë¥¼ ì „ë‹¬í•˜ë„ë¡ ë˜í¼ ì‚¬ìš©
            # ë˜í¼ëŠ” í´ë¡œì €ë¥¼ ì‚¬ìš©í•˜ì—¬ prediction_historyì™€ consecutive_mismatchesë¥¼ ìº¡ì²˜
            def create_safety_first_strategy_wrapper():
                # prediction_historyì™€ consecutive_mismatchesë¥¼ ì €ì¥í•  ë³€ìˆ˜
                history_ref = {'data': []}
                mismatches_ref = {'count': 0}
                
                def wrapper(m, p, method):
                    # simulate_game_scenarioì—ì„œ íˆìŠ¤í† ë¦¬ë¥¼ ì—…ë°ì´íŠ¸í•˜ë¯€ë¡œ
                    # ì—¬ê¸°ì„œëŠ” í˜„ì¬ íˆìŠ¤í† ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡
                    return predict_safety_first(m, p, recent_history=history_ref['data'], consecutive_mismatches=mismatches_ref['count'])
                
                # ë˜í¼ì— íˆìŠ¤í† ë¦¬ ì°¸ì¡° ì¶”ê°€ (simulate_game_scenarioì—ì„œ ì—…ë°ì´íŠ¸)
                wrapper._history_ref = history_ref
                wrapper._mismatches_ref = mismatches_ref
                return wrapper
            
            safety_wrapper = create_safety_first_strategy_wrapper()
            selected_strategies.append((safety_wrapper, "ì•ˆì „ìš°ì„ "))
        
        if use_weighted:
            selected_strategies.append((lambda m, p, method: predict_for_prefix(m, p, "ê°€ì¤‘ì¹˜ ê¸°ë°˜"), "ê°€ì¤‘ì¹˜ê¸°ë°˜"))
        
        if use_ensemble_voting:
            selected_strategies.append((lambda m, p, method: predict_ensemble_voting(m, p), "ì•™ìƒë¸”_íˆ¬í‘œ"))
        
        if use_ensemble_weighted:
            selected_strategies.append((lambda m, p, method: predict_ensemble_weighted(m, p), "ì•™ìƒë¸”_ê°€ì¤‘í‰ê· "))
        
        if use_confidence_threshold:
            selected_strategies.append((lambda m, p, method: predict_confidence_threshold(m, p, method, threshold=60), "ì‹ ë¢°ë„ì„ê³„ê°’_60"))
        
        if use_confidence_reverse:
            selected_strategies.append((lambda m, p, method: predict_confidence_reverse(m, p, method, threshold=50), "ì‹ ë¢°ë„ì—­ì „_50"))
        
        if use_reverse:
            selected_strategies.append((lambda m, p, method: predict_reverse(m, p, method), "ì—­ì „ëµ"))
        
        if not selected_strategies:
            st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ ì „ëµì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                total_strategies = len(selected_strategies)
                all_results = {}
                
                for idx, (strategy_func, strategy_name) in enumerate(selected_strategies):
                    status_text.text(f"ì „ëµ '{strategy_name}' í…ŒìŠ¤íŠ¸ ì¤‘... ({idx + 1}/{total_strategies})")
                    progress_bar.progress((idx + 1) / total_strategies)
                    
                    # ê° ì „ëµë³„ë¡œ ì „ì²´ DB í…ŒìŠ¤íŠ¸
                    strategy_results = test_strategy_on_all_data(
                        strategy_func,
                        strategy_name,
                        df_strings,
                        strategy_window_sizes_list,
                        base_method,
                        train_ratio
                    )
                    all_results[strategy_name] = strategy_results
                
                progress_bar.empty()
                status_text.empty()
                
                st.markdown("---")
                
                # ê²°ê³¼ ë¹„êµ í‘œì‹œ
                display_strategy_comparison(all_results)
                
            except Exception as e:
                progress_bar.empty()
                status_text.empty()
                st.error(f"âŒ ì „ëµ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                import traceback
                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    st.markdown("---")
    
    # ìµœì  ìœˆë„ìš° í¬ê¸° ë° ì„ê³„ê°’ íƒìƒ‰ ì„¹ì…˜
    st.header("ğŸ¯ ìµœì  ìœˆë„ìš° í¬ê¸° ë° ì„ê³„ê°’ íƒìƒ‰")
    
    st.markdown("""
    **ëª©í‘œ:**
    - ìœˆë„ìš° í¬ê¸°ì™€ ì‹ ë¢°ë„ ì„ê³„ê°’ì˜ ìµœì  ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤
    - ì—¬ëŸ¬ ì¡°í•©ì„ ìë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ìµœì ê°’ ì¶”ì²œ
    - ì—°ì† ë¶ˆì¼ì¹˜/ì¼ì¹˜ 5íšŒ ì´ìƒ ë°œìƒì´ ê°€ì¥ ì ì€ ì¡°í•© ì„ íƒ
    """)
    
    # ìœˆë„ìš° í¬ê¸° ë²”ìœ„ ì„¤ì •
    st.markdown("### ìœˆë„ìš° í¬ê¸° ë²”ìœ„")
    col_opt_window1, col_opt_window2 = st.columns(2)
    with col_opt_window1:
        opt_window_start = st.number_input(
            "ìœˆë„ìš° í¬ê¸° ì‹œì‘",
            min_value=5,
            max_value=15,
            value=6,
            step=1,
            key="opt_threshold_window_start"
        )
    with col_opt_window2:
        opt_window_end = st.number_input(
            "ìœˆë„ìš° í¬ê¸° ë",
            min_value=5,
            max_value=15,
            value=9,
            step=1,
            key="opt_threshold_window_end"
        )
    
    # ì„ê³„ê°’ ë²”ìœ„ ì„¤ì •
    st.markdown("### ì‹ ë¢°ë„ ì„ê³„ê°’ ë²”ìœ„")
    col_opt_threshold1, col_opt_threshold2, col_opt_threshold3 = st.columns(3)
    with col_opt_threshold1:
        opt_threshold_start = st.number_input(
            "ì„ê³„ê°’ ì‹œì‘ (%)",
            min_value=0,
            max_value=100,
            value=50,
            step=5,
            key="opt_threshold_start"
        )
    with col_opt_threshold2:
        opt_threshold_end = st.number_input(
            "ì„ê³„ê°’ ë (%)",
            min_value=0,
            max_value=100,
            value=70,
            step=5,
            key="opt_threshold_end"
        )
    with col_opt_threshold3:
        opt_threshold_step = st.number_input(
            "ì„ê³„ê°’ ê°„ê²© (%)",
            min_value=1,
            max_value=20,
            value=1,
            step=1,
            key="opt_threshold_step"
        )
    
    # ê¸°ë³¸ ì˜ˆì¸¡ ë°©ë²• ì„ íƒ
    opt_base_method = st.selectbox(
        "ê¸°ë³¸ ì˜ˆì¸¡ ë°©ë²•",
        options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
        index=0,
        key="opt_threshold_base_method"
    )
    
    # ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ ì¡°ê±´ ì„¤ì •
    st.markdown("### ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ ì¡°ê±´")
    min_prediction_ratio = st.number_input(
        "ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ (%)",
        min_value=0,
        max_value=100,
        value=20,
        step=1,
        key="min_prediction_ratio",
        help="ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ë¹„ìœ¨ì´ ì´ ê°’ ì´ìƒì¸ ì¡°í•©ë§Œ ì¶”ì²œ ëŒ€ìƒìœ¼ë¡œ ê³ ë ¤í•©ë‹ˆë‹¤. ë¼ì´ë¸Œ ê²Œì„ì—ì„œ ì˜ˆì¸¡ ê¸°íšŒê°€ ì ì€ ì¡°í•©ì„ ì œì™¸í•©ë‹ˆë‹¤."
    )
    
    # ìœ íš¨ì„± ê²€ì‚¬
    if opt_window_start > opt_window_end:
        st.warning("âš ï¸ ìœˆë„ìš° í¬ê¸° ì‹œì‘ê°’ì´ ëê°’ë³´ë‹¤ í½ë‹ˆë‹¤.")
        opt_window_sizes_list = []
    else:
        opt_window_sizes_list = list(range(opt_window_start, opt_window_end + 1))
    
    if opt_threshold_start > opt_threshold_end:
        st.warning("âš ï¸ ì„ê³„ê°’ ì‹œì‘ê°’ì´ ëê°’ë³´ë‹¤ í½ë‹ˆë‹¤.")
        opt_threshold_list = []
    else:
        opt_threshold_list = list(range(opt_threshold_start, opt_threshold_end + 1, opt_threshold_step))
    
    # ì¡°í•© ìˆ˜ í‘œì‹œ
    if opt_window_sizes_list and opt_threshold_list:
        total_combinations = len(opt_window_sizes_list) * len(opt_threshold_list)
        st.info(f"í…ŒìŠ¤íŠ¸í•  ì¡°í•© ìˆ˜: {total_combinations}ê°œ (ìœˆë„ìš° í¬ê¸° {len(opt_window_sizes_list)}ê°œ Ã— ì„ê³„ê°’ {len(opt_threshold_list)}ê°œ)")
    
    # ìµœì í™” í…ŒìŠ¤íŠ¸ ë²„íŠ¼
    col_opt_test1, col_opt_test2 = st.columns([3, 1])
    with col_opt_test1:
        st.markdown(f"**DB ì „ì²´ Grid String ìˆ˜**: {len(df_strings)}ê°œ")
        if len(df_strings) == 0:
            st.warning("âš ï¸ DBì— grid_stringì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê±°ë‚˜ íŒŒì‹±í•˜ì—¬ ì €ì¥í•˜ì„¸ìš”.")
    with col_opt_test2:
        st.markdown("<br>", unsafe_allow_html=True)
        start_opt_test_button = st.button("ìµœì  ì¡°í•© íƒìƒ‰", type="primary", use_container_width=True, key="start_opt_combination_test")
    
    # ìµœì  ì¡°í•© íƒìƒ‰ ì‹¤í–‰
    if start_opt_test_button and opt_window_sizes_list and opt_threshold_list and len(df_strings) > 0:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            total_combinations = len(opt_window_sizes_list) * len(opt_threshold_list)
            all_combination_results = []
            current_combination = 0
            
            for window_size in opt_window_sizes_list:
                for threshold in opt_threshold_list:
                    current_combination += 1
                    status_text.text(
                        f"ìœˆë„ìš° í¬ê¸° {window_size}, ì„ê³„ê°’ {threshold}% í…ŒìŠ¤íŠ¸ ì¤‘... "
                        f"({current_combination}/{total_combinations})"
                    )
                    progress_bar.progress(current_combination / total_combinations)
                    
                    # ì„ê³„ê°’ ì „ëµ í•¨ìˆ˜ ìƒì„±
                    strategy_func = lambda m, p, method: predict_confidence_threshold(m, p, method, threshold=threshold)
                    strategy_name = f"ì„ê³„ê°’_{threshold}"
                    
                    # í•´ë‹¹ ì¡°í•© í…ŒìŠ¤íŠ¸
                    strategy_results = test_strategy_on_all_data(
                        strategy_func,
                        strategy_name,
                        df_strings,
                        [window_size],
                        opt_base_method,
                        train_ratio
                    )
                    
                    if window_size in strategy_results:
                        result = strategy_results[window_size]
                        # ì‹¤íŒ¨ ì§€í‘œ ê³„ì‚°
                        total_failures = result.get('total_consecutive_5_count', 0) + result.get('total_consecutive_5_match_count', 0)
                        max_failures = max(
                            result.get('max_consecutive_mismatches', 0),
                            result.get('max_consecutive_matches', 0)
                        )
                        
                        # ì‹ ë¢°ë„ í†µê³„ ë¶„ì„ (ì¤‘ë³µ ê³„ì‚° ì œê±°: test_strategy_on_all_dataì—ì„œ ì´ë¯¸ ìˆ˜ì§‘í•œ history ì‚¬ìš©)
                        all_histories = result.get('all_histories', [])
                        if all_histories:
                            confidence_stats = analyze_confidence_statistics(all_histories, threshold)
                        else:
                            # historyê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
                            confidence_stats = {
                                'total_steps': 0,
                                'total_predictions': 0,
                                'total_abstained': 0,
                                'prediction_ratio': 0,
                                'high_confidence_count': 0,
                                'high_confidence_ratio': 0,
                                'high_confidence_ratio_overall': 0,
                                'confidence_bins': {},
                                'avg_confidence': 0,
                                'min_confidence': 0,
                                'max_confidence': 0,
                                'avg_interval': 0,
                                'max_interval': 0,
                                'min_interval': 0,
                                'confidence_intervals': [],
                                'threshold': threshold
                            }
                        
                        all_combination_results.append({
                            'window_size': window_size,
                            'threshold': threshold,
                            'strategy_name': strategy_name,
                            'max_consecutive_mismatches': result.get('max_consecutive_mismatches', 0),
                            'max_consecutive_matches': result.get('max_consecutive_matches', 0),
                            'max_failures': max_failures,
                            'total_consecutive_5_count': result.get('total_consecutive_5_count', 0),
                            'total_consecutive_5_match_count': result.get('total_consecutive_5_match_count', 0),
                            'total_failures': total_failures,
                            'avg_accuracy': result.get('avg_accuracy', 0),
                            'tested_grid_strings': result.get('tested_grid_strings', 0),
                            'total_steps': result.get('total_steps', 0),
                            'confidence_stats': confidence_stats
                        })
            
            progress_bar.empty()
            status_text.empty()
            
            st.markdown("---")
            
            # ê²°ê³¼ ë¹„êµ í…Œì´ë¸”
            if all_combination_results:
                st.markdown("### ğŸ“Š ì¡°í•©ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
                
                comparison_data = []
                for result in all_combination_results:
                    conf_stats = result.get('confidence_stats', {})
                    high_conf_ratio_overall = conf_stats.get('high_confidence_ratio_overall', 0)
                    meets_min_requirement = high_conf_ratio_overall >= min_prediction_ratio
                    
                    comparison_data.append({
                        'ìœˆë„ìš° í¬ê¸°': result['window_size'],
                        'ì„ê³„ê°’ (%)': result['threshold'],
                        'ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜': result['max_consecutive_mismatches'],
                        'ìµœëŒ€ ì—°ì† ì¼ì¹˜': result['max_consecutive_matches'],
                        'ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ': result['max_failures'],
                        'ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ+': result['total_consecutive_5_count'],
                        'ì—°ì† ì¼ì¹˜ 5íšŒ+': result['total_consecutive_5_match_count'],
                        'ì´ ì‹¤íŒ¨ íšŸìˆ˜': result['total_failures'],
                        'í‰ê·  ì •í™•ë„ (%)': f"{result['avg_accuracy']:.2f}",
                        'ì˜ˆì¸¡ ìˆ˜í–‰ ë¹„ìœ¨ (%)': f"{conf_stats.get('prediction_ratio', 0):.2f}",
                        'ì„ê³„ê°’ ì´ìƒ ë¹„ìœ¨ (%)': f"{high_conf_ratio_overall:.2f}",
                        'í•„í„° ì¡°ê±´ ë§Œì¡±': 'âœ…' if meets_min_requirement else 'âŒ',
                        'ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ìˆ˜': conf_stats.get('high_confidence_count', 0),
                        'í‰ê·  ê°„ê²©': f"{conf_stats.get('avg_interval', 0):.1f}",
                        'ìµœëŒ€ ê°„ê²©': conf_stats.get('max_interval', 0),
                        'í…ŒìŠ¤íŠ¸ëœ Grid ìˆ˜': result['tested_grid_strings']
                    })
                
                # ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì˜¤ë¦„ì°¨ìˆœ)
                comparison_data.sort(key=lambda x: (x['ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ'], x['ì´ ì‹¤íŒ¨ íšŸìˆ˜']))
                
                comparison_df = pd.DataFrame(comparison_data)
                st.dataframe(comparison_df, use_container_width=True, hide_index=True)
                
                # ìµœì  ì¡°í•© ì¶”ì²œ
                st.markdown("---")
                st.markdown("### ğŸ¯ ìµœì  ì¡°í•© ì¶”ì²œ")
                
                # í•„í„°ë§ ì¡°ê±´ ì ìš©: ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¡°í•©ë§Œ ì¶”ì²œ ëŒ€ìƒìœ¼ë¡œ ê³ ë ¤
                filtered_results = [
                    r for r in all_combination_results 
                    if r.get('confidence_stats', {}).get('high_confidence_ratio_overall', 0) >= min_prediction_ratio
                ]
                
                # ì ìˆ˜ ê¸°ë°˜ ì„ íƒ
                def get_sort_key(x):
                    # ì ìˆ˜ ê¸°ë°˜ ì •ë ¬
                    return calculate_optimal_score(x, min_prediction_ratio=min_prediction_ratio)
                
                if filtered_results:
                    best_combination = min(filtered_results, key=get_sort_key)
                    best_conf_stats = best_combination.get('confidence_stats', {})
                    best_score = calculate_optimal_score(best_combination, min_prediction_ratio=min_prediction_ratio)
                    st.info(f"ğŸ’¡ ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ {min_prediction_ratio}% ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” {len(filtered_results)}ê°œ ì¡°í•© ì¤‘ì—ì„œ ì¶”ì²œí•©ë‹ˆë‹¤. (ì ìˆ˜: {best_score:.2f})")
                else:
                    # í•„í„°ë§ëœ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê²½ê³ ì™€ í•¨ê»˜ ì¡°ê±´ ì™„í™”
                    st.warning(f"âš ï¸ ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ {min_prediction_ratio}% ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¡°í•©ì´ ì—†ìŠµë‹ˆë‹¤.")
                    # ì¡°ê±´ì„ 10%ë¡œ ì™„í™”í•˜ì—¬ ì¬ì‹œë„
                    filtered_results = [
                        r for r in all_combination_results 
                        if r.get('confidence_stats', {}).get('high_confidence_ratio_overall', 0) >= 10
                    ]
                    if filtered_results:
                        best_combination = min(filtered_results, key=get_sort_key)
                        best_conf_stats = best_combination.get('confidence_stats', {})
                        best_score = calculate_optimal_score(best_combination, min_prediction_ratio=10)
                        st.info(f"ğŸ’¡ ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ 10% ì¡°ê±´ìœ¼ë¡œ ì™„í™”í•˜ì—¬ ì¶”ì²œí•©ë‹ˆë‹¤. ({len(filtered_results)}ê°œ ì¡°í•© ì¤‘ ì„ íƒ, ì ìˆ˜: {best_score:.2f})")
                    else:
                        # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì„ íƒí•˜ë˜ ê²½ê³  í‘œì‹œ
                        best_combination = min(all_combination_results, key=get_sort_key)
                        best_conf_stats = best_combination.get('confidence_stats', {})
                        best_score = calculate_optimal_score(best_combination, min_prediction_ratio=min_prediction_ratio)
                        st.error(f"âŒ ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¡°í•©ì´ ì—†ì–´ ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤. ì˜ˆì¸¡ ê¸°íšŒê°€ ë§¤ìš° ì ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì ìˆ˜: {best_score:.2f})")
                
                # í•„í„°ë§ ì¡°ê±´ ë§Œì¡± ì—¬ë¶€ í™•ì¸
                high_conf_ratio_overall = best_conf_stats.get('high_confidence_ratio_overall', 0)
                meets_min_requirement = high_conf_ratio_overall >= min_prediction_ratio
                
                # 2ì°¨ í•„í„°ë§: ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ ì²´í¬ (ê²½ê³ ë§Œ)
                forced_warning = ""
                if 'forced_prediction_ratio' in best_combination:
                    forced_ratio = best_combination['forced_prediction_ratio']
                    if forced_ratio > 50:
                        forced_warning = f" âš ï¸ ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ {forced_ratio:.1f}% (50% ì´ˆê³¼)"
                
                if meets_min_requirement:
                    if high_conf_ratio_overall >= 30:
                        status_icon = "âœ…"
                        status_color = "success"
                    elif high_conf_ratio_overall >= 20:
                        status_icon = "âš ï¸"
                        status_color = "warning"
                    else:
                        status_icon = "âŒ"
                        status_color = "error"
                    st.success(f"{status_icon} **ìµœì  ì¡°í•©: ìœˆë„ìš° í¬ê¸° {best_combination['window_size']}, ì„ê³„ê°’ {best_combination['threshold']}%** (ì˜ˆì¸¡ ë¹ˆë„: {high_conf_ratio_overall:.2f}%){forced_warning}")
                else:
                    st.warning(f"âš ï¸ **ìµœì  ì¡°í•©: ìœˆë„ìš° í¬ê¸° {best_combination['window_size']}, ì„ê³„ê°’ {best_combination['threshold']}%** (ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ {min_prediction_ratio}% ì¡°ê±´ ë¯¸ë§Œ: {high_conf_ratio_overall:.2f}%){forced_warning}")
                
                # ì‹ ë¢°ë„ ë¶„í¬ ê²½ê³ : ì‹¤ì œ ì‹ ë¢°ë„ ë¶„í¬ì™€ ì¶”ì²œ ì„ê³„ê°’ ë¹„êµ
                recommended_threshold = best_combination['threshold']
                recommended_window = best_combination['window_size']
                
                # ì‹¤ì œ ì‹ ë¢°ë„ ë¶„í¬ í™•ì¸ (DBì—ì„œ ì§ì ‘ ì¡°íšŒ)
                try:
                    conn = get_db_connection()
                    if conn:
                        try:
                            # í•´ë‹¹ ìœˆë„ìš° í¬ê¸°ì˜ prefixë³„ ì‹ ë¢°ë„ ê³„ì‚°
                            query = """
                                SELECT 
                                    prefix,
                                    suffix,
                                    COUNT(*) as suffix_count
                                FROM ngram_chunks
                                WHERE window_size = ?
                                GROUP BY prefix, suffix
                            """
                            
                            df_raw = pd.read_sql_query(query, conn, params=[recommended_window])
                            
                            if len(df_raw) > 0:
                                prefix_confidences = []
                                
                                for prefix in df_raw['prefix'].unique():
                                    prefix_data = df_raw[df_raw['prefix'] == prefix]
                                    b_count = prefix_data[prefix_data['suffix'] == 'b']['suffix_count'].sum() if 'b' in prefix_data['suffix'].values else 0
                                    p_count = prefix_data[prefix_data['suffix'] == 'p']['suffix_count'].sum() if 'p' in prefix_data['suffix'].values else 0
                                    total_count = prefix_data['suffix_count'].sum()
                                    
                                    if total_count > 0:
                                        b_ratio = (b_count / total_count * 100)
                                        p_ratio = (p_count / total_count * 100)
                                        confidence = max(b_ratio, p_ratio)
                                        prefix_confidences.append(confidence)
                                
                                if prefix_confidences:
                                    over_threshold_count = sum(1 for c in prefix_confidences if c >= recommended_threshold)
                                    over_threshold_ratio = (over_threshold_count / len(prefix_confidences) * 100) if prefix_confidences else 0
                                    
                                    if over_threshold_ratio < 20:
                                        st.error(f"âŒ **ì¤‘ìš” ê²½ê³ **: ì¶”ì²œëœ ì„ê³„ê°’ {recommended_threshold}%ì— í•´ë‹¹í•˜ëŠ” prefixê°€ ì „ì²´ì˜ {over_threshold_ratio:.1f}%({over_threshold_count}/{len(prefix_confidences)}ê°œ)ì— ë¶ˆê³¼í•©ë‹ˆë‹¤. ì´ ì„ê³„ê°’ì„ ì‚¬ìš©í•˜ë©´ ì˜ˆì¸¡ ê¸°íšŒê°€ ë§¤ìš° ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ 'ğŸ“Š ìœˆë„ìš° í¬ê¸°ë³„ Prefix ê´€ì¸¡ìˆ˜ ë° ì‹ ë¢°ë„ í†µê³„' ì„¹ì…˜ì—ì„œ ì‹¤ì œ ì‹ ë¢°ë„ ë¶„í¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                                    elif over_threshold_ratio < 30:
                                        st.warning(f"âš ï¸ **ì£¼ì˜**: ì¶”ì²œëœ ì„ê³„ê°’ {recommended_threshold}%ì— í•´ë‹¹í•˜ëŠ” prefixê°€ ì „ì²´ì˜ {over_threshold_ratio:.1f}%({over_threshold_count}/{len(prefix_confidences)}ê°œ)ì…ë‹ˆë‹¤. ì˜ˆì¸¡ ë¹ˆë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                    else:
                                        st.info(f"ğŸ’¡ ì¶”ì²œëœ ì„ê³„ê°’ {recommended_threshold}%ì— í•´ë‹¹í•˜ëŠ” prefixê°€ ì „ì²´ì˜ {over_threshold_ratio:.1f}%({over_threshold_count}/{len(prefix_confidences)}ê°œ)ì…ë‹ˆë‹¤.")
                        finally:
                            conn.close()
                except Exception as e:
                    st.warning(f"âš ï¸ ì‹¤ì œ ì‹ ë¢°ë„ ë¶„í¬ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
                col_best1, col_best2 = st.columns(2)
                
                with col_best1:
                    st.markdown("**ì„±ëŠ¥ ì§€í‘œ:**")
                    st.info(f"""
                    - ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜: {best_combination['max_consecutive_mismatches']}ê°œ
                    - ìµœëŒ€ ì—°ì† ì¼ì¹˜: {best_combination['max_consecutive_matches']}ê°œ
                    - ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ: {best_combination['max_failures']}ê°œ
                    - ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ+: {best_combination['total_consecutive_5_count']}íšŒ
                    - ì—°ì† ì¼ì¹˜ 5íšŒ+: {best_combination['total_consecutive_5_match_count']}íšŒ
                    - ì´ ì‹¤íŒ¨ íšŸìˆ˜: {best_combination['total_failures']}íšŒ
                    - í‰ê·  ì •í™•ë„: {best_combination['avg_accuracy']:.2f}%
                    """)
                
                with col_best2:
                    st.markdown("**ì‹ ë¢°ë„ í†µê³„:**")
                    # ì˜ˆì¸¡ ë¹ˆë„ ê°•ì¡°
                    if high_conf_ratio_overall >= 30:
                        prediction_status = "âœ… ì–‘í˜¸"
                    elif high_conf_ratio_overall >= 20:
                        prediction_status = "âš ï¸ ë³´í†µ"
                    else:
                        prediction_status = "âŒ ë¶€ì¡±"
                    
                    # ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
                    forced_prediction_info = ""
                    if 'forced_prediction_ratio' in best_combination:
                        forced_ratio_display = best_combination['forced_prediction_ratio']
                        if forced_ratio_display > 50:
                            forced_prediction_info = f"\n- âš ï¸ ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨: {forced_ratio_display:.2f}% (50% ì´ˆê³¼)"
                        else:
                            forced_prediction_info = f"\n- ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨: {forced_ratio_display:.2f}%"
                    
                    # ì ìˆ˜ ê³„ì‚°
                    best_score_display = calculate_optimal_score(best_combination, min_prediction_ratio=min_prediction_ratio)
                    
                    # í•„í„°ë§ ì¡°ê±´ ë§Œì¡± ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ
                    if meets_min_requirement:
                        st.info(f"""
                        - **ì˜ˆì¸¡ ë¹ˆë„**: {high_conf_ratio_overall:.2f}% ({prediction_status})
                        - ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ë¹„ìœ¨: {best_conf_stats.get('high_confidence_ratio', 0):.2f}%
                        - ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’ ì´ìƒ ë¹„ìœ¨: {high_conf_ratio_overall:.2f}% âœ…
                        - ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ìˆ˜: {best_conf_stats.get('high_confidence_count', 0)}ê°œ
                        - ì „ì²´ ì˜ˆì¸¡ ìˆ˜: {best_conf_stats.get('total_predictions', 0)}ê°œ
                        - í‰ê·  ì‹ ë¢°ë„: {best_conf_stats.get('avg_confidence', 0):.2f}%
                        - í‰ê·  ê°„ê²©: {best_conf_stats.get('avg_interval', 0):.1f}ìŠ¤í…
                        - ìµœëŒ€ ê°„ê²©: {best_conf_stats.get('max_interval', 0)}ìŠ¤í…{forced_prediction_info}
                        - **ì ìˆ˜**: {best_score_display:.2f}
                        """)
                    else:
                        st.warning(f"""
                        - **ì˜ˆì¸¡ ë¹ˆë„**: {high_conf_ratio_overall:.2f}% ({prediction_status})
                        - ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ë¹„ìœ¨: {best_conf_stats.get('high_confidence_ratio', 0):.2f}%
                        - ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’ ì´ìƒ ë¹„ìœ¨: {high_conf_ratio_overall:.2f}% âš ï¸ (ìµœì†Œ {min_prediction_ratio}% ë¯¸ë§Œ)
                        - ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ìˆ˜: {best_conf_stats.get('high_confidence_count', 0)}ê°œ
                        - ì „ì²´ ì˜ˆì¸¡ ìˆ˜: {best_conf_stats.get('total_predictions', 0)}ê°œ
                        - í‰ê·  ì‹ ë¢°ë„: {best_conf_stats.get('avg_confidence', 0):.2f}%
                        - í‰ê·  ê°„ê²©: {best_conf_stats.get('avg_interval', 0):.1f}ìŠ¤í…
                        - ìµœëŒ€ ê°„ê²©: {best_conf_stats.get('max_interval', 0)}ìŠ¤í…{forced_prediction_info}
                        - **ì ìˆ˜**: {best_score_display:.2f}
                        """)
                
                # ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„í¬ í‘œì‹œ
                st.markdown("---")
                st.markdown("### ğŸ“Š ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„í¬")
                
                conf_bins = best_conf_stats.get('confidence_bins', {})
                if conf_bins:
                    bins_data = []
                    for bin_range, count in conf_bins.items():
                        total = best_conf_stats.get('total_predictions', 1)
                        ratio = (count / total * 100) if total > 0 else 0
                        bins_data.append({
                            'ì‹ ë¢°ë„ êµ¬ê°„': bin_range + '%',
                            'ì˜ˆì¸¡ ìˆ˜': count,
                            'ë¹„ìœ¨ (%)': f"{ratio:.2f}"
                        })
                    
                    bins_df = pd.DataFrame(bins_data)
                    st.dataframe(bins_df, use_container_width=True, hide_index=True)
                    
                    # ê²½ê³  ë©”ì‹œì§€ (ê°•í™”)
                    prediction_ratio = best_conf_stats.get('prediction_ratio', 0)
                    high_conf_ratio_overall = best_conf_stats.get('high_confidence_ratio_overall', 0)
                    
                    if prediction_ratio < 50:
                        st.warning(f"âš ï¸ **ì£¼ì˜**: ì˜ˆì¸¡ ìˆ˜í–‰ ë¹„ìœ¨ì´ {prediction_ratio:.2f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    
                    # ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ ì¡°ê±´ê³¼ ë¹„êµí•˜ì—¬ ê²½ê³  ê°•í™”
                    if high_conf_ratio_overall < min_prediction_ratio:
                        st.error(f"âŒ **ê²½ê³ **: ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ì˜ˆì¸¡ì˜ ë¹„ìœ¨ì´ {high_conf_ratio_overall:.2f}%ë¡œ ì„¤ì •í•œ ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„({min_prediction_ratio}%)ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤. ë¼ì´ë¸Œ ê²Œì„ì—ì„œ ì˜ˆì¸¡ ê¸°íšŒê°€ ë§¤ìš° ì ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    elif high_conf_ratio_overall < 10:
                        st.warning(f"âš ï¸ **ì£¼ì˜**: ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ì˜ˆì¸¡ì˜ ë¹„ìœ¨ì´ {high_conf_ratio_overall:.2f}%ë¡œ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤. ì‹¤íš¨ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    elif high_conf_ratio_overall < 20:
                        st.info(f"ğŸ’¡ ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ì˜ˆì¸¡ì˜ ë¹„ìœ¨ì´ {high_conf_ratio_overall:.2f}%ì…ë‹ˆë‹¤. ì˜ˆì¸¡ ê°„ ê°„ê²©ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    max_interval = best_conf_stats.get('max_interval', 0)
                    avg_interval = best_conf_stats.get('avg_interval', 0)
                    
                    # ê°„ê²© ì„¤ëª… ì¶”ê°€
                    st.markdown("#### ğŸ“ ê°„ê²©(Interval) ì„¤ëª…")
                    st.info(f"""
                    **ê°„ê²©ì˜ ì˜ë¯¸**: ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ì˜ˆì¸¡ ì‚¬ì´ì˜ ìŠ¤í… ìˆ˜ì…ë‹ˆë‹¤.
                    
                    - **ìµœëŒ€ ê°„ê²© {max_interval}ìŠ¤í…**: ê°€ì¥ ê¸´ ëŒ€ê¸° ì‹œê°„
                      â†’ ì˜ˆ: Step 1ì—ì„œ ì˜ˆì¸¡ í›„, Step {max_interval + 1}ì—ì„œ ë‹¤ìŒ ì˜ˆì¸¡
                    - **í‰ê·  ê°„ê²© {avg_interval:.1f}ìŠ¤í…**: í‰ê·  ëŒ€ê¸° ì‹œê°„
                    
                    **ì£¼ì˜**: 
                    - ìµœëŒ€ ê°„ê²©ì´ 1ì´ë©´ â†’ ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ì´ ì—°ì†ëœ ìŠ¤í…ì— ë‚˜íƒ€ë‚¨ (ë§¤ìš° ì¢‹ìŒ)
                    - ìµœëŒ€ ê°„ê²©ì´ 10ì´ë©´ â†’ ì²« ì˜ˆì¸¡ í›„ ìµœëŒ€ 10ìŠ¤í… ëŒ€ê¸° í›„ ë‹¤ìŒ ì˜ˆì¸¡ ê°€ëŠ¥
                    - ì¤‘ê°„ì— ì„ê³„ê°’ ë¯¸ë§Œ ì˜ˆì¸¡ì´ ìˆì–´ë„ ê°„ê²©ì— í¬í•¨ë©ë‹ˆë‹¤.
                    """)
                    
                    if max_interval > 10:
                        st.warning(f"âš ï¸ **ì£¼ì˜**: ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ì˜ˆì¸¡ ê°„ ìµœëŒ€ ê°„ê²©ì´ {max_interval}ìŠ¤í…ì…ë‹ˆë‹¤. ì²« ë²ˆì§¸ ì‹¤íŒ¨ í›„ ë‹¤ìŒ ì˜ˆì¸¡ê¹Œì§€ ê¸´ ëŒ€ê¸° ì‹œê°„ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    elif max_interval > 5:
                        st.info(f"ğŸ’¡ **ì •ë³´**: ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ì˜ˆì¸¡ ê°„ ìµœëŒ€ ê°„ê²©ì´ {max_interval}ìŠ¤í…ì…ë‹ˆë‹¤. ëŒ€ê¸° ì‹œê°„ì´ ë‹¤ì†Œ ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    elif max_interval <= 1:
                        st.success(f"âœ… **ì¢‹ìŒ**: ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ì˜ˆì¸¡ ê°„ ìµœëŒ€ ê°„ê²©ì´ {max_interval}ìŠ¤í…ì…ë‹ˆë‹¤. ê±°ì˜ ë§¤ ìŠ¤í…ë§ˆë‹¤ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                
                # ìƒìœ„ 5ê°œ ì¡°í•© í‘œì‹œ
                st.markdown("---")
                st.markdown("### ğŸ“ˆ ìƒìœ„ 5ê°œ ì¡°í•©")
                
                top_5 = sorted(all_combination_results, key=lambda x: (x['max_failures'], x['total_failures']))[:5]
                
                top_5_data = []
                for idx, result in enumerate(top_5, 1):
                    top_5_data.append({
                        'ìˆœìœ„': idx,
                        'ìœˆë„ìš° í¬ê¸°': result['window_size'],
                        'ì„ê³„ê°’ (%)': result['threshold'],
                        'ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ': result['max_failures'],
                        'ì´ ì‹¤íŒ¨ íšŸìˆ˜': result['total_failures'],
                        'í‰ê·  ì •í™•ë„ (%)': f"{result['avg_accuracy']:.2f}"
                    })
                
                top_5_df = pd.DataFrame(top_5_data)
                st.dataframe(top_5_df, use_container_width=True, hide_index=True)
                
                # íˆíŠ¸ë§µ ì‹œê°í™” (ì„ íƒì‚¬í•­)
                st.markdown("---")
                st.markdown("### ğŸ”¥ ì‹¤íŒ¨ ì§€í‘œ íˆíŠ¸ë§µ")
                
                # ìœˆë„ìš° í¬ê¸° Ã— ì„ê³„ê°’ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                heatmap_data = {}
                for result in all_combination_results:
                    window = result['window_size']
                    threshold = result['threshold']
                    if window not in heatmap_data:
                        heatmap_data[window] = {}
                    heatmap_data[window][threshold] = result['max_failures']
                
                # DataFrameìœ¼ë¡œ ë³€í™˜
                heatmap_df = pd.DataFrame(heatmap_data).T
                heatmap_df = heatmap_df.sort_index()
                heatmap_df = heatmap_df.sort_index(axis=1)
                
                st.dataframe(heatmap_df, use_container_width=True)
                st.caption("ê°’ì´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤ (ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ)")
            else:
                st.warning("âš ï¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"âŒ ìµœì  ì¡°í•© íƒìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    # ì˜ˆì¸¡ê°’ í…Œì´ë¸” ì €ì¥/ì—…ë°ì´íŠ¸ ì„¹ì…˜
    st.markdown("---")
    st.header("ğŸ’¾ ì˜ˆì¸¡ê°’ í…Œì´ë¸” ì €ì¥/ì—…ë°ì´íŠ¸")
    st.markdown("ì´ì „ ë°ì´í„°ë¡œ ì˜ˆì¸¡ê°’ì„ ê³„ì‚°í•˜ì—¬ DB í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤. ë¼ì´ë¸Œ ê²Œì„ ì „ì— ì‹¤í–‰í•˜ì„¸ìš”.")
    
    col_pred1, col_pred2 = st.columns([2, 1])
    
    with col_pred1:
        # ê¸°ì¤€ grid_string_id ì„ íƒ
        df_all_strings = load_preprocessed_data()
        if len(df_all_strings) > 0:
            # grid_string_idì™€ ì •ë³´ë¥¼ í•¨ê»˜ í‘œì‹œ
            grid_string_options = []
            for _, row in df_all_strings.iterrows():
                display_text = f"ID {row['id']} - ê¸¸ì´ {row['string_length']} - {row['created_at']}"
                grid_string_options.append((row['id'], display_text))
            
            # ìµœì‹  ê²ƒë¶€í„° í‘œì‹œ
            grid_string_options.sort(key=lambda x: x[0], reverse=True)
            
            selected_cutoff_id = st.selectbox(
                "ê¸°ì¤€ Grid String ID (ì´ ID ì´í•˜ê°€ ì´ì „ ë°ì´í„°)",
                options=[None] + [opt[0] for opt in grid_string_options],
                format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else f"ID {x} ì´í•˜",
                key="pred_cutoff_id"
            )
            
            if selected_cutoff_id is not None:
                selected_info = df_all_strings[df_all_strings['id'] == selected_cutoff_id].iloc[0]
                st.info(f"ì„ íƒëœ ê¸°ì¤€: ID {selected_cutoff_id} (ê¸¸ì´: {selected_info['string_length']}, ìƒì„±ì¼: {selected_info['created_at']})")
        else:
            selected_cutoff_id = None
            st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with col_pred2:
        st.markdown("<br>", unsafe_allow_html=True)
        generate_predictions_button = st.button("ì˜ˆì¸¡ê°’ ì €ì¥/ì—…ë°ì´íŠ¸", type="primary", use_container_width=True, key="generate_predictions")
    
    # ìœˆë„ìš° í¬ê¸°, ë°©ë²•, ì„ê³„ê°’ ì„ íƒ
    col_pred3, col_pred4, col_pred5 = st.columns(3)
    
    with col_pred3:
        pred_window_sizes = st.multiselect(
            "ìœˆë„ìš° í¬ê¸°",
            options=[5, 6, 7, 8, 9],
            default=[6, 7, 8, 9],
            key="pred_window_sizes"
        )
    
    with col_pred4:
        pred_methods = st.multiselect(
            "ì˜ˆì¸¡ ë°©ë²•",
            options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
            default=["ë¹ˆë„ ê¸°ë°˜"],
            key="pred_methods"
        )
    
    with col_pred5:
        pred_thresholds = st.multiselect(
            "ì„ê³„ê°’ (%)",
            options=[0, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100],
            default=[0, 50, 60, 70, 80, 90, 100],
            key="pred_thresholds",
            help="0ì€ ì„ê³„ê°’ ì—†ì´ ëª¨ë“  ì˜ˆì¸¡ í¬í•¨"
        )
    
    # ì˜ˆì¸¡ê°’ ì €ì¥/ì—…ë°ì´íŠ¸ ì‹¤í–‰
    if generate_predictions_button and pred_window_sizes and pred_methods and pred_thresholds and len(df_all_strings) > 0:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            status_text.text("ì˜ˆì¸¡ê°’ ê³„ì‚° ë° ì €ì¥ ì¤‘...")
            progress_bar.progress(0.1)
            
            result = save_or_update_predictions_for_historical_data(
                cutoff_grid_string_id=selected_cutoff_id,
                window_sizes=pred_window_sizes,
                methods=pred_methods,
                thresholds=pred_thresholds,
                batch_size=1000
            )
            
            progress_bar.progress(1.0)
            status_text.empty()
            progress_bar.empty()
            
            if result:
                st.success(f"âœ… ì˜ˆì¸¡ê°’ ì €ì¥/ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                col_res1, col_res2, col_res3, col_res4 = st.columns(4)
                with col_res1:
                    st.metric("ì´ ì €ì¥/ì—…ë°ì´íŠ¸", f"{result['total_saved']:,}ê°œ")
                with col_res2:
                    st.metric("ìƒˆ ë ˆì½”ë“œ", f"{result['new_records']:,}ê°œ")
                with col_res3:
                    st.metric("ì—…ë°ì´íŠ¸", f"{result['updated_records']:,}ê°œ")
                with col_res4:
                    st.metric("ê³ ìœ  Prefix ìˆ˜", f"{result['unique_prefixes']:,}ê°œ")
            else:
                st.error("âŒ ì˜ˆì¸¡ê°’ ì €ì¥/ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"âŒ ì˜ˆì¸¡ê°’ ì €ì¥/ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    # ìƒˆ ë°ì´í„° ìµœì  ë¶„ì„ ì„¹ì…˜
    st.markdown("---")
    st.header("ğŸ¯ ìƒˆ ë°ì´í„° ìµœì  ë¶„ì„")
    st.markdown("ì €ì¥ëœ ì˜ˆì¸¡ê°’ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ë§Œìœ¼ë¡œ ìµœì  ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤.")
    
    col_opt_new1, col_opt_new2 = st.columns([2, 1])
    
    with col_opt_new1:
        # ê¸°ì¤€ grid_string_id ì„ íƒ (ì„¸ì…˜ ìƒíƒœë¡œ ìœ ì§€)
        if 'opt_cutoff_id_new' not in st.session_state:
            st.session_state.opt_cutoff_id_new = None
        
        if len(df_all_strings) > 0:
            grid_string_options_new = []
            for _, row in df_all_strings.iterrows():
                display_text = f"ID {row['id']} - ê¸¸ì´ {row['string_length']} - {row['created_at']}"
                grid_string_options_new.append((row['id'], display_text))
            
            grid_string_options_new.sort(key=lambda x: x[0], reverse=True)
            
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ê°’ì´ ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
            default_index = 0
            if st.session_state.opt_cutoff_id_new is not None:
                # ì €ì¥ëœ ê°’ì´ ì˜µì…˜ì— ìˆëŠ”ì§€ í™•ì¸
                try:
                    default_index = [opt[0] for opt in grid_string_options_new].index(st.session_state.opt_cutoff_id_new)
                except ValueError:
                    default_index = 0
            
            selected_cutoff_id_new = st.selectbox(
                "ê¸°ì¤€ Grid String ID (ì´ ID ì´í›„ê°€ ìƒˆë¡œìš´ ë°ì´í„°)",
                options=[opt[0] for opt in grid_string_options_new],
                format_func=lambda x: f"ID {x} ì´í›„",
                index=default_index,
                key="opt_cutoff_id_new_selectbox",
                help="ì´ ID ì´í›„ì˜ ë°ì´í„°ë§Œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ì´ ID ì´í•˜ì˜ ë°ì´í„°ëŠ” í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤."
            )
            
            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.opt_cutoff_id_new = selected_cutoff_id_new
            
            if selected_cutoff_id_new is not None:
                selected_info_new = df_all_strings[df_all_strings['id'] == selected_cutoff_id_new].iloc[0]
                new_data_count = len(df_all_strings[df_all_strings['id'] > selected_cutoff_id_new])
                st.info(f"ì„ íƒëœ ê¸°ì¤€: ID {selected_cutoff_id_new} (ê¸¸ì´: {selected_info_new['string_length']}, ìƒì„±ì¼: {selected_info_new['created_at']}) | ìƒˆë¡œìš´ ë°ì´í„°: {new_data_count}ê°œ")
        else:
            selected_cutoff_id_new = None
            st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with col_opt_new2:
        st.markdown("<br>", unsafe_allow_html=True)
        start_new_analysis_button = st.button("ìµœì  ì¡°í•© ì°¾ê¸°", type="primary", use_container_width=True, key="start_new_analysis")
    
    # ìœˆë„ìš° í¬ê¸° ë° ì„ê³„ê°’ ë²”ìœ„ ì„¤ì •
    col_opt_new3, col_opt_new4, col_opt_new5 = st.columns(3)
    
    with col_opt_new3:
        new_window_sizes = st.multiselect(
            "ìœˆë„ìš° í¬ê¸°",
            options=[5, 6, 7, 8, 9],
            default=[6, 7, 8],
            key="new_window_sizes"
        )
    
    with col_opt_new4:
        new_threshold_start = st.number_input(
            "ì„ê³„ê°’ ì‹œì‘ (%)",
            min_value=0,
            max_value=100,
            value=50,
            step=1,
            key="new_threshold_start"
        )
        new_threshold_end = st.number_input(
            "ì„ê³„ê°’ ë (%)",
            min_value=0,
            max_value=100,
            value=60,
            step=1,
            key="new_threshold_end"
        )
        new_threshold_step = st.number_input(
            "ì„ê³„ê°’ ê°„ê²© (%)",
            min_value=1,
            max_value=20,
            value=1,
            step=1,
            key="new_threshold_step"
        )
    
    with col_opt_new5:
        new_method = st.selectbox(
            "ì˜ˆì¸¡ ë°©ë²•",
            options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
            index=0,
            key="new_method"
        )
        use_stored = st.checkbox(
            "ì €ì¥ëœ ì˜ˆì¸¡ê°’ ì‚¬ìš©",
            value=True,
            key="use_stored_predictions",
            help="ì²´í¬í•˜ë©´ DB í…Œì´ë¸”ì—ì„œ ì¡°íšŒ, í•´ì œí•˜ë©´ ì‹¤ì‹œê°„ ê³„ì‚°"
        )
    
    # ìµœì  ë¶„ì„ ì‹¤í–‰
    # selected_cutoff_id_newì€ ì„¸ì…˜ ìƒíƒœì—ì„œ ê°€ì ¸ì˜¤ê¸°
    if 'opt_cutoff_id_new' in st.session_state:
        selected_cutoff_id_new = st.session_state.opt_cutoff_id_new
    else:
        selected_cutoff_id_new = None
    
    if start_new_analysis_button and selected_cutoff_id_new and new_window_sizes:
        if new_threshold_start > new_threshold_end:
            st.warning("âš ï¸ ì„ê³„ê°’ ì‹œì‘ê°’ì´ ëê°’ë³´ë‹¤ í½ë‹ˆë‹¤.")
        else:
            new_threshold_list = list(range(new_threshold_start, new_threshold_end + 1, new_threshold_step))
            
            if not new_threshold_list:
                st.warning("âš ï¸ ìœ íš¨í•œ ì„ê³„ê°’ ë²”ìœ„ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    status_text.text("ìµœì  ì¡°í•© ë¶„ì„ ì¤‘...")
                    progress_bar.progress(0.1)
                    
                    all_combination_results = find_optimal_combination_for_new_data(
                        cutoff_grid_string_id=selected_cutoff_id_new,
                        window_sizes=new_window_sizes,
                        thresholds=new_threshold_list,
                        method=new_method,
                        use_stored_predictions=use_stored
                    )
                    
                    progress_bar.progress(1.0)
                    status_text.empty()
                    progress_bar.empty()
                    
                    if all_combination_results:
                        # ê²°ê³¼ í‘œì‹œ (ê¸°ì¡´ ìµœì  íƒìƒ‰ ì„¹ì…˜ê³¼ ë™ì¼í•œ í˜•ì‹)
                        st.markdown("### ğŸ“Š ì¡°í•©ë³„ ë¹„êµ")
                        
                        # ì „ì²´ í†µê³„ í‘œì‹œ
                        first_result = all_combination_results[0]
                        total_count = len(df_all_strings[df_all_strings['id'] > selected_cutoff_id_new])
                        total_count_valid = len(df_all_strings[
                            (df_all_strings['id'] > selected_cutoff_id_new) & 
                            (df_all_strings['string_length'] >= min(new_window_sizes))
                        ])
                        
                        st.info(f"""
                        **ì „ì²´ í†µê³„:**
                        - ì „ì²´ Grid String: {total_count_valid}ê°œ (ìœˆë„ìš° í¬ê¸° ì¡°ê±´ ì¶©ì¡±)
                        - ìœ íš¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {first_result.get('valid_test_count', 0)}ê°œ ({first_result.get('valid_ratio', 0):.1f}%)
                        - ìŠ¤í‚µëœ ì¼€ì´ìŠ¤: {first_result.get('skipped_count', 0)}ê°œ ({first_result.get('skipped_ratio', 0):.1f}%)
                          - ë¶ˆì¼ì¹˜ ìƒíƒœë¡œ ì¢…ë£Œ: {first_result.get('ending_mismatch_count', 0)}ê°œ
                        - ì˜ë¦° ì¼€ì´ìŠ¤: {first_result.get('truncated_count', 0)}ê°œ
                        - ì˜ë¦° ìŠ¤í… ìˆ˜: {first_result.get('total_truncated_steps', 0)}ê°œ
                        """)
                        
                        comparison_data = []
                        for result in all_combination_results:
                            conf_stats = result.get('confidence_stats', {})
                            comparison_data.append({
                                'ìœˆë„ìš° í¬ê¸°': result['window_size'],
                                'ì„ê³„ê°’ (%)': result['threshold'],
                                'ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ': result['max_failures'],
                                'ì´ ì‹¤íŒ¨ íšŸìˆ˜': result['total_failures'],
                                'í‰ê·  ì •í™•ë„ (%)': f"{result['avg_accuracy']:.2f}",
                                'ì˜ˆì¸¡ ìˆ˜í–‰ ë¹„ìœ¨ (%)': f"{conf_stats.get('prediction_ratio', 0):.2f}",
                                'ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’ ì´ìƒ ë¹„ìœ¨ (%)': f"{conf_stats.get('high_confidence_ratio_overall', 0):.2f}",
                                'í‰ê·  ê°„ê²©': f"{conf_stats.get('avg_interval', 0):.1f}",
                                'ìµœëŒ€ ê°„ê²©': conf_stats.get('max_interval', 0),
                                'ìœ íš¨ í…ŒìŠ¤íŠ¸ ìˆ˜': result.get('valid_test_count', 0),
                                'ìŠ¤í‚µ ìˆ˜': result.get('skipped_count', 0)
                            })
                        
                        comparison_data.sort(key=lambda x: (x['ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ'], x['ì´ ì‹¤íŒ¨ íšŸìˆ˜']))
                        comparison_df = pd.DataFrame(comparison_data)
                        st.dataframe(comparison_df, use_container_width=True, hide_index=True)
                        
                        # ìµœì  ì¡°í•© ì¶”ì²œ
                        st.markdown("### ğŸ¯ ìµœì  ì¡°í•© ì¶”ì²œ")
                        
                        # 1ì°¨ í•„í„°ë§: ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ ì¡°ê±´ (í•„ìˆ˜, ê¸°ë³¸ê°’ 20%)
                        min_prediction_ratio_new = 20
                        filtered_results_new = [
                            r for r in all_combination_results 
                            if r.get('confidence_stats', {}).get('high_confidence_ratio_overall', 0) >= min_prediction_ratio_new
                        ]
                        
                        # ì ìˆ˜ ê¸°ë°˜ ì„ íƒ
                        if filtered_results_new:
                            best_combination = min(filtered_results_new, key=lambda x: calculate_optimal_score(x, min_prediction_ratio=min_prediction_ratio_new))
                            st.info(f"ğŸ’¡ ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ {min_prediction_ratio_new}% ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” {len(filtered_results_new)}ê°œ ì¡°í•© ì¤‘ì—ì„œ ì¶”ì²œí•©ë‹ˆë‹¤.")
                        else:
                            # í•„í„°ë§ëœ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¡°ê±´ ì™„í™”í•˜ì—¬ ì¬ì‹œë„
                            filtered_results_new = [
                                r for r in all_combination_results 
                                if r.get('confidence_stats', {}).get('high_confidence_ratio_overall', 0) >= 10
                            ]
                            if filtered_results_new:
                                best_combination = min(filtered_results_new, key=lambda x: calculate_optimal_score(x, min_prediction_ratio=10))
                                st.warning(f"âš ï¸ ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ {min_prediction_ratio_new}% ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¡°í•©ì´ ì—†ì–´ 10% ì¡°ê±´ìœ¼ë¡œ ì™„í™”í•˜ì—¬ ì¶”ì²œí•©ë‹ˆë‹¤.")
                            else:
                                # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì„ íƒí•˜ë˜ ê²½ê³  í‘œì‹œ
                                best_combination = min(all_combination_results, key=lambda x: calculate_optimal_score(x, min_prediction_ratio=min_prediction_ratio_new))
                                st.error(f"âŒ ìµœì†Œ ì˜ˆì¸¡ ë¹ˆë„ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¡°í•©ì´ ì—†ì–´ ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤. ì˜ˆì¸¡ ê¸°íšŒê°€ ë§¤ìš° ì ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        
                        best_conf_stats = best_combination.get('confidence_stats', {})
                        high_conf_ratio_overall_new = best_conf_stats.get('high_confidence_ratio_overall', 0)
                        best_score_new = calculate_optimal_score(best_combination, min_prediction_ratio=min_prediction_ratio_new)
                        
                        # ì˜ˆì¸¡ ë¹ˆë„ì— ë”°ë¥¸ ìƒíƒœ í‘œì‹œ
                        if high_conf_ratio_overall_new >= 30:
                            status_icon = "âœ…"
                            status_message = f"âœ… **ìµœì  ì¡°í•©: ìœˆë„ìš° í¬ê¸° {best_combination['window_size']}, ì„ê³„ê°’ {best_combination['threshold']}%** (ì˜ˆì¸¡ ë¹ˆë„: {high_conf_ratio_overall_new:.2f}%, ì ìˆ˜: {best_score_new:.2f})"
                            st.success(status_message)
                        elif high_conf_ratio_overall_new >= 20:
                            status_message = f"âš ï¸ **ìµœì  ì¡°í•©: ìœˆë„ìš° í¬ê¸° {best_combination['window_size']}, ì„ê³„ê°’ {best_combination['threshold']}%** (ì˜ˆì¸¡ ë¹ˆë„: {high_conf_ratio_overall_new:.2f}%, ì ìˆ˜: {best_score_new:.2f})"
                            st.warning(status_message)
                        else:
                            status_message = f"âŒ **ìµœì  ì¡°í•©: ìœˆë„ìš° í¬ê¸° {best_combination['window_size']}, ì„ê³„ê°’ {best_combination['threshold']}%** (ì˜ˆì¸¡ ë¹ˆë„: {high_conf_ratio_overall_new:.2f}%, ì ìˆ˜: {best_score_new:.2f})"
                            st.error(status_message)
                        
                        col_best_new1, col_best_new2 = st.columns(2)
                        
                        with col_best_new1:
                            st.markdown("**ì„±ëŠ¥ ì§€í‘œ:**")
                            st.info(f"""
                            - ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜: {best_combination['max_consecutive_mismatches']}ê°œ
                            - ìµœëŒ€ ì—°ì† ì¼ì¹˜: {best_combination['max_consecutive_matches']}ê°œ
                            - ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ: {best_combination['max_failures']}ê°œ
                            - ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ+: {best_combination['total_consecutive_5_count']}íšŒ
                            - ì—°ì† ì¼ì¹˜ 5íšŒ+: {best_combination['total_consecutive_5_match_count']}íšŒ
                            - ì´ ì‹¤íŒ¨ íšŸìˆ˜: {best_combination['total_failures']}íšŒ
                            - í‰ê·  ì •í™•ë„: {best_combination['avg_accuracy']:.2f}%
                            """)
                        
                        with col_best_new2:
                            st.markdown("**ì‹ ë¢°ë„ í†µê³„:**")
                            high_conf_ratio_overall_display = best_conf_stats.get('high_confidence_ratio_overall', 0)
                            
                            # ì˜ˆì¸¡ ë¹ˆë„ ê°•ì¡°
                            if high_conf_ratio_overall_display >= 30:
                                prediction_status = "âœ… ì–‘í˜¸"
                            elif high_conf_ratio_overall_display >= 20:
                                prediction_status = "âš ï¸ ë³´í†µ"
                            else:
                                prediction_status = "âŒ ë¶€ì¡±"
                            
                            # ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
                            forced_prediction_info = ""
                            if 'forced_prediction_ratio' in best_combination:
                                forced_ratio_display = best_combination['forced_prediction_ratio']
                                if forced_ratio_display > 50:
                                    forced_prediction_info = f"\n- âš ï¸ ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨: {forced_ratio_display:.2f}% (50% ì´ˆê³¼)"
                                else:
                                    forced_prediction_info = f"\n- ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨: {forced_ratio_display:.2f}%"
                            
                            st.info(f"""
                            - **ì˜ˆì¸¡ ë¹ˆë„**: {high_conf_ratio_overall_display:.2f}% ({prediction_status})
                            - ì„ê³„ê°’({best_combination['threshold']}%) ì´ìƒ ë¹„ìœ¨: {best_conf_stats.get('high_confidence_ratio', 0):.2f}%
                            - ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’ ì´ìƒ ë¹„ìœ¨: {high_conf_ratio_overall_display:.2f}%
                            - ì„ê³„ê°’ ì´ìƒ ì˜ˆì¸¡ ìˆ˜: {best_conf_stats.get('high_confidence_count', 0)}ê°œ
                            - ì „ì²´ ì˜ˆì¸¡ ìˆ˜: {best_conf_stats.get('total_predictions', 0)}ê°œ
                            - í‰ê·  ì‹ ë¢°ë„: {best_conf_stats.get('avg_confidence', 0):.2f}%
                            - í‰ê·  ê°„ê²©: {best_conf_stats.get('avg_interval', 0):.1f}ìŠ¤í…
                            - ìµœëŒ€ ê°„ê²©: {best_conf_stats.get('max_interval', 0)}ìŠ¤í…{forced_prediction_info}
                            - **ì ìˆ˜**: {best_score_new:.2f}
                            """)
                    else:
                        st.warning("âš ï¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    progress_bar.empty()
                    status_text.empty()
                    st.error(f"âŒ ìµœì  ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    import traceback
                    st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    # ìœˆë„ìš° í¬ê¸°ë³„ prefix ê´€ì¸¡ìˆ˜ ë° ì‹ ë¢°ë„ í†µê³„ í‘œì‹œ
    st.markdown("---")
    # ì˜ˆì¸¡ ê¸°íšŒ ë³´ì¥ ì‹œìŠ¤í…œ (ê°•ì œ ì˜ˆì¸¡) ì„¹ì…˜
    st.markdown("---")
    st.header("ğŸ›¡ï¸ ì˜ˆì¸¡ ê¸°íšŒ ë³´ì¥ ì‹œìŠ¤í…œ (ê°•ì œ ì˜ˆì¸¡)")
    
    st.markdown("""
    **ëª©í‘œ:**
    - ì˜ˆì¸¡ ê¸°íšŒë¥¼ ë³´ì¥í•˜ë©´ì„œ ì—°ì† ì‹¤íŒ¨ë¥¼ í”¼í•˜ëŠ” ìµœì  ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤
    - ìµœëŒ€ ê°„ê²© ì œì•½ì„ ì„¤ì •í•˜ì—¬ ì˜ˆì¸¡ê°’ì´ ì—†ëŠ” ìƒíƒœë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤
    - N ìŠ¤í… ë™ì•ˆ ì˜ˆì¸¡ì´ ì—†ìœ¼ë©´ ì„ê³„ê°’ì„ ë¬´ì‹œí•˜ê³  ê°•ì œ ì˜ˆì¸¡í•©ë‹ˆë‹¤
    """)
    
    col_fallback1, col_fallback2 = st.columns([2, 1])
    
    with col_fallback1:
        # ê¸°ì¤€ grid_string_id ì„ íƒ
        if 'fallback_cutoff_id' not in st.session_state:
            st.session_state.fallback_cutoff_id = None
        
        if len(df_strings) > 0:
            grid_string_options_fallback = []
            for _, row in df_strings.iterrows():
                display_text = f"ID {row['id']} - ê¸¸ì´ {len(row['grid_string'])} - {row['created_at']}"
                grid_string_options_fallback.append((row['id'], display_text))
            
            grid_string_options_fallback.sort(key=lambda x: x[0], reverse=True)
            
            default_index_fallback = 0
            if st.session_state.fallback_cutoff_id is not None:
                try:
                    default_index_fallback = [opt[0] for opt in grid_string_options_fallback].index(st.session_state.fallback_cutoff_id)
                except ValueError:
                    default_index_fallback = 0
            
            selected_cutoff_id_fallback = st.selectbox(
                "ê¸°ì¤€ Grid String ID (ì´ ID ì´í›„ê°€ ìƒˆë¡œìš´ ë°ì´í„°)",
                options=[opt[0] for opt in grid_string_options_fallback],
                format_func=lambda x: f"ID {x} ì´í›„",
                index=default_index_fallback,
                key="fallback_cutoff_id_selectbox"
            )
            
            st.session_state.fallback_cutoff_id = selected_cutoff_id_fallback
            
            if selected_cutoff_id_fallback is not None:
                selected_info_fallback = df_strings[df_strings['id'] == selected_cutoff_id_fallback].iloc[0]
                new_data_count_fallback = len(df_strings[df_strings['id'] > selected_cutoff_id_fallback])
                st.info(f"ì„ íƒëœ ê¸°ì¤€: ID {selected_cutoff_id_fallback} | ìƒˆë¡œìš´ ë°ì´í„°: {new_data_count_fallback}ê°œ")
        else:
            selected_cutoff_id_fallback = None
            st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with col_fallback2:
        st.markdown("<br>", unsafe_allow_html=True)
        start_fallback_analysis_button = st.button("ìµœì  ì¡°í•© ì°¾ê¸°", type="primary", use_container_width=True, key="start_fallback_analysis")
    
    # ì„¤ì •
    col_fallback3, col_fallback4, col_fallback5 = st.columns(3)
    
    with col_fallback3:
        fallback_window_sizes = st.multiselect(
            "ìœˆë„ìš° í¬ê¸°",
            options=[5, 6, 7, 8, 9],
            default=[6, 7, 8],
            key="fallback_window_sizes"
        )
    
    with col_fallback4:
        fallback_threshold = st.number_input(
            "ì„ê³„ê°’ (%)",
            min_value=0,
            max_value=100,
            value=60,
            step=1,
            key="fallback_threshold",
            help="ì‹ ë¢°ë„ê°€ ì´ ê°’ ì´ìƒì¼ ë•Œë§Œ ì˜ˆì¸¡"
        )
        fallback_max_intervals = st.multiselect(
            "ìµœëŒ€ ì˜ˆì¸¡ ì—†ìŒ ê°„ê²© (ìŠ¤í…)",
            options=[5, 6, 7, 8, 9, 10],
            default=[5, 6, 7],
            key="fallback_max_intervals",
            help="ì´ ê°„ê²©ì„ ë„˜ê¸°ë©´ ì„ê³„ê°’ ë¬´ì‹œí•˜ê³  ê°•ì œ ì˜ˆì¸¡"
        )
    
    with col_fallback5:
        fallback_method = st.selectbox(
            "ì˜ˆì¸¡ ë°©ë²•",
            options=["ë¹ˆë„ ê¸°ë°˜", "ê°€ì¤‘ì¹˜ ê¸°ë°˜", "ì•ˆì „ ìš°ì„ "],
            index=0,
            key="fallback_method"
        )
    
    # ìµœì  ì¡°í•© íƒìƒ‰ ì‹¤í–‰
    if start_fallback_analysis_button and selected_cutoff_id_fallback and fallback_window_sizes and fallback_max_intervals:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            status_text.text("ì˜ˆì¸¡ ê¸°íšŒ ë³´ì¥ ì‹œìŠ¤í…œ ë¶„ì„ ì¤‘...")
            progress_bar.progress(0.1)
            
            all_combination_results = find_optimal_combination_for_new_data(
                cutoff_grid_string_id=selected_cutoff_id_fallback,
                window_sizes=fallback_window_sizes,
                thresholds=[fallback_threshold],
                method=fallback_method,
                use_stored_predictions=True,
                max_intervals=fallback_max_intervals
            )
            
            progress_bar.progress(1.0)
            status_text.empty()
            progress_bar.empty()
            
            if all_combination_results:
                st.markdown("### ğŸ“Š ì¡°í•©ë³„ ë¹„êµ")
                
                comparison_data = []
                for result in all_combination_results:
                    conf_stats = result.get('confidence_stats', {})
                    comparison_data.append({
                        'ìœˆë„ìš° í¬ê¸°': result['window_size'],
                        'ì„ê³„ê°’ (%)': result['threshold'],
                        'ìµœëŒ€ ê°„ê²©': result.get('max_interval', 'N/A'),
                        'ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ': result['max_failures'],
                        'ì´ ì‹¤íŒ¨ íšŸìˆ˜': result['total_failures'],
                        'í‰ê·  ì •í™•ë„ (%)': f"{result['avg_accuracy']:.2f}",
                        'ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨ (%)': f"{result.get('forced_prediction_ratio', 0):.2f}",
                        'í‰ê·  ê°„ê²©': f"{result.get('avg_interval', 0):.1f}",
                        'ì˜ˆì¸¡ ìˆ˜í–‰ ë¹„ìœ¨ (%)': f"{conf_stats.get('prediction_ratio', 0):.2f}",
                        'ìœ íš¨ í…ŒìŠ¤íŠ¸ ìˆ˜': result.get('valid_test_count', 0)
                    })
                
                comparison_data.sort(key=lambda x: (x['ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ'], x['ì´ ì‹¤íŒ¨ íšŸìˆ˜']))
                comparison_df = pd.DataFrame(comparison_data)
                st.dataframe(comparison_df, use_container_width=True, hide_index=True)
                
                # ìµœì  ì¡°í•© ì¶”ì²œ
                st.markdown("### ğŸ¯ ìµœì  ì¡°í•© ì¶”ì²œ")
                best_combination = min(all_combination_results, key=lambda x: (x['max_failures'], x['total_failures']))
                best_conf_stats = best_combination.get('confidence_stats', {})
                
                st.success(f"âœ… **ìµœì  ì¡°í•©: ìœˆë„ìš° í¬ê¸° {best_combination['window_size']}, ì„ê³„ê°’ {best_combination['threshold']}%, ìµœëŒ€ ê°„ê²© {best_combination.get('max_interval', 'N/A')}**")
                
                col_best_fallback1, col_best_fallback2 = st.columns(2)
                
                with col_best_fallback1:
                    st.markdown("**ì„±ëŠ¥ ì§€í‘œ:**")
                    st.info(f"""
                    - ìµœëŒ€ ì—°ì† ë¶ˆì¼ì¹˜: {best_combination['max_consecutive_mismatches']}ê°œ
                    - ìµœëŒ€ ì—°ì† ì¼ì¹˜: {best_combination['max_consecutive_matches']}ê°œ
                    - ìµœëŒ€ ì‹¤íŒ¨ ì§€í‘œ: {best_combination['max_failures']}ê°œ
                    - ì—°ì† ë¶ˆì¼ì¹˜ 5íšŒ+: {best_combination['total_consecutive_5_count']}íšŒ
                    - ì—°ì† ì¼ì¹˜ 5íšŒ+: {best_combination['total_consecutive_5_match_count']}íšŒ
                    - ì´ ì‹¤íŒ¨ íšŸìˆ˜: {best_combination['total_failures']}íšŒ
                    - í‰ê·  ì •í™•ë„: {best_combination['avg_accuracy']:.2f}%
                    """)
                
                with col_best_fallback2:
                    st.markdown("**ì˜ˆì¸¡ ê¸°íšŒ í†µê³„:**")
                    forced_ratio = best_combination.get('forced_prediction_ratio', 0)
                    avg_int = best_combination.get('avg_interval', 0)
                    total_pred = best_combination.get('total_predictions', 0)
                    forced_pred = best_combination.get('forced_predictions', 0)
                    
                    st.info(f"""
                    - ì „ì²´ ì˜ˆì¸¡ ìˆ˜: {total_pred}ê°œ
                    - ê°•ì œ ì˜ˆì¸¡ ìˆ˜: {forced_pred}ê°œ
                    - ê°•ì œ ì˜ˆì¸¡ ë¹„ìœ¨: {forced_ratio:.2f}%
                    - í‰ê·  ê°„ê²©: {avg_int:.1f} ìŠ¤í…
                    - ì˜ˆì¸¡ ìˆ˜í–‰ ë¹„ìœ¨: {best_conf_stats.get('prediction_ratio', 0):.2f}%
                    - ì „ì²´ ìŠ¤í… ëŒ€ë¹„ ì„ê³„ê°’ ì´ìƒ ë¹„ìœ¨: {best_conf_stats.get('high_confidence_ratio_overall', 0):.2f}%
                    """)
            else:
                st.warning("âš ï¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            progress_bar.empty()
            status_text.empty()
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    st.markdown("---")
    
    st.header("ğŸ“Š ìœˆë„ìš° í¬ê¸°ë³„ Prefix ê´€ì¸¡ìˆ˜ ë° ì‹ ë¢°ë„ í†µê³„")
    st.markdown("DBì—ì„œ ì§ì ‘ ì§‘ê³„í•œ ìœˆë„ìš° í¬ê¸°ë³„ prefixë³„ ê´€ì¸¡ìˆ˜ì™€ ì‹ ë¢°ë„ì…ë‹ˆë‹¤.")
    
    try:
        # ìœˆë„ìš° í¬ê¸°ë³„ prefix ê´€ì¸¡ìˆ˜ ë° ì‹ ë¢°ë„ ì§‘ê³„
        window_sizes_to_analyze = [5, 6, 7]
        
        conn = get_db_connection()
        if conn is None:
            st.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        else:
            try:
                all_results = []
                
                for window_size in window_sizes_to_analyze:
                    # í•´ë‹¹ ìœˆë„ìš° í¬ê¸°ì˜ prefixë³„ ê´€ì¸¡ìˆ˜ ë° suffixë³„ ê´€ì¸¡ìˆ˜ ì§‘ê³„
                    query = """
                        SELECT 
                            prefix,
                            suffix,
                            COUNT(*) as suffix_count
                        FROM ngram_chunks
                        WHERE window_size = ?
                        GROUP BY prefix, suffix
                        ORDER BY prefix, suffix
                    """
                    
                    df_raw = pd.read_sql_query(query, conn, params=[window_size])
                    
                    if len(df_raw) > 0:
                        # prefixë³„ë¡œ ì§‘ê³„í•˜ì—¬ ë¹„ìœ¨ ë° ì‹ ë¢°ë„ ê³„ì‚°
                        prefix_stats = []
                        
                        for prefix in df_raw['prefix'].unique():
                            prefix_data = df_raw[df_raw['prefix'] == prefix]
                            
                            # suffixë³„ ê´€ì¸¡ìˆ˜
                            b_count = prefix_data[prefix_data['suffix'] == 'b']['suffix_count'].sum() if 'b' in prefix_data['suffix'].values else 0
                            p_count = prefix_data[prefix_data['suffix'] == 'p']['suffix_count'].sum() if 'p' in prefix_data['suffix'].values else 0
                            total_count = prefix_data['suffix_count'].sum()
                            
                            # ë¹„ìœ¨ ê³„ì‚°
                            b_ratio = (b_count / total_count * 100) if total_count > 0 else 0
                            p_ratio = (p_count / total_count * 100) if total_count > 0 else 0
                            
                            # ì‹ ë¢°ë„ = max(ë¹„ìœ¨ë“¤)
                            confidence = max(b_ratio, p_ratio)
                            
                            # ì˜ˆì¸¡ê°’ (ë” ë†’ì€ ë¹„ìœ¨ì˜ suffix)
                            predicted = 'b' if b_ratio > p_ratio else ('p' if p_ratio > b_ratio else None)
                            
                            # ê°€ëŠ¥í•œ suffix ëª©ë¡
                            possible_suffixes = ', '.join(prefix_data['suffix'].unique())
                            
                            prefix_stats.append({
                                'ìœˆë„ìš° í¬ê¸°': window_size,
                                'Prefix': prefix,
                                'ì´ ê´€ì¸¡ìˆ˜': total_count,
                                "b ê´€ì¸¡ìˆ˜": b_count,
                                "p ê´€ì¸¡ìˆ˜": p_count,
                                "b ë¹„ìœ¨ (%)": f"{b_ratio:.2f}",
                                "p ë¹„ìœ¨ (%)": f"{p_ratio:.2f}",
                                'ì‹ ë¢°ë„ (%)': f"{confidence:.2f}",
                                'ì˜ˆì¸¡ê°’': predicted if predicted else '-',
                                'ê°€ëŠ¥í•œ Suffix': possible_suffixes
                            })
                        
                        if prefix_stats:
                            df_prefix_stats = pd.DataFrame(prefix_stats)
                            # ê´€ì¸¡ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
                            df_prefix_stats = df_prefix_stats.sort_values('ì´ ê´€ì¸¡ìˆ˜', ascending=False)
                            all_results.append(df_prefix_stats)
                
                if all_results:
                    # ëª¨ë“  ê²°ê³¼ í•©ì¹˜ê¸°
                    combined_df = pd.concat(all_results, ignore_index=True)
                    
                    # í…Œì´ë¸”ë¡œ í‘œì‹œ
                    st.dataframe(combined_df, use_container_width=True, hide_index=True)
                    
                    # ìš”ì•½ í†µê³„
                    st.markdown("### ğŸ“ˆ ìš”ì•½ í†µê³„")
                    summary_data = []
                    all_confidence_distributions = {}  # ìœˆë„ìš° í¬ê¸°ë³„ 1% ë‹¨ìœ„ ë¶„í¬ ì €ì¥
                    
                    for window_size in window_sizes_to_analyze:
                        window_df = combined_df[combined_df['ìœˆë„ìš° í¬ê¸°'] == window_size]
                        if len(window_df) > 0:
                            # ì‹ ë¢°ë„ í†µê³„ ê³„ì‚°
                            confidences = pd.to_numeric(window_df['ì‹ ë¢°ë„ (%)'], errors='coerce')
                            
                            # 1% ë‹¨ìœ„ ì‹ ë¢°ë„ êµ¬ê°„ë³„ í†µê³„ (0-100%)
                            confidence_bins_1pct = {}
                            for i in range(0, 100):
                                confidence_bins_1pct[f"{i}-{i+1}"] = 0
                            
                            # 100%ëŠ” ë³„ë„ ì²˜ë¦¬
                            confidence_bins_1pct['100'] = 0
                            
                            for conf in confidences:
                                if pd.notna(conf):
                                    conf_int = int(conf)
                                    if conf >= 100:
                                        confidence_bins_1pct['100'] += 1
                                    elif conf_int < 100:
                                        bin_key = f"{conf_int}-{conf_int+1}"
                                        if bin_key in confidence_bins_1pct:
                                            confidence_bins_1pct[bin_key] += 1
                            
                            # 0ì´ ì•„ë‹Œ êµ¬ê°„ë§Œ ì €ì¥
                            filtered_bins = {k: v for k, v in confidence_bins_1pct.items() if v > 0}
                            all_confidence_distributions[window_size] = filtered_bins
                            
                            total_prefixes = len(window_df)
                            
                            # ê¸°ë³¸ í†µê³„
                            summary_data.append({
                                'ìœˆë„ìš° í¬ê¸°': window_size,
                                'ê³ ìœ  Prefix ìˆ˜': total_prefixes,
                                'ì´ ê´€ì¸¡ìˆ˜': window_df['ì´ ê´€ì¸¡ìˆ˜'].sum(),
                                'í‰ê·  ê´€ì¸¡ìˆ˜': f"{window_df['ì´ ê´€ì¸¡ìˆ˜'].mean():.2f}",
                                'í‰ê·  ì‹ ë¢°ë„ (%)': f"{confidences.mean():.2f}",
                                'ìµœì†Œ ì‹ ë¢°ë„ (%)': f"{confidences.min():.2f}",
                                'ìµœëŒ€ ì‹ ë¢°ë„ (%)': f"{confidences.max():.2f}"
                            })
                    
                    if summary_data:
                        summary_df = pd.DataFrame(summary_data)
                        st.dataframe(summary_df, use_container_width=True, hide_index=True)
                        
                        # ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„í¬ (1% ë‹¨ìœ„) - ìœˆë„ìš° í¬ê¸°ë³„ë¡œ í‘œì‹œ
                        st.markdown("### ğŸ“Š ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„í¬ (1% ë‹¨ìœ„)")
                        
                        for window_size in window_sizes_to_analyze:
                            if window_size in all_confidence_distributions:
                                bins = all_confidence_distributions[window_size]
                                
                                if bins:
                                    with st.expander(f"ìœˆë„ìš° í¬ê¸° {window_size} - ì‹ ë¢°ë„ ë¶„í¬", expanded=False):
                                        # ë¶„í¬ ë°ì´í„° ì¤€ë¹„
                                        dist_data = []
                                        
                                        def sort_key(x):
                                            """ì •ë ¬ í‚¤ í•¨ìˆ˜: êµ¬ê°„ì„ ìˆ«ìë¡œ ë³€í™˜"""
                                            key = x[0]
                                            if key == '100':
                                                return 100.0
                                            elif '-' in key:
                                                return float(key.split('-')[0])
                                            else:
                                                return float(key)
                                        
                                        for bin_range, count in sorted(bins.items(), key=sort_key):
                                            total_prefixes = summary_df[summary_df['ìœˆë„ìš° í¬ê¸°'] == window_size]['ê³ ìœ  Prefix ìˆ˜'].iloc[0]
                                            ratio = (count / total_prefixes * 100) if total_prefixes > 0 else 0
                                            dist_data.append({
                                                'ì‹ ë¢°ë„ êµ¬ê°„ (%)': bin_range,
                                                'Prefix ìˆ˜': count,
                                                'ë¹„ìœ¨ (%)': f"{ratio:.2f}"
                                            })
                                        
                                        dist_df = pd.DataFrame(dist_data)
                                        
                                        # ì—¬ëŸ¬ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í‘œì‹œ (ê°€ë…ì„± í–¥ìƒ)
                                        num_cols = 3
                                        cols = st.columns(num_cols)
                                        
                                        rows_per_col = (len(dist_df) + num_cols - 1) // num_cols
                                        
                                        for col_idx in range(num_cols):
                                            with cols[col_idx]:
                                                start_idx = col_idx * rows_per_col
                                                end_idx = min((col_idx + 1) * rows_per_col, len(dist_df))
                                                if start_idx < len(dist_df):
                                                    col_df = dist_df.iloc[start_idx:end_idx]
                                                    st.dataframe(col_df, use_container_width=True, hide_index=True)
                                        
                                        # íˆìŠ¤í† ê·¸ë¨ ìŠ¤íƒ€ì¼ ì‹œê°í™” (í…ìŠ¤íŠ¸ ê¸°ë°˜)
                                        st.markdown("#### ì‹œê°í™”")
                                        max_count = max(bins.values()) if bins else 1
                                        
                                        def sort_key(x):
                                            """ì •ë ¬ í‚¤ í•¨ìˆ˜: êµ¬ê°„ì„ ìˆ«ìë¡œ ë³€í™˜"""
                                            key = x[0]
                                            if key == '100':
                                                return 100.0
                                            elif '-' in key:
                                                return float(key.split('-')[0])
                                            else:
                                                return float(key)
                                        
                                        for bin_range, count in sorted(bins.items(), key=sort_key):
                                            total_prefixes = summary_df[summary_df['ìœˆë„ìš° í¬ê¸°'] == window_size]['ê³ ìœ  Prefix ìˆ˜'].iloc[0]
                                            ratio = (count / total_prefixes * 100) if total_prefixes > 0 else 0
                                            bar_length = int((count / max_count) * 50) if max_count > 0 else 0
                                            bar = 'â–ˆ' * bar_length
                                            st.text(f"{bin_range:>8}%: {bar} {count:>4}ê°œ ({ratio:>5.2f}%)")
                                        
                                        # ìš”ì•½ ì •ë³´
                                        def get_bin_value(k):
                                            """êµ¬ê°„ í‚¤ë¥¼ ìˆ«ìë¡œ ë³€í™˜"""
                                            if k == '100':
                                                return 100.0
                                            elif '-' in k:
                                                return float(k.split('-')[0])
                                            else:
                                                return float(k)
                                        
                                        over_60_count = sum(v for k, v in bins.items() if get_bin_value(k) >= 60)
                                        over_60_ratio = (over_60_count / total_prefixes * 100) if total_prefixes > 0 else 0
                                        over_70_count = sum(v for k, v in bins.items() if get_bin_value(k) >= 70)
                                        over_80_count = sum(v for k, v in bins.items() if get_bin_value(k) >= 80)
                                        
                                        st.markdown("---")
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.metric("60% ì´ìƒ Prefix", f"{over_60_count}ê°œ", f"{over_60_ratio:.1f}%")
                                        with col2:
                                            st.metric("70% ì´ìƒ Prefix", f"{over_70_count}ê°œ")
                                        with col3:
                                            st.metric("80% ì´ìƒ Prefix", f"{over_80_count}ê°œ")
                                        
                                        # ê²½ê³  ë©”ì‹œì§€
                                        if over_60_ratio < 20:
                                            st.warning(f"âš ï¸ **ê²½ê³ **: 60% ì´ìƒ ì‹ ë¢°ë„ì¸ prefixê°€ {over_60_ratio:.1f}%ë¡œ ë§¤ìš° ì ìŠµë‹ˆë‹¤. ì„ê³„ê°’ 60%ë¥¼ ì‚¬ìš©í•˜ë©´ ì˜ˆì¸¡ ê¸°íšŒê°€ ë§¤ìš° ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                        elif over_60_ratio < 30:
                                            st.info(f"ğŸ’¡ **ì •ë³´**: 60% ì´ìƒ ì‹ ë¢°ë„ì¸ prefixê°€ {over_60_ratio:.1f}%ì…ë‹ˆë‹¤. ì„ê³„ê°’ 60% ì‚¬ìš© ì‹œ ì˜ˆì¸¡ ë¹ˆë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                else:
                                    st.info(f"ìœˆë„ìš° í¬ê¸° {window_size}: ë°ì´í„° ì—†ìŒ")
                else:
                    st.warning("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ngram_chunksê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                
            except Exception as e:
                st.error(f"âŒ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                import traceback
                st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            finally:
                conn.close()
            
    except Exception as e:
        st.error(f"âŒ ìœˆë„ìš° í¬ê¸°ë³„ prefix ê´€ì¸¡ìˆ˜ ë° ì‹ ë¢°ë„ í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    # ì•™ìƒë¸” íˆ¬í‘œ ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ ì„¹ì…˜ (ë…ë¦½, í™”ë©´ ê°€ì¥ ë§ˆì§€ë§‰)
    st.markdown("---")
    st.header("ì•™ìƒë¸” íˆ¬í‘œ ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦")
    st.markdown("ìƒˆë¡œ ì¶”ê°€ë˜ëŠ” grid_stringì„ ì•™ìƒë¸” íˆ¬í‘œ ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤ ë°©ì‹ìœ¼ë¡œ ìë™ í…ŒìŠ¤íŠ¸í•˜ì—¬ ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # ì„¤ì • ì„¹ì…˜
    # Session state ì´ˆê¸°í™”
    if 'validation_ensemble_cutoff_id' not in st.session_state:
        st.session_state.validation_ensemble_cutoff_id = None
    
    with st.form("validation_ensemble_settings_form", clear_on_submit=False):
        st.markdown("### ì„¤ì •")
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # ê¸°ì¤€ Grid String ID ì„ íƒ
            df_all_strings = load_preprocessed_data()
            if len(df_all_strings) > 0:
                # grid_string_idì™€ ì •ë³´ë¥¼ í•¨ê»˜ í‘œì‹œ
                grid_string_options = []
                for _, row in df_all_strings.iterrows():
                    display_text = f"ID {row['id']} - ê¸¸ì´ {row['string_length']} - {row['created_at']}"
                    grid_string_options.append((row['id'], display_text))
                
                # ìµœì‹  ê²ƒë¶€í„° í‘œì‹œ
                grid_string_options.sort(key=lambda x: x[0], reverse=True)
                
                # í˜„ì¬ ì„ íƒëœ ê°’ ê°€ì ¸ì˜¤ê¸°
                current_selected = st.session_state.validation_ensemble_cutoff_id
                default_index = 0
                if current_selected is not None:
                    option_ids = [None] + [opt[0] for opt in grid_string_options]
                    if current_selected in option_ids:
                        default_index = option_ids.index(current_selected)
                
                selected_cutoff_id = st.selectbox(
                    "ê¸°ì¤€ Grid String ID (ì´ ID ì´í›„ì˜ ë°ì´í„° ê²€ì¦)",
                    options=[None] + [opt[0] for opt in grid_string_options],
                    format_func=lambda x: "ì „ì²´ ë°ì´í„°" if x is None else f"ID {x} ì´í›„",
                    index=default_index,
                    key="validation_ensemble_cutoff_id_select"
                )
                
                if selected_cutoff_id is not None:
                    selected_info = df_all_strings[df_all_strings['id'] == selected_cutoff_id].iloc[0]
                    st.info(f"ì„ íƒëœ ê¸°ì¤€: ID {selected_cutoff_id} (ê¸¸ì´: {selected_info['string_length']}, ìƒì„±ì¼: {selected_info['created_at']})")
                    
                    # ì´í›„ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                    conn = get_db_connection()
                    if conn is not None:
                        try:
                            count_query = "SELECT COUNT(*) as count FROM preprocessed_grid_strings WHERE id > ?"
                            count_df = pd.read_sql_query(count_query, conn, params=[selected_cutoff_id])
                            after_count = count_df.iloc[0]['count']
                            st.caption(f"ê²€ì¦ ëŒ€ìƒ: {after_count}ê°œì˜ grid_string")
                        except:
                            pass
                        finally:
                            conn.close()
            else:
                selected_cutoff_id = None
                st.warning("âš ï¸ ì €ì¥ëœ grid_stringì´ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            st.markdown("<br>", unsafe_allow_html=True)
            st.markdown("**ê²€ì¦ ì„¤ì • (ê³ ì •)**")
            st.info("ìœˆë„ìš° í¬ê¸°: 7")
            st.info("ì„ê³„ê°’: ì‚¬ìš© ì•ˆí•¨")
        
        # ê²€ì¦ ì‹¤í–‰ ë²„íŠ¼
        if st.form_submit_button("ê²€ì¦ ì‹¤í–‰", type="primary", use_container_width=True):
            if selected_cutoff_id is None:
                st.warning("âš ï¸ ê¸°ì¤€ Grid String IDë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                st.session_state.validation_ensemble_cutoff_id = selected_cutoff_id
                st.session_state.validation_ensemble_results = None
                st.rerun()
    
    # ê²€ì¦ ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œ
    if 'validation_ensemble_cutoff_id' in st.session_state and st.session_state.validation_ensemble_cutoff_id is not None:
        cutoff_id = st.session_state.validation_ensemble_cutoff_id
        
        # ê²°ê³¼ê°€ ìºì‹œë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‹¤í–‰
        if 'validation_ensemble_results' in st.session_state and st.session_state.validation_ensemble_results is not None:
            batch_results = st.session_state.validation_ensemble_results
        else:
            with st.spinner("ê²€ì¦ ì‹¤í–‰ ì¤‘..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    batch_results = batch_validate_ensemble_scenario(
                        cutoff_id,
                        window_size=7,
                        use_threshold=False
                    )
                    
                    if batch_results is not None:
                        st.session_state.validation_ensemble_results = batch_results
                    else:
                        st.error("ê²€ì¦ ì‹¤í–‰ ì‹¤íŒ¨")
                        batch_results = None
                        
                except Exception as e:
                    st.error(f"ê²€ì¦ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    import traceback
                    st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                    batch_results = None
                finally:
                    progress_bar.empty()
                    status_text.empty()
        
        # ê²°ê³¼ í‘œì‹œ
        if batch_results is not None and len(batch_results['results']) > 0:
            summary = batch_results['summary']
            results = batch_results['results']
            
            # ìš”ì•½ í†µê³„
            st.markdown("---")
            st.markdown("### ìš”ì•½ í†µê³„")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì´ Grid String ìˆ˜", f"{summary['total_grid_strings']}")
            with col2:
                st.metric("í‰ê·  ì •í™•ë„", f"{summary['avg_accuracy']:.2f}%")
            with col3:
                st.metric("ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", f"{summary['max_consecutive_failures']}")
            with col4:
                st.metric("í‰ê·  ìµœëŒ€ ì—°ì† ì‹¤íŒ¨", f"{summary['avg_max_consecutive_failures']:.2f}")
            
            # ì „ì²´ í†µê³„
            st.markdown("---")
            st.markdown("### ì „ì²´ í†µê³„")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì´ ìŠ¤í… ìˆ˜", f"{summary['total_steps']}")
            with col2:
                st.metric("ì´ ì‹¤íŒ¨ íšŸìˆ˜", f"{summary['total_failures']}")
            
            # Grid Stringë³„ ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
            st.markdown("---")
            st.markdown("### Grid Stringë³„ ìƒì„¸ ê²°ê³¼")
            
            results_data = []
            for result in results:
                results_data.append({
                    'Grid String ID': result['grid_string_id'],
                    'ìµœëŒ€ ì—°ì† ì‹¤íŒ¨': result['max_consecutive_failures'],
                    'ì´ ìŠ¤í…': result['total_steps'],
                    'ì´ ì‹¤íŒ¨': result['total_failures'],
                    'ì •í™•ë„ (%)': f"{result['accuracy']:.2f}"
                })
            
            results_df = pd.DataFrame(results_data)
            st.dataframe(results_df, use_container_width=True, hide_index=True)
            
            # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
            st.markdown("---")
            st.markdown("### ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ë¶„í¬")
            
            max_failures_list = [r['max_consecutive_failures'] for r in results]
            if len(max_failures_list) > 0:
                max_value = max(max_failures_list)
                
                # êµ¬ê°„ë³„ ë¶„í¬ ê³„ì‚°
                bins = defaultdict(int)
                for value in max_failures_list:
                    if value == 0:
                        bins['0'] += 1
                    elif value <= 2:
                        bins['1-2'] += 1
                    elif value <= 5:
                        bins['3-5'] += 1
                    elif value <= 10:
                        bins['6-10'] += 1
                    else:
                        bins['11+'] += 1
                
                # íˆìŠ¤í† ê·¸ë¨ í‘œì‹œ
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.markdown("#### êµ¬ê°„ë³„ ë¶„í¬")
                    max_count = max(bins.values()) if bins else 1
                    
                    for bin_range, count in sorted(bins.items(), key=lambda x: {
                        '0': 0, '1-2': 1, '3-5': 2, '6-10': 3, '11+': 4
                    }.get(x[0], 5)):
                        ratio = (count / len(results) * 100) if len(results) > 0 else 0
                        bar_length = int((count / max_count) * 50) if max_count > 0 else 0
                        bar = 'â–ˆ' * bar_length
                        st.text(f"{bin_range:>8}: {bar} {count:>4}ê°œ ({ratio:>5.2f}%)")
                
                with col2:
                    st.markdown("#### í†µê³„")
                    st.metric("ìµœì†Œê°’", min(max_failures_list))
                    st.metric("ìµœëŒ€ê°’", max(max_failures_list))
                    st.metric("ì¤‘ì•™ê°’", sorted(max_failures_list)[len(max_failures_list) // 2])
            
            # ì¸ì‚¬ì´íŠ¸ ë¶„ì„
            st.markdown("---")
            st.markdown("### ì¸ì‚¬ì´íŠ¸ ë¶„ì„")
            
            # ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ ë°œìƒí•œ grid_string ë¶„ì„
            max_failure_results = [r for r in results if r['max_consecutive_failures'] == summary['max_consecutive_failures']]
            if len(max_failure_results) > 0:
                st.markdown(f"#### ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ ({summary['max_consecutive_failures']}íšŒ) ë°œìƒ Grid String")
                max_failure_ids = [r['grid_string_id'] for r in max_failure_results]
                st.info(f"Grid String ID: {', '.join(map(str, max_failure_ids))}")
            
            # ì„±ê³µë¥ ì´ ë†’ì€/ë‚®ì€ grid_string ë¶„ì„
            sorted_results = sorted(results, key=lambda x: x['accuracy'], reverse=True)
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("#### ì •í™•ë„ ìƒìœ„ 5ê°œ")
                top5_data = []
                for i, result in enumerate(sorted_results[:5], 1):
                    top5_data.append({
                        'ìˆœìœ„': i,
                        'Grid String ID': result['grid_string_id'],
                        'ì •í™•ë„ (%)': f"{result['accuracy']:.2f}",
                        'ìµœëŒ€ ì—°ì† ì‹¤íŒ¨': result['max_consecutive_failures']
                    })
                top5_df = pd.DataFrame(top5_data)
                st.dataframe(top5_df, use_container_width=True, hide_index=True)
            
            with col2:
                st.markdown("#### ì •í™•ë„ í•˜ìœ„ 5ê°œ")
                bottom5_data = []
                for i, result in enumerate(sorted_results[-5:], 1):
                    bottom5_data.append({
                        'ìˆœìœ„': len(sorted_results) - 5 + i,
                        'Grid String ID': result['grid_string_id'],
                        'ì •í™•ë„ (%)': f"{result['accuracy']:.2f}",
                        'ìµœëŒ€ ì—°ì† ì‹¤íŒ¨': result['max_consecutive_failures']
                    })
                bottom5_df = pd.DataFrame(bottom5_data)
                st.dataframe(bottom5_df, use_container_width=True, hide_index=True)
            
            # ì•™ìƒë¸” íˆ¬í‘œ ë°©ì‹ì˜ ê°•ì /ì•½ì  ë¶„ì„
            st.markdown("---")
            st.markdown("#### ì•™ìƒë¸” íˆ¬í‘œ ë°©ì‹ ë¶„ì„")
            
            # ì—°ì† ì‹¤íŒ¨ê°€ 5íšŒ ì´ìƒì¸ ê²½ìš° ë¶„ì„
            high_failure_results = [r for r in results if r['max_consecutive_failures'] >= 5]
            if len(high_failure_results) > 0:
                high_failure_ratio = (len(high_failure_results) / len(results) * 100)
                st.warning(f"âš ï¸ ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ 5íšŒ ì´ìƒì¸ Grid String: {len(high_failure_results)}ê°œ ({high_failure_ratio:.1f}%)")
                st.caption("5íšŒ ì—°ì† ì‹¤íŒ¨ëŠ” ê²Œì„ ì‹¤íŒ¨ ì¡°ê±´ì´ë¯€ë¡œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                st.success(f"âœ… ëª¨ë“  Grid Stringì—ì„œ ìµœëŒ€ ì—°ì† ì‹¤íŒ¨ê°€ 5íšŒ ë¯¸ë§Œì…ë‹ˆë‹¤.")
            
            # í‰ê·  ì •í™•ë„ ë¶„ì„
            if summary['avg_accuracy'] >= 70:
                st.success(f"âœ… í‰ê·  ì •í™•ë„ê°€ {summary['avg_accuracy']:.2f}%ë¡œ ë†’ìŠµë‹ˆë‹¤.")
            elif summary['avg_accuracy'] >= 50:
                st.info(f"ğŸ’¡ í‰ê·  ì •í™•ë„ê°€ {summary['avg_accuracy']:.2f}%ì…ë‹ˆë‹¤.")
            else:
                st.warning(f"âš ï¸ í‰ê·  ì •í™•ë„ê°€ {summary['avg_accuracy']:.2f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤.")
            
            # ì´ˆê¸°í™” ë²„íŠ¼
            if st.button("ê²°ê³¼ ì´ˆê¸°í™”", key="validation_ensemble_reset"):
                if 'validation_ensemble_results' in st.session_state:
                    del st.session_state.validation_ensemble_results
                if 'validation_ensemble_cutoff_id' in st.session_state:
                    del st.session_state.validation_ensemble_cutoff_id
                st.rerun()
        else:
            st.info("ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
if __name__ == "__main__":
    main()

