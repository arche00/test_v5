import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import os
from bs4 import BeautifulSoup
import json
import sqlite3
import uuid
import copy  # Add copy module for deep copy

# í˜ì´ì§€ ì„¤ì •ì„ ê°€ì¥ ë¨¼ì € ì‹¤í–‰
st.set_page_config(
    page_title="Pattern Analysis System V12",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS to minimize top margin
st.markdown("""
    <style>
        .block-container {
            padding-top: 1rem;
        }
    </style>
""", unsafe_allow_html=True)

# Table dimensions
TABLE_WIDTH = 15
TABLE_HEIGHT = 6

# Cell types
CELL_BANKER = 'b'
CELL_PLAYER = 'p'
CELL_TIE = 't'
CELL_EMPTY = ''

# Pattern definitions
PATTERN_WIDTH = 2
PATTERN_TOP_ROWS = [0,1,2]
PATTERN_BOTTOM_ROWS = [3,4,5]

def parse_bead_road_svg(svg_code):
    """
    HTML div ê¸°ë°˜ í…Œì´ë¸”(qV_qY, qV_qp, qV_q0 êµ¬ì¡°)ì„
    prediction_test_v4.pyì™€ í˜¸í™˜ë˜ëŠ” grid[x][y] (15x6) í˜•íƒœë¡œ íŒŒì‹±
    
    [ìœ ì§€ë³´ìˆ˜ ë…¸íŠ¸ - 2025-01-16]
    í´ë˜ìŠ¤ëª… ë³€ê²½ ì´ë ¥:
    - 2025-01-16: rg_rj â†’ qz_qC, rg_qu â†’ qz_pO, rg_rl â†’ qz_qF
    - 2025-01-17: qz_qC â†’ qV_qY, qz_pO â†’ qV_qp, qz_qF â†’ qV_q0 (ìƒˆë¡œìš´ êµ¬ì¡°)
    - 2025-01-XX: qV_qY â†’ qF_qI, qV_qp â†’ qF_p1, qV_q0 â†’ qF_qK (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: qF_qI â†’ rk_rn, qF_p1 â†’ rk_ov, qF_qK â†’ rk_rp (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: rk_rn â†’ sb_sf, rk_ov â†’ sb_ry, rk_rp â†’ sb_sh (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: sb_sf â†’ rI_rL, sb_ry â†’ rI_pq, sb_sh â†’ rI_rN (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: rI_rL â†’ ti_tl, rI_pq â†’ ti_rR, rI_rN â†’ ti_tn (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: ti_tl â†’ to_tr, ti_rR â†’ to_st, ti_tn â†’ to_tt (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: to_tr â†’ sp_ss, to_st â†’ sp_rM, to_tt â†’ sp_su (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: sp_ss â†’ sT_sW, sp_rM â†’ sT_qG, sp_su â†’ sT_sY (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: sT_sW â†’ sH_sK, sT_qG â†’ sH_so, sT_sY â†’ sH_sM (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: sH_sK â†’ tr_tu, sH_so â†’ tr_rU, sH_sM â†’ tr_tw (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: tr_tu â†’ sx_sA, tr_rU â†’ sx_rU, tr_tw â†’ sx_sC (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: sx_sA â†’ sB_sF, sx_rU â†’ sB_rL, sx_sC â†’ sB_sH (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: sB_sF â†’ rs_rv, sB_rL â†’ rs_ri, sB_sH â†’ rs_rx (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: rs_rv â†’ sf_si, rs_ri â†’ sf_sm, rs_rx â†’ sf_sn (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: sf_si â†’ o0_pb, sf_sm â†’ o0_pg, sf_sn â†’ o0_ph (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: o0_pb â†’ rK_rN, o0_pg â†’ rK_qU, o0_ph â†’ rK_rP (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: rK_rN â†’ pO_pR, rK_qU â†’ pO_pm, rK_rP â†’ pO_pT (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: pO_pR â†’ pl_po, pO_pm â†’ pl_ps, pO_pT â†’ pl_pt (ìµœì‹  êµ¬ì¡°)
    - 2025-01-XX: pl_po â†’ qR_qU, pl_ps â†’ qR_qY, pl_pt â†’ qR_qZ (ìµœì‹  êµ¬ì¡°)
    - ì´ì „: rg_rj â†’ qz_qC (ë©”ì¸ ì»¨í…Œì´ë„ˆ)
    - ì´ì „: rg_qu â†’ qz_pO (í–‰)
    - ì´ì „: rg_rl â†’ qz_qF (ì…€)
    
    ë‹¤ìŒ ë³€ê²½ ì‹œ ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤:
    - main_container = soup.find('div', class_='qR_qU')
    - rows = main_container.find_all('div', class_='qR_qY')
    - cells = row.find_all('div', class_='qR_qZ')
    """
    soup = BeautifulSoup(svg_code, 'html.parser')
    grid = [['' for _ in range(TABLE_HEIGHT)] for _ in range(TABLE_WIDTH)]
    
    # [ìœ ì§€ë³´ìˆ˜] í´ë˜ìŠ¤ëª… ë³€ê²½ ì‹œ ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •
    main_container = soup.find('div', class_='qR_qU')
    if not main_container:
        st.warning("qR_qU í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return grid
    
    # [ìœ ì§€ë³´ìˆ˜] í´ë˜ìŠ¤ëª… ë³€ê²½ ì‹œ ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •
    rows = main_container.find_all('div', class_='qR_qY')
    for row_idx, row in enumerate(rows):
        if row_idx >= TABLE_HEIGHT:
            break
        
        # [ìœ ì§€ë³´ìˆ˜] í´ë˜ìŠ¤ëª… ë³€ê²½ ì‹œ ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •
        cells = row.find_all('div', class_='qR_qZ')
        for col_idx, cell in enumerate(cells):
            if col_idx >= TABLE_WIDTH:
                break
            text_content = cell.get_text(strip=True)
            svg_elements = cell.find_all('svg')
            svg_colors = []
            for svg in svg_elements:
                paths = svg.find_all('path')
                for path in paths:
                    fill_color = path.get('fill', '')
                    if fill_color:
                        svg_colors.append(fill_color)
            result = ''
            if 'í”Œ' in text_content:
                result = 'p'
            elif 'ë±…' in text_content:
                result = 'b'
            elif 'ë¬´' in text_content:
                result = 't'
            elif svg_colors:
                for color in svg_colors:
                    if '234, 66, 66' in color or 'rgba(234, 66, 66' in color:
                        result = 'b'
                        break
                    elif '45, 139, 232' in color or 'rgb(45, 139, 232)' in color:
                        result = 'p'
                        break
            grid[col_idx][row_idx] = result
    return grid

def display_grid_with_title(grid, title):
    html = '''
    <style>
    .grid-container { display: table; border-collapse: collapse; margin: 0 auto 20px auto; width: 80%; margin-top: 0 !important; }
    .grid-row { display: table-row; }
    .bead-road-cell { width: 22px; height: 22px; border: 1px solid black; display: table-cell; 
                     text-align: center; vertical-align: middle; font-family: monospace; font-size: 0.95rem; padding: 0; }
    .banker { color: red; font-weight: bold; }
    .player { color: blue; font-weight: bold; }
    .tie { color: green; font-weight: bold; }
    .grid-title { font-size:1.05rem; font-weight:600; margin-bottom:0 !important; padding-bottom:0 !important; display:block; }
    </style>
    '''
    html += f'<span class="grid-title">{title}</span>'
    html += '<div class="grid-container">'
    for y in range(TABLE_HEIGHT):
        html += '<div class="grid-row">'
        for x in range(TABLE_WIDTH):
            cell = grid[x][y]
            css_class = 'banker' if cell == 'b' else 'player' if cell == 'p' else 'tie' if cell == 't' else ''
            html += f'<div class="bead-road-cell {css_class}">{cell.upper() if cell else "&nbsp;"}</div>'
        html += '</div>'
    html += '</div>'
    st.markdown(html, unsafe_allow_html=True)

def convert_tie_values(grid):
    """
    Convert T values according to rules.
    Updated on 2024-03-21 to match parser_v2.py logic:
    - First column: T is converted to the value from the second row for first row, or previous row for other rows
    - Other columns: T is converted based on conditional logic comparing left, left-up, and up values
    """
    converted_grid = [row[:] for row in grid]  # Copy grid
    
    # Apply 1st column rule
    for y in range(6):
        if converted_grid[0][y] == 't':
            if y == 0:  # 1st row 1st column
                converted_grid[0][y] = converted_grid[0][1]  # Convert to 2nd row 1st column value
            else:  # 1st column other rows
                converted_grid[0][y] = converted_grid[0][y-1]  # Convert to previous row value
    
    # Apply other columns rule
    for x in range(1, 15):
        for y in range(6):
            if converted_grid[x][y] == 't':
                if y == 0:  # 1st row of each column
                    converted_grid[x][y] = converted_grid[x-1][y]  # Convert to previous column 1st value
                else:  # Other rows
                    # Get values from left, left up, and up
                    left = converted_grid[x-1][y]
                    left_up = converted_grid[x-1][y-1]
                    up = converted_grid[x][y-1]
                    
                    # If left-up and up are the same, use that value
                    if left_up == up:
                        converted_grid[x][y] = up
                    # If left-up and left are the same, use that value
                    elif left_up == left:
                        converted_grid[x][y] = left
                    # Otherwise use the up value
                    else:
                        converted_grid[x][y] = up
    
    return converted_grid

def apply_column_range_to_grid(grid, start_col=0, end_col=None):
    """
    ì§€ì •í•œ ì—´ ë²”ìœ„ ë°–ì˜ ë°ì´í„°ë¥¼ ì œê±°í•œ ìƒˆë¡œìš´ ê·¸ë¦¬ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    gridì˜ ì „ì²´ í­ì€ ìœ ì§€í•˜ê³ , ë²”ìœ„ ë°–ì˜ ì…€ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ì±„ì›ë‹ˆë‹¤.
    """
    if not grid:
        return grid
    
    grid_width = len(grid)
    grid_height = len(grid[0]) if grid[0] else 0
    
    if end_col is None:
        end_col = grid_width - 1
    
    start_col = max(0, int(start_col))
    end_col = min(int(end_col), grid_width - 1)
    
    if start_col > end_col:
        return [['' for _ in range(grid_height)] for _ in range(grid_width)]
    
    new_grid = [['' for _ in range(grid_height)] for _ in range(grid_width)]
    
    for x in range(start_col, end_col + 1):
        for y in range(grid_height):
            new_grid[x][y] = grid[x][y]
    
    return new_grid

def realign_grid_by_columns(grid, start_col=0, end_col=None):
    """
    ì„ íƒí•œ ì—´ ë²”ìœ„ë¥¼ 0ë²ˆ ì—´ë¶€í„° ì°¨ë¡€ëŒ€ë¡œ 'ì™¼ìª½ ì •ë ¬'í•˜ê³ ,
    ë‚˜ë¨¸ì§€ ì—´ì€ ë¹ˆ ê°’ìœ¼ë¡œ ë‚¨ê¸°ëŠ” ê·¸ë¦¬ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì´ë ‡ê²Œ í•˜ë©´ ì„ íƒí•œ ì‹œì‘ ì—´ì´ ìƒˆë¡œìš´ 1ì—´(0ë²ˆ ì¸ë±ìŠ¤)ì²˜ëŸ¼ ë™ì‘í•©ë‹ˆë‹¤.
    """
    if not grid:
        return grid
    
    grid_width = len(grid)
    grid_height = len(grid[0]) if grid[0] else 0
    
    if end_col is None:
        end_col = grid_width - 1
    
    start_col = max(0, int(start_col))
    end_col = min(int(end_col), grid_width - 1)
    
    if start_col > end_col:
        return [['' for _ in range(grid_height)] for _ in range(grid_width)]
    
    new_grid = [['' for _ in range(grid_height)] for _ in range(grid_width)]
    dest_x = 0
    
    # ì„ íƒí•œ ì—´ ë²”ìœ„ë¥¼ 0ë²ˆ ì—´ë¶€í„° ì°¨ë¡€ëŒ€ë¡œ ë°°ì¹˜
    for x in range(start_col, end_col + 1):
        for y in range(grid_height):
            new_grid[dest_x][y] = grid[x][y]
        dest_x += 1
    
    return new_grid

# ============================================================================
# ë…ë¦½ì ì¸ ì¸ë±ìŠ¤ ê³„ì‚° í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œì— ì˜í–¥ ì—†ìŒ)
# ============================================================================

def get_cell_index(x, y):
    """
    ê·¸ë¦¬ë“œ ì…€ì˜ ì¸ë±ìŠ¤ë¥¼ ê³„ì‚° (ì—´ ìš°ì„  ìˆœì„œ)
    
    Args:
        x: ì—´ ì¸ë±ìŠ¤ (0-based)
        y: í–‰ ì¸ë±ìŠ¤ (0-based)
    
    Returns:
        int: ì…€ ì¸ë±ìŠ¤ (0-based, ì—´ ìš°ì„  ìˆœì„œ)
    """
    return y + (x * TABLE_HEIGHT)

def get_flag_triggered_cell_index(converted_group_range):
    """
    Flag ì¡°ê±´ ì¶©ì¡± ì‹œì  (Converted Grid)ì˜ ì…€ ì¸ë±ìŠ¤ë¥¼ ê³„ì‚°
    ê·¸ë£¹ì˜ ì‹œì‘ ì—´ì˜ ì²« ë²ˆì§¸ ì…€ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜
    
    Args:
        converted_group_range: Converted Gridì˜ ê·¸ë£¹ ë²”ìœ„ ë¬¸ìì—´ (ì˜ˆ: "4-6")
    
    Returns:
        int: ê·¸ë£¹ ì‹œì‘ ì—´ì˜ ì²« ë²ˆì§¸ ì…€ ì¸ë±ìŠ¤ (0-based)
    """
    try:
        parts = converted_group_range.split('-')
        if len(parts) != 2:
            return None
        
        start_col = int(parts[0]) - 1  # 1-based to 0-based
        # ê·¸ë£¹ ì‹œì‘ ì—´ì˜ ì²« ë²ˆì§¸ ì…€ ì¸ë±ìŠ¤ (í–‰ 0)
        return get_cell_index(start_col, 0)
    except Exception as e:
        return None

def count_t_before_cell_index(original_grid, cell_index):
    """
    ì›ë³¸ ê·¸ë¦¬ë“œì—ì„œ íŠ¹ì • ì…€ ì¸ë±ìŠ¤ ì´ì „ì˜ T ê°œìˆ˜ë¥¼ ê³„ì‚° (ì—´ ìš°ì„  ìˆœì„œ)
    í•´ë‹¹ ì…€ ì¸ë±ìŠ¤ ìœ„ì¹˜ì˜ ì…€ì„ í¬í•¨í•˜ì§€ ì•Šê³ , ê·¸ ì´ì „ê¹Œì§€ì˜ T ê°œìˆ˜ë¥¼ ê³„ì‚°
    
    Args:
        original_grid: ì›ë³¸ ê·¸ë¦¬ë“œ (Tê°€ ë³€í™˜ë˜ê¸° ì „)
        cell_index: ì…€ ì¸ë±ìŠ¤ (0-based, ì´ ì¸ë±ìŠ¤ ìœ„ì¹˜ì˜ ì…€ì€ í¬í•¨í•˜ì§€ ì•ŠìŒ)
    
    Returns:
        int: íŠ¹ì • ì…€ ì¸ë±ìŠ¤ ì´ì „ê¹Œì§€ì˜ T ê°œìˆ˜
    """
    if not original_grid or cell_index < 0:
        return 0
    
    t_count = 0
    current_index = 0
    
    # ì—´ ìš°ì„  ìˆœì„œë¡œ ê·¸ë¦¬ë“œë¥¼ ìˆœíšŒí•˜ë©° T ê°œìˆ˜ ì„¸ê¸°
    for x in range(TABLE_WIDTH):
        for y in range(TABLE_HEIGHT):
            # í˜„ì¬ ì¸ë±ìŠ¤ê°€ ëª©í‘œ ì…€ ì¸ë±ìŠ¤ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨ (í•´ë‹¹ ì…€ì€ í¬í•¨í•˜ì§€ ì•ŠìŒ)
            if current_index >= cell_index:
                return t_count
            if original_grid[x][y] == 't':
                t_count += 1
            current_index += 1
    
    return t_count

def adjust_index_by_t_count(cell_index, original_grid):
    """
    T ê°œìˆ˜ë§Œí¼ ì¸ë±ìŠ¤ë¥¼ ì¡°ì •
    
    Args:
        cell_index: ì›ë³¸ ì¸ë±ìŠ¤ (0-based)
        original_grid: ì›ë³¸ ê·¸ë¦¬ë“œ (Tê°€ ë³€í™˜ë˜ê¸° ì „)
    
    Returns:
        int: ì¡°ì •ëœ ì¸ë±ìŠ¤ (0-based)
    """
    if not original_grid or cell_index < 0:
        return cell_index
    
    t_count = count_t_before_cell_index(original_grid, cell_index)
    adjusted_index = max(0, cell_index - t_count)
    return adjusted_index

def get_reconstructed_group_from_index(adjusted_index):
    """
    ì¡°ì •ëœ ì¸ë±ìŠ¤ë¡œë¶€í„° T-Removed Reconstructed Gridì˜ ê·¸ë£¹ ë²”ìœ„ë¥¼ ê³„ì‚°
    ê·¸ë£¹ì€ 3ì—´ì”©ì´ë¯€ë¡œ, ì¸ë±ìŠ¤ë¥¼ ì—´ë¡œ ë³€í™˜í•˜ì—¬ ê·¸ë£¹ ë²”ìœ„ë¥¼ ê³„ì‚°
    
    Args:
        adjusted_index: ì¡°ì •ëœ ì…€ ì¸ë±ìŠ¤ (0-based)
    
    Returns:
        str: T-Removed Reconstructed Gridì˜ ê·¸ë£¹ ë²”ìœ„ (ì˜ˆ: "2-4")
    """
    if adjusted_index is None or adjusted_index < 0:
        return None
    
    # ì¸ë±ìŠ¤ë¥¼ ì—´ê³¼ í–‰ìœ¼ë¡œ ë³€í™˜
    col = adjusted_index // TABLE_HEIGHT
    row = adjusted_index % TABLE_HEIGHT
    
    # ê·¸ë£¹ì€ 3ì—´ì”©ì´ë¯€ë¡œ, ì‹œì‘ ì—´ê³¼ ë ì—´ ê³„ì‚°
    group_start_col = col
    group_end_col = group_start_col + 2  # 3ì—´ ê·¸ë£¹
    
    # 1-basedë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    return f"{group_start_col + 1}-{group_end_col + 1}"

def convert_flag_group_to_reconstructed_group(converted_group_range, original_grid):
    """
    Flag ì¡°ê±´ ì¶©ì¡± ì‹œì ì˜ Converted Grid ê·¸ë£¹ì„ T-Removed Reconstructed Grid ê·¸ë£¹ìœ¼ë¡œ ë³€í™˜
    ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„ëœ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©
    
    Args:
        converted_group_range: Converted Gridì˜ ê·¸ë£¹ ë²”ìœ„ ë¬¸ìì—´ (ì˜ˆ: "4-6")
        original_grid: ì›ë³¸ ê·¸ë¦¬ë“œ (Tê°€ ë³€í™˜ë˜ê¸° ì „)
    
    Returns:
        str: T-Removed Reconstructed Gridì˜ ê·¸ë£¹ ë²”ìœ„ (ì˜ˆ: "2-4")
    """
    # 1. Flag ì‹œì ì˜ ì…€ ì¸ë±ìŠ¤ ê³„ì‚°
    flag_index = get_flag_triggered_cell_index(converted_group_range)
    if flag_index is None:
        return converted_group_range
    
    # 2. T ê°œìˆ˜ë§Œí¼ ì¸ë±ìŠ¤ ì¡°ì •
    adjusted_index = adjust_index_by_t_count(flag_index, original_grid)
    
    # 3. ì¡°ì •ëœ ì¸ë±ìŠ¤ë¡œ ê·¸ë£¹ ê³„ì‚°
    reconstructed_group = get_reconstructed_group_from_index(adjusted_index)
    
    return reconstructed_group if reconstructed_group else converted_group_range

def get_cell_position_from_index(cell_index):
    """
    ì…€ ì¸ë±ìŠ¤ë¡œë¶€í„° ì—´ê³¼ í–‰ ìœ„ì¹˜ë¥¼ ê³„ì‚°
    
    Args:
        cell_index: ì…€ ì¸ë±ìŠ¤ (0-based)
    
    Returns:
        tuple: (ì—´, í–‰) ìœ„ì¹˜ (0-based)
    """
    if cell_index is None or cell_index < 0:
        return None, None
    
    col = cell_index // TABLE_HEIGHT
    row = cell_index % TABLE_HEIGHT
    return col, row

def get_detailed_flag_info(converted_group_range, original_grid):
    """
    Flag ì¡°ê±´ ì¶©ì¡± ì‹œì ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜
    
    Args:
        converted_group_range: Converted Gridì˜ ê·¸ë£¹ ë²”ìœ„ ë¬¸ìì—´ (ì˜ˆ: "4-6")
        original_grid: ì›ë³¸ ê·¸ë¦¬ë“œ (Tê°€ ë³€í™˜ë˜ê¸° ì „)
    
    Returns:
        dict: ìƒì„¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
            - converted_cell_index: Converted Grid ì…€ ì¸ë±ìŠ¤
            - converted_col: Converted Grid ì—´ ìœ„ì¹˜ (1-based)
            - converted_row: Converted Grid í–‰ ìœ„ì¹˜ (1-based)
            - t_count: T ê°œìˆ˜ (í•´ë‹¹ ì…€ ì¸ë±ìŠ¤ ì´ì „ê¹Œì§€)
            - t_count_debug: ë””ë²„ê¹…ìš© ìƒì„¸ T ê°œìˆ˜ ì •ë³´
            - reconstructed_cell_index: T-Removed Reconstructed Grid ì…€ ì¸ë±ìŠ¤
            - reconstructed_col: T-Removed Reconstructed Grid ì—´ ìœ„ì¹˜ (1-based)
            - reconstructed_row: T-Removed Reconstructed Grid í–‰ ìœ„ì¹˜ (1-based)
            - reconstructed_group: T-Removed Reconstructed Grid ê·¸ë£¹ ë²”ìœ„
    """
    # 1. Flag ì‹œì ì˜ ì…€ ì¸ë±ìŠ¤ ê³„ì‚°
    flag_index = get_flag_triggered_cell_index(converted_group_range)
    if flag_index is None:
        return None
    
    # 2. Converted Grid ìœ„ì¹˜ ì •ë³´
    converted_col, converted_row = get_cell_position_from_index(flag_index)
    
    # 3. T ê°œìˆ˜ ê³„ì‚° (ë””ë²„ê¹… ì •ë³´ í¬í•¨)
    t_count = count_t_before_cell_index(original_grid, flag_index)
    
    # ë””ë²„ê¹…: T ê°œìˆ˜ ê³„ì‚° ìƒì„¸ ì •ë³´
    t_count_debug = []
    current_index = 0
    for x in range(TABLE_WIDTH):
        for y in range(TABLE_HEIGHT):
            if current_index >= flag_index:
                break
            if original_grid[x][y] == 't':
                t_count_debug.append(f"ì—´{x+1}í–‰{y+1}(ì¸ë±ìŠ¤{current_index})")
            current_index += 1
        if current_index >= flag_index:
            break
    
    # 4. T ê°œìˆ˜ë§Œí¼ ì¸ë±ìŠ¤ ì¡°ì •
    adjusted_index = adjust_index_by_t_count(flag_index, original_grid)
    
    # 5. T-Removed Reconstructed Grid ìœ„ì¹˜ ì •ë³´
    reconstructed_col, reconstructed_row = get_cell_position_from_index(adjusted_index)
    
    # 6. ê·¸ë£¹ ë²”ìœ„ ê³„ì‚°
    reconstructed_group = get_reconstructed_group_from_index(adjusted_index)
    
    return {
        'converted_cell_index': flag_index,
        'converted_col': converted_col + 1 if converted_col is not None else None,  # 1-based
        'converted_row': converted_row + 1 if converted_row is not None else None,  # 1-based
        't_count': t_count,
        't_count_debug': t_count_debug,
        'reconstructed_cell_index': adjusted_index,
        'reconstructed_col': reconstructed_col + 1 if reconstructed_col is not None else None,  # 1-based
        'reconstructed_row': reconstructed_row + 1 if reconstructed_row is not None else None,  # 1-based
        'reconstructed_group': reconstructed_group
    }

# ============================================================================
# 3í–‰3ì—´ ë²”ìœ„ T ê°œìˆ˜ ê³„ì‚° í•¨ìˆ˜ (ë…ë¦½ì  êµ¬í˜„)
# ============================================================================

def count_t_in_range_3x3(original_grid):
    """
    3í–‰3ì—´ê¹Œì§€ í¬í•¨í•œ ë²”ìœ„ì˜ T ê°œìˆ˜ë¥¼ ê³„ì‚° (ë…ë¦½ì  êµ¬í˜„)
    - 1ì—´: ëª¨ë“  í–‰ (1-6í–‰, 0-based: 0-5)
    - 2ì—´: ëª¨ë“  í–‰ (1-6í–‰, 0-based: 0-5)
    - 3ì—´: 1-3í–‰ë§Œ (0-based: 0-2)
    
    Args:
        original_grid: ì›ë³¸ ê·¸ë¦¬ë“œ (Tê°€ ë³€í™˜ë˜ê¸° ì „)
    
    Returns:
        int: ë²”ìœ„ ë‚´ì˜ T ê°œìˆ˜
    """
    if not original_grid:
        return 0
    
    grid_height = len(original_grid[0]) if original_grid and original_grid[0] else 0
    
    t_count = 0
    # 1ì—´ (0): ëª¨ë“  í–‰ (0-5)
    # 2ì—´ (1): ëª¨ë“  í–‰ (0-5)
    # 3ì—´ (2): 1-3í–‰ë§Œ (0-2)
    for col_offset in range(3):
        x = col_offset
        if x >= len(original_grid):
            break
        
        # 1ì—´, 2ì—´ì€ ëª¨ë“  í–‰, 3ì—´ì€ 3í–‰ê¹Œì§€
        max_row = grid_height if col_offset < 2 else 3
        
        for y in range(min(max_row, grid_height)):
            if original_grid[x][y] == 't':
                t_count += 1
    
    return t_count

def display_t_count_3x3(original_grid):
    """
    3í–‰3ì—´ ë²”ìœ„ì˜ T ê°œìˆ˜ë¥¼ ì˜¤ë¥¸ìª½ ìƒë‹¨ì— í‘œì‹œ (ìµœì†Œí•œì˜ ì˜ì—­, 2ì¤„)
    
    Args:
        original_grid: ì›ë³¸ ê·¸ë¦¬ë“œ (Tê°€ ë³€í™˜ë˜ê¸° ì „)
    """
    if not original_grid:
        return
    
    t_count = count_t_in_range_3x3(original_grid)
    
    # ì˜¤ë¥¸ìª½ ì •ë ¬ëœ ì»´íŒ©íŠ¸í•œ í‘œì‹œ (2ì¤„)
    st.markdown(f"""
    <div style="text-align: right; margin-bottom: 0.5rem;">
        <div style="font-size: 0.9rem; color: #666;">3í–‰3ì—´ ë²”ìœ„ T ê°œìˆ˜</div>
        <div style="font-size: 1.2rem; font-weight: bold; color: #1e40af;">{t_count}</div>
    </div>
    """, unsafe_allow_html=True)

# ============================================================================
# ê¸°ì¡´ í•¨ìˆ˜ë“¤
# ============================================================================

def get_original_t_count_before_column(original_grid, column_index):
    """
    ì›ë³¸ ê·¸ë¦¬ë“œì—ì„œ íŠ¹ì • ì—´ ì´ì „ì— ìˆëŠ” Tì˜ ê°œìˆ˜ë¥¼ ì„¸ëŠ” í•¨ìˆ˜
    ì—´ ìš°ì„  ìˆœì„œë¡œ íŠ¹ì • ì—´ ì´ì „ê¹Œì§€ì˜ T ê°œìˆ˜ë¥¼ ê³„ì‚°
    
    Args:
        original_grid: ì›ë³¸ ê·¸ë¦¬ë“œ (Tê°€ ë³€í™˜ë˜ê¸° ì „, aligned_grid)
        column_index: ì—´ ì¸ë±ìŠ¤ (0-based, ì´ ì—´ ì´ì „ê¹Œì§€ ê³„ì‚°)
    
    Returns:
        int: íŠ¹ì • ì—´ ì´ì „ê¹Œì§€ ì—´ ìš°ì„  ìˆœì„œë¡œ ì„¼ Tì˜ ê°œìˆ˜
    """
    if not original_grid or column_index < 0:
        return 0
    
    t_count = 0
    # ì—´ ìš°ì„  ìˆœì„œë¡œ íŠ¹ì • ì—´ ì´ì „ê¹Œì§€ì˜ T ê°œìˆ˜ ì„¸ê¸°
    for x in range(column_index):  # column_index ì´ì „ê¹Œì§€
        for y in range(TABLE_HEIGHT):
            if original_grid[x][y] == 't':
                t_count += 1
    
    return t_count

def convert_group_to_reconstructed_index(converted_group_range, original_grid):
    """
    Converted Gridì˜ ê·¸ë£¹ ë²”ìœ„ë¥¼ T-Removed Reconstructed Gridì˜ ê·¸ë£¹ ë²”ìœ„ë¡œ ë³€í™˜
    ë‹¨ìˆœí•˜ê²Œ ê·¸ë£¹ ì‹œì‘ ì—´ ì´ì „ì˜ T ê°œìˆ˜ë§Œí¼ ì¸ë±ìŠ¤ë¥¼ ì¡°ì •
    
    Args:
        converted_group_range: Converted Gridì˜ ê·¸ë£¹ ë²”ìœ„ ë¬¸ìì—´ (ì˜ˆ: "4-6")
        original_grid: ì›ë³¸ ê·¸ë¦¬ë“œ (Tê°€ ë³€í™˜ë˜ê¸° ì „, aligned_grid)
    
    Returns:
        str: T-Removed Reconstructed Gridì˜ ê·¸ë£¹ ë²”ìœ„ (ì˜ˆ: "2-4")
    """
    try:
        # ê·¸ë£¹ ë²”ìœ„ íŒŒì‹± (ì˜ˆ: "4-6" -> start=3, end=5)
        parts = converted_group_range.split('-')
        if len(parts) != 2:
            return converted_group_range
        
        start_col = int(parts[0]) - 1  # 1-based to 0-based
        end_col = int(parts[1]) - 1    # 1-based to 0-based
        
        # ê·¸ë£¹ ì‹œì‘ ì—´ ì´ì „ì˜ T ê°œìˆ˜ ê³„ì‚° (ì—´ ìš°ì„  ìˆœì„œ)
        t_count = get_original_t_count_before_column(original_grid, start_col)
        
        # T ê°œìˆ˜ë§Œí¼ ì¸ë±ìŠ¤ ì¡°ì •
        reconstructed_start = max(0, start_col - t_count)
        reconstructed_end = max(0, end_col - t_count)
        
        # 1-basedë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return f"{reconstructed_start + 1}-{reconstructed_end + 1}"
    except Exception as e:
        return converted_group_range

def remove_tie_and_reconstruct_grid(grid):
    """
    6í–‰Ã—15ì—´ ê·¸ë¦¬ë“œ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ Të¥¼ ì œê±°í•˜ê³  ì¬êµ¬ì„±
    
    ê³¼ì •:
    1. ì „ì²´ ê·¸ë¦¬ë“œë¥¼ ì—´ ìš°ì„  ìˆœì„œë¡œ 1ì°¨ì› ë°°ì—´ë¡œ í¼ì¹˜ê¸°
    2. T ê°’ ì œê±°
    3. ë‚¨ì€ ê°’ë“¤ë¡œ 6í–‰Ã—15ì—´ ê·¸ë¦¬ë“œ ì¬êµ¬ì„±
    """
    # 1ë‹¨ê³„: ê·¸ë¦¬ë“œë¥¼ ì—´ ìš°ì„  ìˆœì„œë¡œ 1ì°¨ì› ë°°ì—´ë¡œ í¼ì¹˜ê¸°
    flattened_values = []
    for x in range(TABLE_WIDTH):  # ì—´ ìš°ì„  ìˆœíšŒ (0~14)
        for y in range(TABLE_HEIGHT):  # ê° ì—´ì˜ í–‰ ìˆœíšŒ (0~5)
            cell_value = grid[x][y]
            if cell_value != 't' and cell_value != '':  # Tê°€ ì•„ë‹ˆê³  ë¹ˆ ê°’ë„ ì•„ë‹Œ ê²½ìš°
                flattened_values.append(cell_value)
    
    # 2ë‹¨ê³„: ìƒˆë¡œìš´ 6í–‰Ã—15ì—´ ê·¸ë¦¬ë“œ ìƒì„±
    new_grid = [['' for _ in range(TABLE_HEIGHT)] for _ in range(TABLE_WIDTH)]
    
    # 3ë‹¨ê³„: ë‚¨ì€ ê°’ë“¤ì„ ì—´ ìš°ì„  ìˆœì„œë¡œ ìƒˆë¡œìš´ ê·¸ë¦¬ë“œì— ë°°ì¹˜
    value_index = 0
    for x in range(TABLE_WIDTH):  # ì—´ ìš°ì„  ìˆœíšŒ
        for y in range(TABLE_HEIGHT):  # ê° ì—´ì˜ í–‰ ìˆœíšŒ
            if value_index < len(flattened_values):
                new_grid[x][y] = flattened_values[value_index]
                value_index += 1
            else:
                break  # ë” ì´ìƒ ì±„ìš¸ ê°’ì´ ì—†ìœ¼ë©´ ì¤‘ë‹¨
        if value_index >= len(flattened_values):
            break
    
    return new_grid

def divide_grid_into_overlapping_zones_for_reconstructed(grid, zone_width=3):
    """
    T ì œê±° ì¬êµ¬ì„± ê·¸ë¦¬ë“œìš© ë…ë¦½ì ì¸ êµ¬ì—­ ë¶„í•  í•¨ìˆ˜
    """
    zones = []
    for start_x in range(15 - zone_width + 1):
        end_x = start_x + zone_width
        zone_data = [[grid[x][y] for y in range(6)] for x in range(start_x, end_x)]
        
        # ê¸°ë³¸ ì¡°ê±´: b, t, pê°€ ìˆëŠ”ì§€ í™•ì¸
        has_basic_data = any(cell in {'b', 't', 'p'} for column in zone_data for cell in column)
        
        # ì• ê·¸ë£¹ì˜ Pattern 4 ë²ˆí˜¸ê°€ ì¶”ì¶œë˜ë©´ ë‹¤ìŒ ê·¸ë£¹ ë…¸ì¶œ ì¡°ê±´
        should_show_next_group = False
        if start_x > 0:  # ì²« ë²ˆì§¸ ê·¸ë£¹ì´ ì•„ë‹Œ ê²½ìš°
            # ì• ê·¸ë£¹ì˜ Pattern 4 ìœ„ì¹˜ í™•ì¸ (start_x-1, end_x-1 ë²”ìœ„)
            prev_zone_data = [[grid[x][y] for y in range(6)] for x in range(start_x-1, end_x-1)]
            patterns = get_pattern_positions()
            prev_group_patterns = [p for p in patterns if p['columns'][0] >= start_x-1 and p['columns'][1] <= end_x-1]
            
            if len(prev_group_patterns) >= 4:
                # ì• ê·¸ë£¹ì˜ Pattern 4 ê°’ ì¶”ì¶œ
                pattern4_values = []
                for x, y in prev_group_patterns[3]['coordinates']:
                    relative_x = x - (start_x-1)
                    value = prev_zone_data[relative_x][y]
                    if value:
                        pattern4_values.append(value.upper())
                
                # Pattern 4 ë²ˆí˜¸ê°€ ì¶”ì¶œë˜ë©´ ë‹¤ìŒ ê·¸ë£¹ ë…¸ì¶œ
                if pattern4_values:
                    pattern4_number = find_pattern_number_only([x.lower() for x in pattern4_values])
                    if pattern4_number and pattern4_number != '-':
                        should_show_next_group = True
        
        # ì²« ë²ˆì§¸ ê·¸ë£¹ì´ê±°ë‚˜ ì• ê·¸ë£¹ì˜ Pattern 4ê°€ ì¶”ì¶œëœ ê²½ìš° í‘œì‹œ
        if has_basic_data and (start_x == 0 or should_show_next_group):
            zones.append({
                'zone_data': zone_data,
                'start_x': start_x,
                'end_x': end_x - 1
            })
    return zones

def get_first_two_group_values_for_reconstructed(zone):
    """
    T ì œê±° ì¬êµ¬ì„± ê·¸ë¦¬ë“œìš© ë…ë¦½ì ì¸ ì²« 2ê°œ ê·¸ë£¹ ê°’ ì¶”ì¶œ í•¨ìˆ˜
    """
    patterns = get_pattern_positions()
    group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
    
    if len(group_patterns) < 4:
        return ''
        
    pattern_values = []
    for pattern in group_patterns[:4]:
        values = []
        for x, y in pattern['coordinates']:
            relative_x = x - zone['start_x']
            value = zone['zone_data'][relative_x][y]
            if value:
                values.append(value.upper())
        pattern_values.append(values)
        
    groups_123 = []
    pattern_123_valid = True
    
    if len(pattern_values) >= 3:
        for i in range(3):
            if not pattern_values[i]:
                pattern_123_valid = False
                break
            group = find_pattern_group(pattern_values[i])
            if group is None:
                pattern_123_valid = False
                break
            groups_123.append(group)
    
    pattern_123_text = ''.join(groups_123) if pattern_123_valid and len(groups_123) == 3 else ''
    return pattern_123_text[:2] if len(pattern_123_text) >= 2 else ''

def display_pattern1_sequence_prediction_for_reconstructed(zones):
    """Pattern 1 Numberì˜ Sequence prediction ì˜ˆì¸¡ê°’ì„ í‘œì‹œí•˜ëŠ” ë…ë¦½ì ì¸ í•¨ìˆ˜"""
    if not zones:
        return
    
    try:
        # Group 1-3 zoneë§Œ ì²˜ë¦¬ (start_x=0, end_x=2)
        group_1_3_zones = [zone for zone in zones if zone['start_x'] == 0 and zone['end_x'] == 2]
        
        if not group_1_3_zones:
            return
            
        zone = group_1_3_zones[0]  # Group 1-3 zone
        
        # íŒ¨í„´ ìœ„ì¹˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        patterns = get_pattern_positions()
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) < 1:
            return
        
        # Pattern 1 ê°’ ì¶”ì¶œ
        pattern1_values = []
        for x, y in group_patterns[0]['coordinates']:
            relative_x = x - zone['start_x']
            value = zone['zone_data'][relative_x][y]
            if value:
                pattern1_values.append(value.upper())
        
        # Pattern 1 ë²ˆí˜¸ ì¶”ì¶œ
        pattern1_number = find_pattern_number_only([x.lower() for x in pattern1_values]) if pattern1_values else None
        
        if pattern1_number and pattern1_number != '-':
            # íŒ¨í„´ ë²ˆí˜¸ í¬ë§·íŒ…
            def format_pattern_number(pattern_num):
                if pattern_num and len(pattern_num) > 2:
                    return pattern_num[:2]
                elif pattern_num and len(pattern_num) == 1:
                    return '0' + pattern_num
                else:
                    return pattern_num
            
            pattern1_formatted = format_pattern_number(pattern1_number)
            
            # P_Sequenceì™€ B_Sequence ì˜ˆì¸¡ê°’ ì¡°íšŒ
            p_predicted_value, p_found, _, _, p_gap = get_best_prediction_from_sequence_table(pattern1_formatted, 'P_Sequence')
            b_predicted_value, b_found, _, _, b_gap = get_best_prediction_from_sequence_table(pattern1_formatted, 'B_Sequence')
            
            # ê²°ê³¼ í‘œì‹œ
            st.markdown("#### Group 1-3 Pattern 1 Sequence Prediction")
            st.text(f"Pattern 1 Number: {pattern1_number}")
            
            if p_found:
                gap_text = f" Gap={'T' if p_gap > 0 else 'F'}"
                st.text(f"Pattern 1 P_Sequence prediction: {p_predicted_value.upper()}{gap_text}")
            else:
                st.text("Pattern 1 P_Sequence prediction: N/A")
            
            if b_found:
                gap_text = f" Gap={'T' if b_gap > 0 else 'F'}"
                st.text(f"Pattern 1 B_Sequence prediction: {b_predicted_value.upper()}{gap_text}")
            else:
                st.text("Pattern 1 B_Sequence prediction: N/A")
            
            st.markdown("---")
        
    except Exception as e:
        st.error(f"Pattern 1 Sequence Prediction í‘œì‹œ ì˜¤ë¥˜: {str(e)}")

def display_pattern_groups_for_reconstructed(zones):
    """
    T ì œê±° ì¬êµ¬ì„± ê·¸ë¦¬ë“œìš© ë…ë¦½ì ì¸ íŒ¨í„´ ê·¸ë£¹ ë¶„ì„ í‘œì‹œ í•¨ìˆ˜
    """
    if not zones:
        return
    
    st.markdown("### Pattern Group Analysis (T-Removed Reconstructed)")
    
    # Pattern 1 Number Sequence Prediction (ë…ë¦½ì ì¸ ìƒˆ ê¸°ëŠ¥)
    display_pattern1_sequence_prediction_for_reconstructed(zones)
    
    # Display all groups' first 2 values concatenated
    all_first_two = ''
    for zone in zones:
        first_two = get_first_two_group_values_for_reconstructed(zone)
        if first_two:
            all_first_two += first_two
    
    if all_first_two:
        st.text(f"All groups' first 2 values: {all_first_two}")
        st.markdown("---")
    
    # Sort zones by start_x to display in order
    sorted_zones = sorted(zones, key=lambda x: x['start_x'])
    
    for zone in sorted_zones:
        patterns = get_pattern_positions()
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) < 4:
            continue
            
        pattern_values = []
        for pattern in group_patterns[:4]:
            values = []
            for x, y in pattern['coordinates']:
                relative_x = x - zone['start_x']
                value = zone['zone_data'][relative_x][y]
                if value:
                    values.append(value.upper())
            pattern_values.append(values)
            
        # ê° íŒ¨í„´ë³„ ë„˜ë²„ ë¦¬ìŠ¤íŠ¸
        pattern_numbers = []
        for v in pattern_values[:4]:
            pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
            pattern_numbers.append(pattern_number if pattern_number is not None else '-')
        
        # ë„˜ë²„ ê°€ê³µ
        numbers_dict = process_pattern_numbers(pattern_numbers)
        
        groups_123 = []
        groups_1234 = []
        pattern_123_valid = True
        if len(pattern_values) >= 3:
            for i in range(3):
                if not pattern_values[i]:
                    pattern_123_valid = False
                    break
                group = find_pattern_group(pattern_values[i])
                if group is None:
                    pattern_123_valid = False
                    break
                groups_123.append(group)
        
        pattern_1234_valid = True
        if len(pattern_values) >= 4:
            for i in range(4):
                if not pattern_values[i]:
                    pattern_1234_valid = False
                    break
                group = find_pattern_group(pattern_values[i])
                if group is None:
                    pattern_1234_valid = False
                    break
                groups_1234.append(group)
        
        pattern_123_text = ''.join(groups_123) if pattern_123_valid and len(groups_123) == 3 else ''
        pattern_1234_text = ''.join(groups_1234) if pattern_1234_valid and len(groups_1234) == 4 else ''
        
        first_two = get_first_two_group_values_for_reconstructed(zone)
        group_range = f"{zone['start_x'] + 1}-{zone['end_x'] + 1}"
        
        # íŒ¨í„´ ë²ˆí˜¸ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_pattern_numbers = any(pattern_num != '-' for pattern_num in pattern_numbers[:4])
        
        if any([pattern_123_text, pattern_1234_text, first_two]) or has_pattern_numbers:
            st.markdown(f"#### Group {group_range}")
            for idx, v in enumerate(pattern_values[:4]):
                pattern_number = pattern_numbers[idx]
                st.text(f"Pattern {idx+1} Number: {pattern_number if pattern_number is not None else '-'}")
            
            # Add combined pattern numbers display
            if len(pattern_numbers) >= 2:
                pattern1_2 = pattern_numbers[0] + pattern_numbers[1] if pattern_numbers[0] != '-' and pattern_numbers[1] != '-' else '-'
                st.text(f"Pattern 1,2: {pattern1_2}")
            
            if len(pattern_numbers) >= 3:
                pattern1_2_3 = pattern_numbers[0] + pattern_numbers[1] + pattern_numbers[2] if all(p != '-' for p in pattern_numbers[:3]) else '-'
                st.text(f"Pattern 1,2,3: {pattern1_2_3}")
            
            # Add pattern 3,4 combined display
            if len(pattern_numbers) >= 4:
                pattern3_4 = pattern_numbers[2] + pattern_numbers[3] if pattern_numbers[2] != '-' and pattern_numbers[3] != '-' else '-'
                st.text(f"Pattern 3,4: {pattern3_4}")
            
            st.text(f"Pattern 1,2,3 Group: {pattern_123_text}")
            st.text(f"Pattern 1,2,3,4 Group: {pattern_1234_text}")
            st.text(f"First 2 values: {first_two}")
            st.markdown("---")

def display_session_prediction_results_for_reconstructed(zones):
    """Display Session Prediction Results and Sequence Prediction Results for T-Removed Reconstructed Grid"""
    if not zones:
        return
    
    # Session Prediction Results: left to right
    sorted_zones_results = sorted(zones, key=lambda x: x['start_x'])
    
    # Collect all prediction results (Session Prediction Results)
    all_prediction_results = []
    for zone in sorted_zones_results:
        pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results_for_reconstructed(zone)
        if comparison1_2:
            all_prediction_results.append(comparison1_2.upper())
        if comparison1_2_3:
            all_prediction_results.append(comparison1_2_3.upper())
    
    # Display combined prediction results (ìˆ¨ê¹€ ì²˜ë¦¬)
    # if all_prediction_results:
    #     combined_results = ''.join(all_prediction_results)
    #     st.markdown("### Session Prediction Results (T-Removed Reconstructed)")
    #     st.markdown(f"**{combined_results}**")
    #     st.markdown("---")
    
    # Display sequence prediction results using pattern_sequence_prediction table for T-Removed Reconstructed
    sequence_prediction_results = generate_sequence_prediction_results_for_reconstructed(zones)
    if sequence_prediction_results:
        st.markdown("### Sequence Prediction Results (T-Removed Reconstructed)")
        st.markdown(f"**{sequence_prediction_results}**")
        st.markdown("---")
    
    # Display high probability gap results for T-Removed Reconstructed
    high_probability_gap_results = generate_high_probability_gap_results_for_reconstructed(zones)
    if high_probability_gap_results:
        st.markdown("### High Probability Gap Results (T-Removed Reconstructed)")
        st.markdown(f"**{high_probability_gap_results}**")
        
        # Display comparison results (P/F based on sequence prediction results)
        show_gap_comparison_results = False
        high_probability_gap_comparison_results = generate_high_probability_gap_comparison_results_for_reconstructed(zones)
        if show_gap_comparison_results and high_probability_gap_comparison_results:
            st.markdown("### High Probability Gap Comparison Results (T-Removed Reconstructed)")
            st.markdown(f"**{high_probability_gap_comparison_results}**")
        
        st.markdown("---")
        
        # ìƒˆë¡œìš´ ë…ë¦½ì ì¸ ì˜ˆì¸¡ê°’ í‘œì‹œ
        display_independent_prediction_results_for_reconstructed(zones)

def display_session_prediction_results_main(zones):
    """Display Session Prediction Results for Converted Grid"""
    if not zones:
        return

    sorted_zones_results = sorted(zones, key=lambda x: x['start_x'])
    all_prediction_results = []
    for zone in sorted_zones_results:
        pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results(zone)
        if comparison1_2:
            all_prediction_results.append(comparison1_2.upper())
        if comparison1_2_3:
            all_prediction_results.append(comparison1_2_3.upper())

    if all_prediction_results:
        combined_results = ''.join(all_prediction_results)
        st.markdown("### Session Prediction Results")
        st.markdown(f"**{combined_results}**")
        st.markdown("---")

def display_independent_prediction_results_for_reconstructed(zones):
    """ê¸°ì¡´ ì½”ë“œì™€ ë…ë¦½ì ì¸ ì˜ˆì¸¡ê°’ í‘œì‹œ í•¨ìˆ˜"""
    if not zones:
        return
    
    try:
        # Zoneì„ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì •ë ¬
        sorted_zones = sorted(zones, key=lambda x: x['start_x'])
        
        all_predictions = []  # ì˜ˆì¸¡ê°’ë§Œ ì €ì¥
        
        for zone in sorted_zones:
            # íŒ¨í„´ ìœ„ì¹˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            patterns = get_pattern_positions()
            group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
            
            if len(group_patterns) < 2:
                continue
            
            # íŒ¨í„´ ê°’ ì¶”ì¶œ
            pattern_values = []
            for pattern in group_patterns[:2]:  # Pattern 1, Pattern 2ë§Œ
                values = []
                for x, y in pattern['coordinates']:
                    relative_x = x - zone['start_x']
                    value = zone['zone_data'][relative_x][y]
                    if value:
                        values.append(value.upper())
                pattern_values.append(values)
            
            # íŒ¨í„´ ë²ˆí˜¸ ì¶”ì¶œ
            pattern_numbers = []
            for v in pattern_values:
                pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
                pattern_numbers.append(pattern_number if pattern_number is not None else '-')
            
            # Pattern 1, Pattern 2 ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
            pattern1_number = pattern_numbers[0] if pattern_numbers[0] != '-' else ''
            pattern2_number = pattern_numbers[1] if len(pattern_numbers) > 1 and pattern_numbers[1] != '-' else ''
            
            # íŒ¨í„´ ë²ˆí˜¸ í¬ë§·íŒ…
            def format_pattern_number(pattern_num):
                if pattern_num and len(pattern_num) > 2:
                    return pattern_num[:2]
                elif pattern_num and len(pattern_num) == 1:
                    return '0' + pattern_num
                else:
                    return pattern_num
            
            pattern1_formatted = format_pattern_number(pattern1_number)
            pattern2_formatted = format_pattern_number(pattern2_number)
            
            # ì‹œí€€ìŠ¤ íƒ€ì… ê²°ì •
            pattern1_sequence_value = zone['zone_data'][2][0] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 0 else ''
            pattern2_sequence_value = zone['zone_data'][2][3] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 3 else ''
            
            sequence_type1 = 'P_Sequence' if pattern1_sequence_value.upper() == 'P' else 'B_Sequence' if pattern1_sequence_value.upper() == 'B' else ''
            sequence_type2 = 'P_Sequence' if pattern2_sequence_value.upper() == 'P' else 'B_Sequence' if pattern2_sequence_value.upper() == 'B' else ''
            
            # Pattern 1 ì˜ˆì¸¡ê°’ ì¡°íšŒ
            if pattern1_formatted and sequence_type1:
                predicted_value, found, _, _, _ = get_best_prediction_from_sequence_table(pattern1_formatted, sequence_type1)
                if found:
                    all_predictions.append(predicted_value)
            
            # Pattern 2 ì˜ˆì¸¡ê°’ ì¡°íšŒ
            if pattern2_formatted and sequence_type2:
                predicted_value, found, _, _, _ = get_best_prediction_from_sequence_table(pattern2_formatted, sequence_type2)
                if found:
                    all_predictions.append(predicted_value)
        
        # íŒ¨í„´ ìƒì„¸ì •ë³´ í‘œì‹œ
        display_pattern_details_for_reconstructed(zones)
        
    except Exception as e:
        st.error(f"ë…ë¦½ì ì¸ ì˜ˆì¸¡ê°’ í‘œì‹œ ì˜¤ë¥˜: {str(e)}")

def display_pattern_details_for_reconstructed(zones):
    """íŒ¨í„´ ìƒì„¸ì •ë³´ë¥¼ Group í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•˜ëŠ” ë…ë¦½ì ì¸ í•¨ìˆ˜"""
    if not zones:
        return
    
    try:
        # Zoneì„ ì˜¤ë¥¸ìª½â†’ì™¼ìª½ ìˆœì„œë¡œ ì •ë ¬ (Group Resultsì™€ ë™ì¼í•œ ìˆœì„œ)
        sorted_zones = sorted(zones, key=lambda x: x['start_x'], reverse=True)
        
        for zone in sorted_zones:
            group_range = f"{zone['start_x'] + 1}-{zone['end_x'] + 1}"
            
            # íŒ¨í„´ ìœ„ì¹˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            patterns = get_pattern_positions()
            group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
            
            if len(group_patterns) < 4:
                continue
            
            # íŒ¨í„´ ê°’ ì¶”ì¶œ
            pattern_values = []
            for pattern in group_patterns[:4]:
                values = []
                for x, y in pattern['coordinates']:
                    relative_x = x - zone['start_x']
                    value = zone['zone_data'][relative_x][y]
                    if value:
                        values.append(value.upper())
                pattern_values.append(values)
            
            # íŒ¨í„´ ë²ˆí˜¸ ì¶”ì¶œ
            pattern_numbers = []
            for v in pattern_values:
                pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
                pattern_numbers.append(pattern_number if pattern_number is not None else '-')
            
            # íŒ¨í„´ ë²ˆí˜¸ ê°€ê³µ
            numbers_dict = process_pattern_numbers(pattern_numbers)
            
            # Pattern 1,2 ì¡°í•©
            pattern1_2_combined = numbers_dict.get('pattern1_2_combined', '-')
            pattern1_2_result = zone['zone_data'][2][1] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 1 else ''
            
            # Pattern 1,2,3 ì¡°í•©
            pattern1_2_3_combined = numbers_dict.get('pattern1_2_3_combined', '-')
            pattern1_2_3_result = zone['zone_data'][2][4] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 4 else ''
            
            # Pattern 3,4 ì¡°í•©
            pattern3_4_combined = numbers_dict.get('pattern3_4_combined', '-')
            
            # ì‹œí€€ìŠ¤ íƒ€ì… ê²°ì •
            pattern1_sequence_value = zone['zone_data'][2][0] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 0 else ''
            pattern2_sequence_value = zone['zone_data'][2][3] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 3 else ''
            
            sequence_type1 = 'P_Sequence' if pattern1_sequence_value.upper() == 'P' else 'B_Sequence' if pattern1_sequence_value.upper() == 'B' else ''
            sequence_type2 = 'P_Sequence' if pattern2_sequence_value.upper() == 'P' else 'B_Sequence' if pattern2_sequence_value.upper() == 'B' else ''
            
            # íŒ¨í„´ ë²ˆí˜¸ í¬ë§·íŒ…
            def format_pattern_number(pattern_num):
                if pattern_num and len(pattern_num) > 2:
                    return pattern_num[:2]
                elif pattern_num and len(pattern_num) == 1:
                    return '0' + pattern_num
                else:
                    return pattern_num
            
            pattern1_formatted = format_pattern_number(pattern_numbers[0]) if pattern_numbers[0] != '-' else ''
            pattern2_formatted = format_pattern_number(pattern_numbers[1]) if len(pattern_numbers) > 1 and pattern_numbers[1] != '-' else ''
            
            # Pattern 1,2 ì˜ˆì¸¡ ë° ë¹„êµ
            pattern1_2_prediction = ''
            pattern1_2_comparison = ''
            if pattern1_formatted and sequence_type1:
                predicted_value, found, _, _, _ = get_best_prediction_from_sequence_table(pattern1_formatted, sequence_type1)
                if found:
                    pattern1_2_prediction = predicted_value
                    if pattern1_2_result:
                        pattern1_2_comparison = 'W' if pattern1_2_result.upper() == predicted_value.upper() else 'L'
            
            # Pattern 1,2,3 ì˜ˆì¸¡ ë° ë¹„êµ
            pattern1_2_3_prediction = ''
            pattern1_2_3_comparison = ''
            if pattern2_formatted and sequence_type2:
                predicted_value, found, _, _, _ = get_best_prediction_from_sequence_table(pattern2_formatted, sequence_type2)
                if found:
                    pattern1_2_3_prediction = predicted_value
                    if pattern1_2_3_result:
                        pattern1_2_3_comparison = 'W' if pattern1_2_3_result.upper() == predicted_value.upper() else 'L'
            
            # í‘œì‹œí•  ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
            has_content = any([
                pattern1_2_result, pattern1_2_3_result, pattern1_2_prediction, 
                pattern1_2_3_prediction, pattern1_2_comparison, pattern1_2_3_comparison
            ])
            is_group_1_3 = (zone['start_x'] == 0 and zone['end_x'] == 2)
            
            # íŒ¨í„´ ë²ˆí˜¸ê°€ ìˆëŠ”ì§€ í™•ì¸
            has_pattern_numbers = any(pattern_num != '-' for pattern_num in pattern_numbers[:4])
            
            if not has_content and not is_group_1_3 and not has_pattern_numbers:
                continue  # í‘œì‹œí•  ë‚´ìš©ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            
            # Group ì •ë³´ í‘œì‹œ
            st.markdown(f"#### Pattern Analysis Details - Group {group_range} (T-Removed Reconstructed)")
            
            # Pattern 1 ìƒì„¸ ì •ë³´
            st.markdown("**Pattern 1:**")
            st.text(f"Pattern1 number: {pattern_numbers[0] if pattern_numbers[0] != '-' else 'N/A'}")
            
            # Pattern 1 ì‹œí€€ìŠ¤ íƒ€ì…ë³„ ì˜ˆì¸¡ê°’ í‘œì‹œ
            pattern1_formatted = format_pattern_number(pattern_numbers[0]) if pattern_numbers[0] != '-' else ''
            if pattern1_formatted:
                # P_Sequence ì˜ˆì¸¡ê°’
                p_predicted_value, p_found, _, _, p_gap = get_best_prediction_from_sequence_table(pattern1_formatted, 'P_Sequence')
                if p_found:
                    gap_text = f" Gap={'T' if p_gap > 0 else 'F'}"
                    st.text(f"Pattern1 P_Sequence prediction: {p_predicted_value.upper()}{gap_text}")
                else:
                    st.text("Pattern1 P_Sequence prediction: N/A")
                
                # B_Sequence ì˜ˆì¸¡ê°’
                b_predicted_value, b_found, _, _, b_gap = get_best_prediction_from_sequence_table(pattern1_formatted, 'B_Sequence')
                if b_found:
                    gap_text = f" Gap={'T' if b_gap > 0 else 'F'}"
                    st.text(f"Pattern1 B_Sequence prediction: {b_predicted_value.upper()}{gap_text}")
                else:
                    st.text("Pattern1 B_Sequence prediction: N/A")
            else:
                st.text("Pattern1 P_Sequence prediction: N/A")
                st.text("Pattern1 B_Sequence prediction: N/A")
            
            if pattern1_2_result:
                st.text(f"Pattern 1 result: {pattern1_2_result.upper()}")
            else:
                st.text("Pattern 1 result: N/A")
            if pattern1_2_comparison:
                st.text(f"Prediction Result: {pattern1_2_comparison.upper()}")
            else:
                st.text("Prediction Result: N/A")
            
            st.markdown("---")
            
            # Pattern 2 ìƒì„¸ ì •ë³´
            st.markdown("**Pattern 2:**")
            st.text(f"Pattern2 number: {pattern_numbers[1] if len(pattern_numbers) > 1 and pattern_numbers[1] != '-' else 'N/A'}")
            
            # Pattern 2 ì‹œí€€ìŠ¤ íƒ€ì…ë³„ ì˜ˆì¸¡ê°’ í‘œì‹œ
            pattern2_formatted = format_pattern_number(pattern_numbers[1]) if len(pattern_numbers) > 1 and pattern_numbers[1] != '-' else ''
            if pattern2_formatted:
                # P_Sequence ì˜ˆì¸¡ê°’
                p_predicted_value, p_found, _, _, p_gap = get_best_prediction_from_sequence_table(pattern2_formatted, 'P_Sequence')
                if p_found:
                    gap_text = f" Gap={'T' if p_gap > 0 else 'F'}"
                    st.text(f"Pattern2 P_Sequence prediction: {p_predicted_value.upper()}{gap_text}")
                else:
                    st.text("Pattern2 P_Sequence prediction: N/A")
                
                # B_Sequence ì˜ˆì¸¡ê°’
                b_predicted_value, b_found, _, _, b_gap = get_best_prediction_from_sequence_table(pattern2_formatted, 'B_Sequence')
                if b_found:
                    gap_text = f" Gap={'T' if b_gap > 0 else 'F'}"
                    st.text(f"Pattern2 B_Sequence prediction: {b_predicted_value.upper()}{gap_text}")
                else:
                    st.text("Pattern2 B_Sequence prediction: N/A")
            else:
                st.text("Pattern2 P_Sequence prediction: N/A")
                st.text("Pattern2 B_Sequence prediction: N/A")
            
            if pattern1_2_3_result:
                st.text(f"Pattern 2 result: {pattern1_2_3_result.upper()}")
            else:
                st.text("Pattern 2 result: N/A")
            if pattern1_2_3_comparison:
                st.text(f"Prediction Result: {pattern1_2_3_comparison.upper()}")
            else:
                st.text("Prediction Result: N/A")
            
            st.markdown("---")
            
            # Pattern 3 ìƒì„¸ ì •ë³´
            st.markdown("**Pattern 3:**")
            st.text(f"Pattern3 number: {pattern_numbers[2] if len(pattern_numbers) > 2 and pattern_numbers[2] != '-' else 'N/A'}")
            
            # Pattern 3 ì‹œí€€ìŠ¤ íƒ€ì…ë³„ ì˜ˆì¸¡ê°’ í‘œì‹œ
            pattern3_formatted = format_pattern_number(pattern_numbers[2]) if len(pattern_numbers) > 2 and pattern_numbers[2] != '-' else ''
            if pattern3_formatted:
                # P_Sequence ì˜ˆì¸¡ê°’
                p_predicted_value, p_found, _, _, p_gap = get_best_prediction_from_sequence_table(pattern3_formatted, 'P_Sequence')
                if p_found:
                    gap_text = f" Gap={'T' if p_gap > 0 else 'F'}"
                    st.text(f"Pattern3 P_Sequence prediction: {p_predicted_value.upper()}{gap_text}")
                else:
                    st.text("Pattern3 P_Sequence prediction: N/A")
                
                # B_Sequence ì˜ˆì¸¡ê°’
                b_predicted_value, b_found, _, _, b_gap = get_best_prediction_from_sequence_table(pattern3_formatted, 'B_Sequence')
                if b_found:
                    gap_text = f" Gap={'T' if b_gap > 0 else 'F'}"
                    st.text(f"Pattern3 B_Sequence prediction: {b_predicted_value.upper()}{gap_text}")
                else:
                    st.text("Pattern3 B_Sequence prediction: N/A")
            else:
                st.text("Pattern3 P_Sequence prediction: N/A")
                st.text("Pattern3 B_Sequence prediction: N/A")
            
            st.text("Pattern 3 result: N/A")
            st.text("Prediction Result: N/A")
            
            st.markdown("---")
            
            # Pattern 4 ìƒì„¸ ì •ë³´
            st.markdown("**Pattern 4:**")
            st.text(f"Pattern4 number: {pattern_numbers[3] if len(pattern_numbers) > 3 and pattern_numbers[3] != '-' else 'N/A'}")
            
            # Pattern 4 ì‹œí€€ìŠ¤ íƒ€ì…ë³„ ì˜ˆì¸¡ê°’ í‘œì‹œ
            pattern4_formatted = format_pattern_number(pattern_numbers[3]) if len(pattern_numbers) > 3 and pattern_numbers[3] != '-' else ''
            if pattern4_formatted:
                # P_Sequence ì˜ˆì¸¡ê°’
                p_predicted_value, p_found, _, _, p_gap = get_best_prediction_from_sequence_table(pattern4_formatted, 'P_Sequence')
                if p_found:
                    gap_text = f" Gap={'T' if p_gap > 0 else 'F'}"
                    st.text(f"Pattern4 P_Sequence prediction: {p_predicted_value.upper()}{gap_text}")
                else:
                    st.text("Pattern4 P_Sequence prediction: N/A")
                
                # B_Sequence ì˜ˆì¸¡ê°’
                b_predicted_value, b_found, _, _, b_gap = get_best_prediction_from_sequence_table(pattern4_formatted, 'B_Sequence')
                if b_found:
                    gap_text = f" Gap={'T' if b_gap > 0 else 'F'}"
                    st.text(f"Pattern4 B_Sequence prediction: {b_predicted_value.upper()}{gap_text}")
                else:
                    st.text("Pattern4 B_Sequence prediction: N/A")
            else:
                st.text("Pattern4 P_Sequence prediction: N/A")
                st.text("Pattern4 B_Sequence prediction: N/A")
            
            st.text("Pattern 4 result: N/A")
            st.text("Prediction Result: N/A")
            
            st.markdown("---")
        
    except Exception as e:
        st.error(f"íŒ¨í„´ ìƒì„¸ì •ë³´ í‘œì‹œ ì˜¤ë¥˜: {str(e)}")

def get_pattern_results_for_reconstructed(zone):
    """Extract pattern results and predictions from T-Removed Reconstructed zone data"""
    try:
        # Get Pattern 1,2 result (2nd row 3rd column)
        pattern1_2 = zone['zone_data'][2][1] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 1 else ''
        # Get Pattern 1,2,3 result (5th row 3rd column)
        pattern1_2_3 = zone['zone_data'][2][4] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 4 else ''
        
        # Get patterns from zone for pattern number combination
        patterns = get_pattern_positions()
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) >= 2:  # Pattern 1,2ë§Œ ìˆì–´ë„ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
            pattern_values = []
            for pattern in group_patterns[:4]:
                values = []
                for x, y in pattern['coordinates']:
                    relative_x = x - zone['start_x']
                    value = zone['zone_data'][relative_x][y]
                    if value:
                        values.append(value.upper())
                pattern_values.append(values)
                
            # Get pattern numbers
            pattern_numbers = []
            for v in pattern_values[:4]:
                pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
                pattern_numbers.append(pattern_number if pattern_number is not None else '-')
            
            # Get Pattern 1,2 combination
            pattern1_2_combined = pattern_numbers[0] + pattern_numbers[1] if pattern_numbers[0] != '-' and pattern_numbers[1] != '-' else '-'
            # Get Pattern 1,2,3 combination
            pattern1_2_3_combined = pattern_numbers[0] + pattern_numbers[1] + pattern_numbers[2] if all(p != '-' for p in pattern_numbers[:3]) else '-'
            # Get Pattern 3,4 combination
            pattern3_4_combined = pattern_numbers[2] + pattern_numbers[3] if pattern_numbers[2] != '-' and pattern_numbers[3] != '-' else '-'
        else:
            pattern1_2_combined = '-'
            pattern1_2_3_combined = '-'
            pattern3_4_combined = '-'
        
        # Get sequence types for each pattern
        sequence_type_12 = get_pattern_sequence_type(zone)
        sequence_type_123 = get_pattern123_sequence_type(zone)
        
        # Get predictions using hybrid functions
        prediction1_2, found1_2, source1_2 = get_hybrid_pattern_prediction(pattern1_2_combined, sequence_type_12)
        prediction1_2_3, found1_2_3, source1_2_3 = get_hybrid_pattern123_prediction(pattern1_2_3_combined, sequence_type_123)
        
        # Compare and get results
        comparison1_2 = compare_pattern_prediction(pattern1_2, prediction1_2)
        comparison1_2_3 = compare_pattern_prediction(pattern1_2_3, prediction1_2_3)
        
        return pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123
    except Exception as e:
        return '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''

def display_group_1_3_independent():
    """ë…ë¦½ì ìœ¼ë¡œ Group 1-3 (T-Removed Reconstructed) í‘œì‹œ"""
    if not hasattr(st.session_state, 'reconstructed_grid') or not st.session_state.reconstructed_grid:
        return
    
    # Group 1-3 zone ìƒì„± (start_x=0, end_x=2)
    zone_data = [[st.session_state.reconstructed_grid[x][y] for y in range(6)] for x in range(0, 3)]
    zone = {
        'zone_data': zone_data,
        'start_x': 0,
        'end_x': 2
    }
    
    # Pattern ì •ë³´ ì¶”ì¶œ
    patterns = get_pattern_positions()
    group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
    
    # Pattern 1,2 ì •ë³´ ì¶”ì¶œ
    pattern1_2_combined = '-'
    pattern1_2_3_combined = '-'
    pattern3_4_combined = '-'
    
    if len(group_patterns) >= 2:
        pattern_values = []
        for pattern in group_patterns[:4]:
            values = []
            for x, y in pattern['coordinates']:
                relative_x = x - zone['start_x']
                value = zone['zone_data'][relative_x][y]
                if value:
                    values.append(value.upper())
            pattern_values.append(values)
        
        # Pattern numbers ì¶”ì¶œ
        pattern_numbers = []
        for v in pattern_values[:4]:
            pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
            pattern_numbers.append(pattern_number if pattern_number is not None else '-')
        
        # Combined patterns ìƒì„±
        pattern1_2_combined = pattern_numbers[0] + pattern_numbers[1] if pattern_numbers[0] != '-' and pattern_numbers[1] != '-' else '-'
        pattern1_2_3_combined = pattern_numbers[0] + pattern_numbers[1] + pattern_numbers[2] if all(p != '-' for p in pattern_numbers[:3]) else '-'
        pattern3_4_combined = pattern_numbers[2] + pattern_numbers[3] if pattern_numbers[2] != '-' and pattern_numbers[3] != '-' else '-'
    
    # Group 1-3 í‘œì‹œ
    st.markdown("#### Group Results Summary - Group 1-3 (T-Removed Reconstructed)")
    st.text(f"Pattern 1,2 combined: {pattern1_2_combined}")
    st.text(f"Pattern 1,2,3 combined: {pattern1_2_3_combined}")
    st.text(f"Pattern 3,4 combined: {pattern3_4_combined}")
    st.markdown("---")

def display_group_results_for_reconstructed(zones):
    """Display Group Results for T-Removed Reconstructed Grid"""
    if not zones:
        return
    
    # Group info display: right to left
    sorted_zones_groups = sorted(zones, key=lambda x: x['start_x'], reverse=True)
    
    # Display individual group results (right to left)
    for zone in sorted_zones_groups:
        group_range = f"{zone['start_x'] + 1}-{zone['end_x'] + 1}"
        pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results_for_reconstructed(zone)

        # Group 1-3 ì¡°ê±´ í™•ì¸ (ë…ë¦½ì ìœ¼ë¡œ í‘œì‹œë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œì™¸)
        is_group_1_3 = (zone['start_x'] == 0 and zone['end_x'] == 2)
        
        # Group 1-3ì€ ë…ë¦½ì ìœ¼ë¡œ í‘œì‹œë˜ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
        if is_group_1_3:
            continue
        
        # ë‚´ìš© ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        has_content = any([
            pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3
        ])
        
        # ë‚´ìš©ì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        if not has_content:
            continue

        st.markdown(f"#### Group Results Summary - Group {group_range} (T-Removed Reconstructed)")
        # Pattern 1,2 results
        st.text(f"Pattern 1,2 combined: {pattern1_2_combined}")
        if pattern1_2:
            st.text(f"Pattern 1,2 result: {pattern1_2.upper()}")
            if prediction1_2:
                source_emoji_12 = "ğŸ—„ï¸" if source1_2 == "DB" else "ğŸ“„" if source1_2 == "CSV" else "â“"
                st.text(f"Pattern 1,2 Prediction: {prediction1_2.upper()} (ì†ŒìŠ¤: {source_emoji_12} {source1_2})")
                st.text(f"Pattern 1,2 Prediction Result: {comparison1_2.upper()}")
            else:
                st.text("No Pattern 1,2 prediction found")
        # Pattern 1,2,3 results
        st.text(f"Pattern 1,2,3 combined: {pattern1_2_3_combined}")
        if pattern1_2_3:
            st.text(f"Pattern 1,2,3 result: {pattern1_2_3.upper()}")
            if prediction1_2_3:
                source_emoji_123 = "ğŸ—„ï¸" if source1_2_3 == "DB" else "ğŸ“„" if source1_2_3 == "CSV" else "â“"
                st.text(f"Pattern 1,2,3 Prediction: {prediction1_2_3.upper()} (ì†ŒìŠ¤: {source_emoji_123} {source1_2_3})")
                st.text(f"Pattern 1,2,3 Prediction Result: {comparison1_2_3.upper()}")
            else:
                st.text("No Pattern 1,2,3 prediction found")
        # Pattern 3,4 combined always at the end
        st.text(f"Pattern 3,4 combined: {pattern3_4_combined}")
        st.markdown("---")

def get_pattern_positions():
    patterns = []
    pattern_number = 1
    
    for start_col in range(TABLE_WIDTH - PATTERN_WIDTH + 1):
        cols = (start_col, start_col + 1)
        
        top_pattern = {
            'pattern_number': pattern_number,
            'columns': cols,
            'rows': PATTERN_TOP_ROWS,
            'coordinates': [(cols[0], y) for y in PATTERN_TOP_ROWS] + [(cols[1], y) for y in PATTERN_TOP_ROWS]
        }
        patterns.append(top_pattern)
        pattern_number += 1
        
        bottom_pattern = {
            'pattern_number': pattern_number,
            'columns': cols,
            'rows': PATTERN_BOTTOM_ROWS,
            'coordinates': [(cols[0], y) for y in PATTERN_BOTTOM_ROWS] + [(cols[1], y) for y in PATTERN_BOTTOM_ROWS]
        }
        patterns.append(bottom_pattern)
        pattern_number += 1
    
    return patterns

# ============================================================================
# Matrix Column Information Functions (ë…ë¦½ êµ¬í˜„)
# ============================================================================

def find_pattern_matrix_column(pattern_values):
    """
    pattern.jsonì—ì„œ ì…ë ¥ëœ ì‹œí€€ìŠ¤ì™€ ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” íŒ¨í„´ì˜ matrix_column ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        pattern_values (list): íŒ¨í„´ ì‹œí€€ìŠ¤ ë¦¬ìŠ¤íŠ¸, ì˜ˆì‹œ ['b', 'b', 'b']
    
    Returns:
        str or None: 
            - 'continuous': íŒ¨í„´ì´ continuousì¸ ê²½ìš°
            - 'non_continuous': íŒ¨í„´ì´ non_continuousì¸ ê²½ìš°
            - None: íŒ¨í„´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
    """
    try:
        with open('pattern.json', 'r') as f:
            pattern_data = json.load(f)
        pattern_values = [v.lower() for v in pattern_values if v]
        for group_name in ['groupA', 'groupB']:
            patterns = pattern_data['patterns'][group_name]
            for pattern in patterns:
                if pattern.get('sequence') == pattern_values:
                    characteristics = pattern.get('characteristics', {})
                    return characteristics.get('matrix_column')
        return None
    except Exception as e:
        st.error(f"íŒ¨í„´ matrix_column ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def extract_pattern_matrix_column_info_from_converted_grid(zones):
    """
    Converted Gridì—ì„œ íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_column ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë…ë¦½ í•¨ìˆ˜
    ì˜ì¡´ì„± ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„ë¨
    """
    if not zones:
        return []
    
    results = []
    sorted_zones = sorted(zones, key=lambda x: x['start_x'])
    
    for zone in sorted_zones:
        # íŒ¨í„´ ìœ„ì¹˜ ì •ë³´ ìƒì„± (ë…ë¦½ êµ¬í˜„)
        patterns = []
        pattern_number = 1
        for start_col in range(TABLE_WIDTH - PATTERN_WIDTH + 1):
            cols = (start_col, start_col + 1)
            # Top íŒ¨í„´
            top_pattern = {
                'pattern_number': pattern_number,
                'columns': cols,
                'rows': PATTERN_TOP_ROWS,
                'coordinates': [(cols[0], y) for y in PATTERN_TOP_ROWS] + [(cols[1], y) for y in PATTERN_TOP_ROWS]
            }
            patterns.append(top_pattern)
            pattern_number += 1
            # Bottom íŒ¨í„´
            bottom_pattern = {
                'pattern_number': pattern_number,
                'columns': cols,
                'rows': PATTERN_BOTTOM_ROWS,
                'coordinates': [(cols[0], y) for y in PATTERN_BOTTOM_ROWS] + [(cols[1], y) for y in PATTERN_BOTTOM_ROWS]
            }
            patterns.append(bottom_pattern)
            pattern_number += 1
        
        # Zone ë²”ìœ„ ë‚´ íŒ¨í„´ í•„í„°ë§
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) < 4:
            continue
        
        # íŒ¨í„´ ê°’ ì¶”ì¶œ
        pattern_values = []
        for pattern in group_patterns[:4]:
            values = []
            for x, y in pattern['coordinates']:
                relative_x = x - zone['start_x']
                value = zone['zone_data'][relative_x][y]
                if value:
                    values.append(value.upper())
            pattern_values.append(values)
        
        # íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_column ì¶”ì¶œ
        zone_result = {
            'zone_range': f"{zone['start_x'] + 1}-{zone['end_x'] + 1}",
            'pattern_numbers': [],
            'matrix_columns': []
        }
        
        for v in pattern_values[:4]:
            if v:
                # íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_columnì„ í•¨ê»˜ ì¶”ì¶œ (í•œ ë²ˆì˜ ê²€ìƒ‰ìœ¼ë¡œ)
                pattern_values_lower = [x.lower() for x in v]
                pattern_number = None
                matrix_column = None
                try:
                    with open('pattern.json', 'r') as f:
                        pattern_data = json.load(f)
                    for group_name in ['groupA', 'groupB']:
                        patterns_data = pattern_data['patterns'][group_name]
                        for pattern in patterns_data:
                            if pattern.get('sequence') == pattern_values_lower:
                                pattern_number = pattern.get('pattern_number')
                                # íŒ¨í„´ì„ ì°¾ì•˜ì„ ë•Œ characteristicsì—ì„œ matrix_columnë„ í•¨ê»˜ ì¶”ì¶œ
                                characteristics = pattern.get('characteristics', {})
                                matrix_column = characteristics.get('matrix_column')
                                break
                        if pattern_number:
                            break
                except Exception as e:
                    pass
                
                # ê²°ê³¼ ì €ì¥
                zone_result['pattern_numbers'].append(pattern_number if pattern_number else '-')
                
                # matrix_columnì„ T/Fë¡œ ë³€í™˜
                if matrix_column == 'continuous':
                    zone_result['matrix_columns'].append('T')
                elif matrix_column == 'non_continuous':
                    zone_result['matrix_columns'].append('F')
                else:
                    zone_result['matrix_columns'].append('-')
            else:
                zone_result['pattern_numbers'].append('-')
                zone_result['matrix_columns'].append('-')
        
        # íŒ¨í„´ ë²ˆí˜¸ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
        if any(p != '-' for p in zone_result['pattern_numbers']):
            results.append(zone_result)
    
    return results

def extract_pattern_matrix_column_info_from_reconstructed_grid(zones):
    """
    T-Removed Reconstructed Gridì—ì„œ íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_column ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë…ë¦½ í•¨ìˆ˜
    ì˜ì¡´ì„± ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„ë¨
    """
    if not zones:
        return []
    
    results = []
    sorted_zones = sorted(zones, key=lambda x: x['start_x'])
    
    for zone in sorted_zones:
        # íŒ¨í„´ ìœ„ì¹˜ ì •ë³´ ìƒì„± (ë…ë¦½ êµ¬í˜„)
        patterns = []
        pattern_number = 1
        for start_col in range(TABLE_WIDTH - PATTERN_WIDTH + 1):
            cols = (start_col, start_col + 1)
            # Top íŒ¨í„´
            top_pattern = {
                'pattern_number': pattern_number,
                'columns': cols,
                'rows': PATTERN_TOP_ROWS,
                'coordinates': [(cols[0], y) for y in PATTERN_TOP_ROWS] + [(cols[1], y) for y in PATTERN_TOP_ROWS]
            }
            patterns.append(top_pattern)
            pattern_number += 1
            # Bottom íŒ¨í„´
            bottom_pattern = {
                'pattern_number': pattern_number,
                'columns': cols,
                'rows': PATTERN_BOTTOM_ROWS,
                'coordinates': [(cols[0], y) for y in PATTERN_BOTTOM_ROWS] + [(cols[1], y) for y in PATTERN_BOTTOM_ROWS]
            }
            patterns.append(bottom_pattern)
            pattern_number += 1
        
        # Zone ë²”ìœ„ ë‚´ íŒ¨í„´ í•„í„°ë§
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) < 4:
            continue
        
        # íŒ¨í„´ ê°’ ì¶”ì¶œ
        pattern_values = []
        for pattern in group_patterns[:4]:
            values = []
            for x, y in pattern['coordinates']:
                relative_x = x - zone['start_x']
                value = zone['zone_data'][relative_x][y]
                if value:
                    values.append(value.upper())
            pattern_values.append(values)
        
        # íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_column ì¶”ì¶œ
        zone_result = {
            'zone_range': f"{zone['start_x'] + 1}-{zone['end_x'] + 1}",
            'pattern_numbers': [],
            'matrix_columns': []
        }
        
        for v in pattern_values[:4]:
            if v:
                # íŒ¨í„´ ë²ˆí˜¸ ì¶”ì¶œ
                pattern_values_lower = [x.lower() for x in v]
                pattern_number = None
                try:
                    with open('pattern.json', 'r') as f:
                        pattern_data = json.load(f)
                    for group_name in ['groupA', 'groupB']:
                        patterns_data = pattern_data['patterns'][group_name]
                        for pattern in patterns_data:
                            if pattern.get('sequence') == pattern_values_lower:
                                pattern_number = pattern.get('pattern_number')
                                break
                        if pattern_number:
                            break
                except Exception as e:
                    pass
                
                # matrix_column ì¶”ì¶œ
                matrix_column = find_pattern_matrix_column(v)
                
                # ê²°ê³¼ ì €ì¥
                zone_result['pattern_numbers'].append(pattern_number if pattern_number else '-')
                
                # matrix_columnì„ T/Fë¡œ ë³€í™˜
                if matrix_column == 'continuous':
                    zone_result['matrix_columns'].append('T')
                elif matrix_column == 'non_continuous':
                    zone_result['matrix_columns'].append('F')
                else:
                    zone_result['matrix_columns'].append('-')
            else:
                zone_result['pattern_numbers'].append('-')
                zone_result['matrix_columns'].append('-')
        
        # íŒ¨í„´ ë²ˆí˜¸ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
        if any(p != '-' for p in zone_result['pattern_numbers']):
            results.append(zone_result)
    
    return results

# ============================================================================
# Matrix Column with Type Functions (ë…ë¦½ êµ¬í˜„)
# ============================================================================

def find_pattern_matrix_column_with_type(pattern_values):
    """
    pattern.jsonì—ì„œ ì…ë ¥ëœ ì‹œí€€ìŠ¤ì™€ ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” íŒ¨í„´ì˜ matrix_columnê³¼ matrix_type ê°’ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„ëœ í•¨ìˆ˜ (ê¸°ì¡´ find_pattern_matrix_column ì°¸ì¡°í•˜ì§€ ì•ŠìŒ)
    
    Args:
        pattern_values (list): íŒ¨í„´ ì‹œí€€ìŠ¤ ë¦¬ìŠ¤íŠ¸, ì˜ˆì‹œ ['b', 'b', 'b']
    
    Returns:
        str or None: 
            - 'T0', 'T1', 'T2': matrix_columnì´ continuousì´ê³  matrix_typeì´ 0, 1, 2ì¸ ê²½ìš°
            - 'F0', 'F1', 'F2': matrix_columnì´ non_continuousì´ê³  matrix_typeì´ 0, 1, 2ì¸ ê²½ìš°
            - None: íŒ¨í„´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
    """
    try:
        # matrix_type í•„ë“œê°€ ìˆëŠ” íŒŒì¼ ê²½ë¡œ ì‹œë„ (drive-download-20251215/pattern.json)
        pattern_file_paths = [
            'drive-download-20251215/pattern.json',
            'pattern.json'
        ]
        
        pattern_data = None
        for pattern_path in pattern_file_paths:
            try:
                with open(pattern_path, 'r', encoding='utf-8') as f:
                    pattern_data = json.load(f)
                    # matrix_type í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                    has_matrix_type = False
                    for group_name in ['groupA', 'groupB']:
                        if pattern_data.get('patterns', {}).get(group_name):
                            first_pattern = pattern_data['patterns'][group_name][0]
                            if 'characteristics' in first_pattern:
                                if 'matrix_type' in first_pattern['characteristics']:
                                    has_matrix_type = True
                                    break
                    if has_matrix_type:
                        break
            except (FileNotFoundError, IOError):
                continue
        
        if not pattern_data:
            st.error("pattern.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        pattern_values = [v.lower() for v in pattern_values if v]
        for group_name in ['groupA', 'groupB']:
            patterns = pattern_data['patterns'][group_name]
            for pattern in patterns:
                if pattern.get('sequence') == pattern_values:
                    characteristics = pattern.get('characteristics', {})
                    matrix_column = characteristics.get('matrix_column')
                    matrix_type = characteristics.get('matrix_type')
                    
                    # matrix_typeì´ ì—†ìœ¼ë©´ None ë°˜í™˜ (ê¸°ë³¸ê°’ 0 ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                    if matrix_type is None:
                        st.warning(f"íŒ¨í„´ {pattern.get('pattern_number')}ì— matrix_type í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                        return None
                    
                    if matrix_column == 'continuous':
                        return f'T{matrix_type}'
                    elif matrix_column == 'non_continuous':
                        return f'F{matrix_type}'
                    else:
                        return None
        return None
    except Exception as e:
        st.error(f"íŒ¨í„´ matrix_column with type ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def extract_pattern_matrix_column_info_with_type_from_converted_grid(zones):
    """
    Converted Gridì—ì„œ íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_column+matrix_type ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë…ë¦½ í•¨ìˆ˜
    ê¸°ì¡´ extract_pattern_matrix_column_info_from_converted_gridë¥¼ ë³µì œí•˜ì—¬ í™•ì¥í•œ ë²„ì „
    ì˜ì¡´ì„± ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„ë¨
    """
    if not zones:
        return []
    
    results = []
    sorted_zones = sorted(zones, key=lambda x: x['start_x'])
    
    for zone in sorted_zones:
        # íŒ¨í„´ ìœ„ì¹˜ ì •ë³´ ìƒì„± (ë…ë¦½ êµ¬í˜„)
        patterns = []
        pattern_number = 1
        for start_col in range(TABLE_WIDTH - PATTERN_WIDTH + 1):
            cols = (start_col, start_col + 1)
            # Top íŒ¨í„´
            top_pattern = {
                'pattern_number': pattern_number,
                'columns': cols,
                'rows': PATTERN_TOP_ROWS,
                'coordinates': [(cols[0], y) for y in PATTERN_TOP_ROWS] + [(cols[1], y) for y in PATTERN_TOP_ROWS]
            }
            patterns.append(top_pattern)
            pattern_number += 1
            # Bottom íŒ¨í„´
            bottom_pattern = {
                'pattern_number': pattern_number,
                'columns': cols,
                'rows': PATTERN_BOTTOM_ROWS,
                'coordinates': [(cols[0], y) for y in PATTERN_BOTTOM_ROWS] + [(cols[1], y) for y in PATTERN_BOTTOM_ROWS]
            }
            patterns.append(bottom_pattern)
            pattern_number += 1
        
        # Zone ë²”ìœ„ ë‚´ íŒ¨í„´ í•„í„°ë§
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) < 4:
            continue
        
        # íŒ¨í„´ ê°’ ì¶”ì¶œ
        pattern_values = []
        for pattern in group_patterns[:4]:
            values = []
            for x, y in pattern['coordinates']:
                relative_x = x - zone['start_x']
                value = zone['zone_data'][relative_x][y]
                if value:
                    values.append(value.upper())
            pattern_values.append(values)
        
        # íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_column+matrix_type ì¶”ì¶œ
        zone_result = {
            'zone_range': f"{zone['start_x'] + 1}-{zone['end_x'] + 1}",
            'pattern_numbers': [],
            'matrix_columns_with_type': []
        }
        
        for v in pattern_values[:4]:
            if v:
                # íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_column+matrix_typeì„ í•¨ê»˜ ì¶”ì¶œ
                pattern_values_lower = [x.lower() for x in v]
                pattern_number = None
                matrix_column_with_type = None
                try:
                    # matrix_type í•„ë“œê°€ ìˆëŠ” íŒŒì¼ ê²½ë¡œ ì‹œë„
                    pattern_file_paths = [
                        'drive-download-20251215/pattern.json',
                        'pattern.json'
                    ]
                    
                    pattern_data = None
                    for pattern_path in pattern_file_paths:
                        try:
                            with open(pattern_path, 'r', encoding='utf-8') as f:
                                pattern_data = json.load(f)
                                # matrix_type í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                                has_matrix_type = False
                                for group_name_check in ['groupA', 'groupB']:
                                    if pattern_data.get('patterns', {}).get(group_name_check):
                                        first_pattern = pattern_data['patterns'][group_name_check][0]
                                        if 'characteristics' in first_pattern:
                                            if 'matrix_type' in first_pattern['characteristics']:
                                                has_matrix_type = True
                                                break
                                if has_matrix_type:
                                    break
                        except (FileNotFoundError, IOError):
                            continue
                    
                    if pattern_data:
                        for group_name in ['groupA', 'groupB']:
                            patterns_data = pattern_data['patterns'][group_name]
                            for pattern in patterns_data:
                                if pattern.get('sequence') == pattern_values_lower:
                                    pattern_number = pattern.get('pattern_number')
                                    # íŒ¨í„´ì„ ì°¾ì•˜ì„ ë•Œ characteristicsì—ì„œ matrix_columnê³¼ matrix_type í•¨ê»˜ ì¶”ì¶œ
                                    characteristics = pattern.get('characteristics', {})
                                    matrix_column = characteristics.get('matrix_column')
                                    matrix_type = characteristics.get('matrix_type')
                                    
                                    # matrix_typeì´ Noneì´ë©´ ê±´ë„ˆë›°ê¸°
                                    if matrix_type is not None:
                                        if matrix_column == 'continuous':
                                            matrix_column_with_type = f'T{matrix_type}'
                                        elif matrix_column == 'non_continuous':
                                            matrix_column_with_type = f'F{matrix_type}'
                                    break
                            if pattern_number:
                                break
                except Exception as e:
                    pass
                
                # ê²°ê³¼ ì €ì¥
                zone_result['pattern_numbers'].append(pattern_number if pattern_number else '-')
                zone_result['matrix_columns_with_type'].append(matrix_column_with_type if matrix_column_with_type else '-')
            else:
                zone_result['pattern_numbers'].append('-')
                zone_result['matrix_columns_with_type'].append('-')
        
        # íŒ¨í„´ ë²ˆí˜¸ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
        if any(p != '-' for p in zone_result['pattern_numbers']):
            results.append(zone_result)
    
    return results

def extract_pattern_matrix_column_info_with_type_from_reconstructed_grid(zones):
    """
    T-Removed Reconstructed Gridì—ì„œ íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_column+matrix_type ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë…ë¦½ í•¨ìˆ˜
    ê¸°ì¡´ extract_pattern_matrix_column_info_from_reconstructed_gridë¥¼ ë³µì œí•˜ì—¬ í™•ì¥í•œ ë²„ì „
    ì˜ì¡´ì„± ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„ë¨
    """
    if not zones:
        return []
    
    results = []
    sorted_zones = sorted(zones, key=lambda x: x['start_x'])
    
    for zone in sorted_zones:
        # íŒ¨í„´ ìœ„ì¹˜ ì •ë³´ ìƒì„± (ë…ë¦½ êµ¬í˜„)
        patterns = []
        pattern_number = 1
        for start_col in range(TABLE_WIDTH - PATTERN_WIDTH + 1):
            cols = (start_col, start_col + 1)
            # Top íŒ¨í„´
            top_pattern = {
                'pattern_number': pattern_number,
                'columns': cols,
                'rows': PATTERN_TOP_ROWS,
                'coordinates': [(cols[0], y) for y in PATTERN_TOP_ROWS] + [(cols[1], y) for y in PATTERN_TOP_ROWS]
            }
            patterns.append(top_pattern)
            pattern_number += 1
            # Bottom íŒ¨í„´
            bottom_pattern = {
                'pattern_number': pattern_number,
                'columns': cols,
                'rows': PATTERN_BOTTOM_ROWS,
                'coordinates': [(cols[0], y) for y in PATTERN_BOTTOM_ROWS] + [(cols[1], y) for y in PATTERN_BOTTOM_ROWS]
            }
            patterns.append(bottom_pattern)
            pattern_number += 1
        
        # Zone ë²”ìœ„ ë‚´ íŒ¨í„´ í•„í„°ë§
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) < 4:
            continue
        
        # íŒ¨í„´ ê°’ ì¶”ì¶œ
        pattern_values = []
        for pattern in group_patterns[:4]:
            values = []
            for x, y in pattern['coordinates']:
                relative_x = x - zone['start_x']
                value = zone['zone_data'][relative_x][y]
                if value:
                    values.append(value.upper())
            pattern_values.append(values)
        
        # íŒ¨í„´ ë²ˆí˜¸ì™€ matrix_column+matrix_type ì¶”ì¶œ
        zone_result = {
            'zone_range': f"{zone['start_x'] + 1}-{zone['end_x'] + 1}",
            'pattern_numbers': [],
            'matrix_columns_with_type': []
        }
        
        for v in pattern_values[:4]:
            if v:
                # íŒ¨í„´ ë²ˆí˜¸ ì¶”ì¶œ
                pattern_values_lower = [x.lower() for x in v]
                pattern_number = None
                matrix_column_with_type = None
                try:
                    # matrix_type í•„ë“œê°€ ìˆëŠ” íŒŒì¼ ê²½ë¡œ ì‹œë„
                    pattern_file_paths = [
                        'drive-download-20251215/pattern.json',
                        'pattern.json'
                    ]
                    
                    pattern_data = None
                    for pattern_path in pattern_file_paths:
                        try:
                            with open(pattern_path, 'r', encoding='utf-8') as f:
                                pattern_data = json.load(f)
                                # matrix_type í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                                has_matrix_type = False
                                for group_name_check in ['groupA', 'groupB']:
                                    if pattern_data.get('patterns', {}).get(group_name_check):
                                        first_pattern = pattern_data['patterns'][group_name_check][0]
                                        if 'characteristics' in first_pattern:
                                            if 'matrix_type' in first_pattern['characteristics']:
                                                has_matrix_type = True
                                                break
                                if has_matrix_type:
                                    break
                        except (FileNotFoundError, IOError):
                            continue
                    
                    if pattern_data:
                        for group_name in ['groupA', 'groupB']:
                            patterns_data = pattern_data['patterns'][group_name]
                            for pattern in patterns_data:
                                if pattern.get('sequence') == pattern_values_lower:
                                    pattern_number = pattern.get('pattern_number')
                                    # íŒ¨í„´ì„ ì°¾ì•˜ì„ ë•Œ characteristicsì—ì„œ matrix_columnê³¼ matrix_type í•¨ê»˜ ì¶”ì¶œ
                                    characteristics = pattern.get('characteristics', {})
                                    matrix_column = characteristics.get('matrix_column')
                                    matrix_type = characteristics.get('matrix_type')
                                    
                                    # matrix_typeì´ Noneì´ë©´ ê±´ë„ˆë›°ê¸°
                                    if matrix_type is not None:
                                        if matrix_column == 'continuous':
                                            matrix_column_with_type = f'T{matrix_type}'
                                        elif matrix_column == 'non_continuous':
                                            matrix_column_with_type = f'F{matrix_type}'
                                    break
                            if pattern_number:
                                break
                except Exception as e:
                    pass
                
                # matrix_column+matrix_type ì¶”ì¶œ (ë…ë¦½ í•¨ìˆ˜ ì‚¬ìš©)
                if not matrix_column_with_type:
                    matrix_column_with_type_value = find_pattern_matrix_column_with_type(v)
                    if matrix_column_with_type_value:
                        matrix_column_with_type = matrix_column_with_type_value
                
                # ê²°ê³¼ ì €ì¥
                zone_result['pattern_numbers'].append(pattern_number if pattern_number else '-')
                zone_result['matrix_columns_with_type'].append(matrix_column_with_type if matrix_column_with_type else '-')
            else:
                zone_result['pattern_numbers'].append('-')
                zone_result['matrix_columns_with_type'].append('-')
        
        # íŒ¨í„´ ë²ˆí˜¸ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
        if any(p != '-' for p in zone_result['pattern_numbers']):
            results.append(zone_result)
    
    return results

def compare_matrix_column_with_type(converted_str, reconstructed_str):
    """
    matrix_column with type ê°’ì„ ë¹„êµí•˜ëŠ” í•¨ìˆ˜
    ê¸°ì¡´ ë¹„êµ (T/T/F)ì™€ í™•ì¥ ë¹„êµ (T0/T0/F1 vs T0/T0/F2)ë¥¼ ëª¨ë‘ ìˆ˜í–‰
    ê·¸ë£¹ ì „ì²´(4ê°œ íŒ¨í„´) ë¹„êµë„ ìˆ˜í–‰
    
    Args:
        converted_str: Converted Gridì˜ matrix_column with type ë¬¸ìì—´ (ì˜ˆ: "T0T0F1T2")
        reconstructed_str: Reconstructed Gridì˜ matrix_column with type ë¬¸ìì—´ (ì˜ˆ: "T0T0F2T1")
    
    Returns:
        tuple: (basic_match, detailed_match, full_group_match, match_status, full_group_match_status)
            - basic_match: ê¸°ì¡´ ë°©ì‹ ë¹„êµ ê²°ê³¼ (T/Fë§Œ ë¹„êµ, ì• 3ê¸€ì)
            - detailed_match: í™•ì¥ ë°©ì‹ ë¹„êµ ê²°ê³¼ (ì• 3ê°œ íŒ¨í„´, 6ê¸€ì)
            - full_group_match: ê·¸ë£¹ ì „ì²´ ë¹„êµ ê²°ê³¼ (4ê°œ íŒ¨í„´ ì „ì²´)
            - match_status: ì• 3ê°œ íŒ¨í„´ ë¹„êµì˜ ë§¤ì¹˜ ìƒíƒœ HTML ë¬¸ìì—´
            - full_group_match_status: ê·¸ë£¹ ì „ì²´ ë¹„êµì˜ ë§¤ì¹˜ ìƒíƒœ HTML ë¬¸ìì—´
    """
    if converted_str == '-' or reconstructed_str == '-':
        na_status = '<span style="background-color: #D3D3D3; padding: 2px 6px; border-radius: 3px; font-weight: bold;">N/A</span>'
        return False, False, False, na_status, na_status
    
    # ê¸°ì¡´ ë°©ì‹: T/Fë§Œ ì¶”ì¶œí•˜ì—¬ ë¹„êµ (ì• 3ê¸€ì)
    c_basic = ''.join([c for c in converted_str if c in ['T', 'F']])[:3]
    r_basic = ''.join([c for c in reconstructed_str if c in ['T', 'F']])[:3]
    basic_match = (c_basic == r_basic)
    
    # í™•ì¥ ë°©ì‹: ì• 3ê°œ íŒ¨í„´ì˜ ì „ì²´ ê°’ ë¹„êµ (ê° 2ê¸€ìì”©, ì´ 6ê¸€ì)
    c_detailed = converted_str[:6] if len(converted_str) >= 6 else converted_str
    r_detailed = reconstructed_str[:6] if len(reconstructed_str) >= 6 else reconstructed_str
    detailed_match = (c_detailed == r_detailed)
    
    # ê·¸ë£¹ ì „ì²´ ë¹„êµ: ê¸°ë³¸ ë°©ì‹ì²˜ëŸ¼ T/Fë§Œ ì¶”ì¶œí•˜ì—¬ 4ê°œ ë¬¸ì ë¹„êµ
    # ì „ì²´ ë¬¸ìì—´ì—ì„œ T/Fë§Œ ì¶”ì¶œ (ì˜ˆ: "T0T0F1T2" â†’ "TTFT")
    c_full_basic = ''.join([c for c in converted_str if c in ['T', 'F']])[:4]
    r_full_basic = ''.join([c for c in reconstructed_str if c in ['T', 'F']])[:4]
    full_group_match = (c_full_basic == r_full_basic)
    
    # ì• 3ê°œ íŒ¨í„´ ë¹„êµì˜ ë§¤ì¹˜ ìƒíƒœ ê²°ì •
    if detailed_match:
        match_status = '<span style="background-color: #90EE90; padding: 2px 6px; border-radius: 3px; font-weight: bold;">MATCH</span>'
    elif basic_match:
        # ê¸°ì¡´ ë°©ì‹ì—ì„œëŠ” matchì´ì§€ë§Œ í™•ì¥ ë°©ì‹ì—ì„œëŠ” unmatch
        match_status = '<span style="background-color: #FFD700; padding: 2px 6px; border-radius: 3px; font-weight: bold;">PARTIAL</span>'
    else:
        match_status = '<span style="background-color: #FFB6C1; padding: 2px 6px; border-radius: 3px; font-weight: bold;">UNMATCH</span>'
    
    # ê·¸ë£¹ ì „ì²´ ë¹„êµì˜ ë§¤ì¹˜ ìƒíƒœ ê²°ì • (ê¸°ë³¸ ë°©ì‹ì²˜ëŸ¼ T/Fë§Œ ë¹„êµ)
    if full_group_match:
        # 4ê°œ ë¬¸ìê°€ ëª¨ë‘ ì¼ì¹˜í•˜ë©´ MATCH
        full_group_match_status = '<span style="background-color: #90EE90; padding: 2px 6px; border-radius: 3px; font-weight: bold;">MATCH</span>'
    else:
        # 4ê°œ ë¬¸ìê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ UNMATCH
        full_group_match_status = '<span style="background-color: #FFB6C1; padding: 2px 6px; border-radius: 3px; font-weight: bold;">UNMATCH</span>'
    
    return basic_match, detailed_match, full_group_match, match_status, full_group_match_status

def display_grid_matrix_summary(converted_results):
    """
    Converted Gridì™€ T-Removed Reconstructed Gridì˜ matrix_column ì •ë³´ë¥¼ í•œ ì¤„ë¡œ í‘œì‹œí•˜ëŠ” ë…ë¦½ í•¨ìˆ˜
    Cì™€ Rì˜ ê·¸ë£¹ 1ë§Œ ë¹„êµí•˜ì—¬ match/unmatch í‘œì‹œ
    ê¸°ì¡´ ë¹„êµì™€ í™•ì¥ ë¹„êµ(matrix_type í¬í•¨)ë¥¼ ëª¨ë‘ í‘œì‹œ
    """
    st.markdown("#### Grid Matrix Summary")
    
    # 1. Converted Grid Matrix Column ì •ë³´ ìˆ˜ì§‘ (ê·¸ë£¹ 1ë§Œ) - ê¸°ì¡´ ë°©ì‹
    converted_matrix_str = '-'
    if converted_results and len(converted_results) > 0:
        first_result = converted_results[0]
        matrix_columns = first_result.get('matrix_columns', [])
        if matrix_columns:
            # ì „ì²´ matrix_column ê°’ì„ ë¬¸ìì—´ë¡œ ì—°ê²° (ì˜ˆ: "FTFT")
            converted_matrix_str = ''.join(matrix_columns)
    
    # 2. T-Removed Reconstructed Grid Matrix Column ì •ë³´ ìˆ˜ì§‘ (ê·¸ë£¹ 1ë§Œ) - ê¸°ì¡´ ë°©ì‹
    reconstructed_matrix_str = '-'
    if hasattr(st.session_state, 'reconstructed_grid') and st.session_state.reconstructed_grid:
        reconstructed_zones = divide_grid_into_overlapping_zones_for_reconstructed(st.session_state.reconstructed_grid)
        if reconstructed_zones:
            reconstructed_results = extract_pattern_matrix_column_info_from_reconstructed_grid(reconstructed_zones)
            if reconstructed_results and len(reconstructed_results) > 0:
                first_result = reconstructed_results[0]
                matrix_columns = first_result.get('matrix_columns', [])
                if matrix_columns:
                    reconstructed_matrix_str = ''.join(matrix_columns)
    
    # 3. ê¸°ì¡´ ë°©ì‹ ë¹„êµ (T/Fë§Œ ë¹„êµ, ì• 3ê¸€ì)
    match_status_basic = ""
    if converted_matrix_str != '-' and reconstructed_matrix_str != '-':
        # ì• 3ê¸€ì ë¹„êµ
        c_first_3 = converted_matrix_str[:3] if len(converted_matrix_str) >= 3 else converted_matrix_str
        r_first_3 = reconstructed_matrix_str[:3] if len(reconstructed_matrix_str) >= 3 else reconstructed_matrix_str
        
        if c_first_3 == r_first_3:
            match_status_basic = '<span style="background-color: #90EE90; padding: 2px 6px; border-radius: 3px; font-weight: bold;">MATCH</span>'
        else:
            match_status_basic = '<span style="background-color: #FFB6C1; padding: 2px 6px; border-radius: 3px; font-weight: bold;">UNMATCH</span>'
    elif converted_matrix_str != '-' or reconstructed_matrix_str != '-':
        match_status_basic = '<span style="background-color: #D3D3D3; padding: 2px 6px; border-radius: 3px; font-weight: bold;">N/A</span>'
    
    # 4. í™•ì¥ ë°©ì‹: Matrix Column with Type ì •ë³´ ìˆ˜ì§‘ (ê·¸ë£¹ 1ë§Œ)
    converted_matrix_with_type_str = '-'
    if converted_results and len(converted_results) > 0:
        # í™•ì¥ ë²„ì „ í•¨ìˆ˜ë¡œ ì •ë³´ ì¶”ì¶œ
        # zonesë¥¼ ë‹¤ì‹œ ìƒì„± (convert_resultsê°€ ìˆìœ¼ë¯€ë¡œ converted_gridê°€ ì¡´ì¬í•¨)
        if st.session_state.show_grid and st.session_state.converted_grid is not None:
            # divide_grid_into_overlapping_zones í•¨ìˆ˜ ë³µì œ (ë…ë¦½ êµ¬í˜„)
            converted_zones_for_type = []
            grid_for_zones = st.session_state.converted_grid
            zone_width = 3
            for start_x in range(15 - zone_width + 1):
                end_x = start_x + zone_width
                zone_data = [[grid_for_zones[x][y] for y in range(6)] for x in range(start_x, end_x)]
                if any(cell in {'b', 't', 'p'} for column in zone_data for cell in column):
                    converted_zones_for_type.append({
                        'zone_data': zone_data,
                        'start_x': start_x,
                        'end_x': end_x - 1
                    })
            
            if converted_zones_for_type:
                converted_results_with_type = extract_pattern_matrix_column_info_with_type_from_converted_grid(converted_zones_for_type)
                if converted_results_with_type and len(converted_results_with_type) > 0:
                    first_result_with_type = converted_results_with_type[0]
                    matrix_columns_with_type = first_result_with_type.get('matrix_columns_with_type', [])
                    if matrix_columns_with_type:
                        converted_matrix_with_type_str = ''.join(matrix_columns_with_type)
    
    reconstructed_matrix_with_type_str = '-'
    if hasattr(st.session_state, 'reconstructed_grid') and st.session_state.reconstructed_grid:
        reconstructed_zones = divide_grid_into_overlapping_zones_for_reconstructed(st.session_state.reconstructed_grid)
        if reconstructed_zones:
            reconstructed_results_with_type = extract_pattern_matrix_column_info_with_type_from_reconstructed_grid(reconstructed_zones)
            if reconstructed_results_with_type and len(reconstructed_results_with_type) > 0:
                first_result_with_type = reconstructed_results_with_type[0]
                matrix_columns_with_type = first_result_with_type.get('matrix_columns_with_type', [])
                if matrix_columns_with_type:
                    reconstructed_matrix_with_type_str = ''.join(matrix_columns_with_type)
    
    # 5. í™•ì¥ ë°©ì‹ ë¹„êµ (T0/T0/F1 vs T0/T0/F2 ë“± ì„¸ë¶„í™” ë¹„êµ)
    basic_match, detailed_match, full_group_match, match_status_detailed, full_group_match_status = compare_matrix_column_with_type(
        converted_matrix_with_type_str, 
        reconstructed_matrix_with_type_str
    )
    
    # 6. ê¸°ì¡´ ë°©ì‹ í‘œì‹œ (ê·¸ë£¹ 1ë§Œ)
    st.markdown("**ê¸°ì¡´ ë°©ì‹ (T/Fë§Œ ë¹„êµ):**")
    st.markdown(f"**C:** {converted_matrix_str} | **R:** {reconstructed_matrix_str} | {match_status_basic}", unsafe_allow_html=True)
    
    # 7. í™•ì¥ ë°©ì‹ í‘œì‹œ (ê·¸ë£¹ 1ë§Œ, matrix_type í¬í•¨, ì• 3ê°œ íŒ¨í„´ ë¹„êµ)
    st.markdown("**í™•ì¥ ë°©ì‹ - ì• 3ê°œ íŒ¨í„´ (matrix_type í¬í•¨):**")
    st.markdown(f"**C:** {converted_matrix_with_type_str[:6] if len(converted_matrix_with_type_str) >= 6 else converted_matrix_with_type_str} | **R:** {reconstructed_matrix_with_type_str[:6] if len(reconstructed_matrix_with_type_str) >= 6 else reconstructed_matrix_with_type_str} | {match_status_detailed}", unsafe_allow_html=True)
    
    # 8. í™•ì¥ ë°©ì‹ - ê·¸ë£¹ ì „ì²´ ë¹„êµ í‘œì‹œ (4ê°œ íŒ¨í„´ ì „ì²´)
    st.markdown("**í™•ì¥ ë°©ì‹ - ê·¸ë£¹ ì „ì²´ (4ê°œ íŒ¨í„´, matrix_type í¬í•¨):**")
    st.markdown(f"**C:** {converted_matrix_with_type_str} | **R:** {reconstructed_matrix_with_type_str} | {full_group_match_status}", unsafe_allow_html=True)
    
    st.markdown("---")

def display_matrix_column_info():
    """
    Converted Gridì˜ matrix_column ì •ë³´ì™€ Sequence Prediction Resultsë¥¼ í‘œì‹œ
    ì˜¤ë¥¸ìª½ ì˜ì—­ ìµœìƒë‹¨ì— í‘œì‹œë˜ë„ë¡ ì„¤ê³„ë¨
    ê·¸ë£¹ë³„ë¡œ Pattern 1-2ì™€ Pattern 2-3ì˜ matrix_column ê°’ê³¼ Sequence Prediction Resultsë¥¼ ì¶”ì¶œí•˜ì—¬ í‘œì‹œ
    ê° Matrix ì¡°í•©(FF, FT, TF, TT)ì— ëŒ€í•´ ì²« ë²ˆì§¸ë¡œ ì¶”ì¶œëœ Sequence ê°’ì„ ê³ ì • ì €ì¥
    """
    st.markdown("### Matrix Column Information")
    
    # Matrix Sequence Mapping ì´ˆê¸°í™” (ì—†ìœ¼ë©´)
    if 'matrix_sequence_mapping' not in st.session_state:
        st.session_state.matrix_sequence_mapping = {}
    
    # Matrix Sequence ì¶”ì¶œ ìˆœì„œ ì¶”ì  ì´ˆê¸°í™” (ì—†ìœ¼ë©´)
    if 'matrix_sequence_order' not in st.session_state:
        st.session_state.matrix_sequence_order = {}
    if 'matrix_sequence_order_counter' not in st.session_state:
        st.session_state.matrix_sequence_order_counter = 0
    
    # Converted Grid ì •ë³´ ì¶”ì¶œ ë° í‘œì‹œ
    if st.session_state.show_grid and st.session_state.converted_grid is not None:
        zones = divide_grid_into_overlapping_zones(st.session_state.converted_grid)
        if zones:
            converted_results = extract_pattern_matrix_column_info_from_converted_grid(zones)
            if converted_results:
                # Zoneì„ zone_rangeì™€ ë§¤ì¹­í•˜ê¸° ìœ„í•´ ë”•ì…”ë„ˆë¦¬ ìƒì„±
                zones_dict = {}
                sorted_zones = sorted(zones, key=lambda x: x['start_x'])
                for zone in sorted_zones:
                    zone_range = f"{zone['start_x'] + 1}-{zone['end_x'] + 1}"
                    zones_dict[zone_range] = zone
                
                # ë¨¼ì € ëª¨ë“  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ Sequence ê°’ ì €ì¥
                flag_triggered_zone = None
                for result in converted_results:
                    matrix_columns = result['matrix_columns']
                    zone_range = result['zone_range']
                    
                    # Pattern 1-2ì™€ Pattern 2-3 ê°’ ì¶”ì¶œ
                    pattern1_2_matrix = ''
                    pattern2_3_matrix = ''
                    
                    if len(matrix_columns) >= 2:
                        # Pattern 1,2 ì¡°í•© (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸)
                        if matrix_columns[0] != '-' and matrix_columns[1] != '-':
                            pattern1_2_matrix = matrix_columns[0] + matrix_columns[1]
                    
                    if len(matrix_columns) >= 3:
                        # Pattern 2,3 ì¡°í•© (ë‘ ë²ˆì§¸ì™€ ì„¸ ë²ˆì§¸)
                        if matrix_columns[1] != '-' and matrix_columns[2] != '-':
                            pattern2_3_matrix = matrix_columns[1] + matrix_columns[2]
                    
                    # Sequence Prediction Results ì¶”ì¶œ ë° ì €ì¥
                    if zone_range in zones_dict:
                        zone = zones_dict[zone_range]
                        # get_zone_pattern_sequence_resultsë¥¼ ì‚¬ìš©í•˜ì—¬ Sequence Prediction Results ì¶”ì¶œ
                        (pattern1_actual_result, pattern2_actual_result, pattern1_formatted, pattern2_formatted, 
                         sequence_type1, sequence_type2, pattern1_prediction, pattern2_prediction, pattern1_comparison, 
                         pattern2_comparison, all_pattern_info, pattern1_gap_tf, pattern2_gap_tf) = get_zone_pattern_sequence_results(zone)
                        
                        # Pattern 1,2ì˜ Sequence Prediction Results ì €ì¥ (ì²« ë²ˆì§¸ ê°’ë§Œ)
                        new_value_saved = False
                        if pattern1_2_matrix and pattern1_comparison in ['W', 'L']:
                            key_1_2 = f"pattern1_2_{pattern1_2_matrix}"
                            if key_1_2 not in st.session_state.matrix_sequence_mapping:
                                # ì²« ë²ˆì§¸ ê°’ìœ¼ë¡œ ì €ì¥
                                st.session_state.matrix_sequence_mapping[key_1_2] = pattern1_comparison
                                # ìˆœì„œ ì •ë³´ ì €ì¥
                                st.session_state.matrix_sequence_order_counter += 1
                                st.session_state.matrix_sequence_order[key_1_2] = {
                                    'order': st.session_state.matrix_sequence_order_counter,
                                    'zone': zone_range,
                                    'matrix': pattern1_2_matrix
                                }
                                new_value_saved = True
                        
                        # Pattern 2,3ì˜ Sequence Prediction Results ì €ì¥ (ì²« ë²ˆì§¸ ê°’ë§Œ)
                        if pattern2_3_matrix and pattern2_comparison in ['W', 'L']:
                            key_2_3 = f"pattern2_3_{pattern2_3_matrix}"
                            if key_2_3 not in st.session_state.matrix_sequence_mapping:
                                # ì²« ë²ˆì§¸ ê°’ìœ¼ë¡œ ì €ì¥
                                st.session_state.matrix_sequence_mapping[key_2_3] = pattern2_comparison
                                # ìˆœì„œ ì •ë³´ ì €ì¥
                                st.session_state.matrix_sequence_order_counter += 1
                                st.session_state.matrix_sequence_order[key_2_3] = {
                                    'order': st.session_state.matrix_sequence_order_counter,
                                    'zone': zone_range,
                                    'matrix': pattern2_3_matrix
                                }
                                new_value_saved = True
                        
                        # ìƒˆë¡œìš´ ê°’ì´ ì €ì¥ëœ ê²½ìš°ì—ë§Œ í”Œë˜ê·¸ ì¡°ê±´ í™•ì¸
                        if new_value_saved and (flag_triggered_zone is None):
                            # ì¡°ê±´ 1: FFì˜ Pattern 1,2 Sequenceì™€ Pattern 2,3 Sequenceê°€ ëª¨ë‘ ì±„ì›Œì§
                            ff_p1_2 = st.session_state.matrix_sequence_mapping.get('pattern1_2_FF', '-')
                            ff_p2_3 = st.session_state.matrix_sequence_mapping.get('pattern2_3_FF', '-')
                            ff_complete = (ff_p1_2 != '-' and ff_p2_3 != '-')
                            
                            # ì¡°ê±´ 2: FT, TF, TT ì¤‘ì—ì„œ Pattern 1,2 Sequenceê°€ í•˜ë‚˜ë¼ë„ ìˆê³ , Pattern 2,3 Sequenceê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì¶©ì¡±
                            ft_p1_2 = st.session_state.matrix_sequence_mapping.get('pattern1_2_FT', '-')
                            ft_p2_3 = st.session_state.matrix_sequence_mapping.get('pattern2_3_FT', '-')
                            
                            tf_p1_2 = st.session_state.matrix_sequence_mapping.get('pattern1_2_TF', '-')
                            tf_p2_3 = st.session_state.matrix_sequence_mapping.get('pattern2_3_TF', '-')
                            
                            tt_p1_2 = st.session_state.matrix_sequence_mapping.get('pattern1_2_TT', '-')
                            tt_p2_3 = st.session_state.matrix_sequence_mapping.get('pattern2_3_TT', '-')
                            
                            # Pattern 1,2 Sequenceê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
                            has_p1_2 = (ft_p1_2 != '-' or tf_p1_2 != '-' or tt_p1_2 != '-')
                            # Pattern 2,3 Sequenceê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
                            has_p2_3 = (ft_p2_3 != '-' or tf_p2_3 != '-' or tt_p2_3 != '-')
                            
                            # ë‘ ê°’ì´ ê°ê° í•˜ë‚˜ì”© ìˆìœ¼ë©´ ì¡°ê±´ ì¶©ì¡±
                            other_complete = (has_p1_2 and has_p2_3)
                            
                            # ì–´ë–¤ ì¡°í•©ì—ì„œ ê°’ì´ ë‚˜ì™”ëŠ”ì§€ í™•ì¸ (í‘œì‹œìš©)
                            other_combo_p1_2 = 'FT' if ft_p1_2 != '-' else ('TF' if tf_p1_2 != '-' else ('TT' if tt_p1_2 != '-' else ''))
                            other_combo_p2_3 = 'FT' if ft_p2_3 != '-' else ('TF' if tf_p2_3 != '-' else ('TT' if tt_p2_3 != '-' else ''))
                            other_p1_2_value = ft_p1_2 if ft_p1_2 != '-' else (tf_p1_2 if tf_p1_2 != '-' else (tt_p1_2 if tt_p1_2 != '-' else '-'))
                            other_p2_3_value = ft_p2_3 if ft_p2_3 != '-' else (tf_p2_3 if tf_p2_3 != '-' else (tt_p2_3 if tt_p2_3 != '-' else '-'))
                            
                            # ë‘ ì¡°ê±´ì´ ëª¨ë‘ ì¶©ì¡±ë˜ë©´ í”Œë˜ê·¸ ì„¤ì •
                            if ff_complete and other_complete:
                                # í”Œë˜ê·¸ê°€ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì„¤ì •
                                if 'matrix_flag_info' not in st.session_state or not st.session_state.matrix_flag_info.get('triggered', False):
                                    flag_triggered_zone = zone_range
                                    st.session_state.matrix_flag_info = {
                                        'triggered': True,
                                        'zone': zone_range,
                                        'ff_p1_2': ff_p1_2,
                                        'ff_p2_3': ff_p2_3,
                                        'other_combo_p1_2': other_combo_p1_2,
                                        'other_combo_p2_3': other_combo_p2_3,
                                        'other_p1_2': other_p1_2_value,
                                        'other_p2_3': other_p2_3_value
                                    }
                
                # Grid Matrix Summary í‘œì‹œ (ë…ë¦½ í•¨ìˆ˜ í˜¸ì¶œ)
                display_grid_matrix_summary(converted_results)
                
                # ì €ì¥ëœ Matrix ì¡°í•©ë³„ ì²« Sequence ê°’ í…Œì´ë¸” í‘œì‹œ
                st.markdown("#### Matrix Combination Sequence Mapping Table")
                
                # Matrix ì¡°í•© ë¦¬ìŠ¤íŠ¸
                matrix_combinations = ['FF', 'FT', 'TF', 'TT']
                
                # í…Œì´ë¸” ë°ì´í„° ìƒì„±
                mapping_table_data = []
                for matrix_combo in matrix_combinations:
                    pattern1_2_key = f"pattern1_2_{matrix_combo}"
                    pattern2_3_key = f"pattern2_3_{matrix_combo}"
                    
                    pattern1_2_sequence = st.session_state.matrix_sequence_mapping.get(pattern1_2_key, '-')
                    pattern2_3_sequence = st.session_state.matrix_sequence_mapping.get(pattern2_3_key, '-')
                    
                    # ìˆœì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    order_info_1_2 = st.session_state.matrix_sequence_order.get(pattern1_2_key, {})
                    order_info_2_3 = st.session_state.matrix_sequence_order.get(pattern2_3_key, {})
                    
                    order_1_2 = order_info_1_2.get('order', None) if pattern1_2_sequence != '-' else None
                    order_2_3 = order_info_2_3.get('order', None) if pattern2_3_sequence != '-' else None
                    
                    # ìˆœì„œ í‘œì‹œ ë¬¸ìì—´ ìƒì„±
                    order_display_1_2 = f"#{order_1_2}" if order_1_2 else '-'
                    order_display_2_3 = f"#{order_2_3}" if order_2_3 else '-'
                    
                    mapping_table_data.append({
                        'Matrix Combination': matrix_combo,
                        'Pattern 1,2 Sequence': f"{pattern1_2_sequence} ({order_display_1_2})" if pattern1_2_sequence != '-' else '-',
                        'Pattern 2,3 Sequence': f"{pattern2_3_sequence} ({order_display_2_3})" if pattern2_3_sequence != '-' else '-'
                    })
                
                # í…Œì´ë¸”ë¡œ í‘œì‹œ
                if mapping_table_data:
                    mapping_df = pd.DataFrame(mapping_table_data)
                    st.table(mapping_df)
                
                # í”Œë˜ê·¸ ì¡°ê±´ ì¬í™•ì¸ (ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ í›„)
                # ì¡°ê±´ 1: FFì˜ Pattern 1,2 Sequenceì™€ Pattern 2,3 Sequenceê°€ ëª¨ë‘ ì±„ì›Œì§
                ff_p1_2 = st.session_state.matrix_sequence_mapping.get('pattern1_2_FF', '-')
                ff_p2_3 = st.session_state.matrix_sequence_mapping.get('pattern2_3_FF', '-')
                ff_complete = (ff_p1_2 != '-' and ff_p2_3 != '-')
                
                # ì¡°ê±´ 2: FT, TF, TT ì¤‘ì—ì„œ Pattern 1,2 Sequenceê°€ í•˜ë‚˜ë¼ë„ ìˆê³ , Pattern 2,3 Sequenceê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì¶©ì¡±
                ft_p1_2 = st.session_state.matrix_sequence_mapping.get('pattern1_2_FT', '-')
                ft_p2_3 = st.session_state.matrix_sequence_mapping.get('pattern2_3_FT', '-')
                
                tf_p1_2 = st.session_state.matrix_sequence_mapping.get('pattern1_2_TF', '-')
                tf_p2_3 = st.session_state.matrix_sequence_mapping.get('pattern2_3_TF', '-')
                
                tt_p1_2 = st.session_state.matrix_sequence_mapping.get('pattern1_2_TT', '-')
                tt_p2_3 = st.session_state.matrix_sequence_mapping.get('pattern2_3_TT', '-')
                
                # Pattern 1,2 Sequenceê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
                has_p1_2 = (ft_p1_2 != '-' or tf_p1_2 != '-' or tt_p1_2 != '-')
                # Pattern 2,3 Sequenceê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
                has_p2_3 = (ft_p2_3 != '-' or tf_p2_3 != '-' or tt_p2_3 != '-')
                
                # ë‘ ê°’ì´ ê°ê° í•˜ë‚˜ì”© ìˆìœ¼ë©´ ì¡°ê±´ ì¶©ì¡±
                other_complete = (has_p1_2 and has_p2_3)
                
                # ì–´ë–¤ ì¡°í•©ì—ì„œ ê°’ì´ ë‚˜ì™”ëŠ”ì§€ í™•ì¸ (í‘œì‹œìš©)
                other_combo_p1_2 = 'FT' if ft_p1_2 != '-' else ('TF' if tf_p1_2 != '-' else ('TT' if tt_p1_2 != '-' else ''))
                other_combo_p2_3 = 'FT' if ft_p2_3 != '-' else ('TF' if tf_p2_3 != '-' else ('TT' if tt_p2_3 != '-' else ''))
                other_p1_2_value = ft_p1_2 if ft_p1_2 != '-' else (tf_p1_2 if tf_p1_2 != '-' else (tt_p1_2 if tt_p1_2 != '-' else '-'))
                other_p2_3_value = ft_p2_3 if ft_p2_3 != '-' else (tf_p2_3 if tf_p2_3 != '-' else (tt_p2_3 if tt_p2_3 != '-' else '-'))
                
                # ë‘ ì¡°ê±´ì´ ëª¨ë‘ ì¶©ì¡±ë˜ë©´ í”Œë˜ê·¸ ì„¤ì •
                if ff_complete and other_complete:
                    # í”Œë˜ê·¸ê°€ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜, í˜„ì¬ ê·¸ë£¹ì—ì„œ ìƒˆë¡œ ì¶©ì¡±ëœ ê²½ìš°
                    if 'matrix_flag_info' not in st.session_state or not st.session_state.matrix_flag_info.get('triggered', False):
                        # ë§ˆì§€ë§‰ ê·¸ë£¹ì„ í”Œë˜ê·¸ ìœ„ì¹˜ë¡œ ì„¤ì •
                        flag_zone = converted_results[-1]['zone_range'] if converted_results else 'Unknown'
                        st.session_state.matrix_flag_info = {
                            'triggered': True,
                            'zone': flag_zone,
                            'ff_p1_2': ff_p1_2,
                            'ff_p2_3': ff_p2_3,
                            'other_combo_p1_2': other_combo_p1_2,
                            'other_combo_p2_3': other_combo_p2_3,
                            'other_p1_2': other_p1_2_value,
                            'other_p2_3': other_p2_3_value
                        }
                
                # í”Œë˜ê·¸ ì •ë³´ í‘œì‹œ
                if 'matrix_flag_info' in st.session_state and st.session_state.matrix_flag_info.get('triggered', False):
                    flag_info = st.session_state.matrix_flag_info
                    st.markdown("#### ğŸš© Flag Triggered")
                    
                    # Converted Grid ê¸°ì¤€ ê·¸ë£¹
                    converted_group = flag_info['zone']
                    
                    # ìƒì„¸ ì •ë³´ ê³„ì‚°
                    original_grid = st.session_state.grid if st.session_state.grid else None
                    if original_grid:
                        detailed_info = get_detailed_flag_info(converted_group, original_grid)
                        
                        if detailed_info:
                            # Converted Grid ìƒì„¸ ì •ë³´
                            st.markdown("##### Converted Grid")
                            st.text(f"ê·¸ë£¹ ë²”ìœ„: Group {converted_group}")
                            st.text(f"ì…€ ì¸ë±ìŠ¤: {detailed_info['converted_cell_index']}")
                            st.text(f"ìœ„ì¹˜: ì—´ {detailed_info['converted_col']}, í–‰ {detailed_info['converted_row']}")
                            
                            # T ê°œìˆ˜ ì •ë³´
                            st.markdown("##### T ë³€í™˜ ì •ë³´")
                            st.text(f"T ê°œìˆ˜ (ì…€ ì¸ë±ìŠ¤ {detailed_info['converted_cell_index']} ì´ì „): {detailed_info['t_count']}ê°œ")
                            if detailed_info.get('t_count_debug'):
                                st.text(f"T ìœ„ì¹˜: {', '.join(detailed_info['t_count_debug'][:10])}" + ("..." if len(detailed_info['t_count_debug']) > 10 else ""))
                            
                            # T-Removed Reconstructed Grid ìƒì„¸ ì •ë³´
                            st.markdown("##### T-Removed Reconstructed Grid")
                            st.text(f"ê·¸ë£¹ ë²”ìœ„: Group {detailed_info['reconstructed_group']}")
                            st.text(f"ì…€ ì¸ë±ìŠ¤: {detailed_info['reconstructed_cell_index']}")
                            st.text(f"ìœ„ì¹˜: ì—´ {detailed_info['reconstructed_col']}, í–‰ {detailed_info['reconstructed_row']}")
                        else:
                            # ìƒì„¸ ì •ë³´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                            st.success(f"**ì¡°ê±´ ì¶©ì¡± ì‹œì  (Converted Grid): Group {converted_group}**")
                            reconstructed_group = convert_flag_group_to_reconstructed_group(converted_group, original_grid)
                            st.success(f"**ì¡°ê±´ ì¶©ì¡± ì‹œì  (T-Removed Reconstructed Grid): Group {reconstructed_group}**")
                    else:
                        st.success(f"**ì¡°ê±´ ì¶©ì¡± ì‹œì  (Converted Grid): Group {converted_group}**")
                        
                        # T-Removed Reconstructed Gridì—ì„œ í•´ë‹¹ ê·¸ë£¹ ì •ë³´ ì¶”ì¶œ
                        if detailed_info and hasattr(st.session_state, 'reconstructed_grid') and st.session_state.reconstructed_grid:
                            reconstructed_zones = divide_grid_into_overlapping_zones_for_reconstructed(st.session_state.reconstructed_grid)
                            if reconstructed_zones:
                                # reconstructed_group íŒŒì‹± (ì˜ˆ: "2-4" -> start=1, end=3)
                                reconstructed_group = detailed_info['reconstructed_group']
                                parts = reconstructed_group.split('-')
                                if len(parts) == 2:
                                    recon_start = int(parts[0]) - 1
                                    recon_end = int(parts[1]) - 1
                                    
                                    # í•´ë‹¹ ê·¸ë£¹ ì°¾ê¸°
                                    for recon_zone in reconstructed_zones:
                                        if recon_zone['start_x'] == recon_start and recon_zone['end_x'] == recon_end:
                                            st.markdown("##### T-Removed Reconstructed Grid í•´ë‹¹ ê·¸ë£¹ ì •ë³´")
                                            # ê·¸ë£¹ì˜ íŒ¨í„´ ì •ë³´ ì¶”ì¶œ
                                            patterns = get_pattern_positions()
                                            group_patterns = [p for p in patterns if p['columns'][0] >= recon_zone['start_x'] and p['columns'][1] <= recon_zone['end_x']]
                                            
                                            if len(group_patterns) >= 4:
                                                pattern_values = []
                                                for pattern in group_patterns[:4]:
                                                    values = []
                                                    for x, y in pattern['coordinates']:
                                                        relative_x = x - recon_zone['start_x']
                                                        value = recon_zone['zone_data'][relative_x][y]
                                                        if value:
                                                            values.append(value.upper())
                                                    pattern_values.append(values)
                                                
                                                # íŒ¨í„´ ë²ˆí˜¸ ì¶”ì¶œ
                                                pattern_numbers = []
                                                for v in pattern_values[:4]:
                                                    pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
                                                    pattern_numbers.append(pattern_number if pattern_number is not None else '-')
                                                
                                                st.text(f"Pattern 1 Number: {pattern_numbers[0]}")
                                                st.text(f"Pattern 2 Number: {pattern_numbers[1] if len(pattern_numbers) > 1 else '-'}")
                                                st.text(f"Pattern 3 Number: {pattern_numbers[2] if len(pattern_numbers) > 2 else '-'}")
                                                st.text(f"Pattern 4 Number: {pattern_numbers[3] if len(pattern_numbers) > 3 else '-'}")
                                            break
                    
                    st.text(f"FF - Pattern 1,2 Sequence: {flag_info['ff_p1_2']}, Pattern 2,3 Sequence: {flag_info['ff_p2_3']}")
                    st.text(f"{flag_info['other_combo_p1_2']} - Pattern 1,2 Sequence: {flag_info['other_p1_2']}")
                    st.text(f"{flag_info['other_combo_p2_3']} - Pattern 2,3 Sequence: {flag_info['other_p2_3']}")
                else:
                    # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ (ì¡°ê±´ì´ ì¶©ì¡±ë˜ì§€ ì•Šì€ ê²½ìš°)
                    st.markdown("#### ğŸ” Flag Status (Debug)")
                    st.text(f"FF Complete: {ff_complete} (P1,2: {ff_p1_2}, P2,3: {ff_p2_3})")
                    st.text(f"FT - P1,2: {ft_p1_2}, P2,3: {ft_p2_3}")
                    st.text(f"TF - P1,2: {tf_p1_2}, P2,3: {tf_p2_3}")
                    st.text(f"TT - P1,2: {tt_p1_2}, P2,3: {tt_p2_3}")
                    st.text(f"Has P1,2: {has_p1_2}, Has P2,3: {has_p2_3}")
                    st.text(f"Other Complete: {other_complete}")
                    st.text(f"Flag Triggered: {ff_complete and other_complete}")
                    # session_state í™•ì¸
                    if 'matrix_flag_info' in st.session_state:
                        st.text(f"Flag Info Exists: {st.session_state.matrix_flag_info}")
                    else:
                        st.text("Flag Info: Not set")
                
                # Converted Grid Matrix Column í…ìŠ¤íŠ¸ í˜•ì‹ í‘œì‹œ (í•˜ë‹¨)
                st.markdown("#### Converted Grid Matrix Column")
                
                for result in converted_results:
                    matrix_columns = result['matrix_columns']
                    pattern_numbers = result.get('pattern_numbers', [])
                    zone_range = result['zone_range']
                    
                    # Pattern 1-2ì™€ Pattern 2-3 ê°’ ì¶”ì¶œ
                    pattern1_2_matrix = ''
                    pattern2_3_matrix = ''
                    
                    if len(matrix_columns) >= 2:
                        # Pattern 1,2 ì¡°í•© (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸)
                        if matrix_columns[0] != '-' and matrix_columns[1] != '-':
                            pattern1_2_matrix = matrix_columns[0] + matrix_columns[1]
                    
                    if len(matrix_columns) >= 3:
                        # Pattern 2,3 ì¡°í•© (ë‘ ë²ˆì§¸ì™€ ì„¸ ë²ˆì§¸)
                        if matrix_columns[1] != '-' and matrix_columns[2] != '-':
                            pattern2_3_matrix = matrix_columns[1] + matrix_columns[2]
                    
                    # ì €ì¥ëœ Sequence ê°’ ê°€ì ¸ì˜¤ê¸°
                    pattern1_2_sequence = ''
                    pattern2_3_sequence = ''
                    
                    if pattern1_2_matrix:
                        key_1_2 = f"pattern1_2_{pattern1_2_matrix}"
                        if key_1_2 in st.session_state.matrix_sequence_mapping:
                            pattern1_2_sequence = st.session_state.matrix_sequence_mapping[key_1_2]
                    
                    if pattern2_3_matrix:
                        key_2_3 = f"pattern2_3_{pattern2_3_matrix}"
                        if key_2_3 in st.session_state.matrix_sequence_mapping:
                            pattern2_3_sequence = st.session_state.matrix_sequence_mapping[key_2_3]
                    
                    # ì „ì²´ matrix_column ê°’ì„ ë¬¸ìì—´ë¡œ ì—°ê²° (ì˜ˆ: "FTFT")
                    matrix_col_str = ''.join(matrix_columns)
                    
                    # íŒ¨í„´ ë²ˆí˜¸ í‘œì‹œ
                    pattern_nums_str = ', '.join([f"P{i+1}:{pattern_numbers[i] if i < len(pattern_numbers) else '-'}" for i in range(4)])
                    st.text(f"Group {zone_range}: {matrix_col_str} ({pattern_nums_str})")
                    
                    # Pattern 1-2ì™€ Pattern 2-3 í‘œì‹œ (Matrix Column)
                    if pattern1_2_matrix:
                        st.text(f"  Pattern 1,2 Matrix: {pattern1_2_matrix}")
                    if pattern2_3_matrix:
                        st.text(f"  Pattern 2,3 Matrix: {pattern2_3_matrix}")
                    
                    # Pattern 1-2ì™€ Pattern 2-3 í‘œì‹œ (Sequence Prediction Results - ì €ì¥ëœ ê°’)
                    if pattern1_2_sequence:
                        st.text(f"  Pattern 1,2 Sequence: {pattern1_2_sequence}")
                    if pattern2_3_sequence:
                        st.text(f"  Pattern 2,3 Sequence: {pattern2_3_sequence}")
                
                # ì €ì¥ëœ ë§¤í•‘ ì •ë³´ í‘œì‹œ (ì„ íƒì‚¬í•­ - ë””ë²„ê¹…ìš©)
                # st.markdown("#### Matrix Sequence Mapping")
                # st.json(st.session_state.matrix_sequence_mapping)
    
    st.markdown("---")

def divide_grid_into_overlapping_zones(grid, zone_width=3):
    zones = []
    for start_x in range(15 - zone_width + 1):
        end_x = start_x + zone_width
        zone_data = [[grid[x][y] for y in range(6)] for x in range(start_x, end_x)]
        if any(cell in {'b', 't', 'p'} for column in zone_data for cell in column):
            zones.append({
                'zone_data': zone_data,
                'start_x': start_x,
                'end_x': end_x - 1
            })
    return zones

def find_pattern_group(pattern_values):
    try:
        with open('pattern.json', 'r') as f:
            pattern_data = json.load(f)
        
        pattern_values = [v.lower() for v in pattern_values if v]
        
        for group_name in ['groupA', 'groupB']:
            patterns = pattern_data['patterns'][group_name]
            for pattern in patterns:
                if pattern.get('sequence') == pattern_values:
                    return pattern.get('group', group_name[5].lower())
        
        return None
    except Exception as e:
        st.error(f"íŒ¨í„´ ê·¸ë£¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def get_first_two_group_values(zone):
    patterns = get_pattern_positions()
    group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
    
    if len(group_patterns) < 4:
        return ''
        
    pattern_values = []
    for pattern in group_patterns[:4]:
        values = []
        for x, y in pattern['coordinates']:
            relative_x = x - zone['start_x']
            value = zone['zone_data'][relative_x][y]
            if value:
                values.append(value.upper())
        pattern_values.append(values)
        
    groups_123 = []
    pattern_123_valid = True
    
    if len(pattern_values) >= 3:
        for i in range(3):
            if not pattern_values[i]:
                pattern_123_valid = False
                break
            group = find_pattern_group(pattern_values[i])
            if group is None:
                pattern_123_valid = False
                break
            groups_123.append(group)
    
    pattern_123_text = ''.join(groups_123) if pattern_123_valid and len(groups_123) == 3 else ''
    return pattern_123_text[:2] if len(pattern_123_text) >= 2 else ''

def find_pattern_number_only(pattern_values):
    """
    pattern.jsonì—ì„œ ì…ë ¥ëœ ì‹œí€€ìŠ¤ì™€ ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” íŒ¨í„´ì˜ ë„˜ë²„ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    Args:
        pattern_values (list): ì˜ˆì‹œ ['b', 'b', 'b']
    Returns:
        str or None: íŒ¨í„´ ë„˜ë²„(ì˜ˆ: '144047'), ì—†ìœ¼ë©´ None
    """
    try:
        with open('pattern.json', 'r') as f:
            pattern_data = json.load(f)
        pattern_values = [v.lower() for v in pattern_values if v]
        for group_name in ['groupA', 'groupB']:
            patterns = pattern_data['patterns'][group_name]
            for pattern in patterns:
                if pattern.get('sequence') == pattern_values:
                    return pattern.get('pattern_number')
        return None
    except Exception as e:
        st.error(f"íŒ¨í„´ ë„˜ë²„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def process_pattern_numbers(pattern_numbers):
    """
    ê·¸ë£¹ ë‚´ íŒ¨í„´ë³„ ë„˜ë²„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì•„ë˜ì™€ ê°™ì´ ê°€ê³µí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    Args:
        pattern_numbers (list): [íŒ¨í„´1ë„˜ë²„, íŒ¨í„´2ë„˜ë²„, íŒ¨í„´3ë„˜ë²„, íŒ¨í„´4ë„˜ë²„]
    Returns:
        dict: pattern1_number, result1_number, pattern2_number, result2_number
    """
    # None ë˜ëŠ” '-' ì²˜ë¦¬
    n1 = pattern_numbers[0] if len(pattern_numbers) > 0 and pattern_numbers[0] not in [None, '-'] else ''
    n2 = pattern_numbers[1] if len(pattern_numbers) > 1 and pattern_numbers[1] not in [None, '-'] else ''
    n3 = pattern_numbers[2] if len(pattern_numbers) > 2 and pattern_numbers[2] not in [None, '-'] else ''
    n4 = pattern_numbers[3] if len(pattern_numbers) > 3 and pattern_numbers[3] not in [None, '-'] else ''
    return {
        'pattern1_number': n1 + n2,
        'result1_number': n3,
        'pattern2_number': n1 + n2 + n3,
        'result2_number': n4
    }

def display_pattern_groups(zones):
    if not zones:
        return
    
    st.markdown("### Pattern Group Analysis")
    
    # Display all groups' first 2 values concatenated
    all_first_two = ''
    for zone in zones:
        first_two = get_first_two_group_values(zone)
        if first_two:
            all_first_two += first_two
    
    if all_first_two:
        st.text(f"All groups' first 2 values: {all_first_two}")
        st.markdown("---")
    
    # Sort zones by start_x to display in order
    sorted_zones = sorted(zones, key=lambda x: x['start_x'])
    
    for zone in sorted_zones:
        patterns = get_pattern_positions()
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) < 4:
            continue
            
        pattern_values = []
        for pattern in group_patterns[:4]:
            values = []
            for x, y in pattern['coordinates']:
                relative_x = x - zone['start_x']
                value = zone['zone_data'][relative_x][y]
                if value:
                    values.append(value.upper())
            pattern_values.append(values)
            
        # ê° íŒ¨í„´ë³„ ë„˜ë²„ ë¦¬ìŠ¤íŠ¸
        pattern_numbers = []
        for v in pattern_values[:4]:
            pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
            pattern_numbers.append(pattern_number if pattern_number is not None else '-')
        
        # ë„˜ë²„ ê°€ê³µ
        numbers_dict = process_pattern_numbers(pattern_numbers)
        
        groups_123 = []
        groups_1234 = []
        pattern_123_valid = True
        if len(pattern_values) >= 3:
            for i in range(3):
                if not pattern_values[i]:
                    pattern_123_valid = False
                    break
                group = find_pattern_group(pattern_values[i])
                if group is None:
                    pattern_123_valid = False
                    break
                groups_123.append(group)
        
        pattern_1234_valid = True
        if len(pattern_values) >= 4:
            for i in range(4):
                if not pattern_values[i]:
                    pattern_1234_valid = False
                    break
                group = find_pattern_group(pattern_values[i])
                if group is None:
                    pattern_1234_valid = False
                    break
                groups_1234.append(group)
        
        pattern_123_text = ''.join(groups_123) if pattern_123_valid and len(groups_123) == 3 else ''
        pattern_1234_text = ''.join(groups_1234) if pattern_1234_valid and len(groups_1234) == 4 else ''
        
        first_two = get_first_two_group_values(zone)
        group_range = f"{zone['start_x'] + 1}-{zone['end_x'] + 1}"
        
        if any([pattern_123_text, pattern_1234_text, first_two]):
            st.markdown(f"#### Group {group_range}")
            for idx, v in enumerate(pattern_values[:4]):
                pattern_number = pattern_numbers[idx]
                st.text(f"Pattern {idx+1} Number: {pattern_number if pattern_number is not None else '-'}")
            
            # Add combined pattern numbers display
            if len(pattern_numbers) >= 2:
                pattern1_2 = pattern_numbers[0] + pattern_numbers[1] if pattern_numbers[0] != '-' and pattern_numbers[1] != '-' else '-'
                st.text(f"Pattern 1,2: {pattern1_2}")
            
            if len(pattern_numbers) >= 3:
                pattern1_2_3 = pattern_numbers[0] + pattern_numbers[1] + pattern_numbers[2] if all(p != '-' for p in pattern_numbers[:3]) else '-'
                st.text(f"Pattern 1,2,3: {pattern1_2_3}")
            
            # Add pattern 3,4 combined display
            if len(pattern_numbers) >= 4:
                pattern3_4 = pattern_numbers[2] + pattern_numbers[3] if pattern_numbers[2] != '-' and pattern_numbers[3] != '-' else '-'
                st.text(f"Pattern 3,4: {pattern3_4}")
            
            st.text(f"Pattern 1,2,3 Group: {pattern_123_text}")
            st.text(f"Pattern 1,2,3,4 Group: {pattern_1234_text}")
            st.text(f"First 2 values: {first_two}")
            st.markdown("---")

def get_pattern_sequence_type(zone):
    """Get pattern sequence type from zone data for Pattern 1,2"""
    try:
        # Get 1st row 3rd column value (index 0,2)
        value = zone['zone_data'][2][0] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 0 else ''
        return 'P_Sequence' if value.upper() == 'P' else 'B_Sequence' if value.upper() == 'B' else ''
    except Exception as e:
        st.error(f"Error in get_pattern_sequence_type: {str(e)}")  # Error log
        return ''

def get_pattern123_sequence_type(zone):
    """Get pattern sequence type from zone data for Pattern 1,2,3"""
    try:
        # Get 4th row 3rd column value (index 3,2)
        value = zone['zone_data'][2][3] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 3 else ''
        return 'P_Sequence' if value.upper() == 'P' else 'B_Sequence' if value.upper() == 'B' else ''
    except Exception as e:
        st.error(f"Error in get_pattern123_sequence_type: {str(e)}")  # Error log
        return ''

def get_pattern_from_zone(zone):
    """Extract pattern from zone data"""
    try:
        # Get Pattern 1,2 result (2nd row 3rd column)
        pattern = zone['zone_data'][2][1] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 1 else ''
        return pattern.upper() if pattern else ''
    except Exception as e:
        return ''

def get_pattern_prediction_from_db(pattern, sequence_type):
    """DBì—ì„œ Pattern 1,2 ì˜ˆì¸¡ê°’ ì¡°íšŒ"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # íŒ¨í„´ ë²ˆí˜¸ ì „ì²˜ë¦¬ ì œê±° - ì›ë³¸ í˜•ì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        pattern_str = str(pattern).strip()
        
        # DBì—ì„œ ì˜ˆì¸¡ê°’ ì¡°íšŒ
        cursor.execute('''
            SELECT prediction, frequency, success_rate
            FROM pattern12_predictions 
            WHERE pattern_number = ? AND sequence_type = ?
        ''', (pattern_str, sequence_type))
        
        result = cursor.fetchone()
        if result:
            prediction, frequency, success_rate = result
            return prediction, True, frequency, success_rate
        return '', False, 0, 0
        
    except Exception as e:
        st.error(f"DB ì˜ˆì¸¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return '', False, 0, 0
    finally:
        if conn:
            conn.close()

def get_pattern123_prediction_from_db(pattern, sequence_type):
    """DBì—ì„œ Pattern 1,2,3 ì˜ˆì¸¡ê°’ ì¡°íšŒ"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # íŒ¨í„´ ë²ˆí˜¸ ì „ì²˜ë¦¬ ì œê±° - ì›ë³¸ í˜•ì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        pattern_str = str(pattern).strip()
        
        # DBì—ì„œ ì˜ˆì¸¡ê°’ ì¡°íšŒ
        cursor.execute('''
            SELECT prediction, frequency, success_rate
            FROM pattern123_predictions 
            WHERE pattern_number = ? AND sequence_type = ?
        ''', (pattern_str, sequence_type))
        
        result = cursor.fetchone()
        if result:
            prediction, frequency, success_rate = result
            return prediction, True, frequency, success_rate
        return '', False, 0, 0
        
    except Exception as e:
        st.error(f"DB ì˜ˆì¸¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return '', False, 0, 0
    finally:
        if conn:
            conn.close()

def get_pattern_prediction(pattern, sequence_type):
    """í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (DB ìš°ì„ , ì—†ìœ¼ë©´ CSV)"""
    result, found, source = get_hybrid_pattern_prediction(pattern, sequence_type)
    return result, found

def get_pattern123_prediction(pattern, sequence_type):
    """í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (DB ìš°ì„ , ì—†ìœ¼ë©´ CSV)"""
    result, found, source = get_hybrid_pattern123_prediction(pattern, sequence_type)
    return result, found

def update_prediction_tables(pattern_number, sequence_type, prediction, result, pattern_type='12'):
    """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        table_name = f"pattern{pattern_type}_predictions"
        
        # íŒ¨í„´ ë²ˆí˜¸ ì „ì²˜ë¦¬ ì œê±° - ì›ë³¸ í˜•ì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        pattern_str = str(pattern_number).strip()
        
        # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
        cursor.execute(f'''
            SELECT frequency, success_count 
            FROM {table_name} 
            WHERE pattern_number = ? AND sequence_type = ? AND prediction = ?
        ''', (pattern_str, sequence_type, prediction))
        
        existing = cursor.fetchone()
        
        if existing:
            # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
            frequency, success_count = existing
            new_frequency = frequency + 1
            new_success_count = success_count + (1 if result.upper() == 'W' else 0)
            new_success_rate = (new_success_count / new_frequency * 100)
            
            cursor.execute(f'''
                UPDATE {table_name} 
                SET frequency = ?, success_count = ?, success_rate = ?, updated_at = CURRENT_TIMESTAMP
                WHERE pattern_number = ? AND sequence_type = ? AND prediction = ?
            ''', (new_frequency, new_success_count, new_success_rate, pattern_str, sequence_type, prediction))
        else:
            # ìƒˆ ë°ì´í„° ì‚½ì…
            success_count = 1 if result.upper() == 'W' else 0
            success_rate = 100.0 if result.upper() == 'W' else 0.0
            
            cursor.execute(f'''
                INSERT INTO {table_name} 
                (pattern_number, sequence_type, prediction, frequency, success_count, success_rate)
                VALUES (?, ?, ?, 1, ?, ?)
            ''', (pattern_str, sequence_type, prediction, success_count, success_rate))
        
        conn.commit()
        return True
        
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        if conn:
            conn.close()

def compare_pattern_prediction(pattern, prediction):
    """Compare pattern result with prediction"""
    if pattern and prediction:
        return 'w' if pattern.upper() == prediction.upper() else 'l'
    return ''

def get_pattern_results(zone):
    """Extract pattern results and predictions from zone data"""
    try:
        # Get Pattern 1,2 result (2nd row 3rd column)
        pattern1_2 = zone['zone_data'][2][1] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 1 else ''
        # Get Pattern 1,2,3 result (5th row 3rd column)
        pattern1_2_3 = zone['zone_data'][2][4] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 4 else ''
        
        # Get patterns from zone for pattern number combination
        patterns = get_pattern_positions()
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) >= 4:
            pattern_values = []
            for pattern in group_patterns[:4]:
                values = []
                for x, y in pattern['coordinates']:
                    relative_x = x - zone['start_x']
                    value = zone['zone_data'][relative_x][y]
                    if value:
                        values.append(value.upper())
                pattern_values.append(values)
                
            # Get pattern numbers
            pattern_numbers = []
            for v in pattern_values[:4]:
                pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
                pattern_numbers.append(pattern_number if pattern_number is not None else '-')
            
            # Get Pattern 1,2 combination
            pattern1_2_combined = pattern_numbers[0] + pattern_numbers[1] if pattern_numbers[0] != '-' and pattern_numbers[1] != '-' else '-'
            # Get Pattern 1,2,3 combination
            pattern1_2_3_combined = pattern_numbers[0] + pattern_numbers[1] + pattern_numbers[2] if all(p != '-' for p in pattern_numbers[:3]) else '-'
            # Get Pattern 3,4 combination
            pattern3_4_combined = pattern_numbers[2] + pattern_numbers[3] if pattern_numbers[2] != '-' and pattern_numbers[3] != '-' else '-'
        else:
            pattern1_2_combined = '-'
            pattern1_2_3_combined = '-'
            pattern3_4_combined = '-'
        
        # Get sequence types for each pattern
        sequence_type_12 = get_pattern_sequence_type(zone)
        sequence_type_123 = get_pattern123_sequence_type(zone)
        
        # Get predictions using hybrid functions
        prediction1_2, found1_2, source1_2 = get_hybrid_pattern_prediction(pattern1_2_combined, sequence_type_12)
        prediction1_2_3, found1_2_3, source1_2_3 = get_hybrid_pattern123_prediction(pattern1_2_3_combined, sequence_type_123)
        
        # Compare and get results
        comparison1_2 = compare_pattern_prediction(pattern1_2, prediction1_2)
        comparison1_2_3 = compare_pattern_prediction(pattern1_2_3, prediction1_2_3)
        
        return pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123
    except Exception as e:
        return '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''

def save_pattern_analysis(zones, session_id):
    """Save pattern analysis results to database"""
    try:
        # Get absolute path to database file
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # ê¸°ì¡´ sequence_type í•„ë“œë¥¼ pattern12_sequence_typeìœ¼ë¡œ ë³€ê²½
        try:
            cursor.execute('ALTER TABLE pattern_analysis RENAME COLUMN sequence_type TO pattern12_sequence_type')
        except:
            pass  # ì´ë¯¸ ë³€ê²½ëœ ê²½ìš° ë¬´ì‹œ
        
        # pattern123_sequence_type í•„ë“œ ì¶”ê°€
        try:
            cursor.execute('ALTER TABLE pattern_analysis ADD COLUMN pattern123_sequence_type TEXT')
        except:
            pass  # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
        
        # Get current date and total groups
        current_date = datetime.now().date()
        total_groups = len(zones)
        
        # Prepare data for insertion
        for idx, zone in enumerate(zones, 1):
            group_range = f"{zone['start_x'] + 1}-{zone['end_x'] + 1}"
            
            # Get pattern results
            pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results(zone)
            
            # Calculate prediction accuracy
            total_predictions = 0
            correct_predictions = 0
            if comparison1_2:
                total_predictions += 1
                if comparison1_2 == 'W':
                    correct_predictions += 1
            if comparison1_2_3:
                total_predictions += 1
                if comparison1_2_3 == 'W':
                    correct_predictions += 1
            prediction_accuracy = (correct_predictions / total_predictions * 100) if total_predictions > 0 else 0
            
            # Insert data with separate sequence types
            cursor.execute('''
                INSERT INTO pattern_analysis (
                    session_id, session_date, total_groups_in_session,
                    group_id, group_start, group_end, group_sequence,
                    pattern12_result, pattern12_combined, pattern12_prediction, pattern12_prediction_result,
                    pattern123_result, pattern123_combined, pattern123_prediction, pattern123_prediction_result,
                    pattern12_sequence_type, pattern123_sequence_type, prediction_accuracy
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                session_id, current_date, total_groups,
                group_range, zone['start_x'] + 1, zone['end_x'] + 1, idx,
                pattern1_2, pattern1_2_combined, prediction1_2, comparison1_2,
                pattern1_2_3, pattern1_2_3_combined, prediction1_2_3, comparison1_2_3,
                sequence_type_12, sequence_type_123, prediction_accuracy
            ))
        
        conn.commit()
        return True
            
    except Exception as e:
        st.error(f"Database error: {str(e)}")
        return False
    finally:
        if conn:
            conn.close()

def create_new_tables():
    """ìƒˆë¡œìš´ íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ í…Œì´ë¸” ìƒì„±"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Session Prediction Results í…Œì´ë¸” ìƒì„±
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS new_session_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                pattern_type TEXT NOT NULL,
                prediction_results TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
            )
        ''')
        
        # Pattern Group Analysis í…Œì´ë¸” ìƒì„±
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS new_pattern_group_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                pattern_type TEXT NOT NULL,
                group_range TEXT NOT NULL,
                pattern_result TEXT,
                pattern_combined TEXT,
                sequence_type TEXT,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
            )
        ''')
        
        conn.commit()
        return True
        
    except Exception as e:
        st.error(f"ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        if conn:
            conn.close()

def save_new_pattern_analysis(zones, session_id, pattern_type):
    """ìƒˆë¡œìš´ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ë¥¼ ë…ë¦½ì ì¸ í…Œì´ë¸”ì— ì €ì¥"""
    try:
        # ê¸°ì¡´ DBì— ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„±í•˜ì—¬ ì €ì¥
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # 1. Session Prediction Results ì €ì¥
        all_prediction_results = []
        sorted_zones_results = sorted(zones, key=lambda x: x['start_x'])
        
        for zone in sorted_zones_results:
            pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results(zone)
            
            if comparison1_2:
                all_prediction_results.append(comparison1_2.upper())
            if comparison1_2_3:
                all_prediction_results.append(comparison1_2_3.upper())
        
        if all_prediction_results:
            combined_results = ''.join(all_prediction_results)
            
            # ìƒˆë¡œìš´ í…Œì´ë¸”ì— ì €ì¥
            cursor.execute('''
                INSERT INTO new_session_predictions (session_id, pattern_type, prediction_results)
                VALUES (?, ?, ?)
            ''', (session_id, pattern_type, combined_results))
        
        # 2. Pattern Group Analysis ì €ì¥
        for zone in zones:
            group_range = f"{zone['start_x'] + 1}-{zone['end_x'] + 1}"
            pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results(zone)
            
            # Pattern1, Pattern2, Pattern3ì— ë”°ë¼ ë‹¤ë¥¸ ë°ì´í„° ì €ì¥
            if pattern_type == 'pattern1':
                pattern_result = pattern1_2
                pattern_combined = pattern1_2_combined
            elif pattern_type == 'pattern2':
                pattern_result = pattern1_2_3
                pattern_combined = pattern1_2_3_combined
            else:  # pattern3
                pattern_result = pattern3_4_combined
                pattern_combined = pattern3_4_combined
            
            cursor.execute('''
                INSERT INTO new_pattern_group_analysis 
                (session_id, pattern_type, group_range, pattern_result, pattern_combined, sequence_type)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (session_id, pattern_type, group_range, pattern_result, pattern_combined, sequence_type))
        
        conn.commit()
        return True
        
    except Exception as e:
        st.error(f"ìƒˆë¡œìš´ íŒ¨í„´ ë¶„ì„ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        if conn:
            conn.close()

def update_prediction_tables_from_new_data(zones):
    """ìƒˆë¡œ ì €ì¥ëœ íŒ¨í„´ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Pattern 1,2 ì˜ˆì¸¡ ë°ì´í„° ìˆ˜ì§‘
        pattern12_data = {}
        pattern123_data = {}
        
        for zone in zones:
            # Get pattern results for this zone
            pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results(zone)
            
            # Process Pattern 1,2 data
            if pattern1_2_combined and prediction1_2 and comparison1_2:
                key = (pattern1_2_combined, sequence_type)
                if key not in pattern12_data:
                    pattern12_data[key] = {'b': 0, 'p': 0, 'total': 0}
                
                # ì‹¤ì œ ê²°ê³¼ ê³„ì‚°: wì´ë©´ ì˜ˆì¸¡ê°’, lì´ë©´ ì˜ˆì¸¡ê°’ì˜ ë°˜ëŒ€ê°’
                if prediction1_2 == 'b':
                    opposite_result = 'p'
                elif prediction1_2 == 'p':
                    opposite_result = 'b'
                else:
                    opposite_result = prediction1_2
                
                actual_result = prediction1_2 if comparison1_2.upper() == 'W' else opposite_result
                pattern12_data[key][actual_result] += 1
                pattern12_data[key]['total'] += 1
            
            # Process Pattern 1,2,3 data
            if pattern1_2_3_combined and prediction1_2_3 and comparison1_2_3:
                key = (pattern1_2_3_combined, sequence_type)
                if key not in pattern123_data:
                    pattern123_data[key] = {'b': 0, 'p': 0, 'total': 0}
                
                # ì‹¤ì œ ê²°ê³¼ ê³„ì‚°: wì´ë©´ ì˜ˆì¸¡ê°’, lì´ë©´ ì˜ˆì¸¡ê°’ì˜ ë°˜ëŒ€ê°’
                if prediction1_2_3 == 'b':
                    opposite_result = 'p'
                elif prediction1_2_3 == 'p':
                    opposite_result = 'b'
                else:
                    opposite_result = prediction1_2_3
                
                actual_result = prediction1_2_3 if comparison1_2_3.upper() == 'W' else opposite_result
                pattern123_data[key][actual_result] += 1
                pattern123_data[key]['total'] += 1
        
        # Update Pattern 1,2 predictions
        for (pattern_number, sequence_type), data in pattern12_data.items():
            # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì‚¬ìš©
            if data['b'] > data['p']:
                prediction = 'b'
                success_count = data['b']
            elif data['p'] > data['b']:
                prediction = 'p'
                success_count = data['p']
            else:
                # ë™ì ì¸ ê²½ìš° ê¸°ë³¸ê°’
                prediction = 'b'
                success_count = data['b']
            
            frequency = data['total']
            success_rate = (success_count / frequency * 100) if frequency > 0 else 0
            
            # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (pattern_numberì™€ sequence_typeë§Œìœ¼ë¡œ)
            cursor.execute('''
                SELECT frequency, success_count, prediction
                FROM pattern12_predictions 
                WHERE pattern_number = ? AND sequence_type = ?
            ''', (pattern_number, sequence_type))
            
            existing = cursor.fetchone()
            
            if existing:
                # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
                old_frequency, old_success_count, old_prediction = existing
                
                # ì˜ˆì¸¡ê°’ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if old_prediction == prediction:
                    # ê°™ì€ ì˜ˆì¸¡ê°’ì´ë©´ ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€
                    new_frequency = old_frequency + frequency
                    new_success_count = old_success_count + success_count
                    new_success_rate = (new_success_count / new_frequency * 100)
                    
                    cursor.execute('''
                        UPDATE pattern12_predictions 
                        SET frequency = ?, success_count = ?, success_rate = ?, updated_at = CURRENT_TIMESTAMP
                        WHERE pattern_number = ? AND sequence_type = ?
                    ''', (new_frequency, new_success_count, new_success_rate, pattern_number, sequence_type))
                else:
                    # ì˜ˆì¸¡ê°’ì´ ë³€ê²½ë˜ì—ˆìœ¼ë©´ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆë¡œ ì‚½ì…
                    cursor.execute('''
                        DELETE FROM pattern12_predictions 
                        WHERE pattern_number = ? AND sequence_type = ?
                    ''', (pattern_number, sequence_type))
                    
                    cursor.execute('''
                        INSERT INTO pattern12_predictions 
                        (pattern_number, sequence_type, prediction, frequency, success_count, success_rate)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (pattern_number, sequence_type, prediction, frequency, success_count, success_rate))
            else:
                # ìƒˆ ë°ì´í„° ì‚½ì…
                cursor.execute('''
                    INSERT INTO pattern12_predictions 
                    (pattern_number, sequence_type, prediction, frequency, success_count, success_rate)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (pattern_number, sequence_type, prediction, frequency, success_count, success_rate))
        
        # Update Pattern 1,2,3 predictions
        for (pattern_number, sequence_type), data in pattern123_data.items():
            # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì‚¬ìš©
            if data['b'] > data['p']:
                prediction = 'b'
                success_count = data['b']
            elif data['p'] > data['b']:
                prediction = 'p'
                success_count = data['p']
            else:
                # ë™ì ì¸ ê²½ìš° ê¸°ë³¸ê°’
                prediction = 'b'
                success_count = data['b']
            
            frequency = data['total']
            success_rate = (success_count / frequency * 100) if frequency > 0 else 0
            
            # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (pattern_numberì™€ sequence_typeë§Œìœ¼ë¡œ)
            cursor.execute('''
                SELECT frequency, success_count, prediction
                FROM pattern123_predictions 
                WHERE pattern_number = ? AND sequence_type = ?
            ''', (pattern_number, sequence_type))
            
            existing = cursor.fetchone()
            
            if existing:
                # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
                old_frequency, old_success_count, old_prediction = existing
                
                # ì˜ˆì¸¡ê°’ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if old_prediction == prediction:
                    # ê°™ì€ ì˜ˆì¸¡ê°’ì´ë©´ ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€
                    new_frequency = old_frequency + frequency
                    new_success_count = old_success_count + success_count
                    new_success_rate = (new_success_count / new_frequency * 100)
                    
                    cursor.execute('''
                        UPDATE pattern123_predictions 
                        SET frequency = ?, success_count = ?, success_rate = ?, updated_at = CURRENT_TIMESTAMP
                        WHERE pattern_number = ? AND sequence_type = ?
                    ''', (new_frequency, new_success_count, new_success_rate, pattern_number, sequence_type))
                else:
                    # ì˜ˆì¸¡ê°’ì´ ë³€ê²½ë˜ì—ˆìœ¼ë©´ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆë¡œ ì‚½ì…
                    cursor.execute('''
                        DELETE FROM pattern123_predictions 
                        WHERE pattern_number = ? AND sequence_type = ?
                    ''', (pattern_number, sequence_type))
                    
                    cursor.execute('''
                        INSERT INTO pattern123_predictions 
                        (pattern_number, sequence_type, prediction, frequency, success_count, success_rate)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (pattern_number, sequence_type, prediction, frequency, success_count, success_rate))
            else:
                # ìƒˆ ë°ì´í„° ì‚½ì…
                cursor.execute('''
                    INSERT INTO pattern123_predictions 
                    (pattern_number, sequence_type, prediction, frequency, success_count, success_rate)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (pattern_number, sequence_type, prediction, frequency, success_count, success_rate))
        
        conn.commit()
        return True
        
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        if conn:
            conn.close()

def init_db():
    """Initialize database and create tables if they don't exist"""
    try:
        # Get absolute path to database file
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Create pattern_analysis table if it doesn't exist
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS pattern_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                session_date TEXT NOT NULL,
                total_groups_in_session INTEGER NOT NULL,
                group_id TEXT NOT NULL,
                group_start INTEGER NOT NULL,
                group_end INTEGER NOT NULL,
                group_sequence INTEGER NOT NULL,
                pattern12_result TEXT,
                pattern12_combined TEXT,
                pattern12_prediction TEXT,
                pattern12_prediction_result TEXT,
                pattern123_result TEXT,
                pattern123_combined TEXT,
                pattern123_prediction TEXT,
                pattern123_prediction_result TEXT,
                sequence_type TEXT,
                prediction_accuracy REAL,
                created_at TIMESTAMP DEFAULT (strftime('%Y-%m-%d %H:%M:%S', datetime('now', '+9 hours'))),
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
    except Exception as e:
        st.error(f"Database initialization error: {str(e)}")
    finally:
        if conn:
            conn.close()


def ensure_game_outcome_table():
    """ìµœì†Œ ë°ì´í„° ì €ì¥ìš© í…Œì´ë¸” ìƒì„±"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS game_outcome_summary (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT NOT NULL,
                converted_grid TEXT NOT NULL,
                reconstructed_grid TEXT,
                sequence_prediction_results TEXT,
                reconstructed_sequence_prediction_results TEXT,
                reconstructed_gap_results TEXT,
                created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
            )
        ''')

        conn.commit()
        return True
    except Exception as e:
        st.error(f"Outcome summary table creation error: {str(e)}")
        return False
    finally:
        if conn:
            conn.close()


def serialize_grid_for_storage(grid):
    """ê·¸ë¦¬ë“œë¥¼ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”"""
    if not grid:
        return ''
    try:
        return json.dumps(grid)
    except Exception:
        return ''


def save_game_outcome_summary(converted_grid_str, reconstructed_grid_str, sequence_results, reconstructed_sequence_results, reconstructed_gap_results):
    """ìµœì†Œ ë°ì´í„° ê²°ê³¼ ì €ì¥"""
    if not ensure_game_outcome_table():
        return False, None

    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        session_id = str(uuid.uuid4())
        cursor.execute('''
            INSERT INTO game_outcome_summary (
                session_id,
                converted_grid,
                reconstructed_grid,
                sequence_prediction_results,
                reconstructed_sequence_prediction_results,
                reconstructed_gap_results
            ) VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            session_id,
            converted_grid_str,
            reconstructed_grid_str,
            sequence_results or '',
            reconstructed_sequence_results or '',
            reconstructed_gap_results or ''
        ))

        conn.commit()
        return True, session_id
    except Exception as e:
        st.error(f"Outcome summary save error: {str(e)}")
        return False, None
    finally:
        if conn:
            conn.close()


# Initialize database when the app starts
init_db()

def create_prediction_tables():
    """ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ì €ì¥í•  í…Œì´ë¸”ë“¤ ìƒì„±"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Pattern 1,2 ì˜ˆì¸¡ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS pattern12_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                pattern_number TEXT NOT NULL,
                sequence_type TEXT NOT NULL,
                prediction TEXT NOT NULL,
                frequency INTEGER DEFAULT 1,
                success_count INTEGER DEFAULT 0,
                success_rate REAL DEFAULT 0.0,
                created_at TIMESTAMP DEFAULT (strftime('%Y-%m-%d %H:%M:%S', datetime('now', '+9 hours'))),
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(pattern_number, sequence_type)
            )
        ''')
        
        # Pattern 1,2,3 ì˜ˆì¸¡ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS pattern123_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                pattern_number TEXT NOT NULL,
                sequence_type TEXT NOT NULL,
                prediction TEXT NOT NULL,
                frequency INTEGER DEFAULT 1,
                success_count INTEGER DEFAULT 0,
                success_rate REAL DEFAULT 0.0,
                created_at TIMESTAMP DEFAULT (strftime('%Y-%m-%d %H:%M:%S', datetime('now', '+9 hours'))),
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(pattern_number, sequence_type)
            )
        ''')
        
        conn.commit()
        return True
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        if conn:
            conn.close()

def build_prediction_tables_from_existing_data():
    """ê¸°ì¡´ pattern_analysis ë°ì´í„°ë¡œ ì˜ˆì¸¡ í…Œì´ë¸” êµ¬ì¶•"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # ì˜ˆì¸¡ í…Œì´ë¸” ì´ˆê¸°í™”
        cursor.execute('DELETE FROM pattern12_predictions')
        cursor.execute('DELETE FROM pattern123_predictions')
        
        # Pattern 1,2 ì˜ˆì¸¡ ë°ì´í„° ìˆ˜ì§‘ ë° ì‹¤ì œ ê²°ê³¼ ê³„ì‚°
        cursor.execute('''
            SELECT 
                pattern12_combined,
                pattern12_sequence_type,
                pattern12_prediction,
                pattern12_prediction_result,
                COUNT(*) as frequency
            FROM pattern_analysis 
            WHERE pattern12_combined IS NOT NULL 
                AND pattern12_prediction IS NOT NULL 
                AND pattern12_sequence_type IS NOT NULL
                AND pattern12_prediction_result IS NOT NULL
                AND pattern12_prediction_result != ''
            GROUP BY pattern12_combined, pattern12_sequence_type, pattern12_prediction, pattern12_prediction_result
        ''')
        
        pattern12_raw_data = cursor.fetchall()
        
        # Pattern 1,2,3 ì˜ˆì¸¡ ë°ì´í„° ìˆ˜ì§‘ ë° ì‹¤ì œ ê²°ê³¼ ê³„ì‚°
        cursor.execute('''
            SELECT 
                pattern123_combined,
                pattern123_sequence_type,
                pattern123_prediction,
                pattern123_prediction_result,
                COUNT(*) as frequency
            FROM pattern_analysis 
            WHERE pattern123_combined IS NOT NULL 
                AND pattern123_prediction IS NOT NULL 
                AND pattern123_sequence_type IS NOT NULL
                AND pattern123_prediction_result IS NOT NULL
                AND pattern123_prediction_result != ''
            GROUP BY pattern123_combined, pattern123_sequence_type, pattern123_prediction, pattern123_prediction_result
        ''')
        
        pattern123_raw_data = cursor.fetchall()
        
        # Pattern 1,2 ë°ì´í„° ì²˜ë¦¬
        pattern12_processed = {}
        for row in pattern12_raw_data:
            pattern_number, sequence_type, prediction, result, frequency = row
            
            # ì‹¤ì œ ê²°ê³¼ ê³„ì‚°: wì´ë©´ ì˜ˆì¸¡ê°’, lì´ë©´ ì˜ˆì¸¡ê°’ì˜ ë°˜ëŒ€ê°’
            if prediction == 'b':
                opposite_result = 'p'
            elif prediction == 'p':
                opposite_result = 'b'
            else:
                opposite_result = prediction
            
            actual_result = prediction if result == 'w' else opposite_result
            
            key = (pattern_number, sequence_type)
            if key not in pattern12_processed:
                pattern12_processed[key] = {'b': 0, 'p': 0, 'total': 0}
            
            pattern12_processed[key][actual_result] += frequency
            pattern12_processed[key]['total'] += frequency
        
        # Pattern 1,2,3 ë°ì´í„° ì²˜ë¦¬
        pattern123_processed = {}
        for row in pattern123_raw_data:
            pattern_number, sequence_type, prediction, result, frequency = row
            
            # ì‹¤ì œ ê²°ê³¼ ê³„ì‚°: wì´ë©´ ì˜ˆì¸¡ê°’, lì´ë©´ ì˜ˆì¸¡ê°’ì˜ ë°˜ëŒ€ê°’
            if prediction == 'b':
                opposite_result = 'p'
            elif prediction == 'p':
                opposite_result = 'b'
            else:
                opposite_result = prediction
            
            actual_result = prediction if result == 'w' else opposite_result
            
            key = (pattern_number, sequence_type)
            if key not in pattern123_processed:
                pattern123_processed[key] = {'b': 0, 'p': 0, 'total': 0}
            
            pattern123_processed[key][actual_result] += frequency
            pattern123_processed[key]['total'] += frequency
        
        # ì˜ˆì¸¡ í…Œì´ë¸”ì— ë°ì´í„° ì‚½ì…
        for (pattern_number, sequence_type), data in pattern12_processed.items():
            # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì‚¬ìš©
            if data['b'] > data['p']:
                prediction = 'b'
                success_count = data['b']
            elif data['p'] > data['b']:
                prediction = 'p'
                success_count = data['p']
            else:
                # ë™ì ì¸ ê²½ìš° ê¸°ë³¸ê°’
                prediction = 'b'
                success_count = data['b']
            
            frequency = data['total']
            success_rate = (success_count / frequency * 100) if frequency > 0 else 0
            
            cursor.execute('''
                INSERT OR REPLACE INTO pattern12_predictions 
                (pattern_number, sequence_type, prediction, frequency, success_count, success_rate)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (pattern_number, sequence_type, prediction, frequency, success_count, success_rate))
        
        for (pattern_number, sequence_type), data in pattern123_processed.items():
            # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì‚¬ìš©
            if data['b'] > data['p']:
                prediction = 'b'
                success_count = data['b']
            elif data['p'] > data['b']:
                prediction = 'p'
                success_count = data['p']
            else:
                # ë™ì ì¸ ê²½ìš° ê¸°ë³¸ê°’
                prediction = 'b'
                success_count = data['b']
            
            frequency = data['total']
            success_rate = (success_count / frequency * 100) if frequency > 0 else 0
            
            cursor.execute('''
                INSERT OR REPLACE INTO pattern123_predictions 
                (pattern_number, sequence_type, prediction, frequency, success_count, success_rate)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (pattern_number, sequence_type, prediction, frequency, success_count, success_rate))
        
        conn.commit()
        return True
        
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ í…Œì´ë¸” êµ¬ì¶• ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        if conn:
            conn.close()

def get_prediction_table_statistics():
    """ì˜ˆì¸¡ í…Œì´ë¸”ì˜ í†µê³„ ì •ë³´ ì¡°íšŒ"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Pattern 1,2 í†µê³„
        cursor.execute('''
            SELECT 
                COUNT(*) as total_patterns,
                AVG(success_rate) as avg_success_rate,
                SUM(frequency) as total_frequency,
                COUNT(CASE WHEN success_rate >= 70 THEN 1 END) as high_accuracy_patterns
            FROM pattern12_predictions
        ''')
        pattern12_stats = cursor.fetchone()
        
        # Pattern 1,2,3 í†µê³„
        cursor.execute('''
            SELECT 
                COUNT(*) as total_patterns,
                AVG(success_rate) as avg_success_rate,
                SUM(frequency) as total_frequency,
                COUNT(CASE WHEN success_rate >= 70 THEN 1 END) as high_accuracy_patterns
            FROM pattern123_predictions
        ''')
        pattern123_stats = cursor.fetchone()
        
        return {
            'pattern12': {
                'total_patterns': pattern12_stats[0],
                'avg_success_rate': pattern12_stats[1],
                'total_frequency': pattern12_stats[2],
                'high_accuracy_patterns': pattern12_stats[3]
            },
            'pattern123': {
                'total_patterns': pattern123_stats[0],
                'avg_success_rate': pattern123_stats[1],
                'total_frequency': pattern123_stats[2],
                'high_accuracy_patterns': pattern123_stats[3]
            }
        }
        
    except Exception as e:
        st.error(f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return None
    finally:
        if conn:
            conn.close()

def verify_prediction_tables_creation():
    """ì˜ˆì¸¡ í…Œì´ë¸” ìƒì„± ê²€ì¦"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name IN ('pattern12_predictions', 'pattern123_predictions')")
        existing_tables = [row[0] for row in cursor.fetchall()]
        
        # í…Œì´ë¸” êµ¬ì¡° í™•ì¸
        table_structures = {}
        for table_name in ['pattern12_predictions', 'pattern123_predictions']:
            if table_name in existing_tables:
                cursor.execute(f"PRAGMA table_info({table_name})")
                columns = cursor.fetchall()
                table_structures[table_name] = [col[1] for col in columns]
        
        return {
            'tables_exist': len(existing_tables) == 2,
            'table_structures': table_structures,
            'expected_tables': ['pattern12_predictions', 'pattern123_predictions'],
            'found_tables': existing_tables
        }
        
    except Exception as e:
        return {'error': str(e)}
    finally:
        if conn:
            conn.close()

def verify_prediction_data_build():
    """ì˜ˆì¸¡ ë°ì´í„° êµ¬ì¶• ê²€ì¦"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # ê¸°ì¡´ pattern_analysis ë°ì´í„° í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM pattern_analysis")
        total_analysis_records = cursor.fetchone()[0]
        
        # ì˜ˆì¸¡ í…Œì´ë¸” ë°ì´í„° í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM pattern12_predictions")
        pattern12_records = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM pattern123_predictions")
        pattern123_records = cursor.fetchone()[0]
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        cursor.execute("SELECT * FROM pattern12_predictions LIMIT 3")
        pattern12_samples = cursor.fetchall()
        
        cursor.execute("SELECT * FROM pattern123_predictions LIMIT 3")
        pattern123_samples = cursor.fetchall()
        
        return {
            'total_analysis_records': total_analysis_records,
            'pattern12_records': pattern12_records,
            'pattern123_records': pattern123_records,
            'pattern12_samples': pattern12_samples,
            'pattern123_samples': pattern123_samples,
            'has_data': pattern12_records > 0 and pattern123_records > 0
        }
        
    except Exception as e:
        return {'error': str(e)}
    finally:
        if conn:
            conn.close()

def debug_pattern_analysis_data():
    """pattern_analysis í…Œì´ë¸” ë°ì´í„° ë””ë²„ê¹…"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # í…Œì´ë¸” êµ¬ì¡° í™•ì¸
        cursor.execute("PRAGMA table_info(pattern_analysis)")
        columns = cursor.fetchall()
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        cursor.execute("SELECT * FROM pattern_analysis LIMIT 5")
        sample_data = cursor.fetchall()
        
        # pattern12_combined, pattern123_combined ì»¬ëŸ¼ì˜ ë°ì´í„° í™•ì¸
        cursor.execute("""
            SELECT 
                pattern12_combined,
                pattern12_prediction,
                pattern12_prediction_result,
                pattern123_combined,
                pattern123_prediction,
                pattern123_prediction_result,
                sequence_type
            FROM pattern_analysis 
            WHERE pattern12_combined IS NOT NULL 
                OR pattern123_combined IS NOT NULL
            LIMIT 10
        """)
        pattern_data = cursor.fetchall()
        
        # NULLì´ ì•„ë‹Œ ë°ì´í„° ê°œìˆ˜ í™•ì¸
        cursor.execute("""
            SELECT 
                COUNT(*) as total_records,
                COUNT(pattern12_combined) as pattern12_count,
                COUNT(pattern12_prediction) as pattern12_prediction_count,
                COUNT(pattern12_prediction_result) as pattern12_result_count,
                COUNT(pattern123_combined) as pattern123_count,
                COUNT(pattern123_prediction) as pattern123_prediction_count,
                COUNT(pattern123_prediction_result) as pattern123_result_count,
                COUNT(sequence_type) as sequence_type_count
            FROM pattern_analysis
        """)
        counts = cursor.fetchone()
        
        return {
            'table_structure': [col[1] for col in columns],
            'sample_data': sample_data,
            'pattern_data': pattern_data,
            'counts': {
                'total_records': counts[0],
                'pattern12_combined': counts[1],
                'pattern12_prediction': counts[2],
                'pattern12_prediction_result': counts[3],
                'pattern123_combined': counts[4],
                'pattern123_prediction': counts[5],
                'pattern123_prediction_result': counts[6],
                'sequence_type': counts[7]
            }
        }
        
    except Exception as e:
        return {'error': str(e)}
    finally:
        if conn:
            conn.close()

def debug_success_calculation():
    """success ê³„ì‚° ë¡œì§ ë””ë²„ê¹…"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # pattern12_prediction_result ê°’ ë¶„í¬ í™•ì¸
        cursor.execute("""
            SELECT 
                pattern12_prediction_result,
                COUNT(*) as count
            FROM pattern_analysis 
            WHERE pattern12_prediction_result IS NOT NULL
            GROUP BY pattern12_prediction_result
        """)
        pattern12_results = cursor.fetchall()
        
        # pattern123_prediction_result ê°’ ë¶„í¬ í™•ì¸
        cursor.execute("""
            SELECT 
                pattern123_prediction_result,
                COUNT(*) as count
            FROM pattern_analysis 
            WHERE pattern123_prediction_result IS NOT NULL
            GROUP BY pattern123_prediction_result
        """)
        pattern123_results = cursor.fetchall()
        
        # ì‹¤ì œ success ê³„ì‚° í…ŒìŠ¤íŠ¸ (ëŒ€ë¬¸ì ê¸°ì¤€)
        cursor.execute("""
            SELECT 
                pattern12_combined,
                sequence_type,
                pattern12_prediction,
                pattern12_prediction_result,
                COUNT(*) as frequency,
                SUM(CASE WHEN pattern12_prediction_result = 'W' THEN 1 ELSE 0 END) as success_count_upper,
                SUM(CASE WHEN pattern12_prediction_result = 'w' THEN 1 ELSE 0 END) as success_count_lower,
                SUM(CASE WHEN UPPER(pattern12_prediction_result) = 'W' THEN 1 ELSE 0 END) as success_count_fixed,
                SUM(CASE WHEN pattern12_prediction_result = 'L' THEN 1 ELSE 0 END) as fail_count_upper,
                SUM(CASE WHEN pattern12_prediction_result = 'l' THEN 1 ELSE 0 END) as fail_count_lower,
                SUM(CASE WHEN pattern12_prediction_result IS NULL THEN 1 ELSE 0 END) as null_count
            FROM pattern_analysis 
            WHERE pattern12_combined IS NOT NULL 
                AND pattern12_prediction IS NOT NULL 
                AND sequence_type IS NOT NULL
                AND pattern12_prediction_result IS NOT NULL
                AND pattern12_prediction_result != ''
            GROUP BY pattern12_combined, sequence_type, pattern12_prediction
            LIMIT 10
        """)
        pattern12_calculation = cursor.fetchall()
        
        cursor.execute("""
            SELECT 
                pattern123_combined,
                sequence_type,
                pattern123_prediction,
                pattern123_prediction_result,
                COUNT(*) as frequency,
                SUM(CASE WHEN pattern123_prediction_result = 'W' THEN 1 ELSE 0 END) as success_count_upper,
                SUM(CASE WHEN pattern123_prediction_result = 'w' THEN 1 ELSE 0 END) as success_count_lower,
                SUM(CASE WHEN UPPER(pattern123_prediction_result) = 'W' THEN 1 ELSE 0 END) as success_count_fixed,
                SUM(CASE WHEN pattern123_prediction_result = 'L' THEN 1 ELSE 0 END) as fail_count_upper,
                SUM(CASE WHEN pattern123_prediction_result = 'l' THEN 1 ELSE 0 END) as fail_count_lower,
                SUM(CASE WHEN pattern123_prediction_result IS NULL THEN 1 ELSE 0 END) as null_count
            FROM pattern_analysis 
            WHERE pattern123_combined IS NOT NULL 
                AND pattern123_prediction IS NOT NULL 
                AND sequence_type IS NOT NULL
                AND pattern123_prediction_result IS NOT NULL
                AND pattern123_prediction_result != ''
            GROUP BY pattern123_combined, sequence_type, pattern123_prediction
            LIMIT 10
        """)
        pattern123_calculation = cursor.fetchall()
        
        # ì˜ˆì¸¡ í…Œì´ë¸”ì˜ ì‹¤ì œ ë°ì´í„° í™•ì¸
        cursor.execute("SELECT * FROM pattern12_predictions LIMIT 5")
        pattern12_predictions_sample = cursor.fetchall()
        
        cursor.execute("SELECT * FROM pattern123_predictions LIMIT 5")
        pattern123_predictions_sample = cursor.fetchall()
        
        return {
            'pattern12_results_distribution': pattern12_results,
            'pattern123_results_distribution': pattern123_results,
            'pattern12_calculation_sample': pattern12_calculation,
            'pattern123_calculation_sample': pattern123_calculation,
            'pattern12_predictions_sample': pattern12_predictions_sample,
            'pattern123_predictions_sample': pattern123_predictions_sample
        }
        
    except Exception as e:
        return {'error': str(e)}
    finally:
        if conn:
            conn.close()

def debug_prediction_tables_data():
    """ì˜ˆì¸¡ í…Œì´ë¸”ì˜ ì‹¤ì œ ë°ì´í„° í™•ì¸"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # pattern12_predictions í…Œì´ë¸” ì‹¤ì œ ë°ì´í„° í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM pattern12_predictions")
        pattern12_total = cursor.fetchone()[0]
        
        cursor.execute("""
            SELECT 
                COUNT(*) as total_patterns,
                AVG(success_rate) as avg_success_rate,
                SUM(frequency) as total_frequency,
                COUNT(CASE WHEN success_rate >= 70 THEN 1 END) as high_accuracy_patterns,
                SUM(success_count) as total_success_count,
                SUM(frequency) as total_frequency_sum
            FROM pattern12_predictions
        """)
        pattern12_stats = cursor.fetchone()
        
        # pattern123_predictions í…Œì´ë¸” ì‹¤ì œ ë°ì´í„° í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM pattern123_predictions")
        pattern123_total = cursor.fetchone()[0]
        
        cursor.execute("""
            SELECT 
                COUNT(*) as total_patterns,
                AVG(success_rate) as avg_success_rate,
                SUM(frequency) as total_frequency,
                COUNT(CASE WHEN success_rate >= 70 THEN 1 END) as high_accuracy_patterns,
                SUM(success_count) as total_success_count,
                SUM(frequency) as total_frequency_sum
            FROM pattern123_predictions
        """)
        pattern123_stats = cursor.fetchone()
        
        # ì‹¤ì œ ë°ì´í„° ìƒ˜í”Œ í™•ì¸
        cursor.execute("""
            SELECT 
                pattern_number, sequence_type, prediction, frequency, success_count, success_rate
            FROM pattern12_predictions 
            WHERE success_count > 0 
            ORDER BY success_rate DESC 
            LIMIT 10
        """)
        pattern12_success_samples = cursor.fetchall()
        
        cursor.execute("""
            SELECT 
                pattern_number, sequence_type, prediction, frequency, success_count, success_rate
            FROM pattern123_predictions 
            WHERE success_count > 0 
            ORDER BY success_rate DESC 
            LIMIT 10
        """)
        pattern123_success_samples = cursor.fetchall()
        
        # ëª¨ë“  ë°ì´í„°ê°€ 0ì¸ì§€ í™•ì¸
        cursor.execute("""
            SELECT 
                COUNT(*) as total_records,
                COUNT(CASE WHEN success_count = 0 THEN 1 END) as zero_success_records,
                COUNT(CASE WHEN success_rate = 0 THEN 1 END) as zero_rate_records,
                COUNT(CASE WHEN frequency = 0 THEN 1 END) as zero_frequency_records
            FROM pattern12_predictions
        """)
        pattern12_zero_check = cursor.fetchone()
        
        cursor.execute("""
            SELECT 
                COUNT(*) as total_records,
                COUNT(CASE WHEN success_count = 0 THEN 1 END) as zero_success_records,
                COUNT(CASE WHEN success_rate = 0 THEN 1 END) as zero_rate_records,
                COUNT(CASE WHEN frequency = 0 THEN 1 END) as zero_frequency_records
            FROM pattern123_predictions
        """)
        pattern123_zero_check = cursor.fetchone()
        
        return {
            'pattern12': {
                'total_records': pattern12_total,
                'stats_from_db': {
                    'total_patterns': pattern12_stats[0],
                    'avg_success_rate': pattern12_stats[1],
                    'total_frequency': pattern12_stats[2],
                    'high_accuracy_patterns': pattern12_stats[3],
                    'total_success_count': pattern12_stats[4],
                    'total_frequency_sum': pattern12_stats[5]
                },
                'zero_check': {
                    'total_records': pattern12_zero_check[0],
                    'zero_success_records': pattern12_zero_check[1],
                    'zero_rate_records': pattern12_zero_check[2],
                    'zero_frequency_records': pattern12_zero_check[3]
                },
                'success_samples': pattern12_success_samples
            },
            'pattern123': {
                'total_records': pattern123_total,
                'stats_from_db': {
                    'total_patterns': pattern123_stats[0],
                    'avg_success_rate': pattern123_stats[1],
                    'total_frequency': pattern123_stats[2],
                    'high_accuracy_patterns': pattern123_stats[3],
                    'total_success_count': pattern123_stats[4],
                    'total_frequency_sum': pattern123_stats[5]
                },
                'zero_check': {
                    'total_records': pattern123_zero_check[0],
                    'zero_success_records': pattern123_zero_check[1],
                    'zero_rate_records': pattern123_zero_check[2],
                    'zero_frequency_records': pattern123_zero_check[3]
                },
                'success_samples': pattern123_success_samples
            }
        }
        
    except Exception as e:
        return {'error': str(e)}
    finally:
        if conn:
            conn.close()

def test_db_prediction_functions():
    """2ë‹¨ê³„: DB ê¸°ë°˜ ì˜ˆì¸¡ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    try:
        # í…ŒìŠ¤íŠ¸í•  íŒ¨í„´ë“¤
        test_patterns = [
            ('0114', 'P_Sequence', '12'),
            ('010101', 'B_Sequence', '123'),
            ('9999', 'P_Sequence', '12'),  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒ¨í„´
            ('999999', 'B_Sequence', '123')  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒ¨í„´
        ]
        
        results = []
        
        for pattern, sequence_type, pattern_type in test_patterns:
            if pattern_type == '12':
                prediction, found, frequency, success_rate = get_pattern_prediction_from_db(pattern, sequence_type)
            else:
                prediction, found, frequency, success_rate = get_pattern123_prediction_from_db(pattern, sequence_type)
            
            results.append({
                'pattern': pattern,
                'sequence_type': sequence_type,
                'pattern_type': pattern_type,
                'prediction': prediction,
                'found': found,
                'frequency': frequency,
                'success_rate': success_rate
            })
        
        return {
            'test_results': results,
            'summary': {
                'total_tests': len(results),
                'found_patterns': sum(1 for r in results if r['found']),
                'not_found_patterns': sum(1 for r in results if not r['found'])
            }
        }
        
    except Exception as e:
        return {'error': str(e)}

def add_verification_ui():
    """ê²€ì¦ì„ ìœ„í•œ UI ì¶”ê°€"""
    st.markdown("---")
    st.markdown("### 1ë‹¨ê³„: ì˜ˆì¸¡ í…Œì´ë¸” ê²€ì¦")
    
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        if st.button("1. í…Œì´ë¸” ìƒì„±", key="create_tables_btn"):
            if create_prediction_tables():
                st.success("ì˜ˆì¸¡ í…Œì´ë¸” ìƒì„± ì™„ë£Œ!")
            else:
                st.error("í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨!")
    
    with col2:
        if st.button("2. ë°ì´í„° êµ¬ì¶•", key="build_data_btn"):
            if build_prediction_tables_from_existing_data():
                st.success("ì˜ˆì¸¡ ë°ì´í„° êµ¬ì¶• ì™„ë£Œ!")
            else:
                st.error("ë°ì´í„° êµ¬ì¶• ì‹¤íŒ¨!")
    
    with col3:
        if st.button("3. í†µê³„ í™•ì¸", key="check_stats_btn"):
            stats = get_prediction_table_statistics()
            if stats:
                st.success("í†µê³„ ì¡°íšŒ ì™„ë£Œ!")
                st.json(stats)
            else:
                st.error("í†µê³„ ì¡°íšŒ ì‹¤íŒ¨!")
    
    # ì˜ˆì¸¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸ ë²„íŠ¼ ì¶”ê°€
    st.markdown("### ì˜ˆì¸¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸")
    col_update1, col_update2 = st.columns([1, 1])
    
    with col_update1:
        if st.button("ì˜ˆì¸¡ í…Œì´ë¸” ìˆ˜ë™ ì—…ë°ì´íŠ¸", key="manual_update_btn"):
            if st.session_state.show_grid and st.session_state.converted_grid is not None:
                zones = divide_grid_into_overlapping_zones(st.session_state.converted_grid)
                if zones:
                    if update_prediction_tables_from_new_data(zones):
                        st.success("ì˜ˆì¸¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                    else:
                        st.error("ì˜ˆì¸¡ í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì‹¤íŒ¨!")
                else:
                    st.warning("ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ë¨¼ì € SVG ì½”ë“œë¥¼ íŒŒì‹±í•´ì£¼ì„¸ìš”.")
    
    with col_update2:
        if st.button("ì „ì²´ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í…Œì´ë¸” ì¬êµ¬ì¶•", key="rebuild_predictions_btn"):
            if build_prediction_tables_from_existing_data():
                st.success("ì˜ˆì¸¡ í…Œì´ë¸” ì¬êµ¬ì¶• ì™„ë£Œ!")
            else:
                st.error("ì˜ˆì¸¡ í…Œì´ë¸” ì¬êµ¬ì¶• ì‹¤íŒ¨!")
    
    # 2ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ë²„íŠ¼ ì¶”ê°€
    st.markdown("### 2ë‹¨ê³„: DB ê¸°ë°˜ ì˜ˆì¸¡ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
    if st.button("4. DB ì˜ˆì¸¡ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸", key="test_db_prediction_btn"):
        test_results = test_db_prediction_functions()
        if 'error' not in test_results:
            st.success("DB ì˜ˆì¸¡ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            st.json(test_results)
        else:
            st.error(f"DB ì˜ˆì¸¡ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {test_results['error']}")
    
    # ê²€ì¦ ê²°ê³¼ í‘œì‹œ
    if st.button("ê²€ì¦ ì‹¤í–‰", key="run_verification_btn"):
        st.markdown("#### í…Œì´ë¸” ìƒì„± ê²€ì¦")
        creation_result = verify_prediction_tables_creation()
        st.json(creation_result)
        
        st.markdown("#### ë°ì´í„° êµ¬ì¶• ê²€ì¦")
        build_result = verify_prediction_data_build()
        st.json(build_result)
        
        st.markdown("#### í†µê³„ ì •ë³´")
        stats = get_prediction_table_statistics()
        if stats:
            st.json(stats)

        st.markdown("#### pattern_analysis í…Œì´ë¸” ë””ë²„ê¹…")
        debug_result = debug_pattern_analysis_data()
        st.json(debug_result)

        st.markdown("#### success ê³„ì‚° ë¡œì§ ë””ë²„ê¹…")
        success_debug_result = debug_success_calculation()
        st.json(success_debug_result)

        st.markdown("#### ì˜ˆì¸¡ í…Œì´ë¸” ì‹¤ì œ ë°ì´í„° í™•ì¸")
        debug_prediction_result = debug_prediction_tables_data()
        st.json(debug_prediction_result)

        st.markdown("#### 2ë‹¨ê³„: DB ê¸°ë°˜ ì˜ˆì¸¡ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
        test_results = test_db_prediction_functions()
        st.json(test_results)

def main():
    # Set full page width
    st.markdown("""
        <style>
        .stApp {margin-top: -2.5rem;}
        div[data-testid="stExpander"],
        div[data-testid="stExpander"] *,
        div[data-testid="stVerticalBlock"],
        div[data-testid="stVerticalBlock"] *,
        div[data-testid="stElementContainer"],
        div[data-testid="stElementContainer"] *,
        div[data-testid="stHorizontalBlock"],
        div[data-testid="stHorizontalBlock"] *,
        div[data-testid="stColumn"],
        div[data-testid="stColumn"] * {
            margin: 0 !important;
            padding: 0 !important;
            box-shadow: none !important;
            background: none !important;
        }
        </style>
    """, unsafe_allow_html=True)
    
    st.title("Bead Road Parser V12")
    
    # Initialize session state
    if 'text_key' not in st.session_state:
        st.session_state.text_key = 0
    if 'grid' not in st.session_state:
        st.session_state.grid = None
    if 'show_grid' not in st.session_state:
        st.session_state.show_grid = False
    if 'converted_grid' not in st.session_state:
        st.session_state.converted_grid = None
    if 'selected_cell' not in st.session_state:
        st.session_state.selected_cell = None
    if 'converted_grid_history' not in st.session_state:  # Add history state
        st.session_state.converted_grid_history = []
    if 'reconstructed_grid_history' not in st.session_state:  # Add reconstructed grid history state
        st.session_state.reconstructed_grid_history = []
    if 'reconstructed_selected_cell' not in st.session_state:
        st.session_state.reconstructed_selected_cell = None
    if 'reconstructed_bp_btn_value' not in st.session_state:
        st.session_state.reconstructed_bp_btn_value = 'B'
    if 'reconstructed_grid' not in st.session_state:
        st.session_state.reconstructed_grid = None
    if 'matrix_sequence_mapping' not in st.session_state:
        st.session_state.matrix_sequence_mapping = {}  # Matrix ì¡°í•©ë³„ ì²« ë²ˆì§¸ Sequence ê°’ ì €ì¥
    
    # ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„±
    create_new_tables()
    
    # Split screen into left and right columns (1:1 ratio)
    left_col, right_col = st.columns([1, 1])
    
    # Left column: SVG input and analysis results
    with left_col:
        svg_code = st.text_area("Paste SVG code here", height=68, key=f"svg_input_{st.session_state.text_key}")
        
        col_range_start, col_range_end = st.columns(2)
        with col_range_start:
            slice_start = st.number_input(
                "",
                min_value=1,
                max_value=TABLE_WIDTH,
                value=1,
                step=1,
                format="%d",
                label_visibility="collapsed"
            )
        with col_range_end:
            slice_end = st.number_input(
                "",
                min_value=1,
                max_value=TABLE_WIDTH,
                value=TABLE_WIDTH,
                step=1,
                format="%d",
                label_visibility="collapsed"
            )
        
        if slice_start > slice_end:
            st.warning("ë¶„ì„ ì‹œì‘ ì—´ì€ ì¢…ë£Œ ì—´ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.")
        
        col1, col2, col3 = st.columns([1, 3, 1])
        with col1:
            if st.button("Reset"):
                st.session_state.text_key += 1
                st.session_state.grid = None
                st.session_state.show_grid = False
                st.session_state.converted_grid = None
                st.session_state.selected_cell = None
                st.rerun()
        
        with col2:
            if st.button("Parse SVG"):
                if svg_code:
                    try:
                        # ì›ë³¸ ê·¸ë¦¬ë“œ íŒŒì‹±
                        raw_grid = parse_bead_road_svg(svg_code)
                        start_idx = min(int(slice_start), int(slice_end)) - 1
                        end_idx = max(int(slice_start), int(slice_end)) - 1
                        
                        # ì„ íƒí•œ ì—´ ë²”ìœ„ë¥¼ 0ë²ˆ ì—´ë¶€í„° ì¬ì •ë ¬
                        aligned_grid = realign_grid_by_columns(raw_grid, start_idx, end_idx)
                        st.session_state.grid = aligned_grid
                        st.session_state.show_grid = True
                        
                        # ì¬ì •ë ¬ëœ ê·¸ë¦¬ë“œì— ëŒ€í•´ ë³€í™˜ ë° ì¬êµ¬ì„± ìˆ˜í–‰
                        converted_grid = convert_tie_values(aligned_grid)
                        st.session_state.converted_grid = converted_grid
                        
                        reconstructed_grid = remove_tie_and_reconstruct_grid(aligned_grid)
                        st.session_state.reconstructed_grid = reconstructed_grid
                        
                        st.session_state.selected_cell = None
                        st.success("Successfully parsed the SVG code!")
                    except Exception as e:
                        st.error(f"Error parsing SVG: {str(e)}")
                else:
                    st.warning("Please paste SVG code first")
        
        with col3:
            if st.button("Save Pattern"):
                if st.session_state.show_grid and st.session_state.converted_grid is not None:
                    zones = divide_grid_into_overlapping_zones(st.session_state.converted_grid)
                    if zones:
                        # Generate unique session ID
                        session_id = str(uuid.uuid4())
                        if save_pattern_analysis(zones, session_id):
                            # Save prediction results to database
                            try:
                                # Collect all prediction results
                                all_prediction_results = []
                                sorted_zones_results = sorted(zones, key=lambda x: x['start_x'])  # Left to right order
                                for zone in sorted_zones_results:
                                    pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results(zone)
                                    if comparison1_2:
                                        all_prediction_results.append(comparison1_2.upper())
                                    if comparison1_2_3:
                                        all_prediction_results.append(comparison1_2_3.upper())
                                
                                if all_prediction_results:
                                    combined_results = ''.join(all_prediction_results)
                                    
                                    db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
                                    conn = sqlite3.connect(db_path)
                                    cursor = conn.cursor()
                                    
                                    # Create table if it doesn't exist
                                    cursor.execute('''
                                        CREATE TABLE IF NOT EXISTS session_prediction_results (
                                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                                            session_id TEXT NOT NULL,
                                            prediction_results TEXT NOT NULL,
                                            created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
                                        )
                                    ''')
                                    
                                    # Insert combined results
                                    cursor.execute('''
                                        INSERT INTO session_prediction_results (session_id, prediction_results)
                                        VALUES (?, ?)
                                    ''', (session_id, combined_results))
                                    
                                    conn.commit()
                            except Exception as e:
                                st.error(f"Error saving prediction results: {str(e)}")
                            finally:
                                if conn:
                                    conn.close()
                            
                            # ìƒˆë¡œìš´ ë…ë¦½ì ì¸ í•¨ìˆ˜ í˜¸ì¶œ
                            save_enhanced_prediction_results(zones, session_id)
                            
                            # T-Removed Reconstructed Gridê°€ ì¡´ì¬í•˜ë©´ ì¶”ê°€ë¡œ ì €ì¥
                            if hasattr(st.session_state, 'reconstructed_grid') and st.session_state.reconstructed_grid:
                                reconstructed_zones = divide_grid_into_overlapping_zones_for_reconstructed(st.session_state.reconstructed_grid)
                                if reconstructed_zones:
                                    save_t_removed_reconstructed_results(reconstructed_zones, session_id)
                                    save_t_removed_reconstructed_prediction_results(reconstructed_zones, session_id)
                            
                            st.success("ì €ì¥ ì™„ë£Œ!")
                        else:
                            st.error("Failed to save analysis")
                    else:
                        st.warning("ì €ì¥í•  íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ë¨¼ì € SVG ì½”ë“œë¥¼ íŒŒì‹±í•´ì£¼ì„¸ìš”.")
        
        # Display Full Grid if available
        if st.session_state.show_grid and st.session_state.grid is not None:
            display_grid_with_title(st.session_state.grid, "Full Grid")
            
            # Apply T conversion rule
            if st.session_state.converted_grid is None:
                st.session_state.converted_grid = convert_tie_values(st.session_state.grid)
            display_grid_with_title(st.session_state.converted_grid, "Converted Grid")
            
            # Display T-Removed Reconstructed Grid
            if hasattr(st.session_state, 'reconstructed_grid') and st.session_state.reconstructed_grid:
                display_grid_with_title(st.session_state.reconstructed_grid, "T-Removed Reconstructed Grid")
                
                # Manual input for T-Removed Reconstructed Grid
                with st.expander("ìˆ˜ë™ ì…ë ¥ (T-Removed Reconstructed Grid)", expanded=False):
                    # Find all empty cells
                    empty_cells = [(x+1, y+1) for x in range(TABLE_WIDTH) for y in range(TABLE_HEIGHT) if not st.session_state.reconstructed_grid[x][y]]
                    if empty_cells:
                        selected = st.selectbox("ë¹„ì–´ìˆëŠ” ì…€ ì¢Œí‘œë¥¼ ì„ íƒí•˜ì„¸ìš” (X, Y)", empty_cells, key="reconstructed_empty_cell_select")
                        st.session_state.reconstructed_selected_cell = selected
                        x, y = selected[0]-1, selected[1]-1
                        st.info(f"ì„ íƒëœ ì…€: X={x+1}, Y={y+1}")

                        # B/P ë²„íŠ¼ ì„ íƒ UI
                        colb, colp = st.columns([1,1], gap="large")
                        with colb:
                            if st.button('B', key='reconstructed_bp_btn_b', help='B ì„ íƒ', use_container_width=True):
                                st.session_state.reconstructed_bp_btn_value = 'B'
                        with colp:
                            if st.button('P', key='reconstructed_bp_btn_p', help='P ì„ íƒ', use_container_width=True):
                                st.session_state.reconstructed_bp_btn_value = 'P'
                        st.markdown(f'<div style="margin-top:0.5rem;font-size:1.2rem;font-weight:bold;">í˜„ì¬ ì„ íƒ: <span style="color:#1e40af">{st.session_state.reconstructed_bp_btn_value}</span></div>', unsafe_allow_html=True)

                        col_apply, col_undo = st.columns([1,1])
                        with col_apply:
                            if st.button("ì ìš©", key="apply_reconstructed_manual"):
                                # Save current grid to history for undo
                                st.session_state.reconstructed_grid_history.append(copy.deepcopy(st.session_state.reconstructed_grid))
                                st.session_state.reconstructed_grid[x][y] = st.session_state.reconstructed_bp_btn_value.lower()
                                st.success(f"({x+1}, {y+1}) ì…€ì„ {st.session_state.reconstructed_bp_btn_value}ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.")
                                st.session_state.reconstructed_selected_cell = None
                                st.rerun()
                        with col_undo:
                            if st.button("ë˜ëŒë¦¬ê¸°", key="undo_reconstructed_manual", disabled=len(st.session_state.reconstructed_grid_history) == 0):
                                if st.session_state.reconstructed_grid_history:
                                    st.session_state.reconstructed_grid = st.session_state.reconstructed_grid_history.pop()
                                    st.success("ì´ì „ ìƒíƒœë¡œ ë˜ëŒë ¸ìŠµë‹ˆë‹¤.")
                                    st.session_state.reconstructed_selected_cell = None
                                    st.rerun()
                    else:
                        st.info("ë¹„ì–´ìˆëŠ” ì…€ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # Manual input for empty cells below the table
            with st.expander("ìˆ˜ë™ ì…ë ¥ (Converted Grid)", expanded=False):
                # Find all empty cells
                empty_cells = [(x+1, y+1) for x in range(TABLE_WIDTH) for y in range(TABLE_HEIGHT) if not st.session_state.converted_grid[x][y]]
                if empty_cells:
                    selected = st.selectbox("ë¹„ì–´ìˆëŠ” ì…€ ì¢Œí‘œë¥¼ ì„ íƒí•˜ì„¸ìš” (X, Y)", empty_cells, key="empty_cell_select")
                    st.session_state.selected_cell = selected
                    x, y = selected[0]-1, selected[1]-1
                    st.info(f"ì„ íƒëœ ì…€: X={x+1}, Y={y+1}")

                    # B/P ë²„íŠ¼ ì„ íƒ UI
                    if 'bp_btn_value' not in st.session_state:
                        st.session_state.bp_btn_value = 'B'
                    colb, colp = st.columns([1,1], gap="large")
                    with colb:
                        if st.button('B', key='bp_btn_b', help='B ì„ íƒ', use_container_width=True):
                            st.session_state.bp_btn_value = 'B'
                    with colp:
                        if st.button('P', key='bp_btn_p', help='P ì„ íƒ', use_container_width=True):
                            st.session_state.bp_btn_value = 'P'
                    st.markdown(f'<div style="margin-top:0.5rem;font-size:1.2rem;font-weight:bold;">í˜„ì¬ ì„ íƒ: <span style="color:#1e40af">{st.session_state.bp_btn_value}</span></div>', unsafe_allow_html=True)

                    col_apply, col_undo = st.columns([1,1])
                    with col_apply:
                        if st.button("ì ìš©", key="apply_manual2"):
                            # Save current grid to history for undo
                            st.session_state.converted_grid_history.append(copy.deepcopy(st.session_state.converted_grid))
                            st.session_state.converted_grid[x][y] = st.session_state.bp_btn_value.lower()
                            st.success(f"({x+1}, {y+1}) ì…€ì„ {st.session_state.bp_btn_value}ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.")
                            st.session_state.selected_cell = None
                            st.rerun()
                    with col_undo:
                        if st.button("ë˜ëŒë¦¬ê¸°", key="undo_manual2", disabled=len(st.session_state.converted_grid_history) == 0):
                            if st.session_state.converted_grid_history:
                                st.session_state.converted_grid = st.session_state.converted_grid_history.pop()
                                st.success("ì´ì „ ìƒíƒœë¡œ ë˜ëŒë ¸ìŠµë‹ˆë‹¤.")
                                st.session_state.selected_cell = None
                                st.rerun()
                else:
                    st.info("ë¹„ì–´ìˆëŠ” ì…€ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # Process T-Removed Reconstructed Grid zones and display pattern analysis (ë¨¼ì € í‘œì‹œ)
            if hasattr(st.session_state, 'reconstructed_grid') and st.session_state.reconstructed_grid:
                reconstructed_zones = divide_grid_into_overlapping_zones_for_reconstructed(st.session_state.reconstructed_grid)
                if reconstructed_zones:
                    display_pattern_groups_for_reconstructed(reconstructed_zones)
                else:
                    st.info("No zones with relevant data to display for T-Removed Reconstructed Grid.")
            
            # Process zones and display pattern analysis
            zones = divide_grid_into_overlapping_zones(st.session_state.converted_grid)
            if zones:
                display_pattern_groups(zones)
            else:
                st.info("No zones with relevant data to display.")
    
    # Right column: Group Result
    with right_col:
        # 3í–‰3ì—´ ë²”ìœ„ T ê°œìˆ˜ í‘œì‹œ (ìµœìƒë‹¨, ì˜¤ë¥¸ìª½ ì •ë ¬)
        if st.session_state.grid is not None:
            display_t_count_3x3(st.session_state.grid)
        
        # Matrix Column Information í‘œì‹œ
        display_matrix_column_info()
        
        # Table Identifier ìˆ¨ê¹€ ì²˜ë¦¬
        # st.markdown("""
        #     <style>
        #     div[data-testid="stRadio"] {
        #         margin-bottom: 1rem;
        #     }
        #     div[data-testid="stRadio"] > div {
        #         padding: 0.2rem;
        #     }
        #     div[data-testid="stRadio"] > div[role="radiogroup"] > div[role="radio"] {
        #         border: 1px solid #ddd;
        #         border-radius: 4px;
        #         padding: 0.2rem 0.5rem;
        #         margin: 0.1rem;
        #     }
        #     div[data-testid="stRadio"] > div[role="radiogroup"] > div[role="radio"][aria-checked="true"] {
        #         background-color: #1e40af;
        #         color: white;
        #         border-color: #1e40af;
        #     }
        #     </style>
        # """, unsafe_allow_html=True)
        # 
        # st.markdown("#### Table Identifier")
        # options = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',
        #           'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'N',
        #           'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Z']
        # selected = st.radio("Select table identifier", options, horizontal=True)
        # if selected:
        #     st.markdown(f"<div style='margin-top: -0.5rem; margin-bottom: 1rem; color: #1e40af; font-weight: bold;'>Selected: {selected}</div>", unsafe_allow_html=True)
        # st.markdown("---")

        action_left, action_right = st.columns([3, 1])
        with action_left:
            st.markdown("")
        with action_right:
            if st.button("Save Summary", key="save_game_outcome", use_container_width=True):
                converted_grid = st.session_state.converted_grid if st.session_state.show_grid and st.session_state.converted_grid is not None else None
                if not converted_grid:
                    st.warning("ì €ì¥í•  Converted Gridê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    converted_grid_str = serialize_grid_for_storage(converted_grid)
                    reconstructed_grid = st.session_state.reconstructed_grid if hasattr(st.session_state, 'reconstructed_grid') and st.session_state.reconstructed_grid else None
                    reconstructed_grid_str = serialize_grid_for_storage(reconstructed_grid) if reconstructed_grid else ''

                    converted_zones_for_save = divide_grid_into_overlapping_zones(converted_grid)
                    reconstructed_zones_for_save = divide_grid_into_overlapping_zones_for_reconstructed(reconstructed_grid) if reconstructed_grid else None

                    sequence_results_value = generate_sequence_prediction_results(converted_zones_for_save) if converted_zones_for_save else ''
                    reconstructed_sequence_value = generate_sequence_prediction_results_for_reconstructed(reconstructed_zones_for_save) if reconstructed_zones_for_save else ''
                    reconstructed_gap_value = generate_high_probability_gap_results_for_reconstructed(reconstructed_zones_for_save) if reconstructed_zones_for_save else ''

                    success, saved_session_id = save_game_outcome_summary(
                        converted_grid_str,
                        reconstructed_grid_str,
                        sequence_results_value,
                        reconstructed_sequence_value,
                        reconstructed_gap_value
                    )
                    if success:
                        st.success("Saved")
                    else:
                        st.error("Outcome summary ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        zones = None
        reconstructed_zones = None

        if st.session_state.show_grid and st.session_state.converted_grid is not None:
            zones = divide_grid_into_overlapping_zones(st.session_state.converted_grid)
            if zones:
                sequence_prediction_results = generate_sequence_prediction_results(zones)
                if sequence_prediction_results:
                    st.markdown("### Sequence Prediction Results")
                    st.markdown(f"**{sequence_prediction_results}**")
                    st.markdown("---")

        if hasattr(st.session_state, 'reconstructed_grid') and st.session_state.reconstructed_grid:
            reconstructed_zones = divide_grid_into_overlapping_zones_for_reconstructed(st.session_state.reconstructed_grid)
            if reconstructed_zones:
                display_session_prediction_results_for_reconstructed(reconstructed_zones)

        col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
        with col1:
            st.subheader("Group Result")
        with col2:
            # ë²„íŠ¼ ë†’ì´ë¥¼ ì¤„ì´ëŠ” CSS ìŠ¤íƒ€ì¼
            st.markdown("""
                <style>
                .stButton > button {
                    height: 2rem;
                    padding: 0.25rem 0.5rem;
                    font-size: 0.8rem;
                    color: black !important;
                    background-color: white !important;
                    border: 1px solid #ddd !important;
                    border-radius: 4px !important;
                    font-weight: bold !important;
                }
                .stButton > button:hover {
                    background-color: #f0f0f0 !important;
                }
                </style>
            """, unsafe_allow_html=True)
            
            if st.button("Pattern1", key="save_pattern1", type="primary"):
                if st.session_state.show_grid and st.session_state.converted_grid is not None:
                    zones = divide_grid_into_overlapping_zones(st.session_state.converted_grid)
                    if zones:
                        session_id = str(uuid.uuid4())
                        if save_new_pattern_analysis(zones, session_id, 'pattern1'):
                            st.success("Pattern1 ë¶„ì„ ê²°ê³¼ê°€ ìƒˆë¡œìš´ í…Œì´ë¸”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.error("Pattern1 ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("ì €ì¥í•  íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ë¨¼ì € SVG ì½”ë“œë¥¼ íŒŒì‹±í•´ì£¼ì„¸ìš”.")
        
        with col3:
            if st.button("Pattern2", key="save_pattern2", type="primary"):
                if st.session_state.show_grid and st.session_state.converted_grid is not None:
                    zones = divide_grid_into_overlapping_zones(st.session_state.converted_grid)
                    if zones:
                        session_id = str(uuid.uuid4())
                        if save_new_pattern_analysis(zones, session_id, 'pattern2'):
                            st.success("Pattern2 ë¶„ì„ ê²°ê³¼ê°€ ìƒˆë¡œìš´ í…Œì´ë¸”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.error("Pattern2 ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("ì €ì¥í•  íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ë¨¼ì € SVG ì½”ë“œë¥¼ íŒŒì‹±í•´ì£¼ì„¸ìš”.")
        
        with col4:
            if st.button("Pattern3", key="save_pattern3", type="primary"):
                if st.session_state.show_grid and st.session_state.converted_grid is not None:
                    zones = divide_grid_into_overlapping_zones(st.session_state.converted_grid)
                    if zones:
                        session_id = str(uuid.uuid4())
                        if save_new_pattern_analysis(zones, session_id, 'pattern3'):
                            st.success("Pattern3 ë¶„ì„ ê²°ê³¼ê°€ ìƒˆë¡œìš´ í…Œì´ë¸”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.error("Pattern3 ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("ì €ì¥í•  íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ë¨¼ì € SVG ì½”ë“œë¥¼ íŒŒì‹±í•´ì£¼ì„¸ìš”.")
        
        if zones:
            # Display sequence prediction results using pattern_sequence_prediction table
            sequence_prediction_results = generate_sequence_prediction_results(zones)
            if sequence_prediction_results:
                st.markdown("### Sequence Prediction Results")
                st.markdown(f"**{sequence_prediction_results}**")
                st.markdown("---")

            # Group info display: right to left
            sorted_zones_groups = sorted(zones, key=lambda x: x['start_x'], reverse=True)
            
            # ìƒˆë¡œìš´ ë…ë¦½ì ì¸ í•¨ìˆ˜ í˜¸ì¶œ (ìˆ¨ê¹€ ì²˜ë¦¬)
            # display_enhanced_prediction_results(zones)
            
            # Insert search boxes here
            pattern12_prediction_search_box()
            pattern123_prediction_search_box()
            st.markdown("---")
            
            # Group 1-3 (T-Removed Reconstructed) ë…ë¦½ì ìœ¼ë¡œ í‘œì‹œ
            display_group_1_3_independent()
            
            # T-Removed Reconstructed Grid Group Results (ë‹¤ë¥¸ ê·¸ë£¹ë“¤)
            if hasattr(st.session_state, 'reconstructed_grid') and st.session_state.reconstructed_grid:
                reconstructed_zones = divide_grid_into_overlapping_zones_for_reconstructed(st.session_state.reconstructed_grid)
                if reconstructed_zones:
                    display_group_results_for_reconstructed(reconstructed_zones)
                else:
                    st.info("No zones with relevant data to display for T-Removed Reconstructed Grid Group Results.")
            
            # Display individual group results (right to left) - ê¸°ì¡´ Group Results
            for zone in sorted_zones_groups:
                group_range = f"{zone['start_x'] + 1}-{zone['end_x'] + 1}"
                pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results(zone)

                # Check if there is anything to display for this group
                has_content = any([
                    pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3
                ])
                is_group_1_3 = (zone['start_x'] == 0 and zone['end_x'] == 2)
                if not has_content and not is_group_1_3:
                    continue  # Skip this group if nothing to display and not Group 1-3

                st.markdown(f"#### Group {group_range}")
                # Pattern 1,2 results
                st.text(f"Pattern 1,2 combined: {pattern1_2_combined}")
                if pattern1_2:
                    st.text(f"Pattern 1,2 result: {pattern1_2.upper()}")
                    if prediction1_2:
                        source_emoji_12 = "ğŸ—„ï¸" if source1_2 == "DB" else "ğŸ“„" if source1_2 == "CSV" else "â“"
                        st.text(f"Pattern 1,2 Prediction: {prediction1_2.upper()} (ì†ŒìŠ¤: {source_emoji_12} {source1_2})")
                        st.text(f"Pattern 1,2 Prediction Result: {comparison1_2.upper()}")
                    else:
                        st.text("No Pattern 1,2 prediction found")
                # Pattern 1,2,3 results
                st.text(f"Pattern 1,2,3 combined: {pattern1_2_3_combined}")
                if pattern1_2_3:
                    st.text(f"Pattern 1,2,3 result: {pattern1_2_3.upper()}")
                    if prediction1_2_3:
                        source_emoji_123 = "ğŸ—„ï¸" if source1_2_3 == "DB" else "ğŸ“„" if source1_2_3 == "CSV" else "â“"
                        st.text(f"Pattern 1,2,3 Prediction: {prediction1_2_3.upper()} (ì†ŒìŠ¤: {source_emoji_123} {source1_2_3})")
                        st.text(f"Pattern 1,2,3 Prediction Result: {comparison1_2_3.upper()}")
                    else:
                        st.text("No Pattern 1,2,3 prediction found")
                    # Pattern 3,4 combined always at the end
                    st.text(f"Pattern 3,4 combined: {pattern3_4_combined}")
                    st.markdown("---")
            
            # ê²€ì¦ UI ì¶”ê°€
            st.markdown("---")
            add_verification_ui()
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ UI ì¶”ê°€
            st.markdown("---")
            add_hybrid_test_ui()
            
            # ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ UI ì¶”ê°€
            st.markdown("---")
            add_cleanup_ui()
            


def pattern12_prediction_search_box():
    st.markdown("#### Pattern 1,2 Prediction ê²€ìƒ‰")
    pattern_input = st.text_input("Pattern 1,2 ë²ˆí˜¸ ì…ë ¥", key="pattern12_search_input")
    if st.button("ê²€ìƒ‰", key="pattern12_search_btn"):
        if pattern_input:
            pred_p, found_p, source_p = get_hybrid_pattern_prediction(pattern_input, "P_Sequence")
            pred_b, found_b, source_b = get_hybrid_pattern_prediction(pattern_input, "B_Sequence")
            
            st.markdown("**P_Sequence ê²°ê³¼:**")
            if found_p:
                source_emoji = "ğŸ—„ï¸" if source_p == "DB" else "ğŸ“„" if source_p == "CSV" else "â“"
                st.success(f"Prediction: {pred_p} (ì†ŒìŠ¤: {source_emoji} {source_p})")
            else:
                st.warning("No prediction found for P_Sequence.")
            
            st.markdown("**B_Sequence ê²°ê³¼:**")
            if found_b:
                source_emoji = "ğŸ—„ï¸" if source_b == "DB" else "ğŸ“„" if source_b == "CSV" else "â“"
                st.success(f"Prediction: {pred_b} (ì†ŒìŠ¤: {source_emoji} {source_b})")
            else:
                st.warning("No prediction found for B_Sequence.")
        else:
            st.info("íŒ¨í„´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

def pattern123_prediction_search_box():
    st.markdown("#### Pattern 1,2,3 Prediction ê²€ìƒ‰")
    pattern_input = st.text_input("Pattern 1,2,3 ë²ˆí˜¸ ì…ë ¥", key="pattern123_search_input")
    if st.button("ê²€ìƒ‰", key="pattern123_search_btn"):
        if pattern_input:
            pred_p, found_p, source_p = get_hybrid_pattern123_prediction(pattern_input, "P_Sequence")
            pred_b, found_b, source_b = get_hybrid_pattern123_prediction(pattern_input, "B_Sequence")
            
            st.markdown("**P_Sequence ê²°ê³¼:**")
            if found_p:
                source_emoji = "ğŸ—„ï¸" if source_p == "DB" else "ğŸ“„" if source_p == "CSV" else "â“"
                st.success(f"Prediction: {pred_p} (ì†ŒìŠ¤: {source_emoji} {source_p})")
            else:
                st.warning("No prediction found for P_Sequence.")
            
            st.markdown("**B_Sequence ê²°ê³¼:**")
            if found_b:
                source_emoji = "ğŸ—„ï¸" if source_b == "DB" else "ğŸ“„" if source_b == "CSV" else "â“"
                st.success(f"Prediction: {pred_b} (ì†ŒìŠ¤: {source_emoji} {source_b})")
            else:
                st.warning("No prediction found for B_Sequence.")
        else:
            st.info("íŒ¨í„´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

def get_pattern_prediction_from_csv(pattern, sequence_type):
    """Get prediction from CSV file based on pattern and sequence type"""
    try:
        df = pd.read_csv('/Users/tj/test_v3/pattern1_result_v1.csv')
        if sequence_type and pattern:
            # Map sequence type to prediction column
            prediction_col = 'P_Prediction' if sequence_type == 'P_Sequence' else 'B_Prediction'
            # Remove leading zero from 4-digit pattern numbers
            pattern_str = str(pattern).strip()
            if len(pattern_str) == 4 and pattern_str.startswith('0'):
                pattern_str = pattern_str[1:]
            # Find matching pattern in Pattern_Number column
            filtered_df = df[df['Pattern_Number'].astype(str).str.strip() == pattern_str]
            if not filtered_df.empty:
                return filtered_df[prediction_col].iloc[0], True
        return '', False
    except Exception as e:
        st.error(f"Error in get_pattern_prediction_from_csv: {str(e)}")
        return '', False

def get_pattern123_prediction_from_csv(pattern, sequence_type):
    """Get prediction from CSV file based on pattern 1,2,3 and sequence type"""
    try:
        df = pd.read_csv('/Users/tj/test_v3/pattern2_result_v1.csv')
        if sequence_type and pattern:
            # Map sequence type to prediction column
            prediction_col = 'P_Prediction' if sequence_type == 'P_Sequence' else 'B_Prediction'
            # Remove leading zero from 6-digit pattern numbers
            pattern_str = str(pattern).strip()
            if len(pattern_str) == 6 and pattern_str.startswith('0'):
                pattern_str = pattern_str[1:]
            # Find matching pattern in Pattern_Number column
            filtered_df = df[df['Pattern_Number'].astype(str).str.strip() == pattern_str]
            if not filtered_df.empty:
                return filtered_df[prediction_col].iloc[0], True
        return '', False
    except Exception as e:
        st.error(f"Error in get_pattern123_prediction_from_csv: {str(e)}")
        return '', False

def get_hybrid_pattern_prediction(pattern, sequence_type):
    """
    í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ:
    1. DBì—ì„œ ë¨¼ì € ê²€ìƒ‰
    2. DBì— ì—†ìœ¼ë©´ CSVì—ì„œ ê²€ìƒ‰
    3. ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
    """
    # 1ë‹¨ê³„: DBì—ì„œ ê²€ìƒ‰
    db_result = get_pattern_prediction_from_db(pattern, sequence_type)
    if db_result and db_result[0]:  # DBì— ìˆìœ¼ë©´ ì‚¬ìš©
        return db_result[0], True, "DB"
    
    # 2ë‹¨ê³„: CSVì—ì„œ ê²€ìƒ‰
    csv_result = get_pattern_prediction_from_csv(pattern, sequence_type)
    if csv_result and csv_result[0]:  # CSVì— ìˆìœ¼ë©´ ì‚¬ìš©
        return csv_result[0], True, "CSV"
    
    # 3ë‹¨ê³„: ê¸°ë³¸ê°’ ë°˜í™˜
    return '', False, "NOT_FOUND"

def get_hybrid_pattern123_prediction(pattern, sequence_type):
    """
    í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (Pattern 123):
    1. DBì—ì„œ ë¨¼ì € ê²€ìƒ‰
    2. DBì— ì—†ìœ¼ë©´ CSVì—ì„œ ê²€ìƒ‰
    3. ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
    """
    # 1ë‹¨ê³„: DBì—ì„œ ê²€ìƒ‰
    db_result = get_pattern123_prediction_from_db(pattern, sequence_type)
    if db_result and db_result[0]:  # DBì— ìˆìœ¼ë©´ ì‚¬ìš©
        return db_result[0], True, "DB"
    
    # 2ë‹¨ê³„: CSVì—ì„œ ê²€ìƒ‰
    csv_result = get_pattern123_prediction_from_csv(pattern, sequence_type)
    if csv_result and csv_result[0]:  # CSVì— ìˆìœ¼ë©´ ì‚¬ìš©
        return csv_result[0], True, "CSV"
    
    # 3ë‹¨ê³„: ê¸°ë³¸ê°’ ë°˜í™˜
    return '', False, "NOT_FOUND"

def test_hybrid_prediction_system():
    """í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    test_cases = [
        ("0628", "P_Sequence", "pattern12"),
        ("383647", "B_Sequence", "pattern123"),
        ("0101", "P_Sequence", "pattern12"),
        ("010101", "B_Sequence", "pattern123"),
    ]
    
    results = {}
    for pattern, sequence_type, pattern_type in test_cases:
        if pattern_type == "pattern12":
            result, found, source = get_hybrid_pattern_prediction(pattern, sequence_type)
        else:
            result, found, source = get_hybrid_pattern123_prediction(pattern, sequence_type)
        
        results[f"{pattern}_{sequence_type}"] = {
            "pattern": pattern,
            "sequence_type": sequence_type,
            "pattern_type": pattern_type,
            "result": result,
            "found": found,
            "source": source
        }
    
    return results

def add_hybrid_test_ui():
    """í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ UI ì¶”ê°€"""
    st.subheader("ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    
    if st.button("í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"):
        results = test_hybrid_prediction_system()
        
        st.write("### í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        for key, data in results.items():
            status_emoji = "âœ…" if data["found"] else "âŒ"
            source_emoji = "ğŸ—„ï¸" if data["source"] == "DB" else "ğŸ“„" if data["source"] == "CSV" else "â“"
            
            st.write(f"{status_emoji} **{data['pattern']}** ({data['sequence_type']}) - {data['pattern_type']}")
            st.write(f"   ê²°ê³¼: {data['result']} | ì†ŒìŠ¤: {source_emoji} {data['source']}")
            st.write("---")

def add_cleanup_ui():
    """ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ UI ì¶”ê°€"""
    st.subheader("ğŸ§¹ ì¤‘ë³µ ë°ì´í„° ì •ë¦¬")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if st.button("ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ ì‹¤í–‰", key="cleanup_btn"):
            result = cleanup_duplicate_data()
            
            if result['success']:
                st.success("ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ!")
                st.write("### ì •ë¦¬ ê²°ê³¼:")
                st.write(f"- pattern_analysis: {result['pattern_analysis_count']}ê°œ ë ˆì½”ë“œ")
                st.write(f"- session_prediction_results: {result['session_prediction_results_count']}ê°œ ë ˆì½”ë“œ")
                st.write(f"- enhanced_prediction_results: {result['enhanced_prediction_results_count']}ê°œ ë ˆì½”ë“œ")
            else:
                st.error(f"ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {result['error']}")
    
    with col2:
        if st.button("ì¤‘ë³µ ë°ì´í„° í˜„í™© í™•ì¸", key="check_duplicates_btn"):
            try:
                db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                
                # 1ë¶„ ì´ë‚´ ì¤‘ë³µ ë°ì´í„° í™•ì¸
                cursor.execute("""
                    SELECT prediction_results, COUNT(*) as duplicate_count
                    FROM session_prediction_results 
                    WHERE created_at >= datetime('now', '-1 minute')
                    GROUP BY prediction_results 
                    HAVING COUNT(*) > 1
                    ORDER BY duplicate_count DESC
                """)
                
                duplicates = cursor.fetchall()
                
                if duplicates:
                    st.warning(f"1ë¶„ ì´ë‚´ ì¤‘ë³µ ë°ì´í„° ë°œê²¬: {len(duplicates)}ê°œ ê·¸ë£¹")
                    for prediction_results, count in duplicates:
                        st.write(f"- `{prediction_results}`: {count}ê°œ ì¤‘ë³µ")
                else:
                    st.success("1ë¶„ ì´ë‚´ ì¤‘ë³µ ë°ì´í„° ì—†ìŒ")
                
                # ì „ì²´ í…Œì´ë¸” ë ˆì½”ë“œ ìˆ˜ í™•ì¸
                cursor.execute("SELECT COUNT(*) FROM pattern_analysis")
                pattern_count = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM session_prediction_results")
                session_count = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM enhanced_prediction_results")
                enhanced_count = cursor.fetchone()[0]
                
                st.write("### ì „ì²´ í…Œì´ë¸” í˜„í™©:")
                st.write(f"- pattern_analysis: {pattern_count}ê°œ ë ˆì½”ë“œ")
                st.write(f"- session_prediction_results: {session_count}ê°œ ë ˆì½”ë“œ")
                st.write(f"- enhanced_prediction_results: {enhanced_count}ê°œ ë ˆì½”ë“œ")
                
            except Exception as e:
                st.error(f"ì¤‘ë³µ ë°ì´í„° í™•ì¸ ì˜¤ë¥˜: {str(e)}")
            finally:
                if conn:
                    conn.close()

def display_enhanced_prediction_results(zones):
    """ë…ë¦½ì ì¸ ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜"""
    if not zones:
        return
    
    # ëª¨ë“  zoneì„ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì •ë ¬
    sorted_zones = sorted(zones, key=lambda x: x['start_x'])
    
    # ëª¨ë“  ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘
    all_enhanced_results = []
    
    for zone in sorted_zones:
        # get_pattern_results í•¨ìˆ˜ë¡œ ê° zoneì˜ ê²°ê³¼ ì¶”ì¶œ
        pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results(zone)
        
        # comparison1_2 ì²˜ë¦¬ (CSV ì†ŒìŠ¤ì¼ ë•Œ Pë¡œ ë³€í™˜)
        if comparison1_2:
            if source1_2 == "CSV":
                enhanced_result = "P"
            else:
                enhanced_result = comparison1_2.upper()
            all_enhanced_results.append(enhanced_result)
        
        # comparison1_2_3 ì²˜ë¦¬ (CSV ì†ŒìŠ¤ì¼ ë•Œ Pë¡œ ë³€í™˜)
        if comparison1_2_3:
            if source1_2_3 == "CSV":
                enhanced_result = "P"
            else:
                enhanced_result = comparison1_2_3.upper()
            all_enhanced_results.append(enhanced_result)
    
    # ëª¨ë“  ê²°ê³¼ë¥¼ ì—°ê²°í•˜ì—¬ í‘œì‹œ
    if all_enhanced_results:
        combined_enhanced_results = ''.join(all_enhanced_results)
        st.markdown("### Enhanced Prediction Results")
        st.markdown(f"**{combined_enhanced_results}**")
        st.markdown("---")


def save_enhanced_prediction_results(zones, session_id):
    """Enhanced Prediction Resultsë¥¼ ìƒˆë¡œìš´ í…Œì´ë¸”ì— ì €ì¥í•˜ëŠ” ë…ë¦½ì ì¸ í•¨ìˆ˜"""
    if not zones:
        return False
    
    try:
        # ëª¨ë“  zoneì„ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì •ë ¬
        sorted_zones = sorted(zones, key=lambda x: x['start_x'])
        
        # Enhanced Prediction Results ìˆ˜ì§‘
        all_enhanced_results = []
        
        for zone in sorted_zones:
            # get_pattern_results í•¨ìˆ˜ë¡œ ê° zoneì˜ ê²°ê³¼ ì¶”ì¶œ
            pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results(zone)
            
            # comparison1_2 ì²˜ë¦¬ (CSV ì†ŒìŠ¤ì¼ ë•Œ Pë¡œ ë³€í™˜)
            if comparison1_2:
                if source1_2 == "CSV":
                    enhanced_result = "P"
                else:
                    enhanced_result = comparison1_2.upper()
                all_enhanced_results.append(enhanced_result)
            
            # comparison1_2_3 ì²˜ë¦¬ (CSV ì†ŒìŠ¤ì¼ ë•Œ Pë¡œ ë³€í™˜)
            if comparison1_2_3:
                if source1_2_3 == "CSV":
                    enhanced_result = "P"
                else:
                    enhanced_result = comparison1_2_3.upper()
                all_enhanced_results.append(enhanced_result)
        
        # Enhanced Prediction Resultsë¥¼ DBì— ì €ì¥
        if all_enhanced_results:
            combined_enhanced_results = ''.join(all_enhanced_results)
            
            db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # session_prediction_results í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ì°¸ê³ í•˜ì—¬ ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„±
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS enhanced_prediction_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    enhanced_prediction_results TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
                )
            ''')
            
            # Enhanced Prediction Results ì‚½ì…
            cursor.execute('''
                INSERT INTO enhanced_prediction_results (session_id, enhanced_prediction_results)
                VALUES (?, ?)
            ''', (session_id, combined_enhanced_results))
            
            conn.commit()
            conn.close()
            return True
        
        return False
        
    except Exception as e:
        st.error(f"Error saving enhanced prediction results: {str(e)}")
        return False

def save_t_removed_reconstructed_results(reconstructed_zones, session_id):
    """T-Removed Reconstructed Gridì˜ Session Prediction Resultsë¥¼ ë³„ë„ í…Œì´ë¸”ì— ì €ì¥"""
    if not reconstructed_zones:
        return False
    
    try:
        # Session Prediction Results ìˆ˜ì§‘ (T-Removed Reconstructedìš©)
        all_prediction_results = []
        sorted_zones_results = sorted(reconstructed_zones, key=lambda x: x['start_x'])
        
        for zone in sorted_zones_results:
            pattern1_2, pattern1_2_3, prediction1_2, prediction1_2_3, comparison1_2, comparison1_2_3, sequence_type_12, pattern1_2_combined, pattern1_2_3_combined, pattern3_4_combined, source1_2, source1_2_3, sequence_type_123 = get_pattern_results_for_reconstructed(zone)
            if comparison1_2:
                all_prediction_results.append(comparison1_2.upper())
            if comparison1_2_3:
                all_prediction_results.append(comparison1_2_3.upper())
        
        if all_prediction_results:
            combined_results = ''.join(all_prediction_results)
            
            # ìƒˆë¡œìš´ ë…ë¦½ì ì¸ í…Œì´ë¸”ì— ì €ì¥
            db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS t_removed_reconstructed_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    prediction_results TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours'))
                )
            ''')
            
            # T-Removed Reconstructed ê²°ê³¼ ì‚½ì…
            cursor.execute('''
                INSERT INTO t_removed_reconstructed_results (session_id, prediction_results)
                VALUES (?, ?)
            ''', (session_id, combined_results))
            
            conn.commit()
            conn.close()
            return True
        
        return False
        
    except Exception as e:
        st.error(f"Error saving T-Removed Reconstructed results: {str(e)}")
        return False

def get_pattern_sequence_prediction(first_pattern, sequence_type, fifth_value):
    """pattern_sequence_prediction í…Œì´ë¸”ì—ì„œ ì˜ˆì¸¡ê°’ ì¡°íšŒ"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT occurrence_count, probability
            FROM pattern_sequence_prediction 
            WHERE first_pattern = ? AND sequence_type = ? AND fifth_value = ?
        """, (first_pattern, sequence_type, fifth_value))
        
        result = cursor.fetchone()
        if result:
            occurrence_count, probability = result
            return True, occurrence_count, probability
        return False, 0, 0
        
    except Exception as e:
        st.error(f"íŒ¨í„´ ì‹œí€€ìŠ¤ ì˜ˆì¸¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return False, 0, 0
    finally:
        if conn:
            conn.close()

def get_best_prediction_from_sequence_table(first_pattern, sequence_type):
    """í•´ë‹¹ íŒ¨í„´ê³¼ ì‹œí€€ìŠ¤ íƒ€ì…ì—ì„œ ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ 5ë²ˆì§¸ ê°’ ì˜ˆì¸¡"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT fifth_value, occurrence_count, probability, high_probability_gap
            FROM pattern_sequence_prediction 
            WHERE first_pattern = ? AND sequence_type = ?
            ORDER BY probability DESC
            LIMIT 1
        """, (first_pattern, sequence_type))
        
        result = cursor.fetchone()
        if result:
            fifth_value, occurrence_count, probability, high_probability_gap = result
            return fifth_value, True, occurrence_count, probability, high_probability_gap
        return '', False, 0, 0, 0
        
    except Exception as e:
        st.error(f"ìµœì  ì˜ˆì¸¡ê°’ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return '', False, 0, 0, 0
    finally:
        if conn:
            conn.close()

def get_zone_pattern_sequence_results(zone):
    """ìƒˆë¡œìš´ êµ¬í˜„: Pattern 1ê³¼ Pattern 2 ê°ê° ë³„ê°œë¡œ ì˜ˆì¸¡ ë¹„êµ"""
    try:
        # 1. ê·¸ë£¹ì˜ pattern1ê³¼ pattern2 number ì¶”ì¶œ
        patterns = get_pattern_positions()
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) < 4:
            return '', '', '', '', '', '', '', '', '', '', '', '', ''
        
        # íŒ¨í„´ ê°’ ì¶”ì¶œ
        pattern_values = []
        for pattern in group_patterns[:4]:
            values = []
            for x, y in pattern['coordinates']:
                relative_x = x - zone['start_x']
                value = zone['zone_data'][relative_x][y]
                if value:
                    values.append(value.upper())
            pattern_values.append(values)
        
        # íŒ¨í„´ ë²ˆí˜¸ ì¶”ì¶œ
        pattern_numbers = []
        for v in pattern_values[:4]:
            pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
            pattern_numbers.append(pattern_number if pattern_number is not None else '-')
        
        # Pattern 1, Pattern 2 ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
        pattern1_number = pattern_numbers[0] if pattern_numbers[0] != '-' else ''
        pattern2_number = pattern_numbers[1] if len(pattern_numbers) > 1 and pattern_numbers[1] != '-' else ''
        
        # Pattern ë²ˆí˜¸ë¥¼ 2ìë¦¬ë¡œ í¬ë§· (pattern_sequence_prediction í…Œì´ë¸” ì¡°íšŒìš©)
        def format_pattern_number(pattern_num):
            if pattern_num and len(pattern_num) > 2:
                return pattern_num[:2]
            elif pattern_num and len(pattern_num) == 1:
                return '0' + pattern_num
            else:
                return pattern_num
        
        pattern1_formatted = format_pattern_number(pattern1_number)
        pattern2_formatted = format_pattern_number(pattern2_number)
        
        # ì‹¤ì œ ê²°ê³¼ ì¶”ì¶œ
        pattern1_actual_result = zone['zone_data'][2][1] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 1 else ''
        pattern2_actual_result = zone['zone_data'][2][4] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 4 else ''
        
        # ì‹œí€€ìŠ¤ íƒ€ì… ê²°ì • (ì‹¤ì œ ê²°ê³¼ë³´ë‹¤ í•œ ì¹¸ ìœ„ì˜ ê°’ìœ¼ë¡œ ê²°ì •)
        pattern1_sequence_value = zone['zone_data'][2][0] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 0 else ''
        pattern2_sequence_value = zone['zone_data'][2][3] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 3 else ''
        
        # ê° íŒ¨í„´ë³„ë¡œ ë…ë¦½ì ì¸ ì‹œí€€ìŠ¤ íƒ€ì… ê²°ì •
        sequence_type1 = 'P_Sequence' if pattern1_sequence_value.upper() == 'P' else 'B_Sequence' if pattern1_sequence_value.upper() == 'B' else ''
        sequence_type2 = 'P_Sequence' if pattern2_sequence_value.upper() == 'P' else 'B_Sequence' if pattern2_sequence_value.upper() == 'B' else ''
        
        # Pattern 1 ì˜ˆì¸¡ ë° ë¹„êµ
        pattern1_prediction = ''
        pattern1_comparison = ''
        pattern1_gap_tf = ''
        if pattern1_formatted and sequence_type1:
            predicted_value, found, _, _, gap = get_best_prediction_from_sequence_table(pattern1_formatted, sequence_type1)
            if found:
                pattern1_prediction = predicted_value
                pattern1_gap_tf = 'T' if gap > 0 else 'F'
                if pattern1_actual_result:
                    pattern1_comparison = 'W' if pattern1_actual_result.upper() == predicted_value.upper() else 'L'
        
        # Pattern 2 ì˜ˆì¸¡ ë° ë¹„êµ
        pattern2_prediction = ''
        pattern2_comparison = ''
        pattern2_gap_tf = ''
        if pattern2_formatted and sequence_type2:
            predicted_value, found, _, _, gap = get_best_prediction_from_sequence_table(pattern2_formatted, sequence_type2)
            if found:
                pattern2_prediction = predicted_value
                pattern2_gap_tf = 'T' if gap > 0 else 'F'
                if pattern2_actual_result:
                    pattern2_comparison = 'W' if pattern2_actual_result.upper() == predicted_value.upper() else 'L'
        
        # ë””ë²„ê¹…ìš© ëª¨ë“  íŒ¨í„´ ì •ë³´
        all_pattern_info = f"P1:{pattern_numbers[0]},P2:{pattern_numbers[1]},P3:{pattern_numbers[2]},P4:{pattern_numbers[3] if len(pattern_numbers) > 3 else '-'}"
        
        return (pattern1_actual_result, pattern2_actual_result, pattern1_formatted, pattern2_formatted, 
                sequence_type1, sequence_type2, pattern1_prediction, pattern2_prediction, pattern1_comparison, 
                pattern2_comparison, all_pattern_info, pattern1_gap_tf, pattern2_gap_tf)
        
    except Exception as e:
        return '', '', '', '', '', '', '', '', '', '', '', '', ''

def generate_sequence_prediction_results(zones):
    """ìƒˆë¡œìš´ êµ¬í˜„: Pattern 1ê³¼ Pattern 2 ê°ê°ì˜ W,L ê²°ê³¼ë¥¼ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì—°ê²°"""
    try:
        # 4. 1-3 ë™ì‘ì„ ëª¨ë“  ê·¸ë£¹ì´ ëë‚ ë•Œê¹Œì§€ ë°˜ë³µ
        # Zoneì„ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì •ë ¬
        sorted_zones = sorted(zones, key=lambda x: x['start_x'])
        
        all_wl_results = []  # W, L ê²°ê³¼ë§Œ ì €ì¥ (Pattern 1, Pattern 2 ìˆœì„œ)
        
        for i, zone in enumerate(sorted_zones):
            # ê° ê·¸ë£¹ì— ëŒ€í•´ Pattern 1ê³¼ Pattern 2 ë³„ê°œë¡œ ì²˜ë¦¬
            (pattern1_actual_result, pattern2_actual_result, pattern1_formatted, pattern2_formatted, 
             sequence_type1, sequence_type2, pattern1_prediction, pattern2_prediction, pattern1_comparison, 
             pattern2_comparison, all_pattern_info, pattern1_gap_tf, pattern2_gap_tf) = get_zone_pattern_sequence_results(zone)
            
            # ê° ê·¸ë£¹ë§ˆë‹¤ 2ê°œì˜ ê²°ê³¼ ìˆ˜ì§‘ (Pattern 1, Pattern 2)
            if pattern1_comparison in ['W', 'L']:
                all_wl_results.append(pattern1_comparison)
            if pattern2_comparison in ['W', 'L']:
                all_wl_results.append(pattern2_comparison)
        
        
        # 5. W, L ê²°ê³¼ë¥¼ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì—°ê²°
        combined_results = ''.join(all_wl_results)
        return combined_results
        
    except Exception as e:
        st.error(f"ì‹œí€€ìŠ¤ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return ''

def get_zone_pattern_sequence_results_for_reconstructed(zone):
    """T-Removed Reconstructed Grid ì „ìš©: Pattern 1ê³¼ Pattern 2 ê°ê° ë³„ê°œë¡œ ì˜ˆì¸¡ ë¹„êµ"""
    try:
        # 1. ê·¸ë£¹ì˜ pattern1ê³¼ pattern2 number ì¶”ì¶œ
        patterns = get_pattern_positions()
        group_patterns = [p for p in patterns if p['columns'][0] >= zone['start_x'] and p['columns'][1] <= zone['end_x']]
        
        if len(group_patterns) < 4:
            return '', '', '', '', '', '', '', '', '', '', '', '', ''
        
        # íŒ¨í„´ ê°’ ì¶”ì¶œ
        pattern_values = []
        for pattern in group_patterns[:4]:
            values = []
            for x, y in pattern['coordinates']:
                relative_x = x - zone['start_x']
                value = zone['zone_data'][relative_x][y]
                if value:
                    values.append(value.upper())
            pattern_values.append(values)
        
        # íŒ¨í„´ ë²ˆí˜¸ ì¶”ì¶œ
        pattern_numbers = []
        for v in pattern_values[:4]:
            pattern_number = find_pattern_number_only([x.lower() for x in v]) if v else None
            pattern_numbers.append(pattern_number if pattern_number is not None else '-')
        
        # Pattern 1, Pattern 2 ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
        pattern1_number = pattern_numbers[0] if pattern_numbers[0] != '-' else ''
        pattern2_number = pattern_numbers[1] if len(pattern_numbers) > 1 and pattern_numbers[1] != '-' else ''
        
        # Pattern ë²ˆí˜¸ë¥¼ 2ìë¦¬ë¡œ í¬ë§· (pattern_sequence_prediction í…Œì´ë¸” ì¡°íšŒìš©)
        def format_pattern_number(pattern_num):
            if pattern_num and len(pattern_num) > 2:
                return pattern_num[:2]
            elif pattern_num and len(pattern_num) == 1:
                return '0' + pattern_num
            else:
                return pattern_num
        
        pattern1_formatted = format_pattern_number(pattern1_number)
        pattern2_formatted = format_pattern_number(pattern2_number)
        
        # ì‹¤ì œ ê²°ê³¼ ì¶”ì¶œ (T-Removed Reconstructed Gridì™€ ë™ì¼í•œ ìœ„ì¹˜ ì‚¬ìš©)
        pattern1_actual_result = zone['zone_data'][2][1] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 1 else ''
        pattern2_actual_result = zone['zone_data'][2][4] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 4 else ''
        
        # ì‹œí€€ìŠ¤ íƒ€ì… ê²°ì • (ì‹¤ì œ ê²°ê³¼ë³´ë‹¤ í•œ ì¹¸ ìœ„ì˜ ê°’ìœ¼ë¡œ ê²°ì •)
        pattern1_sequence_value = zone['zone_data'][2][0] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 0 else ''
        pattern2_sequence_value = zone['zone_data'][2][3] if len(zone['zone_data']) > 2 and len(zone['zone_data'][2]) > 3 else ''
        
        # ê° íŒ¨í„´ë³„ë¡œ ë…ë¦½ì ì¸ ì‹œí€€ìŠ¤ íƒ€ì… ê²°ì •
        sequence_type1 = 'P_Sequence' if pattern1_sequence_value.upper() == 'P' else 'B_Sequence' if pattern1_sequence_value.upper() == 'B' else ''
        sequence_type2 = 'P_Sequence' if pattern2_sequence_value.upper() == 'P' else 'B_Sequence' if pattern2_sequence_value.upper() == 'B' else ''
        
        # Pattern 1 ì˜ˆì¸¡ ë° ë¹„êµ
        pattern1_prediction = ''
        pattern1_comparison = ''
        pattern1_gap_tf = ''
        if pattern1_formatted and sequence_type1:
            predicted_value, found, _, _, gap = get_best_prediction_from_sequence_table(pattern1_formatted, sequence_type1)
            if found:
                pattern1_prediction = predicted_value
                pattern1_gap_tf = 'T' if gap > 0 else 'F'
                if pattern1_actual_result:
                    pattern1_comparison = 'W' if pattern1_actual_result.upper() == predicted_value.upper() else 'L'
        
        # Pattern 2 ì˜ˆì¸¡ ë° ë¹„êµ
        pattern2_prediction = ''
        pattern2_comparison = ''
        pattern2_gap_tf = ''
        if pattern2_formatted and sequence_type2:
            predicted_value, found, _, _, gap = get_best_prediction_from_sequence_table(pattern2_formatted, sequence_type2)
            if found:
                pattern2_prediction = predicted_value
                pattern2_gap_tf = 'T' if gap > 0 else 'F'
                if pattern2_actual_result:
                    pattern2_comparison = 'W' if pattern2_actual_result.upper() == predicted_value.upper() else 'L'
        
        # ë””ë²„ê¹…ìš© ëª¨ë“  íŒ¨í„´ ì •ë³´
        all_pattern_info = f"P1:{pattern_numbers[0]},P2:{pattern_numbers[1]},P3:{pattern_numbers[2]},P4:{pattern_numbers[3] if len(pattern_numbers) > 3 else '-'}"
        
        return (pattern1_actual_result, pattern2_actual_result, pattern1_formatted, pattern2_formatted, 
                sequence_type1, sequence_type2, pattern1_prediction, pattern2_prediction, pattern1_comparison, 
                pattern2_comparison, all_pattern_info, pattern1_gap_tf, pattern2_gap_tf)
        
    except Exception as e:
        return '', '', '', '', '', '', '', '', '', '', '', '', ''

def generate_sequence_prediction_results_for_reconstructed(zones):
    """T-Removed Reconstructed Grid ì „ìš©: Pattern 1ê³¼ Pattern 2 ê°ê°ì˜ W,L ê²°ê³¼ë¥¼ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì—°ê²°"""
    try:
        # Zoneì„ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì •ë ¬
        sorted_zones = sorted(zones, key=lambda x: x['start_x'])
        
        all_wl_results = []  # W, L ê²°ê³¼ë§Œ ì €ì¥ (Pattern 1, Pattern 2 ìˆœì„œ)
        
        for i, zone in enumerate(sorted_zones):
            # ê° ê·¸ë£¹ì— ëŒ€í•´ Pattern 1ê³¼ Pattern 2 ë³„ê°œë¡œ ì²˜ë¦¬
            (pattern1_actual_result, pattern2_actual_result, pattern1_formatted, pattern2_formatted, 
             sequence_type1, sequence_type2, pattern1_prediction, pattern2_prediction, pattern1_comparison, 
             pattern2_comparison, all_pattern_info, pattern1_gap_tf, pattern2_gap_tf) = get_zone_pattern_sequence_results_for_reconstructed(zone)
            
            # ê° ê·¸ë£¹ë§ˆë‹¤ 2ê°œì˜ ê²°ê³¼ ìˆ˜ì§‘ (Pattern 1, Pattern 2)
            if pattern1_comparison in ['W', 'L']:
                all_wl_results.append(pattern1_comparison)
            if pattern2_comparison in ['W', 'L']:
                all_wl_results.append(pattern2_comparison)
        
        # 5. W, L ê²°ê³¼ë¥¼ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì—°ê²°
        combined_results = ''.join(all_wl_results)
        return combined_results
        
    except Exception as e:
        st.error(f"T-Removed Reconstructed ì‹œí€€ìŠ¤ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return ''

def generate_high_probability_gap_results_for_reconstructed(zones):
    """T-Removed Reconstructed Grid ì „ìš©: high_probability_gap ê°’ì„ T/Fë¡œ í‘œì‹œ"""
    try:
        # Zoneì„ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì •ë ¬
        sorted_zones = sorted(zones, key=lambda x: x['start_x'])
        
        all_gap_results = []  # T, F ê²°ê³¼ë§Œ ì €ì¥ (Pattern 1, Pattern 2 ìˆœì„œ)
        
        for i, zone in enumerate(sorted_zones):
            # ê° ê·¸ë£¹ì— ëŒ€í•´ Pattern 1ê³¼ Pattern 2 ë³„ê°œë¡œ ì²˜ë¦¬
            (pattern1_actual_result, pattern2_actual_result, pattern1_formatted, pattern2_formatted, 
             sequence_type1, sequence_type2, pattern1_prediction, pattern2_prediction, pattern1_comparison, 
             pattern2_comparison, all_pattern_info, pattern1_gap_tf, pattern2_gap_tf) = get_zone_pattern_sequence_results_for_reconstructed(zone)
            
            # ê° ê·¸ë£¹ë§ˆë‹¤ 2ê°œì˜ gap ê²°ê³¼ ìˆ˜ì§‘ (Pattern 1, Pattern 2)
            if pattern1_gap_tf in ['T', 'F']:
                all_gap_results.append(pattern1_gap_tf)
            if pattern2_gap_tf in ['T', 'F']:
                all_gap_results.append(pattern2_gap_tf)
        
        # T, F ê²°ê³¼ë¥¼ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì—°ê²°
        combined_gap_results = ''.join(all_gap_results)
        return combined_gap_results
        
    except Exception as e:
        st.error(f"T-Removed Reconstructed high_probability_gap ê²°ê³¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return ''

def generate_high_probability_gap_comparison_results_for_reconstructed(zones):
    """T-Removed Reconstructed Grid ì „ìš©: High Probability Gap Resultsì™€ Sequence Prediction Results ë¹„êµí•˜ì—¬ P/F í‘œì‹œ"""
    try:
        # Zoneì„ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì •ë ¬
        sorted_zones = sorted(zones, key=lambda x: x['start_x'])
        
        all_gap_results = []  # T, F ê²°ê³¼ë§Œ ì €ì¥ (Pattern 1, Pattern 2 ìˆœì„œ)
        all_sequence_results = []  # W, L ê²°ê³¼ë§Œ ì €ì¥ (Pattern 1, Pattern 2 ìˆœì„œ)
        
        for i, zone in enumerate(sorted_zones):
            # ê° ê·¸ë£¹ì— ëŒ€í•´ Pattern 1ê³¼ Pattern 2 ë³„ê°œë¡œ ì²˜ë¦¬
            (pattern1_actual_result, pattern2_actual_result, pattern1_formatted, pattern2_formatted, 
             sequence_type1, sequence_type2, pattern1_prediction, pattern2_prediction, pattern1_comparison, 
             pattern2_comparison, all_pattern_info, pattern1_gap_tf, pattern2_gap_tf) = get_zone_pattern_sequence_results_for_reconstructed(zone)
            
            # ê° ê·¸ë£¹ë§ˆë‹¤ 2ê°œì˜ gap ê²°ê³¼ ìˆ˜ì§‘ (Pattern 1, Pattern 2)
            if pattern1_gap_tf in ['T', 'F']:
                all_gap_results.append(pattern1_gap_tf)
            if pattern2_gap_tf in ['T', 'F']:
                all_gap_results.append(pattern2_gap_tf)
            
            # ê° ê·¸ë£¹ë§ˆë‹¤ 2ê°œì˜ sequence ê²°ê³¼ ìˆ˜ì§‘ (Pattern 1, Pattern 2)
            if pattern1_comparison in ['W', 'L']:
                all_sequence_results.append(pattern1_comparison)
            if pattern2_comparison in ['W', 'L']:
                all_sequence_results.append(pattern2_comparison)
        
        # ë¹„êµ ê²°ê³¼ ìƒì„±
        comparison_results = []
        min_length = min(len(all_gap_results), len(all_sequence_results))
        
        for i in range(min_length):
            gap_value = all_gap_results[i]
            sequence_value = all_sequence_results[i]
            
            if gap_value == 'F':
                comparison_results.append('X')
            elif gap_value == 'T':
                if sequence_value == 'W':
                    comparison_results.append('P')
                elif sequence_value == 'L':
                    comparison_results.append('F')
                else:
                    comparison_results.append('X')  # sequence ê°’ì´ ì—†ëŠ” ê²½ìš°
            else:
                comparison_results.append('X')  # gap ê°’ì´ ì—†ëŠ” ê²½ìš°
        
        # ë¹„êµ ê²°ê³¼ë¥¼ ì™¼ìª½â†’ì˜¤ë¥¸ìª½ ìˆœì„œë¡œ ì—°ê²°
        combined_comparison_results = ''.join(comparison_results)
        return combined_comparison_results
        
    except Exception as e:
        st.error(f"T-Removed Reconstructed high_probability_gap ë¹„êµ ê²°ê³¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return ''

def save_t_removed_reconstructed_prediction_results(reconstructed_zones, session_id):
    """T-Removed Reconstructed Gridì˜ Sequence Prediction Resultsì™€ High Probability Gap Resultsë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì €ì¥"""
    if not reconstructed_zones:
        return False
    
    try:
        # 1. Sequence Prediction Results ìƒì„±
        sequence_prediction_results = generate_sequence_prediction_results_for_reconstructed(reconstructed_zones)
        
        # 2. High Probability Gap Results ìƒì„±
        high_probability_gap_results = generate_high_probability_gap_results_for_reconstructed(reconstructed_zones)
        
        # 3. High Probability Gap Comparison Results ìƒì„±
        high_probability_gap_comparison_results = generate_high_probability_gap_comparison_results_for_reconstructed(reconstructed_zones)
        
        # 4. ë‘˜ ë‹¤ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ ì €ì¥
        if sequence_prediction_results and high_probability_gap_results:
            db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS t_removed_reconstructed_prediction_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    sequence_prediction_results TEXT NOT NULL,
                    high_probability_gap_results TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT (datetime('now', '+9 hours')),
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ì¸ë±ìŠ¤ ìƒì„± (ì—†ìœ¼ë©´)
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_t_removed_reconstructed_session_id 
                ON t_removed_reconstructed_prediction_results(session_id)
            ''')
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_t_removed_reconstructed_created_at 
                ON t_removed_reconstructed_prediction_results(created_at DESC)
            ''')
            
            # ê²°ê³¼ ì‚½ì…
            cursor.execute('''
                INSERT INTO t_removed_reconstructed_prediction_results 
                (session_id, sequence_prediction_results, high_probability_gap_results, high_probability_gap_comparison_results)
                VALUES (?, ?, ?, ?)
            ''', (session_id, sequence_prediction_results, high_probability_gap_results, high_probability_gap_comparison_results))
            
            conn.commit()
            conn.close()
            return True
        
        return False
        
    except Exception as e:
        st.error(f"Error saving T-Removed Reconstructed prediction results: {str(e)}")
        return False

def cleanup_duplicate_data():
    """ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ í•¨ìˆ˜ - 1ë¶„ ì´ë‚´ ìƒì„±ëœ ì¤‘ë³µ ë°ì´í„° ì œê±°"""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'pattern_analysis_v4.db')
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # 1. ë°±ì—… ìƒì„±
        cursor.execute("CREATE TABLE IF NOT EXISTS pattern_analysis_backup AS SELECT * FROM pattern_analysis")
        cursor.execute("CREATE TABLE IF NOT EXISTS session_prediction_results_backup AS SELECT * FROM session_prediction_results")
        cursor.execute("CREATE TABLE IF NOT EXISTS enhanced_prediction_results_backup AS SELECT * FROM enhanced_prediction_results")
        
        # 2. ì¤‘ë³µ ë°ì´í„° ì‹ë³„ ë° ì‚­ì œ
        cursor.execute("""
            WITH duplicates AS (
                SELECT prediction_results
                FROM session_prediction_results 
                WHERE created_at >= datetime('now', '-1 minute')
                GROUP BY prediction_results 
                HAVING COUNT(*) > 1
            ),
            to_delete AS (
                SELECT session_id
                FROM session_prediction_results spr
                INNER JOIN duplicates d ON spr.prediction_results = d.prediction_results
                WHERE session_id NOT IN (
                    SELECT session_id
                    FROM (
                        SELECT session_id,
                               ROW_NUMBER() OVER (
                                   PARTITION BY prediction_results 
                                   ORDER BY created_at DESC
                               ) as rn
                        FROM session_prediction_results
                        WHERE prediction_results IN (SELECT prediction_results FROM duplicates)
                    ) ranked
                    WHERE rn = 1
                )
            )
            DELETE FROM session_prediction_results WHERE session_id IN (SELECT session_id FROM to_delete)
        """)
        
        # 3. pattern_analysis í…Œì´ë¸”ì—ì„œ ì¤‘ë³µ ì œê±°
        cursor.execute("""
            DELETE FROM pattern_analysis 
            WHERE session_id NOT IN (SELECT session_id FROM session_prediction_results)
        """)
        
        # 4. enhanced_prediction_results í…Œì´ë¸”ì—ì„œ ì¤‘ë³µ ì œê±°
        cursor.execute("""
            DELETE FROM enhanced_prediction_results 
            WHERE session_id NOT IN (SELECT session_id FROM session_prediction_results)
        """)
        
        conn.commit()
        
        # 5. ì •ë¦¬ ê²°ê³¼ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM pattern_analysis")
        pattern_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM session_prediction_results")
        session_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM enhanced_prediction_results")
        enhanced_count = cursor.fetchone()[0]
        
        return {
            'success': True,
            'pattern_analysis_count': pattern_count,
            'session_prediction_results_count': session_count,
            'enhanced_prediction_results_count': enhanced_count
        }
        
    except Exception as e:
        st.error(f"ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return {'success': False, 'error': str(e)}
    finally:
        if conn:
            conn.close()


if __name__ == "__main__":
    main() 